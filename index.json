[{"content":"1. 독서 기간 일반 서적 2025-01-04 ~ 2025-01-05 2. 도서 분류 서명 완독 여부 일반 소년이 온다 v 3. 기타 동문 예술 거리의 홍지 서림에서 구매. 괜히 노벨 문학상을 받은게 아니다\u0026hellip;\n각 장마다 다른 화자가 이야기하는 구성인데 각 갈래들이 이어지는 과정에서 정확하게 전달되는 표현들이, 감정들이\n읽는 내내 먹먹하게 했다.\n5.18 에 대해 다룬 많은 책들과 영화들이 계엄군의 잔혹함에 대한 기억을 남겨 왔다면\n이번 한강의 책은 그때의 광주시민들의 가슴에 생긴 상처들과 상흔들을 문학적으로 승화시켰다.\n지금 정미 누나가 갑자기 대문을 열고 들어온다면 달려나가 무릎을 꿇을 텐데. 같이 도청 앞으로 가서 정대를 찾자고 할텐데. 그러고도 네가 친구냐. 그러고도 네가 사람이야. 정미 누나가 나를 때리는 대로 얻어맞을 텐데. 얻어맞으면서 용서를 빌 텐데. (p36)\n인간은 무엇인가. 인간이 무엇이지 않기 위해 우리는 무엇을 해야 하는가. (p99)\n군인들이 압도적으로 강하다는 걸 모르지 않았습니다. 다만 이상한 건, 그들의 힘만큼이나 강렬한 무엇인가가 나를 압도하고 있었다는 겁니다. 양심. 그래요, 양심. 세상에서 제일 무서운 게 그겁니다. (p114)\n네가 나한테 한번 와 준 것인디. 지나가는 모습이라도 한번 보여줄라고 온것인디. 늙은 내가 너를 놓쳐버렸어야. (p179)\n나는 광주에서 나고 자라면서 5.18에 대해 어렸을 적부터 배우고 자라왔다.\n성인이 되면서 상경했는데, 동료가 5.18 자체를 모르는 것을 보고 적잖이 놀랐던 기억이 난다.\n한강 작가가 이야기하는 것처럼\n이 책이 그때의 광주를, 상처를. 많은 사람들이 기억할 수 있도록 해주었으면 한다.\n","permalink":"https://nolleh.github.io/reading-log/2025-01-04/","summary":"1. 독서 기간 일반 서적 2025-01-04 ~ 2025-01-05 2. 도서 분류 서명 완독 여부 일반 소년이 온다 v 3. 기타 동문 예술 거리의 홍지 서림에서 구매. 괜히 노벨 문학상을 받은게 아니다\u0026hellip;\n각 장마다 다른 화자가 이야기하는 구성인데 각 갈래들이 이어지는 과정에서 정확하게 전달되는 표현들이, 감정들이\n읽는 내내 먹먹하게 했다.\n5.18 에 대해 다룬 많은 책들과 영화들이 계엄군의 잔혹함에 대한 기억을 남겨 왔다면\n이번 한강의 책은 그때의 광주시민들의 가슴에 생긴 상처들과 상흔들을 문학적으로 승화시켰다.","title":"2025 01 04"},{"content":"1. 독서기간 일반 서적 2024-12-10 ~ 2024-12-29 전문 서적 2024-12-10 ~ 2025.ING 2. 도서 분류 서명 완독 여부 일반 봉제 인형 살인사건 v 전문(번역) Essential Math for Data Science ING 전문(원서) Designing Data-Intensive Applications ING 3. 기타 새회사 입사 날짜 잡아두고 휴가/퇴사 기간을 보내고 있다. :) 이직을 해야만 쉴 수 있구나\u0026hellip; 라는 생각에 슬퍼하며, 이번에 쉬는중의 몇가지 목표중 하나, 다 읽어야 겠다 싶은 원서 구매차, 오랜만에 (일반) 책을 (충동)구매.\n영국 드라마화까지 된 소설 봉제 인형 살인사건. 4가지 시리즈중 그 첫번째 장이다.\n한 50~ 100p 즈음부터 흡입력이 생겨서 후루룩 읽다가 어쩐지 시들해져서, 조금 시간이 걸렸다. 약간 예측가능한 흔한 반전이 있었지만, 어쨌든 타임킬링으로 읽기 나쁘지 않았다.\n달리 구매한 전문서적들도 모두 만족스럽다. 수학책은 이해하기 쉽게 작성된 이론들과 바로 실행해볼 수 있는 코드 조각들,\n그리고 함께 첨부된 흥미로운 사례들이 쉽고 재밌게 수학을 배울수 있게 해준다. 미적분, 극한등의 고등 수학 수준까지는 상당히 만족스러운데,\n통계부분부터 뭔가 설명이 조금 부족한채로 공식을 나열하는 형태가 되어버리는것 같아서 내가 완벽히 이해하고 있는게 아닌것 같은 부분들이 생기는 건 아쉬움.\n예를 들어서 허용오차를 소개하는 부분등에서는 공식만 먼저 소개하고 왜 이런 수식이 나오는지에 대한 설명은 없다거나..\nDesign~ 은 현재 하루 10 ~ 20페이지 보는것을 목표로 꾸준히 읽고 있는데, 내용이 상당히 알차다.\n어떤 주제에 대해 해당 문제를 해결하기 위한 다양한 솔루션들을 다양한 관점에서 자세히 다룬다.\n이 책은 이번 휴식기 동안 1회차 완독하고, 이후 몇달뒤 2회차 돌리면서, 다음에 내가 찾아볼수 있도록 - 블로그에 요점들 다시 정리할 예정.\n","permalink":"https://nolleh.github.io/reading-log/2024-12-10/","summary":"1. 독서기간 일반 서적 2024-12-10 ~ 2024-12-29 전문 서적 2024-12-10 ~ 2025.ING 2. 도서 분류 서명 완독 여부 일반 봉제 인형 살인사건 v 전문(번역) Essential Math for Data Science ING 전문(원서) Designing Data-Intensive Applications ING 3. 기타 새회사 입사 날짜 잡아두고 휴가/퇴사 기간을 보내고 있다. :) 이직을 해야만 쉴 수 있구나\u0026hellip; 라는 생각에 슬퍼하며, 이번에 쉬는중의 몇가지 목표중 하나, 다 읽어야 겠다 싶은 원서 구매차, 오랜만에 (일반) 책을 (충동)구매.\n영국 드라마화까지 된 소설 봉제 인형 살인사건.","title":"2024 12 10"},{"content":"Overview 상당히 광고스러운 제목이지만.. 제목이 좀 정보를 포함했으면 좋겠어서 쓰다보니 그렇게 됐다..\n내 돈 내산으로, PreOrder? Early Bird? 로 주문해두었던 crowview Note 가 주문해놓고 한달 정도 잊고 있었는데, 저번 토요일에 (24.12.07) 도착했다!\n구매하려고 정보 알아봤을때 한국 구매자가 있다는 내용은 보기 어려웠고, 구매도 오로지 공식 사이트에서만 신청 주기 별로 발송하는것 같아 공급수량이 많아 보이진 않았던 거 보면, 아마 한국에서는 최초..?로 구매한 걸 수도 있겠다.\nYoutube 에서 관련영상은 하나 있었던거같고, 해당 영상을 통해 사야겠다 싶어서 구매했던 건데,\n해당 영상이나 공식사이트에서나 어떤 기기나(UMPC, Handheld Game Machine, SmartPhone..) 디스플레이/노트북 환경으로 만들어 주는걸 강조하긴 하지만,\n나한테 제일 매력적이었던 포인트는 사실 싱글보드 컴퓨터를 노트북처럼 만들어주는 부분.\n라즈베리파이 가지고 실제적으로 휴대해서 사용한다고 할 때 싱글보드 컴퓨터라는 특성상 필요한 게 너무 많음.\n컴퓨터/모니터/터치 패드 호환 키보드/전원 어댑터/케이블\u0026hellip; 엄청나게 compact 한 제품이지만, 사실상 휴대는 번거로워서 잘 안하게 된다.\n근데 이 제품이 재밌는게, 브릿지보드를 통해 기기의 배터리로 컴퓨터의 전원공급까지 가능하다.\n위 준비물이 -\u0026gt; 컴퓨터/CrowView Note/브릿지보드 만으로 줄어드는 효과\u0026hellip;\nUnpacking 패키지 외관. 심플하게 잘 나온듯.\n언박싱. 포장재도 제품에 상처 안나게 잘 채워져있다.\nBridge 브릿지 보드 연결하는게 좀 너무 뻑뻑해서 힘주다가 부서지지 않을까 걱정되긴 하지만, 전원 공급도 잘되고, 화면도 깔끔하게 잘 나온다.\nReview 약 1시간정도 웹서핑 및 개발 좀 하고, 1시간 정도 동영상 강의 듣고 하니 배터리 완충 상태에서 60% 정도 남는것보면 공식적으로 소개된 시간 5시간정도 러닝타임 나올것으로 보임. 이정도면 배터리만으로 잠깐 갖고 놀기에는 충분하게 느껴진다.\n단점은 컴퓨터 자체가 가격이 저렴하다보니 상대적으로 크게 느껴지는 가격과 (본체 + 브릿지보드 $155.90, 국제 배송비 $17.39) 한화로 24만원 정도는 들어간다. 컴퓨터를 10만원 내외로 산거다보니 상대적으로 비싸보이지만, 일반 터치스크린 휴대용 모니터가 10~20 내외 인걸 감안하면 기능 생각하면 합리적으로 보임.\n그리고 생각보다 무거움. 메인보드 관련한 기기들이 없으니 좀 가벼워지지 않을까 했는데 보유하고있는 13 맥북프로와 큰 차이가 없다. 1.2kg.\n양손에 하나씩 들어봤는데 맥북이 조금 더 무거운정도? 거의 차이를 모를 정도.\n터치패드는 그렇게 좋은 감도는 아닌거 같긴 한데, 적당히 불편하게 쓰지 않을정도. 어차피 마우스는 별로 안쓰기 때문에 크게 의미가 없긴하다.\n스피커 품질은 음질은 엄청 가리는 편은 아니라서 잘 모르겠지만, 볼륨 자체는 꽤 짱짱하게 나와서 만족스러웠음.\nConclusions 싱글 보드 컴퓨터를 휴대하고 싶은 니즈가 있다면 강력 추천. 여행/캠핑갈때 휴대용 게임기 모니터 대용으로도 활용가능하니, 이 용도로도 나쁘지 않다고 보임.\n종종 본가에 갈 때 방에서 사용할 모니터가 없어서 난감한 내게는 상당히 만족스러운 구매가 됐다.\n","permalink":"https://nolleh.github.io/ubuntu/crowview/","summary":"Overview 상당히 광고스러운 제목이지만.. 제목이 좀 정보를 포함했으면 좋겠어서 쓰다보니 그렇게 됐다..\n내 돈 내산으로, PreOrder? Early Bird? 로 주문해두었던 crowview Note 가 주문해놓고 한달 정도 잊고 있었는데, 저번 토요일에 (24.12.07) 도착했다!\n구매하려고 정보 알아봤을때 한국 구매자가 있다는 내용은 보기 어려웠고, 구매도 오로지 공식 사이트에서만 신청 주기 별로 발송하는것 같아 공급수량이 많아 보이진 않았던 거 보면, 아마 한국에서는 최초..?로 구매한 걸 수도 있겠다.\nYoutube 에서 관련영상은 하나 있었던거같고, 해당 영상을 통해 사야겠다 싶어서 구매했던 건데,","title":"전원 공급까지 한번에, 싱글보드 컴퓨터와 잘 맞는 디스플레이, CrowView Note"},{"content":"1. 대출기간 2024-10-18 ~ 2024-11-XX\n2. 도서 서명 완독 여부 (세상에서 가장 쉬운) 세계사 펼쳐보지도 못함 이솝 우화로 읽는 철학 이야기 상동 3. 기타 \u0026hellip; 이때는 그래도 그렇게 바쁘진 않았을텐데\u0026hellip; 인문학 견문을 좀 넓히면 좋겠다 싶어서 대출한 책인데..\n이 책들은 조만간 다시 도전하려함\u0026hellip;\n","permalink":"https://nolleh.github.io/reading-log/2024-10-18/","summary":"1. 대출기간 2024-10-18 ~ 2024-11-XX\n2. 도서 서명 완독 여부 (세상에서 가장 쉬운) 세계사 펼쳐보지도 못함 이솝 우화로 읽는 철학 이야기 상동 3. 기타 \u0026hellip; 이때는 그래도 그렇게 바쁘진 않았을텐데\u0026hellip; 인문학 견문을 좀 넓히면 좋겠다 싶어서 대출한 책인데..\n이 책들은 조만간 다시 도전하려함\u0026hellip;","title":"2024 10 18"},{"content":"1. 대출기간 2024-08-11 ~ 2024-09-XX\n2. 도서 서명 완독 여부 (세상에서 가장 쉬운) 양자 역학 수업 펼쳐보지도 못함 설득이 필요한 순간 v 3. 기타 한창 바쁠때라.. 일부 책은 펼쳐보지도 못하고 반납\u0026hellip;. 설득이 필요한 순간은 저자의 커리어 내용이 대부분을 차지해서, 정작 보고 알고싶었던 내용은 많이 다루고 있지 않았던것 같아 아쉬움.\n","permalink":"https://nolleh.github.io/reading-log/2024-08-11/","summary":"1. 대출기간 2024-08-11 ~ 2024-09-XX\n2. 도서 서명 완독 여부 (세상에서 가장 쉬운) 양자 역학 수업 펼쳐보지도 못함 설득이 필요한 순간 v 3. 기타 한창 바쁠때라.. 일부 책은 펼쳐보지도 못하고 반납\u0026hellip;. 설득이 필요한 순간은 저자의 커리어 내용이 대부분을 차지해서, 정작 보고 알고싶었던 내용은 많이 다루고 있지 않았던것 같아 아쉬움.","title":"2024 08 11"},{"content":"1. 대출기간 2024-07-28 ~ 2024-08-11\n2. 도서 - [ ] 완독 여부 서명 리더십 게임 너무 재밌어서 잠 못 드는 뇌 과학 아, 그때 그렇게 말 할걸 3. 기타 ","permalink":"https://nolleh.github.io/reading-log/2024-07-28/","summary":"1. 대출기간 2024-07-28 ~ 2024-08-11\n2. 도서 - [ ] 완독 여부 서명 리더십 게임 너무 재밌어서 잠 못 드는 뇌 과학 아, 그때 그렇게 말 할걸 3. 기타 ","title":"2024 07 28"},{"content":"Leadership Game written by 짐 에드워즈\n1. 팀장 1일차를 완벽하게 보내는 법 일은 좀 어때요? | 개인 플레이가 더 이상 통하지 않을 때 | 5명의 법칙 | 첫날 반드시 해야할 일 | 좋은질문이 당신을 리더로 만든다.\n새로 맡은 구성원들과 일대일 면담을 해라. 팀원에게 무엇이 효과가 있는지, 회사가 더 해야 할 일은 무엇인지 물어라. 팀원에게 무엇이 문제인지 어떤 일을 그만둬야 하는지 물어라. 앞으로의 계획에 팀원들의 조언을 활용하겠다고 말해라. 팀원들의 계획을 나의 계획으로 바꿔라. 대면 미팅이든, 메일이든, 팀 회의든 모든 수단을 동원해 팀원들과 주고받는 커뮤니케이션의 양을 늘려라. 5명의 법칙을 명심해라. 부하직원을 5인 이하의 여러팀으로 나눌 수 있다면 그렇게 해라. 3인 팀을 구성할 수 있다면 더더욱 좋다. 3인 팀은 정말 잘 돌아간다. 관리자로 출근하는 첫날, 팀원들에게 점심 식사를 대접해라. 서로 관계도 쌓고 팀원들 간의 이상기류도 원만하게 해결할 수 있다. 2. 평범한 사람이 리더십을 발휘하는 법 솔직함은 언제나 통한다 | 팀원을 지지한다는 것\n리더십은 습관적 행위들의 집합일 뿐이다. 개인의 강렬한 매력으로 불러내는 신비한 기운이 아니다. 헛소리는 금물이다. 팀원들은 명료하고 솔직하게 업무 지시를 해 주기를 원한다. 투명하게 보여 줘라. 팀원들은 당신에게 계획이 있는지, 있다면 그 계획이 무엇인지 알고 싶어 한다. 또한 자신들의 업무가 의미있는 결실을 맺기를 원한다. 미루지 마라. 팀원들은 우리의 결정을 기다린다. 결정은 빨리 내릴수록 좋다. 어려운 결정은 특히 그렇다. 결정을 내리지 않거나 속터질 만큼 느리게 대응하는 것은 형편없는 상사가 되는 지름길이다. 좋은 리더는 시장이나 환경이 불리하게 돌아갈 때 재빨리 전술과 전략을 바꾼다. 지금 변화를 선택해라. 아랫사람들이 하는 일을 지지해라. 그들을 믿고 옹호해라. 직원들이 해결찾고 문제를 해결하고 새로운 아이디어를 생각 해 낼 수 있도록 최대한 자유를 허용해라. 될 때까지 해라. 잊지 말자. 자기가 뭘 하고 있는지 아는 관리자는 아무도 없다. 그저 최선을 다하며 그게 정상인 것처럼 행동해라. 3. 꺼내기 어려운 말을 쉽게 하는 법 넷플릭스 CEO 의 제안을 거절한 대가 | 변화가 아니면 죽음을 달라 | 절대적 아군을 만들어라\n변화는 대대적인 조정이 필요할 만큼 어려운 일이다. 당신이 직원들에게 변화를 요구하면서 \u0026ldquo;이런 새로운 일을 해보세요\u0026rdquo; 라고 말할 때 그 말이 많은 직원에게는 \u0026ldquo;여러분이 지금까지 열심히 해 온 건 내 알 바 아니에요\u0026rdquo; 라는 말로 들린다 변화를 요청받은 직원들은 분노하며 좌절 할 수 있다 이런 반응에 당신이 할 수 있는 일은 도미노 회사처럼 변화의 타당성을 반복해서 들려주고 미래의 계획을 보여 주는 것밖에 없다 시간이 흐르면 저항도 수그러들 것이다 직원들에게 어떤 변화가 따라올지 사실과 다름없이 솔직하게 밝혀야 한다 직원들이 업계의 속성과 변화에 실패할 때 도사리고 있는 위험을 이해할 수 있도록 큰그림을 그리는게 좋다 직원들에게 진실을 말해라 그들이 변화에 질겁하는 것은 도움이 되지 않는다 그래서는 변화에 대처할 수 없다 변화는 성가신 일이지만 생업을 잃는 것보다는 낫다. 4. 무조건 통하는 소통의 법칙 팀원이 업물르 이행하지 않을 때 | 같은 말을 스무 번 해라 | 학습의 원추 이론 | 다시 한번, 5 명의 법칙 | 질적 목표와 양적 ㅂ목표 모두 말해 줘라 | 질문을 진짜로 허용해라.\n늘 커뮤니케이션을 해라 자주 큰 소리로 쉽고 말이다 사람들은 단순하고 명료한 지시를 좋아한다 또 회사가 어떻게 돌아가고 있는지 새로운 소식은 없는지 알고 싶어 한다 팀원들에게 질적 목표와 양적 목표를 모두 말해 줘라 메시지를 전달할 때 모든 채널을 동원해라 사람들은 각자 선호하는 커뮤니케이션 수단이 다르다 메일 직접 대면 사내 메신저, 게시판등 모든 채널을 활용해라 인내심을 가져라 유조선은 한 번에 방향을 틀지 않는다. 팀원들의 말을 자주 들어라 나는 적어도 일주일에 한번 부하직원 들과 면담을 한다 어떤 때는 짧게 15분으로 끝내고 어떤 때 는 1시간 동안 정말 심각한 문제를 파고든다. 그리고 일하는 동안 하루 종일 쉬지 않고 팀원들과 대화를 나눈다 메일과 멧지ㅣ도 무수히 보낸다 이렇게 커뮤니케이션에 공을 들이는 것은 데이브의 불후의 명언을 빌리자면 \u0026ldquo;도대체 일이 어떻게 돌아가고 있는지 모두가 알게 하려는 의도다\u0026rdquo;. 같은 말을 반복한다고 기도가 안 ㅗㅌㅇ하는 건 아니다 팀원들이 당신의 말을 마침내 이해하고 지시에 따르기까지 적어도 번 많게는 스무번까지 반복해서 말해야하 할 수도 있다 어떤 날은 자신이 앵무새가 된 기분이 들 것이다 당신이 전하는 말과 사람들이 받아들이는 말은 다르기 때문에 반복이 필수다. 비밀은 금물이다. 가능한 한 투명하게 공개하려고 노력해라. 모든 일에 고맙다고 말해라 말 그대로 항상 다른 사람들이 하는 일과 그 일에 들인 시간에 고마움을 전해라. 감사하다고 직접 소리 내어 말해라. \u0026quot; 그 일을 해줘서 고마워요 쉽지 않은 일이었는데 놓치지 않고 했네요 정말 수고했어요\u0026quot; 라고 말함으로써 직원들이 느끼는 엄청난 업무 스트레스를 누그러뜨릴 수 있다. 5. 번아웃 없이 생산성 높이는 법 상시 업무 모드의 피해자 | 급한 일과 중요한 일 중 뭐가 더 중요할까? | 우선 순위를 매기게 해라 | 가장 덜 중요한 세 가지 일을 제거해 줘라 | 중요한 일만 할 권리를 줘라 | 에이스의 일을 덜어 줘라\n모든 팀원이 자신의 업무에 우선순위를 정하게 해라. 그리고 가장 중요한 일을 먼저 처리하게 해라 별로 중요하지 않은 일은 끝내지 못해도 괜찮다고 말해라 아무도 신경쓰지 않는다 업무량을 줄이는 것은 우선순위를 정하는 것과 같다 사람들은 모든 일을 다 하려 들다가 번아웃을 겪는다 가장 중요한 일만 하는 게 훨씬 더 중요하다. 모든 팀원의 할 일 목록에서 가장 중요하지 않는 세 가지를 제거해라. 80 대 20 법칙을 기억해라. 우리는 상위 20 퍼센트의 직원에게서 80 퍼센트의 결과를 얻을 것이다. 최고 실적을 올리는 20퍼센트의 팀원에게 시간을 더 투자해라. 하루 중 메일 전송 시간을 제한해라. 공식적인 업무 시간이 시작하기나 끝나고 나서 팀원들에게 메시지를 보내지 않도록 주의해라. 자기 자신이나 팀원들을 위한 우선순위를 정할 때는 수기로 쓴 할 일 목록이 효과적이다. 6. 직접 나서지 않고 팀원의 실적 올리는 법 분석은 구체적으로, 칭찬은 공개적으로 | 모든 실패에는 확실한 이유가 있다 | 대박과 쪽박 기법이 실적을 높인다\n대박과 쪽박 기법을 활용해라. 직원들에게 무엇이, 왜 효과가 있었는지 설명하게 해라. 그리고 나서 무엇이, 왜 실패했는지도 설명하게 해라. 평균 이상의 결과를 내는 요소를 파악한 뒤 거기에 시간을 더 투자해라. 칭찬거리가 보이면 모두가 보고 느낄 수 있도록 칭찬해라. 성공 사례를 활용해 다른 일이나 제품 또는 서비스를 성공시킬 새로운 아이디어를 생각해 내라. 성과가 낮은 업무를 중단해라. 성과가 낮은 업무를 하는 직원들을 평균 이상의 성과를 내는 프로젝트에 투입해라. 직원들을 쪽박 프로젝트에서 대박 프로젝트로 옮기면 시간이 흐르면서 전체 실적이 점점 올라간다. 대박과 쪽박 기업은 신규직원을 채용하거나 직원들의 업무량을 늘리지 않고도 실적이 서서히 올라가게 된다. 7. 우상향 성장 그래프 만드는 법 역사상 가장 훌륭한 관리자가 될 필요는 없다 | 복리 성장을 이루는 법 | 평균보다 약간 더 잘하는 것의 놀라운 힘 | 성공은 누적의 싸움이다 | 인내심을 가져라\n슈퍼스타가 될 필요는 없다. 그저 평균보다 약간 더 잘 하면 된다. 성공은 누적의 싸움이다. 변함없이 꾸준하게 이어지는 성과 개선, 즉 이익이 계속해서 복리가 되는 마법을 알아내는 것은 당신이 관리자로서 얻을 수 있는 가장 강력한 무기다. 매달 실적을 약간씩 더 끌어올려라. 팀의 결과를 매달 끌어올리기 위한 현실적이고 달성 가능한 목표를 세워라. 장시간에 걸쳐 성장해라. 성장은 말 그대로 성장이다. 시간이 흐르면 어느새 당신이 원하는 목적지에 도달해 있을 것이다. 복리 성장을 통해 초대박을 일궈라. 조금씩 꾸준하게 늘려 가는 노력이 시간에 따라 더 큰 이익을 가져온다. 8. 지속할 일과 그만둘 일 결정하는 법 희소성의 가치에는 한계가 있다 | 2018년 노벨경제학상의 교훈 | 실현 가능한 목표의 이점\n사람들은 시간이 지날수록 자기일을 더 잘하게 된다. 그 덕분에 우리는 복리로 늘어나는 성과를 얻을 수 있다. 참신한 아이디어는 공짜인 데다 확실하고 지속적인 가치를 창출 한다. 대박과 쪽박 기법은 최선의 아이디어에 중점을 두고 전략을 짜도록 돕는다. 오랜 내공과 참신한 아이디어라는 바람은 당신에게 유리하게 작용한다. 9. 객관적인 데이터를 바탕으로 평가하는 법 데이터는 측정 가능해야한다 | 데이터에 잠식되지 않도록 주의해라\n개인적 경험에 의존한 관리를 자제해라. 개인적인 인상이나 느낌 관계에 의존해 직원들을 판단하지 마라. 직원의 아부성 발언 같은 주관적 요소에 근거해 결정을 내리는 것을 삼가라. 업무는 인기 콘테스트가 아니라 일의 완수 여부를 따지는 콘테스트다. 직원이 가까이 앉아 있느냐 멀리 떨어져 앉아 있느냐 같은 사소한 요소조차 당신이 잘못 된 결정을 하도록 인도할 수 있다. 직원들에게 분명하고 측정 가능한 목표를 제시하고 객관적인 성과 데이터를 수집함으로써 그들을 공정하고 객관적으로 대우해라. 데이터는 구체적이고 측정 가능하며 확인 할 수 있어야한다. 팀원들이 당신이 제시한 목표를 기준으로 자신의 성과 데이터를 수집하고 직접 보여주게 해라. 가장 바람직한 데이터는 시각 데이터다. 즉, 도표와 그래프 형태의 데이터를 통해 동향과 약점을 쉽게 파악할 수 있다. 단기적인 월별 향상도가 아니라 장기적인 패턴을 보여 주는 데이터를 만들어라. 10. 의사결정의 오류를 줄이는 법 퀀트의 오류\n데이터가 우리 대신 결정을 내리게 하지 마라. 다른사람들이 생산하는 데이터에 의존하지 마라. 당신은 그들이 실수하고 있지는 않은지, 잘못된 것을 측정하고 있지는 않은지, 결국 우리의 데이터를 오류투만들고 있지는 않은지 알 길이 없다. 그러니 스스로 데이터를 만들고 확인해라. 지나치게 많은 데이터는 과유불급일 수 있다. 가장 많은 결과를 보여주는 핵심 지표에 집중하고 나머지는 무시해라. 퀀트의 오류를 조심해라. 양질의 데이터를 갖는 것과 양질의 데이터에 판단을 적용하는 것은 별개의 문제다. 당신이 해야 할 판단을 데이터에 위탁하지 마라. 판단하는 것은 당신이 할 일이다. 11. 일 잘 맡기는 법 수직 구조 조직도를 사랑하는 이유 | 가능한 많이 위임해라\n조직도는 반드시 필요하다. 사람들은 자신의 위치가 어디인지 알고 싶어 한다. 5명의 법칙을 잊지 마라. 5명이 넘는 팀을 직속으로 감독하기는 쉽지 않다. 5명의 법칙은 관리자들을 감독하는 상금 관리자들에게도 그대로 적용된다. 직속 부하가 6명을 넘어가면 유능한 관리자도 직원들의 문의와 요구에 시간을 완전히 빼앗겨 기계적으로 반응하는 \u0026lsquo;검표원\u0026rsquo;이 될 위험이 있다. 많이 위임해라. 어차피 5명이 넘어가는 팀이라면 다른 선택지도 없다. 직원들은 관리자에게서 체계적인 모습을 기대할 것이다. 당신이 고도로 체계적이고 목표지향적인 사람이 아니라면 그냥 그런사람인척해라. 그게 평소 습관이 될 때까지 그런 사람인 것처럼 행동해라. 12. 성격유형 검사 현명하게 쓰는 법 MBTI 를 활용해선 안되는 이유\n전 세계 수천 개의 기업 인사팀에서 MBTI 검사를 활용해 직장훈련과 커뮤니케이션 방식을 설계한다. 그러나 MBTI 는 직원들과 소통하는 데 큰 도움이 되지 않는다. 그러니 무시하는게 좋다. 이 검사는 추리소설가와 은행원이 개발한 것이다. 두 사람다 정식 심리학 교육을 받지 않았다. MBTI 는 유명 정신분석가 칼 융에게서 영감을 얻은 것이지만 융은 그 견해를 부정했다. MBTI 는 실제 과학자들의 연구로 틀렸다는 것이 밝혀졌을뿐 아니라 오늘날 최악의 성격유형 검사 중 하나로 여겨진다. MBTI 로 직원들의 성격을 파악했다고 하더라도 관리자의 성공을 좌우하는 것은 직원들의 뇌를 들여다보는 능력보다는 직원들과 효과적으로 소통하는 능력이다. 가능하면 MBTI 를 사용하지 마라! 13. 유능한 사람을 팀원으로 채용하는 법 구직자는 면접 자리에서 무엇이든 말해 준다 | 적극적인 인재 모집의 가장 큰 장점 | 언제나 채용을 1수누이 과제로 삼아라 | 잘못된 채용의 예시 | 판단 기준이 될 수 없는 것 | 다양성이 중요한 실질적 이유\n좋은 사람을 채용하는 것은 당신이 관리자로서 할 수 있는 가장 중요한 활동이다. 언제나 이 일을 최우선순위 과제로 삼아라. 경쟁사에서 일하는 유능한 인재들에게 우리 회사로 스카우드 하고 싶다는 의사를 내비쳐라. 구직 인터뷰를 활용해 경쟁사에 대한 정보를 알아내고 시장에서 우리 회사의 명성을 키워라. 지원자를 인터뷰하면서 우리 회사와 일하고 싶어 할 사람이 또 누가 있을지 알아내라. 구직 인터뷰를 활용해 우리 회사에 공석이 있고 적임자의 연락을 기다리고 있다는 말을 업계에 퍼트려라. 다양성을 염두에 두고 채용해라. 성과는 올라가고 실수는 줄어들 것이다. 14. 나보다 나은 사람 뽑는 법 심사 기준 패키지를 만들어라 | 실무에 탁월한 사람을 뽑아라 | 진짜를 가려내는 방법 | 이런 사람은 놓치지 마라 | 빌런을 걸러 내는 법 | 추천인 요청하기\n역경과 난관을 맞닥뜨렸을 때 나가떨어지지 않은 사람을 채용해라. 모든 지원자에게 요구되는 심사 기준 패키지를 만들어라. 자기 자신보다 이 일을 더 잘하는 사람을 찾아라. 직원을 새로 뽑을 때마다 팀의 평균 능력치를 올려야 한다. 최고의 인재를 모집하려면 다양성을 고려해 채용해라. 수동적으로 채용 공고를 내는 것 만으로는 최고의 인재를 얻을 수 없다. 이번 장에서 상술한 방법을 총동원하여 지원자들에게 공평한 경쟁의 장을 마련해 주고 타고난 운이 아닌, 실제 능력을 부각시켜라. 열성적 인재를 찾아라. 성장현 인재를 찾아라. 적극적인 입사 희망자를 찾아라. 그저 일자리가 필요한 사람은 걸러라. 면접 시 활용할 질문 리스트를 만들어라. 추천인들에게도 비슷한 질문을 해라. 면접을 진행하는 동안 메모해라. 그렇지 않으면 지원자의 장점이 무엇이고 약점이 무엇인지 잊어버릴 것이다. 새로운 직원을 뽑으면 출근 첫날 점심을 대접해 환영받는 분위기를 조성해라. 자신을 반기는 분위기에서 일하는 사람은 같이 일하기도 편하다. 신입 직원의 입장에서도 앞으로 어떤 일을 하면 되는지 좀 더 편안하게 물어볼 수 있는 기회가 된다. 15. 승진카드 활용법 승진기회를 어떻게 얻었는가 ? | 믿고 일을 맡길 수 있는 사람 | 절대 승진 시키면 안 되는 사람 | 직무 수행 능력 부족의 징후들 | 록 스타를 위한 사다리\n다음은 승진자를 고려할 때 눈여겨봐야 할 유형이다. 신뢰할 수 있는 사람 직무 수행 능력이 뛰어난 사람 유난스럽지 않은 사람 생산성이 높은 사람 열성적 인재 성장형 인재 한 번에 잘하는 사람 록 스타를 위한 사다리를 만들어라. 다른 사람을 관리하지 않는 록스타들도 능력을 인정받을 수 있도록 별도의 승진 코스를 만들어라.\n스타 선수들에게 스타라고 말해 주어라. 우리에게 큰 계획이 있고 지금 자리를 굳건히 지키면 보상이 따라올 것이라고 말해라. 우리와 함께할 때 미래가 밝을 것이라고 믿는다면 경쟁사로 이직할 가능낮아진다. (물론, 우리는 우리가 세운 큰 계획을 실행하고 그에 따른 보상을 해주어야한다.)\n16. 상사 관리법 \u0026ldquo;나 대신 이 문제를 어떻게 해결하겠나?\u0026rdquo; | 팀원이 잘한 일을 윗선이 알게 해라. | 양방향 소통의 기본은 보고다\n대부분의 관리자는 지휘 체계 안에 속한다. 따라서 전지전능한 힘 같은 것은 없다. 지휘 체계 위아래를 두루 관리할 필요가 있다. 데이터가 없으면 부하직원들이 하고 있는 일을 파악하기가 생각외로 어려울 수 있다. 팀이 하고 있는 일의 가치를 데이터로 정리해 상부에 전달해라. 직원들도 마참가지로 확인 가능한 데이터와 함께 팀장에게 보고하도록 가르쳐라. 직원들이 자신의 어깨 위 원숭이를 당신에게 맡기게 두지마라. 직원들에게 스스로 문제를 해결할 권한을 줘라. 우선순위 정하기는 교착상태를 해결해 준다. 직원들이 모든 일을 한꺼번에 해결하려고 애쓰지 않도록 당신에게 우선순위를 정해 달라고 요청할 권한을 줘라. 상사에게 일의 우선순위를 정해 달라고 요구할 수 있다는 사실을 직원들이 알아야한다. 17. 미래의 관리자를 알아보는 법 직원 중 한 명을 승진시켜야 한다면 관리자 역할도 잘 해낼 수 있는 자질을 갖춘사람을 찾아야한다. 레벨 4 직원을 찾아라. 이들은 문제가 나타나기 전에 이를 예측하고 해결하려는 사람들이다. 레벨 1 직원은 늘 상사에게 달려가 문제를 해결해 달라고 부탁한다. 레벨 2 직원은 해결책을 찾긴 하지만 여전히 상사가 대신 결정해 주길 바란다. 레벨 3 직원은 상사 대신 문제를 처리한 후 상황을 보고한다. 레벨 4 직원은 문제를 사전에 예측하고 이런 문제가 나타나기 전에 전략을 제시한다. 18. 개인 업무 평가하는 법 효과적인 목표의 세 분류\n관리자는 모든 팀원을 대상으로 분기에 한번씩 공식적인 개인 업무 평가 일정을 잡아야한다. 업무 평가 시에는 직원들이 (숫자로 측정되는) 정량적 목표와 (심사를 통해 평가하는) 정성적 목표를 모두 달성했는지 봐야 한다. 업무 평가 시에는 장기적인 성과를 관찰 할 수 있도록 긴 안목으로 최소 지난 9개월간의 실적을 되짚어 봐야 한다. 업무 평가에는 양질의 데이터가 포함되어야한다. 직원이 얼마나 발전했는지 솔직하고 투명하게 논의해라. 좋은 직원들은 자신이 잘한 일엔 칭찬과 신뢰를 원하지만 결과가 좋지 못한 일엔 지도와 지원 또한 원한다. 업무 평가는 다음분기 목설정하는데 활용해야하 한다. 직원에게 기대하는 목표가 무엇인지 분명하게 기록해라. 각 팀원에게 분기별로 달성할 주요 목표 세 가지를 정해 줘라. 세가지 미만이면 3개월 안에 달성하기가 너무 쉬울 것이고 세가지를 넘어가면 벅차게 느껴질 것이다. 하의상달 방식을 원한다면 직원들에게 회의전에 스스로 자신의 업무평가를 해 보게 해라. 이 방법으로 직원이 자신의 목표 달성도를 현실적으로 생각하고 있는지 알 수 있다. 19. 보상을 위한 협상법 팀원의 임금 인상률 정하는 법 | 나쁜 협상이란 무엇인가 | 충분한 사유가 되려면 | 그래서 어떻게 하란 말인가?\n장기적으로 생각해라. 업계의 실질적인 임금 시세가 얼마인지 파악해라. 성장도를 데이터로 보여 줘라. 평균을 넘어서라. 어려운 일을 반복적으로, 오랫동안 해라. 유난 떨지 마라. 일을 망치면 솔직하게 시인해라. 성공하는 사람들은 더 많은 연봉 제안이 들어오면 으레 수락한다. 20. 일 안하는 팀원 다루는 법 해고하겠다고 협박하지 마라 | 일하지 않는 직원을 처리해라 | 때로는 해고를 결심해야 한다 | 절대 계획 없이 해고하지 마라 | 결단을 위한 체크 리스트\n해고는 관리자에게 최악의 상황이지만 때로는 그렇게 해야 한다. 형편없는 직원을 붙들고 있으면 팀 전체 사기가 떨어진다. 그 직원은 우수한 인재가 들어올 기회를 막고 있다. 절대 계획 없이 해고해서는 안 된다. 다음 중 어느 하나라도 해당되는 직원이 있다면 해고하는 게 좋다. 임무를 받아들이지 않거나 기본적으로 이 회사에서 일하는 걸 못마땅하게 여기는 것 같다. 특별한 이유 없이 지시를 따르지 않는다. 해결하는 일보다 만들어 내는 일이 더 많다. 시키는 일을 꾸준하게 잘하지 못한다. 소란을 일으키기 좋아한다. 불량한 록 스타다. 거짓말이나 속임수, 도둑질을 일삼는다. 21. 밥맛없게 굴지 않으면서 해고하는 법 기습 통보는 금물이다\n해고는 당사자를 포함한 모두가 예상한 수순대로 이뤄져야 한다. 해고 결정은 공정해야하고 실질적이고 입증가능한 결점에 근거해야 한다.. 우리는 해고 결정이 공정하고심사숙고한 결과라는 사실을 입증할 필요가 있다. 그러기 위해서는 계획이 필요하다. 제일 먼저, 서면 경고를 통해 그 직원이 무엇을 잘못하고 있고 그 일에 요구되는 최소한의 기대가 무엇인지 설명해라. 그런 뒤 일정기한을 두고 상황을 만회할 기회를 줘라. 그 지원이 서면에서 정한 기한이 끝났는데도 여전히 기대에 못 미친다면 어쩔 수 없이 내보내야한다. 22. 사내 갈등 예방법 원한은 회사 전체에 독이 될 수 있다 | 적에게 점심을 대접하라 | 지시를 따르지 않는 직원 관리법 | \u0026ldquo;잘 들었습니다만, 결정은 내가 해요.\u0026rdquo; | 나쁜 싹은 시작부터 잘라라\n문제는 싹부터 잘라라. 문제는 저절로 사라지지 않는다. 문제를 해결하기 위해 발 빠르게 개입해야한다. 개인 간 사소한 갈등을 그대로 방치하면 회사가 망할 수도 있다. 직원과 갈등이 생기면 따로 불러내 얘기해라. 부정적인 피드백은 다른사람들이 없는 데서 전달해야한다. 공개적으로 싸우지 마라. 갈등에는 승자와 패자가 있기 마련이고, 패자가 자존심이 깎이더라도 우리 편에 서게 만들 필요가 있다. 그러니 조금이라도 자존심이 덜 깎이도록 독대한 자리에서만 잘못을 지적해라. 개인적인 갈등을 누그러뜨리는 방법 중 하나는 동료에게 점심을 대접하는 것이다. 내가 틀렸을 수도 있다는 걸 받아들이고, 내가 정말 틀렸다면 빠르게 생각을 고쳐라. 사람들은 자신의 실수를 인정하고 곧바로 바로잡는 사람들을 존경한다. 나와 의견이 다른 직원의 말을 끝까지 경청하는 것을 잊지 마라. 하지만 마찬가지로 직원이 좋든 싫든 결정을 내리는 사람은 나라는 걸 분명히 인지시켜라. 고질적인 문제는 그 심각성을 파악할 수 있도록 데이터로 추적해라. 23. 까다로운 사람 다루는 법 몇 가지 흑마술을 배워 두면 유용하다 | 까다로운 사람들을 대하는 요령 | 변호사를 상대하는 방법 | 조용히 권한을 행사해라\n적이 실수하고 있을 때 절대 가로막지 마라. 먼저 듣고 나중에 행동해라. 갈등이 생겼을 때 기다렸다는 듯이 의견을 피력하는 것은 금물이다. 먼저 경청을 하면서 가능한 한 많은 증거를 수집해야한다. 흥분하지 마라. 웬만해선 싸움을 시작하지 마라. 꼭 필요한 경우에만 선별적으로 싸움을 해라. 이길 자신이 없을 때는 직장에서 마찰을 일으켜 봐야 아무 소용이 없다. 우리가 말하고 쓰는 모든 것은 소셜미디어에서 공격의 빌미가 될 수가 있다. 그러니 말하거나 쓰기 전에 생각해라. 불미스러운 일로 사람들의 입방아에 오르내리는 것은 순식간이다. 트위터를 하지 마라. 작은 회사라고 해서 대중의 지나친 감시에서 자유로운 것은 아니다. 변호사들에게 당신의 업무를 변호하라고 요구해라. 업계와 관련된 주요 법과 판례를 공부해라. 그래야 올바른 결정을 내리는 것은 물론 변호사들에게 끌려다니지 않을 수 있다. 다른 관리자 들이 지시해 놓고 잊어버린 잊어버릴 만한 일들을 잘 챙김으로써 팀원들에게 업무의 우선순위를 효율적으로 정해 줘라. 아무도 모르게 문제를 해결할 방법이 있다면 그렇게 해라. 24. 유능한 관리자 되는 법 가만히 있으면 나빠진다 | 남들보다 먼저 기회를 알아보는 법 | 원칙, 전략, 전술\n최악의 상사는 우리에게 귀중한 교훈을 알려 주는 사람들이다. 그들은 어떻게 하면 실패하는지 보여 주는 산증인이다. 잘 봐 둬라. 직원들에게 \u0026ldquo;고마워요\u0026quot;라는 말을 하지 않는 상사들이 많다. 그런 것은 배우지 마라. 모든일에 \u0026ldquo;고마워요\u0026rdquo; 라고 말해라. 직원들이 오로지 돈이 필요해서 일하러 오는 회사라면 관리를 잘못하고 있는 것이다. 좋은 관리자가 되려면 의사 결정의 세 가지 영역인 원칙 전략 전술 면에서 기량을 쌓아야한다. 원칙은 회사의 근간을 세우고 경쟁사들과 차별화를 이루기 위한 것이다. 우리가 원칙적 결정을 하게 되는 경우는 드물지만, 일단 하게 되면다면 매우 중대한 결정이 될 것이다. 전략은 회사의 재정적 ㅅ성패를 좌우할 수 있는 결정이다. 전략적 결정은 원칙적 결정보다 더 흔하게 일어나지만 그렇다고 하루 단위 또는 일주일 단위로 일어나는 것은 아니다 전술은 관리자의 일용할 양식이다 전술ㄹ은 일을 하면서 매일 매시간 내리는 사소한 결정들이다. 25. 원칙 세우는 법 애플 vs FBI | 원칙에는 예외가 없어야 한다 | 원칙에는 절대적인 설득력이 필요하다 | 큰 그림을 팀원에게 공유해라\n관리의 토대는 원칙에 관한 것이어야한다 당신에겐 사명이 있어야한다 윤리 차별점, 고귀한 소명, 미래 비전이 필요하다. 당신이 매일 직장으로 출근하는 진정한 이류를 직원과 고객들이 알아야한다. 그 이유가 단지 돈을 벌기 위한 것이어선 안 된다. 당신이 하는 이야기가 다른 이야기들과 어떻게 다른지 팀원 모두가 알아야 한다. 왜 자신이 이 일을 하고 있는지 팀원 모두가 알아야한다. 그저 늘 하던 일이기 때문에 하는 것이어선 안 된다. 윤리를 중요시 한다면 고귀하거나 정치적인 원칙이 나올 수 있다. 우수한 제품 디자인을 핵심으로 삼는다면 실용적인 원칙이 나올 수 있다. 비지니스의 근간이 고객의 주머니 사정을 생각하는 것이라면 가치 또는 가격을 고려한 원칙이 나올 수 있다. 관리자로서 우리는 회사의 핵심 원칙을 모든 직원과 고객에게 매일 설명할 수 있어야한다. 같은 말을 반복한다고 기도가 안통하는 건 아니다! 26. 전략 세우는 법 이른 승전보와 출구 전략 | 전쟁 발발 | 동상이몽을 꾼 두 CEO | 값비싼 실패의 대가\n전략적 결정은 회사의 핵심 가치에 영향을 끼칠 수 있지만, 반드시 비즈니스의 존재 이유와 직결되는 것은 아니다. 전략적 결정은 일반적으로 새 제품 출시, 신규 경쟁 시장 진입, 새로운 연구 개발 라인 개척 등 새로운 유형의 비즈니스를 시작하는 것과 관련이 있다. 전략적 결정은 대규모 투자 또는 위험을 수반한다. 때로는 회사의 성패를 좌우할 만큼 중대한 결정이 될 수도 있다. 일반적으로 실패의 대가가 크다. 그러니 제대로 된 결정을 해야 한다. 27. 전술 세우는 법 대부분의 업무 시간은 전술적 결정에 쓰인다 | 아무도 회의에 늦지 않게 하는 확실한 방법\n전술적 결정은 회사의 점진적인 발전을 도모하기 위해 내리는 결정이다. 이는 관리자가 내리는 가장 흔한 결정이다. 전술적 결정은 부하 직원들에게 가장 자주 직접적인 영향을 주는 결정이다. 직원들에게 전술적 결정은 가장 자주 경험하는 결정이기 때문에 가장 중요하게 느껴진다. 원칙적 결정과 전략적 결정은 더 큰 판돈이 걸리지만 일선 직원들에게는 요원하게 느껴진다. 모든 회의를 정각에 진행하고 싶은가? 그럼 직원들에게 \u0026ldquo;기차는 승객이 준비됐든 안 됐든 기차역을 떠난다\u0026rdquo; 라고 말해라. 28. 문제를 분류 하는 법 범주의 오류에 따르는 대가\n관리자들은 세 가지 유형의 결정, 즉 원칙적 결정, 전략적 결정, 전술적 결정을 내린다. 자신이 어떤 결정을 내리고 있는지 아는 것이 중요하다. 이를 혼동하는 대가는 어떤 오류냐에 따라 다르기 때문이다. 전술적 오류는 대체로 어렵지 않게 수정할 수 있다. 전략적 오류는 값비싼 비용을 수반할 가능성이 높다. 원칙적 오류는 회사 전체의 비전과 신뢰성에 타격을 줄 수 있다. 범주의 오류를 범하는 것, 다시 말해 실제로는 이 결정을 하면서 저 결정을 하고 있다고 생각하는 것은 대재앙을 부르는 특효약이다. 0. 10초 요약 정리 누군가 어떤 업무를 해주면 \u0026lsquo;고맙다\u0026rsquo;고 말해라. 모든 일에 \u0026lsquo;고맙다\u0026rsquo;고 말해라. 계획을 세워라. 팀원들의 계획을 나의 계획으로 바꾼다면 더욱 좋다. 채용만 잘해도 문제의 80 퍼센트는 해결된다. 새로운 인재를 채용하는 일을 다른 어떤 관리 업무보다 우선해라. 새로운 직원을 채용할 때마다 팀의 평균 능력을 올려야한다. 연막전술과의 전쟁에서 이겨라. 직원들에게 헛소리하지 마라.직원들은 상사가 당면과제를 분명하게 말해 주기를 원한다. 투명하게 공개해라. 변화에 수반되는 일을 직원들에게 솔직하게 말해라. 모든 직원이 업계의 속성과 현안에 대해 이해할 수 있도록 큰 그림을 설명할 필요가 있다. 훌륭한 커뮤니케이션의 기초는 반복이다. 이용 가능한 모든 채널을 활용해 소통해라. 팀원들의 할 일 목록에서 주기적으로 사소한 일을 삭제해 줌으로써 팀원들이 가장 중요한 업무에 집중할 수 있게 해라. 대박과 쪽박 기법을 사용해 직원들이 왜 성공하고 왜 실패했는지 분석하게 해라. 성공과 실패로부터 배워라. 잘한일을 보면 칭찬해라. 다른 업무나 제품, 서비스에 적용할 새로운 아이디어를 내는 데 이 성공 사례를 활용해라. 대박과 쪽박 기법을 지속적으로 적용하면 업무량이나 기술, 직원을늘리지 않고도 팀의 평균 성과와 전체 실적을자동으로 끌어올릴 수 있다. 일관성은 탁월한 사람들의 요술 방망이다. 평균보다 약간 더 잘하는 것의 놀라운 힘을 활용해라. 생산성이 낮은 업무를 중단하고 그 직원들을생서ㅏㄴ성이 높은 업무르ㅗ 이동. 우리는 끝없는 성장의 바다를 떠다니고 있다. 우리의 배는 끝없는 성장을 동력 삼아 앞으로 나아가고 있다.새로운 아이디어는 성장을 일으키고, 사람들은 시간이 지날수록 일을 더 잘하게 된다. 이 두가지 역학은 장기적인 측면에서 눈덩이 처럼 불어난 성과를 가져올 것이다. 업무는 인기 콘테스트가 아니라, 일의 완수 여부를 따지는 콘테스트다. 직원들을 판단할 때는 그럴듯한 말을 하는지가 아니라 업무를 잘하는 지를 봐라. 인맥, 인상 대신 데이터로 해결해라. 개인적 경험에 의존한 관리를 자제해라. 데이터는 구체적이고 측정 가능하며 확인할 수 있어야한다. 퀀트의 오류를 조심해라. 양질의 데이터를 갖는것과 양질의 데이터에 판단을 적용하는 것은 별개의 문제다. 5명의 법칙을 명심해라. 팀원이 6명이 넘어가면 역기능이 임계점에 도달하게 된다.. 상사 관리는 매우 저평가된 기술이다. 레벨 4 행동을 보이는 사람들을 승진시켜라. (또한 반 헤일런 테스트를 사용해 지시사항을 따르지 않는 사람들을 승진시키지 않도록해라.) 나쁜 싹은 시작부터 잘라라. 문제는 저절로 사라지지 않는다. 빠르게 개입해 문제를 해결해라. 직원들이 출근하는 유일한 이유가 돈 때문이라면 우리는 형편없는 관리자일 공산이 크다. 관리자들은 원칙이나 전략, 전술을 바탕으로 세 가지 유형의 결정을 내린다. 전술적 오류는 대체로 손쉽게 수정할 수 있다. 전략적 오류는 비싼 대가를 수반을 가능성이 높다. 원칙적 오류는 전체 비전과 신뢰성에 타격을 줄 수 있다. 범주의 오류를 범하는 것, 다시 말해 실제로는 이 결정을 하면서 저 결정을 하고 있다고 생각하는 것은 대재앙을 부르는 특효약이다. ","permalink":"https://nolleh.github.io/leadership/leadership-game/","summary":"Leadership Game written by 짐 에드워즈\n1. 팀장 1일차를 완벽하게 보내는 법 일은 좀 어때요? | 개인 플레이가 더 이상 통하지 않을 때 | 5명의 법칙 | 첫날 반드시 해야할 일 | 좋은질문이 당신을 리더로 만든다.\n새로 맡은 구성원들과 일대일 면담을 해라. 팀원에게 무엇이 효과가 있는지, 회사가 더 해야 할 일은 무엇인지 물어라. 팀원에게 무엇이 문제인지 어떤 일을 그만둬야 하는지 물어라. 앞으로의 계획에 팀원들의 조언을 활용하겠다고 말해라. 팀원들의 계획을 나의 계획으로 바꿔라.","title":"Leadership Game"},{"content":"다음 번역 zguide\nChapter 1 - Basics Fixing The World 프로그래밍의 물리요, 과학은: 사람들이 쉽게 이해하고 사용할 수 있는 빌딩블록을 만들고 함께 큰 문제를 해결하는 데에 있다.\n우리는 연결되어 있는 세상에 살고 있고 현대의 소프트웨어는 세상을 안내한다.\n하지만 데이터와 지식들은 클라우드와 개인 컴퓨터에 존재하고 인터넷은 \u0026lsquo;연결된\u0026rsquo; 코드의 잠재성을 제안했지만\n현실은 많은 흥미로운 문제들(건강/교육/경제/..)이 코드를 \u0026lsquo;연결\u0026rsquo; 할 방법이 없기 때문에 많은 지식(brain) 을 연결하지 못해 해결되지 못한 채로 남아있다.\nIETF 표준들과같은 많은 노력으로 코드를 연결하기 위한 시도들이 행해졌다. 어플리케이션 개발자들은 HTTP 를 하나의 솔루션으로 사용하여 \u0026lsquo;간단한\u0026rsquo; 문제에는 활용할 수 있겠지만\n이것은 개발자들과 아키텍트들이 큰서버를 생각하고 멍청한 클라이언트들을 구성하도록 격려하면서 문제를 더 악화했다.\n그래서, 현재의 사람들은 여전히 raw UDP 와 raw TCP를 사용한다. 이는 고통스럽고, 느리고, 확장하기 어려우며 중앙화가 필수적이다. 분산P2P 아키텍쳐는 업무를 위해서가 아니라 대부분 play 를 위해 사용된다. 스카이프나 비트토렌트를 데이터를 교환하기 위해 사용하는 어플리케이션이 몇이나 되겠는가?\n이는 다시 프로그래밍의 과학을 다시우리에게 들이민다. 세상을 고치기 위해 우리는 두가지가 필요하다.\n아무 코드를 어느 곳에나 있는 아무 코드로 연결할 방법 이를 가능한한 간단한 빌딩 블럭으로 만들어 유저들이 쉽게 이해하고 사용할 수 있어야 할 것 말도 안되게 간단해 보인다. 그리고 어쩌면 그럴 것도 같다. 이게 요점의 전부다.\nStarting Assumptions version: 3.2 zeromq.\nyou can read C code.\nwe write constants like PUSH or SUBSCRIBE, you can imagine they are really called ZMQ_PUSH or ZMQ_SUBSCRIBE if the programming language needs it.\nAsk and Ye Shall Receive 먼저 코드로 시작해보자. 물론 Hello World 예제부터. 클라이언트와 서버를 만든다. 클라이언트는 \u0026ldquo;Hello\u0026rdquo; 를 서버에 전송, \u0026ldquo;World\u0026rdquo; 라고 응답 받을 것이다.\n// // Hello World server in C++ // Binds REP socket to tcp://*:5555 // Expects \u0026#34;Hello\u0026#34; from client, replies with \u0026#34;World\u0026#34; // #include \u0026lt;zmq.hpp\u0026gt; #include \u0026lt;string\u0026gt; #include \u0026lt;iostream\u0026gt; #ifndef _WIN32 #include \u0026lt;unistd.h\u0026gt; #else #include \u0026lt;windows.h\u0026gt; #define sleep(n)\tSleep(n) #endif int main () { // Prepare our context and socket zmq::context_t context (2); zmq::socket_t socket (context, zmq::socket_type::rep); socket.bind (\u0026#34;tcp://*:5555\u0026#34;); while (true) { zmq::message_t request; // Wait for next request from client socket.recv (request, zmq::recv_flags::none); std::cout \u0026lt;\u0026lt; \u0026#34;Received Hello\u0026#34; \u0026lt;\u0026lt; std::endl; // Do some \u0026#39;work\u0026#39; sleep(1); // Send reply back to client zmq::message_t reply (5); memcpy (reply.data (), \u0026#34;World\u0026#34;, 5); socket.send (reply, zmq::send_flags::none); } return 0; } REQ-REP 소켓쌍은 시작점이다. 클라이언트는 zmq_send() 이후 zmq_recv() 를 하나의 루프에서 실행한다. 이 외의 어떤 다른 시퀀스(한번에 메시지를두번보낸다거나)\n는 응답값이-1 로 반환된다. 유사하게, 서비스는 zmq_recv() 이후 zmq_send() 를 보통 필요한 것처럼 순서대로 발행 한다.\n다른 언어에서도 유사하게 사용된다.\npackage guide; // // Hello World server in Java // Binds REP socket to tcp://*:5555 // Expects \u0026#34;Hello\u0026#34; from client, replies with \u0026#34;World\u0026#34; // import org.zeromq.SocketType; import org.zeromq.ZMQ; import org.zeromq.ZContext; public class hwserver { public static void main(String[] args) throws Exception { try (ZContext context = new ZContext()) { // Socket to talk to clients ZMQ.Socket socket = context.createSocket(SocketType.REP); socket.bind(\u0026#34;tcp://*:5555\u0026#34;); while (!Thread.currentThread().isInterrupted()) { byte[] reply = socket.recv(0); System.out.println( \u0026#34;Received \u0026#34; + \u0026#34;: [\u0026#34; + new String(reply, ZMQ.CHARSET) + \u0026#34;]\u0026#34; ); Thread.sleep(1000); // Do some \u0026#39;work\u0026#39; String response = \u0026#34;world\u0026#34;; socket.send(response.getBytes(ZMQ.CHARSET), 0); } } } } 클라이언트 코드는 다음과 같다.\n// Hello World client #include \u0026lt;zmq.h\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; int main (void) { printf (\u0026#34;Connecting to hello world server...\\n\u0026#34;); void *context = zmq_ctx_new (); void *requester = zmq_socket (context, ZMQ_REQ); zmq_connect (requester, \u0026#34;tcp://localhost:5555\u0026#34;); int request_nbr; for (request_nbr = 0; request_nbr != 10; request_nbr++) { char buffer [10]; printf (\u0026#34;Sending Hello %d...\\n\u0026#34;, request_nbr); zmq_send (requester, \u0026#34;Hello\u0026#34;, 5, 0); zmq_recv (requester, buffer, 10, 0); printf (\u0026#34;Received World %d\\n\u0026#34;, request_nbr); } zmq_close (requester); zmq_ctx_destroy (context); return 0; } 실제라고 보기에는 너무 간단해보이지만, ZeroMQ 소켓은 이미 이전에 배운것처럼 슈퍼파워를 가지고있다.\n수천의 클라이언트를 한번에 붙여도 여전히 행복하게 빠르게 동작할 것이다.\n서버를 kill 하고 나서 다시재시작 해보면, 클라이언트는 정상적으로 회복하지 못할 것이다.\n크래쉬 프로세스에서 다시 회복 하는것, 쉬운 일이 아니다. 신뢰성 있는 요청 응답 플로우를 구현하는 것은\n너무 복잡하기 때문에 여기서 다루지않고 ch4에서 다룬다.\nA Minor Note on Strings C 와 같은 언어에서는 문자열을 전송할 때 null character 가 붙지만 그렇지 않은 언어들도 있음.\n두 언어 사이에서 통신할 때 이때문에 비정상 동작할 수 있음. 그래서 C 기반의 언어에서는 항상 /0 로 종료됨을 단순히 믿을 수 없기때문에 별도의 버퍼를할당하고\n추가 바이트를할당해서 문자열을 복사 해야 한다.\n그래서, 다음과 같은 룰을 정립하자. ZeroMQ 문자열은 길이 지정이 되어 있고 뒤따르는 null 이 없는 것으로 한다.\n하나의 zeroMQ 문자열은 zeroMQ 메시지프레임으로 간결하게 매핑될 수 있으며 아래와 같은 형태가 된다.\nC 에서는, 문자열을 수신 후 다음과 같은 작업을 한다.\n// Receive ZeroMQ string from socket and convert into C string // Chops string at 255 chars, if it\u0026#39;s longer static char * s_recv (void *socket) { char buffer [256]; int size = zmq_recv (socket, buffer, 255, 0); if (size == -1) return NULL; if (size \u0026gt; 255) size = 255; buffer [size] = \u0026#39;\\0\u0026#39;; /* use strndup(buffer, sizeof(buffer)-1) in *nix */ return strdup (buffer); } 이 헬퍼 함수는 다음에 재활용하기 편하게 만들며, 헤더 파일에 패키지해서 사용하면 된다.\n그 결과가 zhelpers.h 이며, 더 달달하고 짧은 C zeroMQ 어플리케이션을 만드는데 도움 줄 것이다.\n이 헤더파일은 C 개발자들만을 위한 부분이기 때문에 여유시간에 읽어보시라.\nA Note on the Naming Convention s_ prefix 는 static method, variables을 나타낸다.\nVersions // Report 0MQ version #include \u0026lt;zhelpers.hpp\u0026gt; int main (void) { s_version(); return EXIT_SUCCESS; } Getting The Message Out 두 번째 흔한 패턴은 일방향 데이터 분배이다.\n// // Weather update server in C++ // Binds PUB socket to tcp://*:5556 // Publishes random weather updates // #include \u0026lt;zmq.hpp\u0026gt; #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;time.h\u0026gt; #if (defined (WIN32)) #include \u0026lt;zhelpers.hpp\u0026gt; #endif #define within(num) (int) ((float) num * random () / (RAND_MAX + 1.0)) int main () { // Prepare our context and publisher zmq::context_t context (1); zmq::socket_t publisher (context, zmq::socket_type::pub); publisher.bind(\u0026#34;tcp://*:5556\u0026#34;); publisher.bind(\u0026#34;ipc://weather.ipc\u0026#34;);\t// Not usable on Windows. // Initialize random number generator srandom ((unsigned) time (NULL)); while (1) { int zipcode, temperature, relhumidity; // Get values that will fool the boss zipcode = within (100000); temperature = within (215) - 80; relhumidity = within (50) + 10; // Send message to all subscribers zmq::message_t message(20); snprintf ((char *) message.data(), 20 , \u0026#34;%05d %d %d\u0026#34;, zipcode, temperature, relhumidity); publisher.send(message, zmq::send_flags::none); } return 0; } // // Weather update client in C++ // Connects SUB socket to tcp://localhost:5556 // Collects weather updates and finds avg temp in zipcode // #include \u0026lt;zmq.hpp\u0026gt; #include \u0026lt;iostream\u0026gt; #include \u0026lt;sstream\u0026gt; int main (int argc, char *argv[]) { zmq::context_t context (1); // Socket to talk to server std::cout \u0026lt;\u0026lt; \u0026#34;Collecting updates from weather server...\\n\u0026#34; \u0026lt;\u0026lt; std::endl; zmq::socket_t subscriber (context, zmq::socket_type::sub); subscriber.connect(\u0026#34;tcp://localhost:5556\u0026#34;); // Subscribe to zipcode, default is NYC, 10001 const char *filter = (argc \u0026gt; 1)? argv [1]: \u0026#34;10001 \u0026#34;; subscriber.set(zmq::sockopt::subscribe, filter); // Process 100 updates int update_nbr; long total_temp = 0; for (update_nbr = 0; update_nbr \u0026lt; 100; update_nbr++) { zmq::message_t update; int zipcode, temperature, relhumidity; subscriber.recv(update, zmq::recv_flags::none); std::istringstream iss(static_cast\u0026lt;char*\u0026gt;(update.data())); iss \u0026gt;\u0026gt; zipcode \u0026gt;\u0026gt; temperature \u0026gt;\u0026gt; relhumidity ; total_temp += temperature; } std::cout \u0026lt;\u0026lt; \u0026#34;Average temperature for zipcode \u0026#39;\u0026#34;\u0026lt;\u0026lt; filter \u0026lt;\u0026lt;\u0026#34;\u0026#39; was \u0026#34;\u0026lt;\u0026lt;(int) (total_temp / update_nbr) \u0026lt;\u0026lt;\u0026#34;F\u0026#34; \u0026lt;\u0026lt; std::endl; return 0; } SUB 소켓은 zmq_setsockopt() 를 사용하여 구독을 등록 후에 SUBSCRIBE 해야만 한다. 어떤 구독도 등록하지 않는다면 어떤 메시지도 수신할 수 없다.\n구독자는 여러명이 될 수 있으며, 업데이트가 ANY 구독자에게라도 매치가 되면, 그 구독자가 수신하게 된다. 구독자는 또 특정 구독을 취소할 수도 있다.\n하나의 구독은 보통, 하지만 항상 그런것은 아니고, 문자 열로 출력할 수 있다. zmq_setsockopt() 를 참조하시라.\nZeroMQ 소켓의 이론에서, 누가 연결을 끊고 누가 바인드를 끊는지는 관계가 없다. 그러나, 실세계에서 문서화 되지 않은 차이가 있으므로, 이건 나중에 다루겠다. 일단 지금은, PUB 을 바인드 하고 SUB 에서 연결하자. (당신의 네트워크 디자인이 허락하는 한)\nPUB-SUB 소켓에 대해 한가지 더 중요히 생각할게 있다.: 구독자가 언제 구독을 시작할지 모른다는 것이다.구독자를 실행 하였더라도, 일정 시간 기다리고 나서 발행자를 실행하여도, 구독자는 항상 발행자가 보내는 첫번째 메시지를 놓칠 것이다. 이건 구독자가 퍼블리셔에 연결할때, 퍼블리셔는 메시지를 이미 보냈을 수 있기 때문이다.\n이 \u0026ldquo;늦은 참석\u0026rdquo; 증상은 충분히 많은 사람들을 고통스럽게 하기 때문에, 자세한 사항을 다룰 예정이다. ZeroMQ 는 백그라운드에서 비동기 I/O 를 수행함을 기억하라.\n다음 순서대로 작업을 처리하는 두 노드가 있다고 하자.\n구독자는 엔드포인트에 연결하여 메시지를 받고 센다. 발행자는 엔드포인트에 바인드하여 그 즉시 1000 메시지를 보낸다. 이러면 구독자는 거의 항상 아무것도 받지 못한다. 당신은 눈을 깜박이며 필터를 체크하고 다시 확인할테지만, 구독자는 여전히 아무것도 받지 못할 것이다.\nTCP 연결을 맺고 핸드쉐이킹을 맺는데 얼마간의 밀리초가 네트워크상태 (피어사이의 홉의 수에 의존해서)에 따라 소요 된다. 이 시간동안, ZeroMQ는 많은 메시지들을 송신할 수 있다. 5msecs 가 연결을 맺는데 소요한다고 가정하고, 그리고 같은 링크가 1M 메시지를 1초에 다룰 수 있다고 하자. 이 5mses 동안, 발행자는 1K message 를 보내기위해 1mesc 만이 필요하다.\nCh2-Sockets and Patterns 에서 이를 어떻게 동기화하고 구독자가 실제로 연결하여 준비 되기 전까지 메시지를 발행하지 않기 위한 방법을 소개한다.\n동기화의 다른 대안은, 데이터 스트림은 무한하고 시작점도, 끝점도 없다고 가정하는 것이다. (위의 날씨 방송 예제가 그 예)\npub-sub 패턴에서 몇가지 포인트:\n구독자 들은 하나이상의 발행자에 한번의 connect 콜만으로 연결할 수 있다. 데이터는 이후 전송되어 인터리브되고, 하나의 발행자가 다른것들을 drown 시키지 않는다. 만약 발행자에게 구독자가 없으면, 모든 메시지를 드랍한다. 만약 TCP 연결을 사용하고 구독자가 느리다면, 발행자에게 메시지가 큐잉된다. 발행자를 이로부터 보호하기 위한 \u0026ldquo;high-water mark\u0026rdquo; 기법은 이후 살펴본다. ZeroMQ v3.x 부터, filtering 은 (tcp:@\u0026lt;\u0026gt;@ or ipc:@\u0026lt;\u0026gt;@) 를 사용하는 경우 발행자 측에서 일어난다. epgm:@\u0026lt;//\u0026gt;@ 프로토콜을 사용하는 경우, filtering 은 구독자 사이드에서 일어난다. ZeroMQ v2.x 에서, 모든 filtering 은 구독자 사이드에서 일어난다. 다음은 10M 메시지를 filter 하고 받는 데 얼마나 걸리는지 2011-era Intel i5 labtop 에서 측정한 결과이나, 다른 이후 장비에서도 큰 차이는 없을 것이다.:\n$ time wuclient Collecting updates from weather server... Average temperature for zipcode \u0026#39;10001 \u0026#39; was 28F real 0m4.470s user 0m0.000s sys 0m0.008s Divide and Conquer 마지막 예제는 다시 철학적인 논의로 돌아와 보자.\n워커로 task 를 전송하여 취합하는 예제.\nventilator 는 병렬로 처리될 수 있는 tasks 를 생성한다. worker 의 집합은 task를 처리한다. sink 는 워커 프로세스로부터 결과를 취합한다. 현실에서는 GPU 를 사용하거나 하는 복잡한 작업을 수행하겠지만, 여기서는 sleep 하는 100 task 를 생성하는 예제이다.\n// // Task ventilator in C++ // Binds PUSH socket to tcp://localhost:5557 // Sends batch of tasks to workers via that socket // #include \u0026lt;zmq.hpp\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;iostream\u0026gt; #define within(num) (int) ((float) num * random () / (RAND_MAX + 1.0)) int main (int argc, char *argv[]) { zmq::context_t context (1); // Socket to send messages on zmq::socket_t sender(context, ZMQ_PUSH); sender.bind(\u0026#34;tcp://*:5557\u0026#34;); std::cout \u0026lt;\u0026lt; \u0026#34;Press Enter when the workers are ready: \u0026#34; \u0026lt;\u0026lt; std::endl; getchar (); std::cout \u0026lt;\u0026lt; \u0026#34;Sending tasks to workers...\\n\u0026#34; \u0026lt;\u0026lt; std::endl; // The first message is \u0026#34;0\u0026#34; and signals start of batch zmq::socket_t sink(context, ZMQ_PUSH); sink.connect(\u0026#34;tcp://localhost:5558\u0026#34;); zmq::message_t message(2); memcpy(message.data(), \u0026#34;0\u0026#34;, 1); sink.send(message); // Initialize random number generator srandom ((unsigned) time (NULL)); // Send 100 tasks int task_nbr; int total_msec = 0; // Total expected cost in msecs for (task_nbr = 0; task_nbr \u0026lt; 100; task_nbr++) { int workload; // Random workload from 1 to 100msecs workload = within (100) + 1; total_msec += workload; message.rebuild(10); memset(message.data(), \u0026#39;\\0\u0026#39;, 10); sprintf ((char *) message.data(), \u0026#34;%d\u0026#34;, workload); sender.send(message); } std::cout \u0026lt;\u0026lt; \u0026#34;Total expected cost: \u0026#34; \u0026lt;\u0026lt; total_msec \u0026lt;\u0026lt; \u0026#34; msec\u0026#34; \u0026lt;\u0026lt; std::endl; sleep (1); // Give 0MQ time to deliver return 0; } worker 는 메시지를 받아 sleep 하고, 끝났을때 시그널을 보낸다.\n// // Task worker in C++ // Connects PULL socket to tcp://localhost:5557 // Collects workloads from ventilator via that socket // Connects PUSH socket to tcp://localhost:5558 // Sends results to sink via that socket // #include \u0026#34;zhelpers.hpp\u0026#34; #include \u0026lt;string\u0026gt; int main (int argc, char *argv[]) { zmq::context_t context(1); // Socket to receive messages on zmq::socket_t receiver(context, ZMQ_PULL); receiver.connect(\u0026#34;tcp://localhost:5557\u0026#34;); // Socket to send messages to zmq::socket_t sender(context, ZMQ_PUSH); sender.connect(\u0026#34;tcp://localhost:5558\u0026#34;); // Process tasks forever while (1) { zmq::message_t message; int workload; // Workload in msecs receiver.recv(\u0026amp;message); std::string smessage(static_cast\u0026lt;char*\u0026gt;(message.data()), message.size()); std::istringstream iss(smessage); iss \u0026gt;\u0026gt; workload; // Do the work s_sleep(workload); // Send results to sink message.rebuild(); sender.send(message); // Simple progress indicator for the viewer std::cout \u0026lt;\u0026lt; \u0026#34;.\u0026#34; \u0026lt;\u0026lt; std::flush; } return 0; } sink 에서는 100 tasks 를 취합, 전체 프로세스가 얼마나 걸릴지 연산하기 때문에, 워커가 실제로 병렬로 처리되고 있는지 확인 할 수 있다.\n// // Task sink in C++ // Binds PULL socket to tcp://localhost:5558 // Collects results from workers via that socket // #include \u0026lt;zmq.hpp\u0026gt; #include \u0026lt;time.h\u0026gt; #include \u0026lt;sys/time.h\u0026gt; #include \u0026lt;iostream\u0026gt; int main (int argc, char *argv[]) { // Prepare our context and socket zmq::context_t context(1); zmq::socket_t receiver(context,ZMQ_PULL); receiver.bind(\u0026#34;tcp://*:5558\u0026#34;); // Wait for start of batch zmq::message_t message; receiver.recv(\u0026amp;message); // Start our clock now struct timeval tstart; gettimeofday (\u0026amp;tstart, NULL); // Process 100 confirmations int task_nbr; int total_msec = 0; // Total calculated cost in msecs for (task_nbr = 0; task_nbr \u0026lt; 100; task_nbr++) { receiver.recv(\u0026amp;message); if (task_nbr % 10 == 0) std::cout \u0026lt;\u0026lt; \u0026#34;:\u0026#34; \u0026lt;\u0026lt; std::flush; else std::cout \u0026lt;\u0026lt; \u0026#34;.\u0026#34; \u0026lt;\u0026lt; std::flush; } // Calculate and report duration of batch struct timeval tend, tdiff; gettimeofday (\u0026amp;tend, NULL); if (tend.tv_usec \u0026lt; tstart.tv_usec) { tdiff.tv_sec = tend.tv_sec - tstart.tv_sec - 1; tdiff.tv_usec = 1000000 + tend.tv_usec - tstart.tv_usec; } else { tdiff.tv_sec = tend.tv_sec - tstart.tv_sec; tdiff.tv_usec = tend.tv_usec - tstart.tv_usec; } total_msec = tdiff.tv_sec * 1000 + tdiff.tv_usec / 1000; std::cout \u0026lt;\u0026lt; \u0026#34;\\nTotal elapsed time: \u0026#34; \u0026lt;\u0026lt; total_msec \u0026lt;\u0026lt; \u0026#34; msec\\n\u0026#34; \u0026lt;\u0026lt; std::endl; return 0; } 하나의 배치는 평균적으로 5초를 소요한다. 1, 2, or 4 개의 워커를 수행했을때, 다음과 같은 결과가 나온다.\n1 worker: total elapsed time: 5034 msecs. 2 workers: total elapsed time: 2421 msecs. 4 workers: total elapsed time: 1018 msecs.\n이 코드에서 짚고 넘어가 볼 디테일들:\n워커는 ventilator 를 upstream 으로 하여 연결하고, downstream 으로 sink 를 연결한다. 이것은 임의의 워커를 추가할 수 있음을 의미한다. 만약 워커가 그들의 엔드포인트에 묶여 있다면, (a) 의 추가 엔드포인트들을 (b) 에 연결할때마다 ventilator 와 siny 양쪽을 수정해야할 필요가 있다. ventilaotr 와 sink 가 우리 아키텍쳐에서 stable 하다고 이야기할 수 있으며 worker 파츠를 dynamic 하다고 이야기 할 수있다.\nbatch 의 시작점을 모든 워커들이 실행되고 구동되기까지로 동기화 해야한다. 이건 ZeroMQ 에서 꽤 흔한 문제(fairly common gotcha) 인데, 쉬운 솔루션은 없다. zmq_connect 메소드는 특정 시간을 소요하게 된다. 따라서 워커 집합이 ventilaotr 에 붙고, 첫번째가 성공적으로 연결하면 모든 메시지의 로드를 짧은 시간내에 다른 애들이 연결하는 중에 받아버릴 수 있다. 만약 배치의 시작점을 동기화 하지 않는다면, 시스템은 전혀 병렬로 처리되지 않을것이다. wait 을 ventilator 에서 제거하고 어떤일이 발생하는지 확인해보시라.\nventilor 의 PUSH 소켓은 task 를 워커들로 고르게 분배한다. (시작하기전에 모두 연결되었다고 가정하자) 이 동작을 로드밸런싱 이라 하며, 다시 자세히 다룰 것이다.\nsink 의 PULL 소켓은 워커들로부터 고르게 수집한다. 이를 fair-queuing 이라 한다.\n이 파이프라인 패턴은 또 \u0026ldquo;느린 참여\u0026rdquo; 신드롬을 노출하는데, PUSH 소켓이 로드밸런싱을 적절히 하지 못하는 문제로 연결된다. 만약 PUSH / PULL 을 사용한다면, 먼저 참여한 하나의 워커가 다른 것에 비해 많은 메시지를 받게 된다. 올바른 로드 밸런싱을 하고 싶다면, 다음을 읽어보는 것이 도움이 될 것이다. Chapter 3- Advanced Request-Replay Patterns\nProgramming with ZeroMQ 다음의 기본적인 조언을 살펴보라.\nZeroMQ 를 단계별로 익히기. 하나의 단순한 Api 도 세상의 가능성을 많이 숨기고 있음. 변수명들을 의미 있게 정하는 것과 같이 나이스한 코드를 작성하기. 만들었을때 테스트하기. 동작을 제대로 하지 않을때, 코드를 부분으로 나누고 각각을 테스트하기. 함수/클래스등으로 추상화를 하기. 많은 코드를 복사/붙여넣기를 하면 에러도 함께 복사/붙여넣기 하는것이다. Getting the Context Right 항상 컨텍스트를 먼저 만들어줘야하는데, 프로세스에서 정확히 하나의 컨텍스트를 생성해야한다. 기술적으로, 컨텍스트는 하나의 프로세스에서의 모든 소켓을 관리하는 컨테이너 로서 동작하며, 하나의 프로세스에서 스레드를 연결하는데 가장 빠른 방법인 inproc 소켓에서는 transport 로서 동작한다. 하나의 프로세스에서 두개의 컨텍스트를 사용하는 것은ZeroMQ 인스턴스를 분리하는 것과 같다. 만약 그걸 원하는 거라면 그렇게 사용해도 괜찮지만 다음을 기억하라.\nzmq_ctx_new() 를 프로세스를 시작할때 한번, zmq_ctx_destroy 를 끝날때 한번 호출하기\nsystem call fork() 를 사용하는 경우 zmq_ctx_new() 는 fork 이후에 child process 에서 한번 호출하자. 일반적으로, 흥미로운(ZeroMQ) 것들은 children 에서 사용하길 원할것이며, 지루한 프로세스 관리는 parent 에서 처리할 것이다.\nMaking a Clean Exit 잡을 끝낼때마다 항상 클린업하라. ZeroMQ 를 python 같은 언어에서 사용할때, 자동으로 처리가 될 것이나, C 같은 곳에서는 사용이 끝났을때 free 해주지 않으면 메모리 릭으로 연결되며, 불안정한 어플리케이션이 될 것이다.\n메모리릭은 한가지 지만, ZeroMQ 는 어플리케이션을 종료할때 꽤 까다롭다. 그 이유는 기술적이고 고통스럽지만, upshot 은 어떤 소켓이라도 연결된 상태로 떠나면, zmq_ctx_destroy() 함수는 영원히 hang 상태에 머무를 것이다. 그리고 모든 소켓을 종료하여도 pending connects 나 send 가 있고 LINGER 를 zero 로 세팅해 놓으면 zmq_ctx_destroy() 는 기본적으로 영원히 기다릴 것이다.\nZeroMQ 객체에 대해, message, socket, context 를 신경써야한다. 다행히 간단한 프로그램에서는 꽤 단순하다.\n가능하다면 zmq_send() 와 zmq_recv() 를 사용하여 zmq_msg_t 객체를 사용하지 않도록 한다. zmq_msg_recv() 를 사용한다면, 메시지를 사용한 뒤에는 항상 zmq_msg_close() 호출하여 반환한다. 많은 소켓을 열고 닫는다면, 어플리케이션을 다시 디자인 할 필요가 있음을 시사한다. 어떤 케이스에는 컨텍스트를 파괴하기 전까지 소켓이 free 되지 않을 수도 있다. 프로그램을 종료할때, 소켓을 닫고 zmq_ctx_destroy() 를 호출하라. 이것이 컨텍스트를 파괴한다. 멀티스레드 워크를 할때, 더 복잡해진다. 다음 챕터에서 멀티스레딩에 대해 다룰테지만, 여러분들중 일부는 경고에도 불구하고 안전하게 걷기전에 달리고 싶어할것이므로, 아래에멀티스레드 어플리케이션에서 clean exit 를 위한 빠르고 지저분한 가이드를 소개한다.\n먼저, 멀티스레드에서 같은 소켓을 사용하지 말아라. 왜 당신이 이걸 사용하면 좋은지 설명하려고 하지 말고, 그냥 하지말아달라. 다음으로, 진행중인 요청을 갖고 있는 각각의 소켓들에 대해 shutdown 할 필요가 있다. 적합한 방법은 낮은 LINGER value (1sec) 를 세팅하는 것이다. 만약 당신이 바인딩한 언어가 컨텍스트를 자동으로 파괴해주지 않는다면, patch 를 제안하라.\n마지막으로, 컨텍스트를 파괴하라. 이것은 어떤 블러킹 수신이나 poll, send 가 스레드에 붙어있더라도(i.e, 같은 컨텍스트를 공유함) 에러를 반환하도록 해준다. 에러를 캐치해서, linger 를 세팅하고, 그 스레드에서 소켓을 close 하라. 같은 컨텍스트를 두번 파괴하지 마라. zmq_ctx_destroy 가 메인스레드에서 호출된다면 모든 소켓이 안전하게 종료 될 때까지 블럭할 것이다.\n짜잔!(Voila!) 충분히 복잡하고 고통스러운 작업이기 때문에, 어떤 언어든 가치있는 바인딩 제작자는 (worth his or her salt) 이걸 자동으로 수행하도록 작업해두었을것이므로, 직접 만들 필요는 없을 것이다.\n","permalink":"https://nolleh.github.io/zeromq/1.basics/","summary":"다음 번역 zguide\nChapter 1 - Basics Fixing The World 프로그래밍의 물리요, 과학은: 사람들이 쉽게 이해하고 사용할 수 있는 빌딩블록을 만들고 함께 큰 문제를 해결하는 데에 있다.\n우리는 연결되어 있는 세상에 살고 있고 현대의 소프트웨어는 세상을 안내한다.\n하지만 데이터와 지식들은 클라우드와 개인 컴퓨터에 존재하고 인터넷은 \u0026lsquo;연결된\u0026rsquo; 코드의 잠재성을 제안했지만\n현실은 많은 흥미로운 문제들(건강/교육/경제/..)이 코드를 \u0026lsquo;연결\u0026rsquo; 할 방법이 없기 때문에 많은 지식(brain) 을 연결하지 못해 해결되지 못한 채로 남아있다.\nIETF 표준들과같은 많은 노력으로 코드를 연결하기 위한 시도들이 행해졌다.","title":"1.basics"},{"content":"라즈베리파이5 * Ubuntu 에서DRM 스트리밍서비스 (OTT) 를 이용하려고 여러 글들을 살펴봄.\nhttps://github.com/brave/brave-browser/issues/28903\nhttps://support.brave.com/hc/en-us/articles/23881756488717-How-do-I-enable-Widevine-DRM-on-Linux\nhttps://forum.radxa.com/t/lets-get-widevine-working/15391\nhttps://github.com/raspberrypi/Raspberry-Pi-OS-64bit/issues/248\n음 다안된다. 구글에서 제공하는 widevinecdm 컴포넌트/라이브러리가 필요한 모양인데 대략 해석해보면 구글에서 공식적으로 지원하는 aacrch 용은 없는 모양이고 일부 오픈소스에서 chrome OS 용으로 제공하는 python 스크립트로 라이브러리를 좀 변조하는 형태로 시도한 내용들이 보이는데\nvivaldi 브라우저에서 컴포턴트가 드디어 노출되는건 확인했지만\n해당 라이브러리가 정상적으로 동작하지는 않는모양.\n그냥 라즈베리파이에서는 공식 제공하는 라즈비안OS 를 사용하는 게 그냥 마음 편할듯.\n다만 난 우분투를 계속 가지고 놀 작정이라 일단 OTT 는 그냥 포기해야하겠다.\n한 세달뒤 쯤에 다시 도전해 봐야지\u0026hellip;\n","permalink":"https://nolleh.github.io/ubuntu/widevinecdm/","summary":"라즈베리파이5 * Ubuntu 에서DRM 스트리밍서비스 (OTT) 를 이용하려고 여러 글들을 살펴봄.\nhttps://github.com/brave/brave-browser/issues/28903\nhttps://support.brave.com/hc/en-us/articles/23881756488717-How-do-I-enable-Widevine-DRM-on-Linux\nhttps://forum.radxa.com/t/lets-get-widevine-working/15391\nhttps://github.com/raspberrypi/Raspberry-Pi-OS-64bit/issues/248\n음 다안된다. 구글에서 제공하는 widevinecdm 컴포넌트/라이브러리가 필요한 모양인데 대략 해석해보면 구글에서 공식적으로 지원하는 aacrch 용은 없는 모양이고 일부 오픈소스에서 chrome OS 용으로 제공하는 python 스크립트로 라이브러리를 좀 변조하는 형태로 시도한 내용들이 보이는데\nvivaldi 브라우저에서 컴포턴트가 드디어 노출되는건 확인했지만\n해당 라이브러리가 정상적으로 동작하지는 않는모양.\n그냥 라즈베리파이에서는 공식 제공하는 라즈비안OS 를 사용하는 게 그냥 마음 편할듯.\n다만 난 우분투를 계속 가지고 놀 작정이라 일단 OTT 는 그냥 포기해야하겠다.","title":"struggles to view OTT on UBUNTU X raspberry Pi 5 - A.K.A using Widevinecdm"},{"content":"Requiring Boot Loader Passwords You can secure the boot process with a secure epassword to prevent someone from bypassing the user authentication step. This can work in conjunction with password protection for the BIOS. Note that while using a bootloader passwrd laone will stop a user from editing the bootloader configuration during the boot process, it will not prevent a user from booting from and alterantive boot media such as optical disks or pen drives. Thus, it should be used with a BIOS password for a full protection.\nGRUB 2 version, things became more complicated to set a password. However, can take advantage of more advanced features, such as user-specific passwords.\nYou never edit grub.cfg directly; instead, modify the configuration files in /etc/grub.d and etc/default/grub and then run update-grub or grub2-mkconfig and same the new configuration file.\n","permalink":"https://nolleh.github.io/linux/18.local-security-principles/5.securing-the-boot-procss-and-hardware-resources/","summary":"Requiring Boot Loader Passwords You can secure the boot process with a secure epassword to prevent someone from bypassing the user authentication step. This can work in conjunction with password protection for the BIOS. Note that while using a bootloader passwrd laone will stop a user from editing the bootloader configuration during the boot process, it will not prevent a user from booting from and alterantive boot media such as optical disks or pen drives.","title":"5.securing the Boot Procss and Hardware Resources"},{"content":"How Passwords Are Stored The system verifies authenticity and identity using user credentials.\nOriginally, encrypted passwords wer stored in the /etc/passwd file, which was readable by everyone. this mde it rather easy for passwords to be craked.\nOn modern systems. passwords are actually stored in an encrypted format in a secondary file named etc/shadow Onyly those with root access can read or modify this file.\nPassword Encrpytion Protecting passwords has became a curucial element of security. Most Linux distributions rely on a modern password encryption algorithm called SHA-512 (Secure Hashing Algorithm 512 bits), developed by the U.S. National Security Agency (NSA) to encrypt passwords.\nThe SHA-512 algorithm is widely used for security applications and protocols. These security applications and protocols include TLS, SSL, PHP, SSH, S/MIME and IPSec. SHA-512 is one of the most tested hashing algorithms.\nfor example, if you wish to experiment with SHA-512 encoding, the word \u0026ldquo;test\u0026rdquo; can be encoded using the program sha512sum to produce the SHA-12 form\nGood Password Practices password aging by chage\nusers to set strong passwords by Pluggable Authentication Modules PAM configuration is implemented using a library called pam_cracklib.so, which can also be replaced by pam_passwdqc.so to take advantage of more options.\n","permalink":"https://nolleh.github.io/linux/18.local-security-principles/4.working-with-passwords/","summary":"How Passwords Are Stored The system verifies authenticity and identity using user credentials.\nOriginally, encrypted passwords wer stored in the /etc/passwd file, which was readable by everyone. this mde it rather easy for passwords to be craked.\nOn modern systems. passwords are actually stored in an encrypted format in a secondary file named etc/shadow Onyly those with root access can read or modify this file.\nPassword Encrpytion Protecting passwords has became a curucial element of security.","title":"4.working With Passwords"},{"content":"The sudoers File /etc/sudoers contains a lot of documentation in it about how to customize. Most Linux distributions now prefer you add a file in the directory etc/sudoers.d with a name the same as user.\nthis file contains the individual user\u0026rsquo;s sudo configuration, and one should leave the main configuration file untouched except for changeds that affect that affect all users.\nsudo commands and any failures are logged in \u0026hellip;\n/var/log/auth.log /var/log/messages /var/log/secure\nProcess Isolation Linux is considered to be more secure than many other operating systems because processes are naturally isolated from each other.\nOne process normally cannot access the resources of another process, even when that process is running with the same user privileges.\nLinux thus makes it difficult (though certainly not impossible) for viruses and security exploits to access and attack random resources on a system.\nMore recent additional security mechanisms that limit risks even further include:\nControl Groups (cgroups) Allows system administrators to group processes and associate finite resources to each cgroup. Containers Makes it possible to run multiple isolated Linux systems (containers) on a single system by relying on cgroup. Virtualization Hardware is emulated in such a way that not only can processes be isolated, but entire systems are run simultaneously as isolated and isulated guests(virtual machines) on one physical host. Hardware Device Accesses Linux limits user access to non-networking hardware devices in a manner that is extremely similar to regularfile access.\nApplications interact by engaging the filesystem layer (which is independent of the actual device or hardware the file resides on). This layer will then open a device special file (often called a device node) under the /dev directory that corresponds to the device being accessed.\nEach device special file has standard owner, group and world permission fields. Security is naturally enforced just as it when standard files are accessed.\nHard disks, for example, are represented as /dev/sd*. While a root user can read and write to the disk kin a raw fashion, for example, by doing something link:\n# echo hello world \u0026gt; /dev/sda1\nThe standard permissions, as shown in the figure, make it impssible for regular users to do so. Writing to a device in this fashion can easily obliterate the filesystem stored on it in a waay that cannot be repared without great effort, if at all. The normal reading and writing of files on the ahrd disk by applications is done at a higher level through the filesystem and never thorough direct access to the device node.\nkeeping Current when security problems in either the Linux kernel or applications and libraries are discovered, Linux distributions have a good record of reacting quickly and pushing out fixes to all systems by updating their software repositories and sending notifications to update immediately.\n","permalink":"https://nolleh.github.io/linux/18.local-security-principles/3.sudo-process-isolation-limiting-hardware-access-and-keeping-systems-current/","summary":"The sudoers File /etc/sudoers contains a lot of documentation in it about how to customize. Most Linux distributions now prefer you add a file in the directory etc/sudoers.d with a name the same as user.\nthis file contains the individual user\u0026rsquo;s sudo configuration, and one should leave the main configuration file untouched except for changeds that affect that affect all users.\nsudo commands and any failures are logged in \u0026hellip;","title":"3.sudo Process Isolation Limiting Hardware Access and Keeping Systems Current"},{"content":"User Accounts Linux kernel authenticated users to access files and applications.\nwhile each user is identified by a unique integer (the user id or UID), a separate database associates a username with each UID.\nTypes of Accounts By default, Linux distinguishes between several account types in order to isolate processes and workloads.\nLinux has fourtypes of accounts:\nroot System Normal Network For a safe working env, it is advised to grant minimum privileges possible and necessary to accounts, and remove inactive accounts.\nThe last utiltiy, which shows the last time each user logged into the system, can be used to help identify potentially inactive accounts which are candidates for system removal.\n","permalink":"https://nolleh.github.io/linux/18.local-security-principles/2.understanding-linux-security/","summary":"User Accounts Linux kernel authenticated users to access files and applications.\nwhile each user is identified by a unique integer (the user id or UID), a separate database associates a username with each UID.\nTypes of Accounts By default, Linux distinguishes between several account types in order to isolate processes and workloads.\nLinux has fourtypes of accounts:\nroot System Normal Network For a safe working env, it is advised to grant minimum privileges possible and necessary to accounts, and remove inactive accounts.","title":"2.understanding Linux Security"},{"content":"Working with PostScript and PDF PostScript is a standard page description language. it effectively manages scalilng of fonts and vector graphics to provide quality printouts.\nThe format itself is a language that Adobe developed in the early 1980s to enable the transfer of data to printers.\nFeature of PostScript are:\nit can be used on any printer that is PostScript-compatible, i.e., any modern printer. Any program that understands the PostScript specification can print to it. Information about page appearance, etc., is embedded in the page. Postscript has been, for most part, superseded by the PDF format (Portable Document Format), which produces far smaller files in a compressed format for which support has been integrated into many applications.\nHowever, one still has to deal with postscript documents, often as an intermediate format, on the way to producing file documents.\n","permalink":"https://nolleh.github.io/linux/17.printing/4.manipulating-postscript-and-pdf-files/","summary":"Working with PostScript and PDF PostScript is a standard page description language. it effectively manages scalilng of fonts and vector graphics to provide quality printouts.\nThe format itself is a language that Adobe developed in the early 1980s to enable the transfer of data to printers.\nFeature of PostScript are:\nit can be used on any printer that is PostScript-compatible, i.e., any modern printer. Any program that understands the PostScript specification can print to it.","title":"4.manipulating Postscript and Pdf Files"},{"content":"Printing on Linux printing itself requires software that converts information from application you are using to a language your printer can understand.\nThe Linux standard for printing software is the Common UNIX Printing System (CUPS)\nModern Linux desktop systems make installing and administering printers simple and intuitive.\nNevertheless, it is instructive to understand the underpinnings of how it is done in Linux.\nCUPS Overview CUPS interprets page descriptions produced by your application (put a paragraph here, draw a line there, and so forth) and then sends the information to the printer. it acts as a print server for both local and network printers.\nPrinters manufactured by different companies may use thire own particular print lnagues and formats. CUPS uses a modular printing system that accommodates a wide variety printers and also processes various data formats.\nConfiguration Files cupsd.conf and printers.conf\nall other CUPS-related configuration files are stored under the /etc/cups\ncupsd.conf is where most system-wide settings are located. it does not contain any printer-specific details.\nmost of the settings available in this file relate to network security\nprinters.conf is where you will find the printer-specific settings.\nJob Files /var/spool/cups commonly known as print queues\nLog Files /var/log/cups/ directory contains logfile that is used by scheduler to record activities that have taken place.\nFilters, Printer Drivers, and Backends CUPS uses filters to convert job file formats to printable formats. Printer drivers contain descriptions for currently connected / configured printers,\nand are usually store under /etc/cups/ppd/.\nThe print data is then sent to the printer through a filter, and via backend that helps to locate devices connected to the system.\n","permalink":"https://nolleh.github.io/linux/17.printing/2.configuration/","summary":"Printing on Linux printing itself requires software that converts information from application you are using to a language your printer can understand.\nThe Linux standard for printing software is the Common UNIX Printing System (CUPS)\nModern Linux desktop systems make installing and administering printers simple and intuitive.\nNevertheless, it is instructive to understand the underpinnings of how it is done in Linux.\nCUPS Overview CUPS interprets page descriptions produced by your application (put a paragraph here, draw a line there, and so forth) and then sends the information to the printer.","title":"2.configuration"},{"content":"$RANDOM: environment variable for\nperforming security-related tasks Reinitializing storage devices Erasing and/or obscuring existing data Generating meaningless data to be used for tests How the Kernel Generates Random Numbers Some servers have hardware random number generators that take as input different types of noise signals, such as thermal noise and photoelectric effect. A transducer converts this noise into an electric signal, which is again converted into a digital number by an A-D converter.\nflowchart LR noise[\u0026#34;noise signal(thermal noise, photoelectric effect)\u0026#34;]--\u0026gt;|transducer|electric[electric signal]--\u0026gt;|A-D converter|digit[digital number] However,most common computers do not contain such specialized hardware and,\ninstead, rely on events created during booting to create the raw data needed.\nRegardless of which of these tow sources is used, the system maintains a so-called entropy pool of these diginal numbers/randoms bits.\nrandom numbers created from this entropy pool\nLinux kernel offers\u0026hellip;\n/dev/random /dev/urandom which draw on the entropy pool to provide random numbers which are drawn from the estimated number of bits of noise in the entropy pool.\n/dev/urandom is faster compared with /dev/random which is used where very high-quality randomness is required (such as a one-time pad or key generation)\n/dev/random is blocked and does not generate any number until additional environmental noise is gathered when the entropy pool is empty, whereas /dev/urandom reuses the internal pool to produce more pseudo-random bits\n","permalink":"https://nolleh.github.io/linux/16.more-on-bash-shell-scripting/some-additional-useful-techniques/","summary":"$RANDOM: environment variable for\nperforming security-related tasks Reinitializing storage devices Erasing and/or obscuring existing data Generating meaningless data to be used for tests How the Kernel Generates Random Numbers Some servers have hardware random number generators that take as input different types of noise signals, such as thermal noise and photoelectric effect. A transducer converts this noise into an electric signal, which is again converted into a digital number by an A-D converter.","title":"Some Additional Useful Techniques"},{"content":"Basic Syntax and Special Characters Character Description # comment, shebang, # \\ nextline, escapecode ; used to interpret what follows as a new command to be executed $ environment variable \u0026gt; redirect output \u0026raquo; Append output \u0026lt; Redirect input | pipe the result into next command Putting Multiple Commands on a Single Line # run consequent command whether or not preceding one succeeded. $ make ; make install ; make clean # proceed next command only when preceding one succeeded. $ make \u0026amp;\u0026amp; make install \u0026amp;\u0026amp; make clean # if cat is succeed, then stop executing any further steps. $ cat file1 || cat file2 || cat file3 Script Parameters Parameter Meaning $0 script name $1, $2.. second, third parameter $* all parameter $# number of arguments Command Substitution $()\nExporting Environment Variables export with no arguments will give a list of all currently exported environment variables.\nFunction showmess() { echo My favorite Linux Distribution is: $1 } showmess Ubuntu ","permalink":"https://nolleh.github.io/linux/15.the-bash-shell-and-basic-scripting/3.syntax/","summary":"Basic Syntax and Special Characters Character Description # comment, shebang, # \\ nextline, escapecode ; used to interpret what follows as a new command to be executed $ environment variable \u0026gt; redirect output \u0026raquo; Append output \u0026lt; Redirect input | pipe the result into next command Putting Multiple Commands on a Single Line # run consequent command whether or not preceding one succeeded. $ make ; make install ; make clean # proceed next command only when preceding one succeeded.","title":"3.syntax"},{"content":"script\u0026rsquo;s return value is stored in the environment variable represented by $?:\necho $? ","permalink":"https://nolleh.github.io/linux/15.the-bash-shell-and-basic-scripting/2.features-and-capabilities/","summary":"script\u0026rsquo;s return value is stored in the environment variable represented by $?:\necho $? ","title":"2.features and Capabilities"},{"content":" Explain the features and capabilities of bash shell scripting. Know the basic syntax of scripting statements. Be famailiar with various methods and constructs used. Test for properties and existence of files and other objects. Use conditional statements, such as if-then-else blocks. Perform arithmetic operations using scripting language. ","permalink":"https://nolleh.github.io/linux/15.the-bash-shell-and-basic-scripting/1.introduction/","summary":" Explain the features and capabilities of bash shell scripting. Know the basic syntax of scripting statements. Be famailiar with various methods and constructs used. Test for properties and existence of files and other objects. Use conditional statements, such as if-then-else blocks. Perform arithmetic operations using scripting language. ","title":"1.introduction"},{"content":"FTP (File Transfer Protocol) FTP is a well-known and popular method for transferring files between computers using the internet. This method is built on a client-server model.\none of the oldest method of network data transfer, dating back to the early 1970s. As such, it is considered inadequate for modern needs, as well as begin intrinsically insecure. However, it is still in use and when security is not a concern (such as with so-called anonymous FTP) it can make sense. However, many websites, such kernel.org, have abandoned its use.\nFTP Clients passwords are user credentials that can be transmitted without encryption and are thus prone to interception. Thus, it was removed in favor of using rsync and web browser https access for example. An an alternative, sftp is a very secure mode of connection, which uses the Secure Shell (ssh) protocol, which we will discuss shortly. sftp encrpyts its data and thus sensitive information is transmitted more securely. However, it does not work with so-called anonymous FTP (guest user credentials).\nSSH: Executing Commands Remotely SSH is a cryptographic network protocol used for secure data communication.\nyou can also configure ssh to securely allow your remote access without typing a password each time.\nto run a command on a remote system via SSH, at the command prompt, you can type ssh some_system my_command\nCopying Files Securely with scp scp user@remotesystem:/home/user/\nyou can also configure scp so that it does not prompt for a password for each transfer.\nLab 14.1 Solution first, make certain your network is properly configured. if your Ethernet device is up and running, ifconfig should display something like\u0026hellip; if it does not show a device with an IP address, you may need to start or restart the network and/or NetworkManager.\nsudo systemctl restart NetworkManager sudo systemctl restart network sudo service NetworkManager restart sudo service network restart If your device was up but had no IP address, the above should have helped fix it, but you can try to get a fresh address with:\nsudo dhclient eth0 we should make sure you have a valid hostname assigned to your machine, with hostname: hostname name need to be connected to a known IP address. This is usually done employing the DNS server (Domain Name System) First, see if the site is up and reachable with ping\nsudo ping -c 3 google.com We have used sudo for ping; some recent Linux distributions have required this to avoid clueless or malicious users from flooding systems with such queries.\nping: unknown host google.com it is likely that something is wrong with your DNS setup. Note on some systems, you will never see the unknown host message, but you will get suspicious result like:\nsudo ping l89xl28vkjs.com PING l..com.site (127.0.53.53) 56(84) bytes of data. 64 bytes from 127.0.53.53: icmp_seq=1 ttl=64 time=0.016 ms where the 127.0.x.x address is a loop feeding back to the host machine you are on. you can eliminate this as being a valid address by doing:\n\u0026hellip;\nwhereas a correct result would look like:\nhost google.com google.com ahs address ... The above command utilizes the DNS server configured in /etc/resolv.conf on your machine. If you want to override that, you could do:\nhost google.com 8.8.8.8 you can also enter it in resolv.conf\nsuppose host or dig fail to connect the name to an IP address. There are many reasons DNS can fail, some of which are: the DNS server is down. In this case try pinging it to see if it is alive (you should have the IP address in /etc/resolv.conf) The server can be up and running, but DNS may not be currently available on the machine. Your route to the DNS server may not be correct. How can we test the route? Tracing the route to one of the public name server we menthioned before\nsudo traceroute 8.8.8.8 what if you only got the first line in the traceroute output? If this happens, most likely your default route is wrong. Try:\nip route show ","permalink":"https://nolleh.github.io/linux/14.network-operations/5.transferring-files/","summary":"FTP (File Transfer Protocol) FTP is a well-known and popular method for transferring files between computers using the internet. This method is built on a client-server model.\none of the oldest method of network data transfer, dating back to the early 1970s. As such, it is considered inadequate for modern needs, as well as begin intrinsically insecure. However, it is still in use and when security is not a concern (such as with so-called anonymous FTP) it can make sense.","title":"5.transferring Files"},{"content":"wget Large file downloads Recursive downloads, where a web page refers to other web pages and all are downloaded at once Password-required downloads Multiple file downloads curl Besides downloading, you may want to obtain information about a URL, such as the source code being used. curl can be used from the command line or a script to read such information.\n","permalink":"https://nolleh.github.io/linux/14.network-operations/4.browsers-wget-and-curl/","summary":"wget Large file downloads Recursive downloads, where a web page refers to other web pages and all are downloaded at once Password-required downloads Multiple file downloads curl Besides downloading, you may want to obtain information about a URL, such as the source code being used. curl can be used from the command line or a script to read such information.","title":"4.browsers Wget and Curl"},{"content":"more networking tools ethtool\nQueries network interfaces and can also set various parameters such as the speed netstat\noption r is for active connection nmap\nscans open ports on a networks; important for security analysis tcpdump\ndumps network traffic for anaysis iptraf\nmonitors network traffic in text mode mtr\ncombines functionality of ping and traceroute and gives a continuously updated display dig\nTests DNS workings;a good replacement for host and nslookup ","permalink":"https://nolleh.github.io/linux/14.network-operations/3.networking-configuration-and-tools/","summary":"more networking tools ethtool\nQueries network interfaces and can also set various parameters such as the speed netstat\noption r is for active connection nmap\nscans open ports on a networks; important for security analysis tcpdump\ndumps network traffic for anaysis iptraf\nmonitors network traffic in text mode mtr\ncombines functionality of ping and traceroute and gives a continuously updated display dig\nTests DNS workings;a good replacement for host and nslookup ","title":"3.networking Configuration and Tools"},{"content":"IPv4 and IPv6 IPv4 uses 32-bits for addresses;there are only 4.3 bilion unique addresses available.\nIPv6 uses 128-bits for addresses; this allows for 3.4 * 10^38 unique addresses.\nOne reason IPv4 has not disappeared is there are widely-used ways t o effectively make many more addresses available by methods such as NAT(Network Address Translation). NAT enables sharing one IP address among many locally connected computers, each of which has a unique address only seen on the local network.\nDecoding IPv4 Addresses A 32-bit IPv4 address is divided into four 8-bit sections called octets\nOctet is just another word for byte.\nClass A Network Addresses first bit of the first octet is always set to zero. As the use of the Internet expanded, B, C were added in order to accommodate the growing demand for independent networks.\n0| \u0026hellip;\nclass B 10: \u0026hellip;\nclass C 110: \u0026hellip; network bit is 21-bits (almost 2.1 million) these are most common for smaller networks which don\u0026rsquo;t have many unique hosts.\neach class C network can support up to 256 unique hosts.\nrange of host addresses is from 192.0.0.0 to 223.255.255.255\nIP Address Allocation Typecally, a range of IP addresses are requested from your Internet Service Provider (ISP) by your organization\u0026rsquo;s network administrator. Often, your choice of which class of IP address you are given depends on the size of your network and expected growth needs. If NAT is in operation, such as in a home network, you only get one externally visible address!\nName Resolution is used to convert numerical IP address values into a human-readable format known as the hostname.\nThe special hostname localhost is associated with the IP address 127.0.0.1 and describes the machine you are currently on (which normally has additional network-related IP addresses).\n","permalink":"https://nolleh.github.io/linux/14.network-operations/2.network-addresses-and-dns/","summary":"IPv4 and IPv6 IPv4 uses 32-bits for addresses;there are only 4.3 bilion unique addresses available.\nIPv6 uses 128-bits for addresses; this allows for 3.4 * 10^38 unique addresses.\nOne reason IPv4 has not disappeared is there are widely-used ways t o effectively make many more addresses available by methods such as NAT(Network Address Translation). NAT enables sharing one IP address among many locally connected computers, each of which has a unique address only seen on the local network.","title":"2.introduction to Networking"},{"content":" Explain basic networking concepts, including types of networks and addressing issues. Configure network interfaces and use basic networking utilities, such as ifconfig, ip, ping, route and traceroute Use grphical and non-graphical browsers, such as Lynx, w3m, Firefox, Chrome and Epiphany. Transfer files to and from clients and servers using both graphical and text mode applications, such as scp, ftp, sftp, curl and wget. ","permalink":"https://nolleh.github.io/linux/14.network-operations/1.introduction/","summary":" Explain basic networking concepts, including types of networks and addressing issues. Configure network interfaces and use basic networking utilities, such as ifconfig, ip, ping, route and traceroute Use grphical and non-graphical browsers, such as Lynx, w3m, Firefox, Chrome and Epiphany. Transfer files to and from clients and servers using both graphical and text mode applications, such as scp, ftp, sftp, curl and wget. ","title":"1.introduction"},{"content":"tr the tr utility is used to translate specified characters into other characters or to delete them.\ntr [options] set1 [set2] set1: to be replaced or removed set2: to be substituted for the characters listed in the first argument.\ntr \u0026lsquo;{}\u0026rsquo; \u0026lsquo;()\u0026rsquo; \u0026lt; inputfile \u0026gt; outputfile\ntranslate braces into parenthesis echo \u0026quot; \u0026hellip; \u0026quot; | tr [:space:] \u0026lsquo;\\t\u0026rsquo;\ntranslate white-space to tabs echo \u0026ldquo;This is for testing\u0026rdquo; | tr -s [:space:]\nsqueeze repetition of characters using -s echo \u0026ldquo;the geek stuff\u0026rdquo; | tr -d \u0026rsquo;t\u0026rsquo;\ndelete specified characters using -d option echo \u0026ldquo;my username is 432234\u0026rdquo; | tr -cd [:digit:]\ncomplement the sets using -c option tr -cd [:print:] \u0026lt; file.txt\nremove all non-printable character from a file tr -s \u0026lsquo;\\n\u0026rsquo; \u0026rsquo; \u0026rsquo; \u0026lt; file.txt\njoin all the lines in a file into a single file tee tee takes the output from any command, and, while sending it to standard output, it also saves it to a file. in other words, it tees the output stream from the command: one stream is displayed on the standard output and the other is saved to a file.\nwc wc -l: line wc -c: bytes wc -w: words\ncut cut -d\u0026quot; \u0026quot; -f3\n","permalink":"https://nolleh.github.io/linux/13.manipluating-text/7.miscellaneous-text-utilities/","summary":"tr the tr utility is used to translate specified characters into other characters or to delete them.\ntr [options] set1 [set2] set1: to be replaced or removed set2: to be substituted for the characters listed in the first argument.\ntr \u0026lsquo;{}\u0026rsquo; \u0026lsquo;()\u0026rsquo; \u0026lt; inputfile \u0026gt; outputfile\ntranslate braces into parenthesis echo \u0026quot; \u0026hellip; \u0026quot; | tr [:space:] \u0026lsquo;\\t\u0026rsquo;\ntranslate white-space to tabs echo \u0026ldquo;This is for testing\u0026rdquo; | tr -s [:space:]","title":"7.miscellaneous Text Utilities"},{"content":"grep grep [0-9] print the lines that contain the numbers 0 through 9 grep -C 3 [pattern] print context of lines (specified number of lines above and below the pattern) for matching the pattern. Here, the number of lines is specified as 3 strings strings is used to extract all character strings found in the file or files given as arguments. it is useful in locating human-readable content embedded in binary files; for text files one can just use grep\nstrings book1.xls | grep my_string grep -e ^ts -e st$ /etc/services ","permalink":"https://nolleh.github.io/linux/13.manipluating-text/6.grep/","summary":"grep grep [0-9] print the lines that contain the numbers 0 through 9 grep -C 3 [pattern] print context of lines (specified number of lines above and below the pattern) for matching the pattern. Here, the number of lines is specified as 3 strings strings is used to extract all character strings found in the file or files given as arguments. it is useful in locating human-readable content embedded in binary files; for text files one can just use grep","title":"6.grep"},{"content":"sort sort -k 3 sort the lines by the 3rd field on each line instead of the beginning sort -u equivalent to run uniq after sort\nuniq uniq removes duplicate consecutive lines in a text file and is useful for simplifying the text display uniq requires that the duplicate entries must be consecutive, one often runs sort first and then pipes the output into uniq;\nto count the number of duplicate entries, use the following command:\nuniq -c filename\npaste the different columns are identified based on delimiters (spacing used to separated two fields).\npaste accepts the following options:\nd delimiters, which specify a list of delimiters to be used instead of tabs for separating consecutive values on a single line.\nEach delimiter is used in turn; when the list has been exhuasted, paste begins again at the first delimiters -s, which causes paste to append the data in series rather than in parallel; that is, in a horizon rather than vertical fashion. classDiagram note \u0026#34;Robert Norton\\nTed Yelsky\u0026#34; note \u0026#34;E001 834-677-1367\\nE002 831-936-5892\u0026#34; note \u0026#34;Robert Norton E001 834-677-1367\\nTed Yelsky E002 831-936-5892\u0026#34; join can be used to combine the files without repeating the data of common columns.\nit first checks whether the files share common fields, such as names or phone numbers, and then joins the lines in two files based on a common field.\nsplit split is sued to break up (or split) a file into equal-sized segments for easier viewing and mnipulation, and is generally used only on relatively large files.\nregular expressions and search patterns pattern usage . any single char a|z a or z $ end of a line ^ beginning of a line * preceding item 0 or more times lab awk -F: \u0026#39;{print $7}\u0026#39; /etc/passwd | sort -u ","permalink":"https://nolleh.github.io/linux/13.manipluating-text/5.file-manipulation-utilities/","summary":"sort sort -k 3 sort the lines by the 3rd field on each line instead of the beginning sort -u equivalent to run uniq after sort\nuniq uniq removes duplicate consecutive lines in a text file and is useful for simplifying the text display uniq requires that the duplicate entries must be consecutive, one often runs sort first and then pipes the output into uniq;\nto count the number of duplicate entries, use the following command:","title":"5.file Manipulation Utilities"},{"content":"introduction to sed and awk many Linux users and administrators will write scripts using comprehensive scripting languages such as Python and perl,\nrather than use sed and awk. However, the utilitites that are described here are much lighter;i.e. they use fewer system resources,\nand execute faster.\nsed abbreviation for stream editor.\ndata from an input source/file (or stream) is taken and moved to a working space.\nthe entire list of operations/modifications is applied over the data in the working space and\nthe final contents are moved to the standard output space(or stream)\nsed command syntax command usage sed -e command specify editing commands at the command line, process input from ad file, and put the output on standard out sed -f scriptfile specify a script file containing sed commands, operate on file, and put output on standard out echo \u0026ldquo;I hate you\u0026rdquo; | sed s/hate/love/ usd sed to filter standard input, putting output on standard out the - e option allows you to specify multiple editing commands simultaneously at the command line.\nsed basic operations sed 1,3s/parttern/replace_string/g file\nsubstitute all string occurrences in a range of lines sed -i s/pattern/replace_string/g file\nsave changes for string substitution in the same file sed -e \u0026#39;s/01/JAN/\u0026#39; \\ -e \u0026#39;s/02/FEB/\u0026#39; \\ .... can change delimiter.\nsed s:/sbin/nologin:/bin/bash:g /etc/passwd awk awk is used to extract and then print specific contents of a file and is often used to construct reports.\nit is a powerful utility and interpreted programming language. it is used to manipulate data files, and for retrieving and processing text. it works well with fields (containing a single piece of data, essentially a column) and records (a collection of fields, essentially a line in a file) head - 10 /etc/passwd awk -F: \u0026#39;{print \u0026#34;name: \u0026#34;$1 shell: \u0026#34; $7}\u0026#39; /etc/passwd | head -10 the input file is read on line at a time, and, for each line, awk matches the given pattern in the given order and performs the requested action. the =F option allows you to specify a particulaar field separator characotr.\n","permalink":"https://nolleh.github.io/linux/13.manipluating-text/4.sed-and-awk/","summary":"introduction to sed and awk many Linux users and administrators will write scripts using comprehensive scripting languages such as Python and perl,\nrather than use sed and awk. However, the utilitites that are described here are much lighter;i.e. they use fewer system resources,\nand execute faster.\nsed abbreviation for stream editor.\ndata from an input source/file (or stream) is taken and moved to a working space.\nthe entire list of operations/modifications is applied over the data in the working space and","title":"4.sed and Awk"},{"content":"working with large files directly opening the file in an editor will probably be inefficient (due to high memory utilization) because most text editors usually try to read the whole file into memory first.\ninstead, one can use less to view the contents of such a large file, scrolling up and down page by page, without the system having to place the entire file in memory before starting.\nless somefile cat somefile | less head reads the first few lines\ntail viewing compressed files many standard command cannot be used directly. associated utilities often have the letter \u0026lsquo;z\u0026rsquo; prefiexed to their name.\nzcat, zless, zdiff, zgrep..\n","permalink":"https://nolleh.github.io/linux/13.manipluating-text/3.working-with-large-and-compressed-files/","summary":"working with large files directly opening the file in an editor will probably be inefficient (due to high memory utilization) because most text editors usually try to read the whole file into memory first.\ninstead, one can use less to view the contents of such a large file, scrolling up and down page by page, without the system having to place the entire file in memory before starting.\nless somefile cat somefile | less head reads the first few lines","title":"3.working With Large and Compressed Files"},{"content":"cat cat\nread / write / concatenate tac prints the lines of a file in reverse order. each line remains the same, but the order of lines is inverted. cat \u0026gt; file cat \u0026raquo; file (any subsequenet lines are appended to the file, until CTRL-D is typed)\nusing cat interactively echo -e option, along with the following switches, is used to enable special character sequences,\nsuch as the newline character or horizontal tab\n","permalink":"https://nolleh.github.io/linux/13.manipluating-text/2.cat-and-echo/","summary":"cat cat\nread / write / concatenate tac prints the lines of a file in reverse order. each line remains the same, but the order of lines is inverted. cat \u0026gt; file cat \u0026raquo; file (any subsequenet lines are appended to the file, until CTRL-D is typed)\nusing cat interactively echo -e option, along with the following switches, is used to enable special character sequences,\nsuch as the newline character or horizontal tab","title":"2.cat and Echo"},{"content":"elevating to root account sudo configuration files are stored in the /tec/sudoers file and in the /etc/sudoers.d directory. by default, the sudoers.d directory is empty\n","permalink":"https://nolleh.github.io/linux/12.user-environment/2.accounts-users-and-groups/","summary":"elevating to root account sudo configuration files are stored in the /tec/sudoers file and in the /etc/sudoers.d directory. by default, the sudoers.d directory is empty","title":"2.accounts,users and groups"},{"content":"filesystems lick /proc are called pseudo filesystems because they exist only in memory\n/var may be put in its own filesystem so that growth can be contained and not fatally affect the ststem\n/boot contains the basic files needed to boot the system\n","permalink":"https://nolleh.github.io/linux/10.file-operations/7.summary/","summary":"filesystems lick /proc are called pseudo filesystems because they exist only in memory\n/var may be put in its own filesystem so that growth can be contained and not fatally affect the ststem\n/boot contains the basic files needed to boot the system","title":"7.summary"},{"content":"1. Backing Up Data cp \u0026lt;-\u0026gt; rsync\nrsync is more efficient, because it checks if the file being copied already exists. rsync copies only the parts of files that have actually changed, it can be very fast cp can only copy files to and from destinations on the local machine (unless mounted using NFS), rsync can also be used to copy files from one machine to another. someone@host:path 2. Using rsync a very useful way to back up a project directory might be to use the following command.\nrsync -r project-X archive-machine:archives/project-X 3. Compressing Data command usage gzip bzip2 produces files significantly smaller than those produced by gzip xz the most space-efficient compression utility used in Linux zip is often required to examine and decompress archives from other operating systems tar utility is often used to group files in an archive and then compress the whole archive at once.\ntar Jczf mydir.tar.xz mydir tar xvf mydir.tar.xz 10. Disk-to-Disk Copying (dd) first 512 byte sector on the disk that contains a table describing the partitions on that disk.\ndd if=/dev/sda of=sda.mbr bs=512 count=1 ","permalink":"https://nolleh.github.io/linux/10.file-operations/5.backing-up-and-compressing-data/","summary":"1. Backing Up Data cp \u0026lt;-\u0026gt; rsync\nrsync is more efficient, because it checks if the file being copied already exists. rsync copies only the parts of files that have actually changed, it can be very fast cp can only copy files to and from destinations on the local machine (unless mounted using NFS), rsync can also be used to copy files from one machine to another. someone@host:path 2. Using rsync a very useful way to back up a project directory might be to use the following command.","title":"5.backing Up and Compressing Data"},{"content":"3. using the file utility in linux, a file\u0026rsquo;s extension does not, by default, ategorize its nature the way it might in other operating systems. for example, one cannot assume that a file named \u0026ldquo;file.txt\u0026rdquo; is a text file and not an executable program.\n6. Lab10.2: Using diff and patch diff -Naur original modified \u0026gt; original.patch patch original \u0026lt; original.patch ","permalink":"https://nolleh.github.io/linux/10.file-operations/4.comparing-files-and-file-types/","summary":"3. using the file utility in linux, a file\u0026rsquo;s extension does not, by default, ategorize its nature the way it might in other operating systems. for example, one cannot assume that a file named \u0026ldquo;file.txt\u0026rdquo; is a text file and not an executable program.\n6. Lab10.2: Using diff and patch diff -Naur original modified \u0026gt; original.patch patch original \u0026lt; original.patch ","title":"4.comparing Files and File Types"},{"content":"A special shorthand notation can send anything written to file descriptor 2 (stderr) to the same place as file descriptor 1 (stdout): 2\u0026gt;\u0026amp;1.\n$ do_something \u0026gt; all-output-file 2\u0026gt;\u0026amp;1\nbash permits an easier syntax for the above:\n$ do_something \u0026gt;\u0026amp; all-output-file\nin pipe\u0026hellip; $ command1 | command2 | command3\nThe above represents what we often call a pipeline, and allows Linux to combine the actions of several commands into one. This is extraordinarily efficient because command2 and command3 do not have to wait for the previous pipeline commands to complete before they can begin processing at the data in their input streams\nfind .. $ find -name \u0026ldquo;*.swp\u0026rdquo; -exec rm {} ’;’\n{} is placeholder the file name will fill\n","permalink":"https://nolleh.github.io/linux/7.command-line-operations/searching-for-files/","summary":"A special shorthand notation can send anything written to file descriptor 2 (stderr) to the same place as file descriptor 1 (stdout): 2\u0026gt;\u0026amp;1.\n$ do_something \u0026gt; all-output-file 2\u0026gt;\u0026amp;1\nbash permits an easier syntax for the above:\n$ do_something \u0026gt;\u0026amp; all-output-file\nin pipe\u0026hellip; $ command1 | command2 | command3\nThe above represents what we often call a pipeline, and allows Linux to combine the actions of several commands into one. This is extraordinarily efficient because command2 and command3 do not have to wait for the previous pipeline commands to complete before they can begin processing at the data in their input streams","title":"Searching For Files"},{"content":"the system actually provide display settings, is uses /etc/x11/xorg.conf\nin recent linux, the file usually present in unusual cricumstatnce such as when cirtain Less\ncommon graphic drivers are in use.\nchanging the file is usually for more advanced users.\nNetwork Time Protocol the Network Time Protocol is most popular and reliable protocol for setting local time by consulting established internet servers.\nstudent:/tmp\u0026gt; $ xdpyinfo | grep dim dimensions: 3200x1080 pixels (847x286 millimeters) ","permalink":"https://nolleh.github.io/linux/5.system-configuration-from-the-graphical-interface/2.system-display-date-and-time-settings/","summary":"the system actually provide display settings, is uses /etc/x11/xorg.conf\nin recent linux, the file usually present in unusual cricumstatnce such as when cirtain Less\ncommon graphic drivers are in use.\nchanging the file is usually for more advanced users.\nNetwork Time Protocol the Network Time Protocol is most popular and reliable protocol for setting local time by consulting established internet servers.\nstudent:/tmp\u0026gt; $ xdpyinfo | grep dim dimensions: 3200x1080 pixels (847x286 millimeters) ","title":"2.system Display Date and Time Settings"},{"content":"apply system, display, timesetting.. track the network settings and manage connections using network manager in linux. install and update software in linux from a graphical interface.\n","permalink":"https://nolleh.github.io/linux/5.system-configuration-from-the-graphical-interface/1.learning-objectives/","summary":"apply system, display, timesetting.. track the network settings and manage connections using network manager in linux. install and update software in linux from a graphical interface.","title":"1.learning Objectives"},{"content":"라즈베리파이에서 우분투를 설치해서 사용하고 있는데, 인터넷 속도가 어마하게 느린 이슈가 있다.\n거기서 개선을 위해 시도해본 것들에 대해 기록할 예정.\n##1. iwconfig\n일단 다음은 확실히 효용이 있는 것으로 보임.\n60mb -\u0026gt; 140mb 정도로 개선됨.\nsudo iwconfig wlan0 power off ##2. zram\n그리고나서, zswap 대신 zram 을 사용하도록 변경.\nsudo apt install -y linux-modules-extra-raspi sudo apt install -y zram-tools sudo apt autoremove --purge -y zram-config sudo nvim /etc/default/zramswap 에디터는 어떤걸 사용해도 상관없지만, nvim 사용하고 있어서 그걸로 세팅. 해당 설정파일에서 다음 데이터들 세팅. (대부분 주석처리 되어있는걸 푸는 형태)\nALGO=zstd PERCENT=50 PRIORITY=100\n##3. use GOOGLE DNS server\nISP 제공자들의 DNS 서버가 느리기때문에, 구글의 DNS 를 사용하도록 설정\nsetting -\u0026gt; DNS : IPv4: 8.8.4.4, 8.8.8.8 IPv6 DNS : 2001:4860:4860::8888, 2001:4860:4860::8844\n##4. Nala mirror\nsudo apt install nala sudo nala fetch 여기까지 설정을 하고 나니 200Mbps 정도 나오고, 크롬탭 몇개 켜놔도 (4개) + tmux + alacritty 돌리는데 무리없는 수준이 됨. cpu 항상 100% 치고 있었는데\n60~70% 정도 수준.\ncf. https://teejeetech.com/2022/06/04/tweaks-for-ubuntu-22-04-on-raspberry-pi-4/\n","permalink":"https://nolleh.github.io/ubuntu/optimize-speed/","summary":"라즈베리파이에서 우분투를 설치해서 사용하고 있는데, 인터넷 속도가 어마하게 느린 이슈가 있다.\n거기서 개선을 위해 시도해본 것들에 대해 기록할 예정.\n##1. iwconfig\n일단 다음은 확실히 효용이 있는 것으로 보임.\n60mb -\u0026gt; 140mb 정도로 개선됨.\nsudo iwconfig wlan0 power off ##2. zram\n그리고나서, zswap 대신 zram 을 사용하도록 변경.\nsudo apt install -y linux-modules-extra-raspi sudo apt install -y zram-tools sudo apt autoremove --purge -y zram-config sudo nvim /etc/default/zramswap 에디터는 어떤걸 사용해도 상관없지만, nvim 사용하고 있어서 그걸로 세팅.","title":"Optimize Speed"},{"content":"apt-get install neovim 과 같은 방법으로는 최신 버전을 설치 할 수 없다.\n최신버전을 설치하려면, 다음 과정을 거쳐야한다.\ncf.https://github.com/neovim/neovim/wiki/Installing-Neovim\nsudo apt-get install software-properties-common\n이 명령어를 선행해줘야할 수도 있다. sudo apt-get remove neovim -y sudo add-apt-repository ppa:neovim-ppa/stable sudo apt-get update -y sudo apt-get install neovim -y https://launchpad.net/~neovim-ppa/+archive/ubuntu/unstable\nppa archive 를 살펴보고 원하는 아키텍쳐 / 버전이 없는경우 unstable 버전에서 찾아서 다시 반복해볼 필요가 있다. 다행히 unstable 버전은 ubuntu 23.04 를 지원하는게 있어서 받아서 씀\u0026hellip;\nsudo add-apt-repository ppa:neovim-ppa/unstable\n이렇게 설치하고 나면, NvChad 를 세팅해보자.\ngit clone https://github.com/NvChad/NvChad ~/.config/nvim \u0026ndash;depth 1 \u0026amp;\u0026amp; nvim\nnvim 을 실행해보면 에러가 발생한다. (LuaJit)\nsnap 을 사용하는게 깔끔한듯.\nsudo snap install \u0026ndash;beta nvim \u0026ndash;classic\nsnap version 도 bytecode 관련한 에러 발생..\n몇가지 시도들이 수포로 돌아가면서\u0026hellip; 결국 neovim을 직접 빌드하기로 했다\u0026hellip;\nclang/gcc, cmake \u0026gt; 3.10 의 prerequstion 과 ninja-build,gettext\n정도 추가로 설치해서 문서에 기술된대로 make CMAKE_BUILD_TYPE=RelWithDebInfo 로 빌드, 그리고 sudo make install\n결과는\u0026hellip;. snap version 과 동일하다\u0026hellip;.\nNvChad 이슈를 뒤져보니\n","permalink":"https://nolleh.github.io/ubuntu/neovim/","summary":"apt-get install neovim 과 같은 방법으로는 최신 버전을 설치 할 수 없다.\n최신버전을 설치하려면, 다음 과정을 거쳐야한다.\ncf.https://github.com/neovim/neovim/wiki/Installing-Neovim\nsudo apt-get install software-properties-common\n이 명령어를 선행해줘야할 수도 있다. sudo apt-get remove neovim -y sudo add-apt-repository ppa:neovim-ppa/stable sudo apt-get update -y sudo apt-get install neovim -y https://launchpad.net/~neovim-ppa/+archive/ubuntu/unstable\nppa archive 를 살펴보고 원하는 아키텍쳐 / 버전이 없는경우 unstable 버전에서 찾아서 다시 반복해볼 필요가 있다. 다행히 unstable 버전은 ubuntu 23.04 를 지원하는게 있어서 받아서 씀\u0026hellip;","title":"Neovim"},{"content":"/etc/default/keyboard\nOption \u0026ldquo;XkbModel\u0026rdquo; \u0026ldquo;kr106\u0026rdquo; Option \u0026ldquo;XkbLayout\u0026rdquo; \u0026ldquo;kr\u0026rdquo;\n","permalink":"https://nolleh.github.io/ubuntu/kblayout/","summary":"/etc/default/keyboard\nOption \u0026ldquo;XkbModel\u0026rdquo; \u0026ldquo;kr106\u0026rdquo; Option \u0026ldquo;XkbLayout\u0026rdquo; \u0026ldquo;kr\u0026rdquo;","title":"Kblayout"},{"content":"mac 에서는, diskutil 과 dd 를 사용해서 microSD 카드를(disk) 포멧 할 수 있다.\ndisk utility 라는 GUI 툴도 있는데, 파티셔닝 되어있던 애를 이걸 통해서 지웠더니 뭔갈 잘못한건지 절반정도의 디스크용량이 날아가 버렸다 ㅡㅡ;;;\n32GB 짜리 SD 카드가 반토막 난 격이라;; dd 와 fdisk 를 활용해서 뭔가 다시 복구하려는 삽질기가 되시겠다\u0026hellip;\n$ diskutil list output\n/dev/disk5 (external, physical): #: TYPE NAME SIZE IDENTIFIER 0: *15.9 GB disk5 format 하려면\n$ diskutil umount $ sudo dd if=/dev/zero of=/dev/{dev-name} bs=1M status=progress ## this is really long term work 되-게 오래 걸리는 작업이라서, 잊지 말고status=progress 옵션을 사용하는 것을 권장 한다. (status 를 안켜고 몇 번 돌리다가 인내하지 못하고 Ctrl + c 를 두 번이나 누르게 되었다\u0026hellip; )\npartition\n$ sudo fdisk /dev/sdc $ ","permalink":"https://nolleh.github.io/cli/diskutil/","summary":"mac 에서는, diskutil 과 dd 를 사용해서 microSD 카드를(disk) 포멧 할 수 있다.\ndisk utility 라는 GUI 툴도 있는데, 파티셔닝 되어있던 애를 이걸 통해서 지웠더니 뭔갈 잘못한건지 절반정도의 디스크용량이 날아가 버렸다 ㅡㅡ;;;\n32GB 짜리 SD 카드가 반토막 난 격이라;; dd 와 fdisk 를 활용해서 뭔가 다시 복구하려는 삽질기가 되시겠다\u0026hellip;\n$ diskutil list output\n/dev/disk5 (external, physical): #: TYPE NAME SIZE IDENTIFIER 0: *15.9 GB disk5 format 하려면\n$ diskutil umount $ sudo dd if=/dev/zero of=/dev/{dev-name} bs=1M status=progress ## this is really long term work 되-게 오래 걸리는 작업이라서, 잊지 말고status=progress 옵션을 사용하는 것을 권장 한다.","title":"Diskutil"},{"content":"Overview in data driven application\u0026rsquo;s poorly designed indexes and a lack of indexes are primary sources bottlenecks. As databases grow in size, finding efficient ways to retrieve and manipluate data becomes increasingly important. Basics of Indexing a database index serves a similar purporse in that of book, speeding up data retrieval without needing to scan every row in a database table\nthe structure of a database index includes an ordered list of values, with each value connected to pointers leading to data pages where these alues reside.\nindexes are typically stored on disk. they are associated with a table to speed up data retrieval. keys made from one or more columns in the table make up the index, which , for most releational database, are stored in B+ tree structure. this structure allows the database to locate associated rows efficiently.\nfinding the right indexes for a database is a balancing act between quick query responses and update costs. Narrow indexes, or those with fewer columns, save on disk apace and mainteneance, while whide indexes cater to a borader range of queries. often, it requires several iterations of designs to find the most efficient index.\nIN its siplest form, an index is stored table that allows for searches to be conducted in O(Log N) imte complexcity uisng binary search on a stored data structure.\nPrimer on B+ Tree understanding it requires some background on its predesessor, ths B-Tree\nThe B-Tree, or Balanced Tree, is a self-balancing tree data structure that maintains stored data and allows for efficient insertion. deletion, and search operation.\n","permalink":"https://nolleh.github.io/mysql/indexing-strategies/","summary":"Overview in data driven application\u0026rsquo;s poorly designed indexes and a lack of indexes are primary sources bottlenecks. As databases grow in size, finding efficient ways to retrieve and manipluate data becomes increasingly important. Basics of Indexing a database index serves a similar purporse in that of book, speeding up data retrieval without needing to scan every row in a database table\nthe structure of a database index includes an ordered list of values, with each value connected to pointers leading to data pages where these alues reside.","title":"Indexing Strategies"},{"content":"패키지를 만들때 기본 구성\n{ \u0026#34;main\u0026#34;: \u0026#34;./dist/cjs/index.js\u0026#34;, \u0026#34;types\u0026#34;: \u0026#34;./dist/cjs/types/index.d.ts\u0026#34;, \u0026#34;files\u0026#34;: [\u0026#34;dist/**/*\u0026#34;], \u0026#34;scripts\u0026#34;: { \u0026#34;clean\u0026#34;: \u0026#34;rm -rf ./dist\u0026#34;, \u0026#34;build\u0026#34;: \u0026#34;pnpm run clean \u0026amp;\u0026amp; pnpm build:esm \u0026amp;\u0026amp; pnpm build:cjs\u0026#34;, \u0026#34;build:esm\u0026#34;: \u0026#34;tsc -p ./tsconfig.esm.json \u0026amp;\u0026amp; mv dist/esm/index.js dist/esm/index.mjs\u0026#34;, \u0026#34;build:cjs\u0026#34;: \u0026#34;tsc -p ./tsconfig.cjs.json\u0026#34;, \u0026#34;prepack\u0026#34;: \u0026#34;pnpm build\u0026#34; }, \u0026#34;repository\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;git\u0026#34;, \u0026#34;url\u0026#34;: \u0026#34;https://github.com/nolleh/serialize-interceptor\u0026#34; }, \u0026#34;keywords\u0026#34;: [ \u0026#34;nestjs\u0026#34;, \u0026#34;nest.js\u0026#34;, \u0026#34;serialize\u0026#34;, \u0026#34;deserialize\u0026#34;, \u0026#34;camel\u0026#34;, \u0026#34;snake\u0026#34;, \u0026#34;json\u0026#34;, \u0026#34;dto\u0026#34;, \u0026#34;transform\u0026#34; ], \u0026#34;exports\u0026#34;: { \u0026#34;.\u0026#34;: { \u0026#34;import\u0026#34;: { \u0026#34;types\u0026#34;: \u0026#34;./dist/esm/types/index.d.ts\u0026#34;, \u0026#34;default\u0026#34;: \u0026#34;./dist/esm/index.mjs\u0026#34; }, \u0026#34;require\u0026#34;: { \u0026#34;types\u0026#34;: \u0026#34;./dist/cjs/types/index.d.ts\u0026#34;, \u0026#34;default\u0026#34;: \u0026#34;./dist/cjs/index.js\u0026#34; } } } } main/types/files { \u0026#34;main\u0026#34;: \u0026#34;./dist/cjs/index.js\u0026#34;, \u0026#34;types\u0026#34;: \u0026#34;./dist/cjs/types/index.d.ts\u0026#34;, \u0026#34;files\u0026#34;: [\u0026#34;dist/**/*\u0026#34;] } 이 패키지의 entry point 는 무엇인지에 대한 정보인지가 main 에, 그 타입에 대한 정보가 types 에, 어떤 파일들이 패포 될 것인지에 대한 정보가 files 로 기입된다. 여기서 files 는, whitelist 로써 동작하며, 가장 높은 우선순위를 보유한 것으로 알고 있음.\nscripts { \u0026#34;build\u0026#34;: \u0026#34;pnpm run clean \u0026amp;\u0026amp; pnpm build:esm \u0026amp;\u0026amp; pnpm build:cjs\u0026#34;, \u0026#34;build:esm\u0026#34;: \u0026#34;tsc -p ./tsconfig.esm.json \u0026amp;\u0026amp; mv dist/esm/index.js dist/esm/index.mjs\u0026#34;, \u0026#34;build:cjs\u0026#34;: \u0026#34;tsc -p ./tsconfig.cjs.json\u0026#34; } esm 을 사용하는 모듈에서 사용될 빌드 파일과 cjs 을 사용하는 모듈 각각에 대해 별도 배포 파일을 생성하기 위해 빌드 설정을 분리한다. build 명령어를 통해서는 양쪽 모두를 빌드한다. ESModule 쪽에서는 mjs extension 을 사용하기 위해 mv 도 잊지 말것.\nrepository / keywords meta information. npmjs.com 등에서 노출 될 때 사용되는 정보.\nexports exports 에 대한 기본 설명 - exports subpath exports 없이는 사용처에서 추가적으로 dist 를 참조해야하는 상황이 발생할 수 있는데, (main 은 index.js 만 지정하기 때문에.)\nex. import { a } form \u0026lsquo;serialize-interceptor/dist/a\u0026rsquo;;\nor\nimport { a } from \u0026lsquo;serialize-interceptor/nested/a\u0026rsquo;\nwhen directory structure is..\n/nested a.ts index.ts\nsubpath 를 배포하기 위해서는 exports 에 추가로 작성하는 형태로 접근가능.\n기본 구문:\n{ exports: { \u0026#34;.\u0026#34;: \u0026#34;./dist/index.js\u0026#34; \u0026#34;./nested\u0026#34;: \u0026#34;./dist/nested/index.js\u0026#34; } } exports - conitional exports 여기서 모듈 시스템에 따른 conditional exports 확장\n","permalink":"https://nolleh.github.io/npm/how-to-make-package/","summary":"패키지를 만들때 기본 구성\n{ \u0026#34;main\u0026#34;: \u0026#34;./dist/cjs/index.js\u0026#34;, \u0026#34;types\u0026#34;: \u0026#34;./dist/cjs/types/index.d.ts\u0026#34;, \u0026#34;files\u0026#34;: [\u0026#34;dist/**/*\u0026#34;], \u0026#34;scripts\u0026#34;: { \u0026#34;clean\u0026#34;: \u0026#34;rm -rf ./dist\u0026#34;, \u0026#34;build\u0026#34;: \u0026#34;pnpm run clean \u0026amp;\u0026amp; pnpm build:esm \u0026amp;\u0026amp; pnpm build:cjs\u0026#34;, \u0026#34;build:esm\u0026#34;: \u0026#34;tsc -p ./tsconfig.esm.json \u0026amp;\u0026amp; mv dist/esm/index.js dist/esm/index.mjs\u0026#34;, \u0026#34;build:cjs\u0026#34;: \u0026#34;tsc -p ./tsconfig.cjs.json\u0026#34;, \u0026#34;prepack\u0026#34;: \u0026#34;pnpm build\u0026#34; }, \u0026#34;repository\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;git\u0026#34;, \u0026#34;url\u0026#34;: \u0026#34;https://github.com/nolleh/serialize-interceptor\u0026#34; }, \u0026#34;keywords\u0026#34;: [ \u0026#34;nestjs\u0026#34;, \u0026#34;nest.js\u0026#34;, \u0026#34;serialize\u0026#34;, \u0026#34;deserialize\u0026#34;, \u0026#34;camel\u0026#34;, \u0026#34;snake\u0026#34;, \u0026#34;json\u0026#34;, \u0026#34;dto\u0026#34;, \u0026#34;transform\u0026#34; ], \u0026#34;exports\u0026#34;: { \u0026#34;.\u0026#34;: { \u0026#34;import\u0026#34;: { \u0026#34;types\u0026#34;: \u0026#34;./dist/esm/types/index.d.ts\u0026#34;, \u0026#34;default\u0026#34;: \u0026#34;.","title":"How to Make Package"},{"content":"Writing Plugin 제목은 거창하게 썼지만, 플러그인이나 rc 파일 작성에 필요한 지식들을 메모해 둘 예정.\nPreview Window :botright pedit { file } :botright pedit Preview Window 에서 라인 출력 function! showInPreview(name, fileType, lines) let l:command = \u0026#34;silent! pedit! +setlocal\\\\ \u0026#34; . \\ \u0026#34;buftype=nofile\\\\ nobuflisted\\\\ \u0026#34; . \\ \u0026#34;noswapfile\\\\ nonumber\\\\ \u0026#34; . \\ \u0026#34;filetype=\u0026#34; . a:fileType . \u0026#34; \u0026#34; . a:name exe l:command if has(\u0026#39;nvim\u0026#39;) let l:bufNr = bufnr(a:name) call nvim_buf_set_lines(l:bufNr, 0, -1, 0, a:lines) else call setbufline(a:name, 1, a:lines) endif endfunction stackExchange\n이 함수는 프리뷰에 stdin 으로 데이터를 노출할 방법이 없을까 검색하다가 찾은 snippet 인데,\ncall ShowInPreview(\u0026#39;this-is-test\u0026#39;, \u0026#39;sql\u0026#39;, \u0026#39;SELECT 0\u0026#39;) 와 같은 구문으로 실행해보면 별도 파일없이 프리뷰에 데이터를 출력가능하다. 1번째는 버퍼이름, 두번째는 해당 버퍼에대한 파일 타입 정보를 전달하는 형태로 보여서 해당 펑션을 선언후에 파라미터들은 미리 정해놓고 shortcut 매핑을 해놓고 세번째 \u0026lsquo;내용\u0026rsquo; 만 전달하는 형태로 사용하면 꽤 쓸만할 것 같다.\n문제는 그 내용을 유의미한 데이터를 얻어오는건데..\npipe plugin 이 쉘 명령어를 실행하고 이 결과를 프리뷰에 노출하는 형태로 구성되어있다. ANSI color 코드랑 결합하면 왜인지 제대로 동작을안한다. (두번째부터) 사실 그걸 디버그하려고 프리뷰 윈도우에 대해서 찾아보기 시작한건데 잘 안되네.\n삽질기는 To Be Continued\u0026hellip;\n","permalink":"https://nolleh.github.io/vim/writing-plugin/","summary":"Writing Plugin 제목은 거창하게 썼지만, 플러그인이나 rc 파일 작성에 필요한 지식들을 메모해 둘 예정.\nPreview Window :botright pedit { file } :botright pedit Preview Window 에서 라인 출력 function! showInPreview(name, fileType, lines) let l:command = \u0026#34;silent! pedit! +setlocal\\\\ \u0026#34; . \\ \u0026#34;buftype=nofile\\\\ nobuflisted\\\\ \u0026#34; . \\ \u0026#34;noswapfile\\\\ nonumber\\\\ \u0026#34; . \\ \u0026#34;filetype=\u0026#34; . a:fileType . \u0026#34; \u0026#34; . a:name exe l:command if has(\u0026#39;nvim\u0026#39;) let l:bufNr = bufnr(a:name) call nvim_buf_set_lines(l:bufNr, 0, -1, 0, a:lines) else call setbufline(a:name, 1, a:lines) endif endfunction stackExchange","title":"Writing Plugin"},{"content":"Graphical Desktop Graphical Desktop CLI or GUI.\nGUI is quick and easy.\nfor repeated tasks, the CLI is often more efficient, while the GUI is easier to navigate if you do not remember all the details or do something only rarely.\nX Window System X window system is loaded as one of the final steps in boot process. It is often just called X.\nA service called the Display Manager keeps track of displays being provided and loads the X server (so-called, because it provides graphical services to applications, sometimes called X clients.)\nthe display manager also handles graphical logins and starts the appropriate desktop environment after a user logs in.\nX is rather old software; A newer system, known as Wayland, is gradually supersending it and is the default display system in Fedora, RHEL 8, and other recent distributions. For the most part, it looks just like X to the user, although under hood it is quite different.\nMore About the Graphical Desktop A desktop environment consists of a session manager, window manager, and A set of utilities.\nif the display manager is not started by default in the default runlevel, you can start the grphical desktop different way, by running startx from the commandline .\nGUI StartUp when you install a desktop env, the display manager starts at the end of the boot process. the default display manager for GNOME is called gdm\nGraphical Desktop Background Each Linux distribution comes with tis own set of desktop backgrounds. you can change the default by choosing a new wallpaper or selecting a custom picture to be set as the desktop background.\nIn addition, you can also change the desktop theme, which changes the look and feel of the Linux system.\n","permalink":"https://nolleh.github.io/linux/4.graphical-interface/2.graphical-desktop/","summary":"Graphical Desktop Graphical Desktop CLI or GUI.\nGUI is quick and easy.\nfor repeated tasks, the CLI is often more efficient, while the GUI is easier to navigate if you do not remember all the details or do something only rarely.\nX Window System X window system is loaded as one of the final steps in boot process. It is often just called X.\nA service called the Display Manager keeps track of displays being provided and loads the X server (so-called, because it provides graphical services to applications, sometimes called X clients.","title":"4-2.graphical Desktop"},{"content":"Graphical interface Learning Objectives By the end of this chapter, you should be able to:\nManage graphical interface sessions. Perform basic operations using the graphical interface. Change the graphical desktop to suit your needs. ","permalink":"https://nolleh.github.io/linux/4.graphical-interface/1.introduction/","summary":"Graphical interface Learning Objectives By the end of this chapter, you should be able to:\nManage graphical interface sessions. Perform basic operations using the graphical interface. Change the graphical desktop to suit your needs. ","title":"4-1.introduction"},{"content":"Summary Chapter Summary A partition is a logical part of the disk. A filesystem is a method of storing/finding files on a hard disk. By dividing the hard disk into partitions, data can be grouped and separated as needed. When a failure or mistake occurs, only the data in the affected partition will be damaged, while the data on the other partitions will likely survive. The boot process has multiple steps, starting with BIOS, which triggers the boot loader to start up the Linux kernel. From there, the initramfs filesystem is invoked, which triggers the init program to complete the startup process. Determining the appropriate distribution to deploy requires that you match your specific system needs to the capabilities of the different distributions. ","permalink":"https://nolleh.github.io/linux/3.linux-basics-and-system-startup/6.summary/","summary":"Summary Chapter Summary A partition is a logical part of the disk. A filesystem is a method of storing/finding files on a hard disk. By dividing the hard disk into partitions, data can be grouped and separated as needed. When a failure or mistake occurs, only the data in the affected partition will be damaged, while the data on the other partitions will likely survive. The boot process has multiple steps, starting with BIOS, which triggers the boot loader to start up the Linux kernel.","title":"3-6.summary"},{"content":"Linux Distribution Installation Choosing a Linux Distribution Questions to Ask when Choosing a Distribution What is the main function of the system (server or desktop)? What types of packages are important to the organization? For example, web server, word processing, etc. How much hard disk space is required and how much is available? For example, when installing Linux on an embedded device, space is usually constrained. How often are packages updated? How long is the support cycle for each release? For example, LTS releases have long-term support. Do you need kernel customization from the vendor or a third party? What hardware are you running on? For example, it might be X86, ARM, PPC, etc. Do you need long-term stability? Can you accept (or need) a more volatile cutting edge system running the latest software? Linux Installation: Planning the partition layout needs to be decieded at the time of installation. and you can always modify the design later, it is always easier to try and get it right to begin with.\nLinux Installation: Software Choices All installing include the bare minimum software for running a Linux distribution.\nMost installers also provide options for adding categories of software.\nAll installers set up some initial security features on the new system.\nIn some cases (such as Ubuntu), only an initial user is set up; direct root login is not configured and root access requires loggin in first as a normal user and then using sudo.\nLinux Installation: Install Source Many installers can do an installation completely automatically, using a configuration file to specify installation options.\nThis file is called a Kickstart file for Red Hat-based systems, an AutoYAST profile for SUSE-based systems, and Preseed file for Debian-based systems.\n","permalink":"https://nolleh.github.io/linux/3.linux-basics-and-system-startup/5.linux-distribution-installation/","summary":"Linux Distribution Installation Choosing a Linux Distribution Questions to Ask when Choosing a Distribution What is the main function of the system (server or desktop)? What types of packages are important to the organization? For example, web server, word processing, etc. How much hard disk space is required and how much is available? For example, when installing Linux on an embedded device, space is usually constrained. How often are packages updated?","title":"3-5.linux Distribution Installation"},{"content":"3-4. Linux FileSystem Basics Linux FileSystem Conventional disk filesystems: ext3, ext4, XFS, Btrfs, JFS, NTFS, vfat, exfat, etc. Flash storage filesystems: ubifs, jffs2, yaffs, etc. Database filesystems Special purpose filesystems: procfs, sysfs, tmpfs, squashfs, debugfs, fuse, etc. Partitions and Filesystems A partition is physically contiguous section of disk, or what appears to be so in some advanced setups.\nA filesystem is a method of storing/finding files on the hard disk (usually in a partition).\nOne can think of a partition as a container in which a filesystem resides, although in some circumstances,\na filesystem can span more than one partition if one uses symbolic links, which we will discuss much later.\nA comparison between filesystems in Windows and Linux is given in the accompanying table:\nWindows Linux Partition Disk1 /dev/sda1 Filesystem Type NTFS/VFAT EXT3/EXT4/XFS/BTRFS\u0026hellip; Mounting Parmeters DriveLetter MountPoint Base Folder (where OS is stored) C:\\ / The Filesystem Hierarchy Standard Linux system store their important files according to a standard layout called the Filesystem Hierarchy Standard (FHS), Having a starndard is designed to ensure that users, administrators, and developers can move between distributions without having to re-learn how the system is organized.\nMore About the Filesystem Hierarchy Standard All linux filesystem names are case-sensative.\n","permalink":"https://nolleh.github.io/linux/3.linux-basics-and-system-startup/4.linux-filesystem-basics/","summary":"3-4. Linux FileSystem Basics Linux FileSystem Conventional disk filesystems: ext3, ext4, XFS, Btrfs, JFS, NTFS, vfat, exfat, etc. Flash storage filesystems: ubifs, jffs2, yaffs, etc. Database filesystems Special purpose filesystems: procfs, sysfs, tmpfs, squashfs, debugfs, fuse, etc. Partitions and Filesystems A partition is physically contiguous section of disk, or what appears to be so in some advanced setups.\nA filesystem is a method of storing/finding files on the hard disk (usually in a partition).","title":"3-4.linux Filesystem Basics"},{"content":"Kernel, init and Services The Linux Kernel boot loader loads kernel and an initial RAM-based file system (initramfs) into memory, so it can be used directly by the kernel.\nkernel loaded, it immediately initializes and configures the computer\u0026rsquo;s memory and also configures all the hardware attached to the system.\nalso load user space applications.\n/sbin/init and Services Once kernel has set up all its hardware and mounted the root filesystem, the kernel runs sbin/init.\nthis then becomes the initial process, which then starts other processes to get the system running.\nMost other processes on the system trace their origin ultimately to init; exceptions include the so-called kernel processes.\nBesides starting the system, init is responsible for keeping the system running and for shutting it down cleanly.\nthis serial process had the system passing through a sequence of runlevels containing collections of scripts that start and stop services.\nEach runlevel supported a different mode of running the system.\nhowever, all major distributions have moved away from this sequential runlevel method of system initialization,\nalthough they usually emulate many System V utilities for compatibility purposes.\nNext, we discuss the new methods, of witch systemd has become dominant.\nStartup Alternatives SysVinit viewed things as a serial process, devided into a series of sequential stages.\nstartup did not easily take advantage of the parallel processing that could be done on multiple processors or cores. (each stage required completion before the next could proceed)\nfurthermore, shutdown and reboot was seen as a relatively rare event; exactly how long it took was not considered important. (this is no longer true)\nsome modern methods, such as use of containers, can require almost instantaneous startup times. Thus, systems now require methods with faster and enhanced capabilities.\nfinally, the older methods required rather complicated startup scripts, which were difficult to keep universal across distribution versions, kernel versions, architectures, and type of systems.\nThe two main alternatives developed were:\nUpstart\ndeveloped by Ubuntu and first included in 2006 Adopted in Fedora 9 (in 2008) and RHEL 6 and its clones systemd\nAdopted by Fedora first (in 2011) Adopted by RHEL 7 and SUSE Replaced Upstart in Ubuntu 16.04 while the migration to systemd was rather controversial, it has been adopted by all major distributions, and so we will not discuss the older System V method or Upstart.\nsystemd Features systemd replaced serialized set of steps with aggressive parallelization techniques, which make this faster largely.\ncomplicated shell script are replaced with simpler configuration files, which enumerates \u0026hellip;\npreprocess for services how to execute service startup indicate conditions of the service should be accomplished when startup is finished /sbin/init now just points to /lib/systemd/systemd\n","permalink":"https://nolleh.github.io/linux/3.linux-basics-and-system-startup/3.kernel-init-and-services/","summary":"Kernel, init and Services The Linux Kernel boot loader loads kernel and an initial RAM-based file system (initramfs) into memory, so it can be used directly by the kernel.\nkernel loaded, it immediately initializes and configures the computer\u0026rsquo;s memory and also configures all the hardware attached to the system.\nalso load user space applications.\n/sbin/init and Services Once kernel has set up all its hardware and mounted the root filesystem, the kernel runs sbin/init.","title":"3-3.kernel Init and Services"},{"content":"Cheatsheet - Shell 쉘 커맨드들을 자주 까먹곤 해서 자주쓰는것 위주로 생각날때마다 하나씩 등록 예정.\nPrimitives if statement if [ 10 -gt 20 ]; then echo \u0026#39;gt\u0026#39;; else echo \u0026#39;lt\u0026#39;; fi; operator desc ! not true -n 문자열의 길이가 0보다 크다 -z 문자열의 길이가 0이다 = 문자열이 같다 -eq 정수가 같다 -gt 정수가 크다 -lt 정수가 작다 -d dir dir 디렉토리가 있다 -e file file 이 있다 for statement for file in *.sh; do echo $file; done echo 로 출력해보면 마지막 값이 나오는것을 보면, file 이라는 변수에 값을 하나씩 할당하고\nfor 문 바깥에서도 유효함 (스코프바깥) 이 확인된다.\nheredoc cat \u0026gt; file.txt \u0026lt;\u0026lt;EOF hello this is nolleh EOF 표준입력으로부터 파일을 생성하는 구문이다. 이렇게도 사용할 수 있지만, 쉘스크립트를 사용할때 아래와 같은 구문을 작성함으로써 복수의 라인을 변수로 선언하는 형태로도 사용가능하다.\nsql=$(cat \u0026lt;\u0026lt;EOF SELECT foo, bar FROM db WHERE foo=\u0026#39;baz\u0026#39; EOF ) Futher strip string let\u0026rsquo;s say you want to strip \u0026lsquo;sh\u0026rsquo;\necho ${a/.sh} 궁금해서 이렇게도 돌려봄.\ntest=aaabbb echo ${test/a} 결과는 aabbb recursive 하게 제거하지 않고, first occurrence 를 제거\ncurly brace 내부가 평가되어 rvalue 에 evaluation 될 수 있도록 감싸주는것을 잊지 말자.\nlist all files in directories 조금 재미있는건 이 명령어와\nfor file in ./*; do echo $file; done 이 명령어의 결과가 다르다는 점이다.\nfor file in *; do echo $file; done ls ./* 평가 결과와 ls *의 차이로 봐도 무관할듯.\n어떤 폴더의 결과를 출력할때 상대경로의 유무가 그 결과에도 함께 반영이 된다.\n만약 순수하게 파일명만 가져오고 싶다면 후자를 사용해야할 것.\n","permalink":"https://nolleh.github.io/cheatsheet/shell/","summary":"Cheatsheet - Shell 쉘 커맨드들을 자주 까먹곤 해서 자주쓰는것 위주로 생각날때마다 하나씩 등록 예정.\nPrimitives if statement if [ 10 -gt 20 ]; then echo \u0026#39;gt\u0026#39;; else echo \u0026#39;lt\u0026#39;; fi; operator desc ! not true -n 문자열의 길이가 0보다 크다 -z 문자열의 길이가 0이다 = 문자열이 같다 -eq 정수가 같다 -gt 정수가 크다 -lt 정수가 작다 -d dir dir 디렉토리가 있다 -e file file 이 있다 for statement for file in *.","title":"Shell"},{"content":"The Boot Process The Linux boot process is the procedure for initializing the system.\nfrom when the computer power is first swithced on until the user interface is fully operational.\nhaving a good understanding of the steps in the boot process may help you with troubleshooting problems, as well as with tailoring the computer\u0026rsquo;s performance to your needs.\nOn the other hand, the boot process can be rather technical, and you can start using Linux without knowing all the details.\nNOTE: You may want to come back and study this section later, if you want to first get a good feel for how to use a Linux system.\nBIOS - The First Step starting an x86-based Linux system involves a number of stps.\nthe Basic Input/Output System (BIOS) initializes the hardware, including the screen and keyboard, and tests the main memory.\nThis process is also called POST (Power On Self Test).\nThe BIOS software is stored on a ROM chip on the motherboard, After this, the remainder of the boot process is controlled by the operating system (OS).\nMaster Boot Record (MBR) and Boot Loader Once the POST is completed -\u0026gt; pass control to boot loader. boot loader is usually stored on one of the hard disks in the system, either in the boot sector (for traditional BIOS/MBR systems). or EFI partition (for more recent (Unified Extensible Firmware interface or EFI/UEFI systems).\nboot loader stored in \u0026hellip;\nhard disk, boot sector, EFI partition thereafter, date,time and the most important peripherals are loaded from CMOS values.\nA number of bootloaders exist for Linux;\nGRUB, ISOLINUX, DAS U-Boot when booting linux, the bootloader is responsible for loading the kernel image and the initial RAM disk or file system (contains some critical files and device drivers needed to start the system) into memory\nBoot Loader in Action BIOS/MBR system, boot loader resides at the first sector of the hard disk (MBR).\nin this stage, boot loader examines partition table and finds the bootable partition\nOnce it finds bootable partition, it then searches for the second stage boot loader, for example GRUB, and loads it into RAM.\nfind boot loader from first sector\nexamines partition table / find bootable partition\nsearch and loads second stage boot loader (ex. GRUB), and load to RAM EFI/UEFI system, UEFI firmware reads its Boot Manger data to determine which UEFI application is to be launched and from where (disk, EFI partition)\nthen launched the UEFI application, for example GRUB, as defined in he boot entry in the firmware\u0026rsquo;s boot maanger.\nthis procedure is more complicated, but more versatile than the older MBR methods.\nUEFI frimware read boot Manager and find UEFI application\nUEFI application launch (ex. GRUB, defined in boot entry in boot manager)\nmore versatile compaired with MBR\nthe second stage boot loader resides under /boot. after choosing the OS, the boot loader loads the kernel of the selected operating system into RAM\nand passes control to it. Kernels almost always compressed, so its first job is to uncompress it self. after this, check/analyze hardware and initialize drviers.\n/boot\u0026rsquo;s second stage boot loader load kernel and pass control to it.\nuncompress / check hardware / and initializes hard drivers.\nInitial RAM Disk initramfs filesystem image contains programs / and binary files that perform all actions needed to mount the proper root filesystem.\nex.\nproviding kernel functionality for the needed filesystem, device drivers for mass storage controllers with a facility called udev (figuraring out which devices are present, locating the device drivers they need to operate propery) root filesystem has been found, it is checked for errors and mounted. mount program instructs the operating system that a filesystem is ready for use, and associates it with a perticular point in the overall hierachy of the filesystem (the mount point).\nIf this is successful,, the initramfs is cleared from RAM and the init program on the root filesystem (/sbin/init) is executed.\ninit handles the mounting and pivoting over to the final real root filesystem. If special hardware drivers are needed before mass stroage can be accessed, they must be in the initramfs image.\nText-Mode Login init starts a number of text-mode login prompts. and to eventually get a command shell.\ndefault command shell is bash(the GNU Bourne Again Shell)\n","permalink":"https://nolleh.github.io/linux/3.linux-basics-and-system-startup/2.the-boot-process/","summary":"The Boot Process The Linux boot process is the procedure for initializing the system.\nfrom when the computer power is first swithced on until the user interface is fully operational.\nhaving a good understanding of the steps in the boot process may help you with troubleshooting problems, as well as with tailoring the computer\u0026rsquo;s performance to your needs.\nOn the other hand, the boot process can be rather technical, and you can start using Linux without knowing all the details.","title":"3-2.the Boot Process"},{"content":"Learning Objectives Identify Linux filesystems. Identify the differences between partitions and filesystems Describe the boot process. Install Linux on a computer. ","permalink":"https://nolleh.github.io/linux/3.linux-basics-and-system-startup/1.introduction/","summary":"Learning Objectives Identify Linux filesystems. Identify the differences between partitions and filesystems Describe the boot process. Install Linux on a computer. ","title":"3-1.introduction"},{"content":"Chapter Summary Linux boroows heavily from UNIX operating system, with withch its creators were well-versed. LInux accesses many features and services through files and file-like objects. Linux is a fully multi-tasking, multi-user operating system, with built-in networking and service processes known as deamons. Linux is developed by a loose confederation of developers from all over the world, collaborating over the Internet,\nwith Linus Torvalds at th head. Technical sill and a desire to contriubte are the only qualifications for participating. The Linux community is a far reaching ecosystem of developers, vendors , and users and supports and advances the Linux operating system. Some of common terms used in Linux are: kernel, distribution, boot loader, service, filesystem, X Windiow system, desktop environment, and command line, A full Linux distribution consists of the kerenl plus a number of other software tools for file-related operations, user management, and software package management. ","permalink":"https://nolleh.github.io/linux/2.linux-philosophy-and-concepts/6.chapter-summary/","summary":"Chapter Summary Linux boroows heavily from UNIX operating system, with withch its creators were well-versed. LInux accesses many features and services through files and file-like objects. Linux is a fully multi-tasking, multi-user operating system, with built-in networking and service processes known as deamons. Linux is developed by a loose confederation of developers from all over the world, collaborating over the Internet,\nwith Linus Torvalds at th head. Technical sill and a desire to contriubte are the only qualifications for participating.","title":"2-6.chapter summary"},{"content":"Linux Distribution Overview making sure that project works properly on the most widely used Linux distributions. To accomplish this, you need to learn amout the different components, services, and configurations associated with each distribution.\n","permalink":"https://nolleh.github.io/linux/2.linux-philosophy-and-concepts/5.linux-distribution/","summary":"Linux Distribution Overview making sure that project works properly on the most widely used Linux distributions. To accomplish this, you need to learn amout the different components, services, and configurations associated with each distribution.","title":"2-5.linux Distribution"},{"content":"Video: Linux Terminology Kernel: Glue between hardware and applications\nDitribution: Collection of software making up a Linux-based OS\nBootLoader: Program that boots the operating system\nService: Program that runs as a background process\nFilesystem: Method for sotring and organizing files\nX window System: toolkit and protocol to build graphical subsystem\nShell: command line interpreter\n","permalink":"https://nolleh.github.io/linux/2.linux-philosophy-and-concepts/4.linux-terminology-overview/","summary":"Video: Linux Terminology Kernel: Glue between hardware and applications\nDitribution: Collection of software making up a Linux-based OS\nBootLoader: Program that boots the operating system\nService: Program that runs as a background process\nFilesystem: Method for sotring and organizing files\nX window System: toolkit and protocol to build graphical subsystem\nShell: command line interpreter","title":"2-4.linux Terminology Overview"},{"content":"Linux Philosophy Overview Linux is constantly enhanced and maintained by a network of developers from all over the world collaborating over the internet, with Linus Torvalds at the head.\nLinux Philosophy Linux borrows heavily from the well-established UNIX operating system. it was written to be a free and open source system to be used in place of UNIX,\nwhich at the time was designed for computers much more powerful than PCs and was quite expensive.\nLinux is a fully multitasking, multiuser operating system, with built-in networking and service processes known as deamons in the UNIX world.\nNOTE: Linux was inspired by UNIX, but it is not UNIX.\nHow Linux Is Built collaborating is power of Linux!\n2-3 month is period to need to release new version of Linux\nMore About Linux Community users and vendors who use many different forums to connect with one another.\nInternet Relay Chat (IRC) software Online communities and discussion boards including Linux User Gorups Many collaborative projects hosted on services such as GitHub and GitLab Newsgroups and mailing lists, including the Linux Kernel Mailing List Community events, e.g. Hackathons, Install Fests, Open Source Summits and Embedded Linux Conferences. linux.com is hosted by The Linux Foundation and serves over one million unique visitors every month.\n","permalink":"https://nolleh.github.io/linux/2.linux-philosophy-and-concepts/3.linux-philosophy/","summary":"Linux Philosophy Overview Linux is constantly enhanced and maintained by a network of developers from all over the world collaborating over the internet, with Linus Torvalds at the head.\nLinux Philosophy Linux borrows heavily from the well-established UNIX operating system. it was written to be a free and open source system to be used in place of UNIX,\nwhich at the time was designed for computers much more powerful than PCs and was quite expensive.","title":"2-3.linux Philosophy"},{"content":"Linux History Overview initially developed on and for intel x86-based personal computers.\nLinux History Linus Torvalds was a student in Helsinki, Finland, in 1991, when he started a project: writing his own operating system kernal. collected together and/or developed the other essential ingredients required to construct an entire operating system with his kernel at the center.\nIn 1992, Linux was re-licensed using General Public License (GPL) by GNU (a project of the Free Software Foundation or FSF, which promotes freely available software),\nwhich made it possible to build a world wide community of developers.\ncomplete systems called Linux distributions in the mid-90\u0026rsquo;s.\nMore About Linux History In 1998, major companies like IBM and Oracle announced their support for the Linux platform and began major development efforts as well.\ntoday, Linux powers more than half of the servers on the Internet, the majority of smartphones (via the Android system, which is built on top of Linux),\nmore than 90 percent of the public cloud workload, and all of the world\u0026rsquo;s most powerful supercomputeres.\n","permalink":"https://nolleh.github.io/linux/2.linux-philosophy-and-concepts/2.linux-history/","summary":"Linux History Overview initially developed on and for intel x86-based personal computers.\nLinux History Linus Torvalds was a student in Helsinki, Finland, in 1991, when he started a project: writing his own operating system kernal. collected together and/or developed the other essential ingredients required to construct an entire operating system with his kernel at the center.\nIn 1992, Linux was re-licensed using General Public License (GPL) by GNU (a project of the Free Software Foundation or FSF, which promotes freely available software),","title":"2-2.linux History"},{"content":"The Power of Linux Three Important Pieces of Context Things change in Linux\nLinux is contantly evolving. no matter how hard to make up-to-date as possible, Course \u0026lt;-/-\u0026gt; Linux We have repeated some things in the class meterial We have tried to avoid holy wars\nthere are many areas where there are strong preference disagreements in the Linux (and wider open source) community. examples include the best editor: emacs vs. vi; GNOME vs. KDE, etc, we have chosen (when nessary) a paticular alternative to emphasize just to keep thing clean. Learning Objectives discuss the history and philosophy of Linux describe the Linux community define the common terms associated with Linux discuss the components of a Linux distribution ","permalink":"https://nolleh.github.io/linux/2.linux-philosophy-and-concepts/1.introduction/","summary":"The Power of Linux Three Important Pieces of Context Things change in Linux\nLinux is contantly evolving. no matter how hard to make up-to-date as possible, Course \u0026lt;-/-\u0026gt; Linux We have repeated some things in the class meterial We have tried to avoid holy wars\nthere are many areas where there are strong preference disagreements in the Linux (and wider open source) community. examples include the best editor: emacs vs. vi; GNOME vs.","title":"2-1.introduction"},{"content":"Course Software Requirements to fully benefit from this course, at least one linux distribution installed.\nyou will learn some more details about many available Linux distributions and the failies thy can be considered to belong to.\nfocus on 3 major distribution families.\nFocus on Three Major Linux Distribution Families The Red Hat Family Red Hat Enterprise Linux (RHEL) heads the family that includes CentOS, CentOS Stream, Fedora and Oracle Linux.\nFedora contains significantly more software than Red Hat\u0026rsquo;s enterprise version.\nCentOS Streams and CentOS are more often for activities, demonstrations, and labs because there is no cost to end user and there is a longer release cylce than Fedora. CentOS 8 has no scheduled updates after 2021. the replacement is CentOS 8 Stream.\nthe difference between the two versions is CentOS Stream gets updates before RHEL, while CentOS gets then after\n3.10 Kernel is used in RHEL/CentOS 7, while version 4.18 is used in RHEL/CentOS 8. it supports hardware platforms such as Intel x86, Arm, Itenium, PowerPC, and IBM System z. it uses yum and dnf RPM-based yum package managers REHL is widely used by enterprises which host their own systems. The SUSE Family We use openSUSE as reference distribution for SUSE family, as it is available to end users at no cost.\nkernel version 4.12 is used in openSUSE Leap 15. RPM-based zypper package manager includes YaST (Yet another Setup Tool) for system administration perposes. SLES is widely used in retail and many other sectors The Debian Family the Debian distribution is upstream for several other distributions, including Ubuntu. Debian is a pure open source community project (not owned by any corporation) and has a strong focus on stability. Ubuntu aims at providing a good compromise between long term stability and ease of use. Since Ubuntu gets most of it packages from Debian\u0026rsquo;s stable branch,\nit also has access to a very large software repository.\nkernel version 5.8 is used in Ubuntu 20.04 LTS it uses the DPKG-based APT package manager (apt, apt-get, apt-cache, etc Ubuntu has been widely used for cloude deployments while Ubuntu is built on top of Debian and is GNOME-based under the hood, it differs visually from the interface on standard Debian, as well as other distributions. ","permalink":"https://nolleh.github.io/linux/1.the-linux-foundation/3.course-linux-requirements/","summary":"Course Software Requirements to fully benefit from this course, at least one linux distribution installed.\nyou will learn some more details about many available Linux distributions and the failies thy can be considered to belong to.\nfocus on 3 major distribution families.\nFocus on Three Major Linux Distribution Families The Red Hat Family Red Hat Enterprise Linux (RHEL) heads the family that includes CentOS, CentOS Stream, Fedora and Oracle Linux.","title":"1-3.course Linux Requirements"},{"content":"founded in 2000, supported by more than 1,000 members and is the world\u0026rsquo;s leading home for collaboration on open source software.\nthe foundation hosts hundreds of world\u0026rsquo;s most important open source projects including linux, kubernetes, Node.js, Hyperledger, ONAP\u0026hellip; and many more.\n","permalink":"https://nolleh.github.io/linux/1.the-linux-foundation/2.the-linux-foundation/","summary":"founded in 2000, supported by more than 1,000 members and is the world\u0026rsquo;s leading home for collaboration on open source software.\nthe foundation hosts hundreds of world\u0026rsquo;s most important open source projects including linux, kubernetes, Node.js, Hyperledger, ONAP\u0026hellip; and many more.","title":"1-2.the Linux Foundation"},{"content":"we will learn\u0026hellip;\nlinux foundation logistics of this online course choosing a linux distribution that\u0026rsquo;s right for you ","permalink":"https://nolleh.github.io/linux/1.the-linux-foundation/1.introduction/","summary":"we will learn\u0026hellip;\nlinux foundation logistics of this online course choosing a linux distribution that\u0026rsquo;s right for you ","title":"1-1.Introduction"},{"content":"","permalink":"https://nolleh.github.io/linux/welcome/","summary":"","title":"Welcome"},{"content":"서론 react, vue, angluar 가 장악하던 FE 진영에서 떠오르고 있는 프레임워크. 주요 철학은 svelte 의 메인 화면에서 보여주고 있는것처럼 \u0026lsquo;보다 짧은 코드\u0026rsquo;, \u0026lsquo;No Virtual DOM\u0026rsquo;, \u0026lsquo;Truely reactive\u0026rsquo; 인 듯하다. 지만 나는 어디까지나 BE 개발자이기 때문에 아직 어떤 의미인지 자세하게는 모르겠고(\u0026hellip;)\n스벨트 컬럼을 새로 생성하며 블로그에 정리를 결심한 것은 어디까지나 호기심이 충만한 나의 심심풀이 변덕이다. (더 정확히는, 팀 내 주니어 개발자와의 원활한 의사 소통을 위해..) 심심할 때 더 자세히 살펴보고 정리할 것. 본문에서는, 단순히 스벨트 프로젝트를 만들고 실행해보는 정도로 정리하겠다.\n시작하기 사용하는 패키지 매니져의 create 명령어(starter kit 을 통해 정의된 프로젝트 생성)\n➜ workspace_github pnpm create vite@latest svelte-test -- -- template svelte Packages: +1 + Packages are hard linked from the content-addressable store to the virtual store. Content-addressable store is at: /Users/nolleh/.pnpm-store/v3 Virtual store is at: node_modules/.pnpm /private/var/folders/97/vks5483s2yn95dxdpdspjsgw0000gq/T/dlx-31846/5: + create-vite 3.1.0 Progress: resolved 1, reused 0, downloaded 1, added 1, done ╭──────────────────────────────────────────────────────────────────╮ │ │ │ Update available! 6.32.3 → 7.13.4. │ │ Changelog: https://github.com/pnpm/pnpm/releases/tag/v7.13.4 │ │ Run pnpm add -g pnpm to update. │ │ │ │ Follow @pnpmjs for updates: https://twitter.com/pnpmjs │ │ │ ╰──────────────────────────────────────────────────────────────────╯ ✔ Select a framework: › Svelte ✔ Select a variant: › TypeScript Scaffolding project in /Users/nolleh/Documents/workspace_github/svelte-test... Done. Now run: cd svelte-test pnpm install pnpm run dev 위 명령은 다음과 같은 폴더들을 생성한다.\n➜ svelte-test l total 128 drwxr-xr-x 15 nolleh staff 480B Oct 11 23:30 . drwxr-xr-x 22 nolleh staff 704B Oct 11 23:29 .. -rw-r--r-- 1 nolleh staff 253B Oct 11 23:29 .gitignore drwxr-xr-x 3 nolleh staff 96B Oct 11 23:29 .vscode -rw-r--r-- 1 nolleh staff 3.1K Oct 11 23:29 README.md -rw-r--r-- 1 nolleh staff 365B Oct 11 23:29 index.html drwxr-xr-x 15 nolleh staff 480B Oct 11 23:30 node_modules -rw-r--r-- 1 nolleh staff 511B Oct 11 23:29 package.json -rw-r--r-- 1 nolleh staff 28K Oct 11 23:29 pnpm-lock.yaml drwxr-xr-x 3 nolleh staff 96B Oct 11 23:29 public drwxr-xr-x 8 nolleh staff 256B Oct 11 23:29 src -rw-r--r-- 1 nolleh staff 207B Oct 11 23:29 svelte.config.js -rw-r--r-- 1 nolleh staff 658B Oct 11 23:29 tsconfig.json -rw-r--r-- 1 nolleh staff 142B Oct 11 23:29 tsconfig.node.json -rw-r--r-- 1 nolleh staff 176B Oct 11 23:29 vite.config.ts ➜ svelte-test 으음 .vscode 폴더도 생성하네, 친절하다. (난 vscode 로 실행할 생각이 없지만) 제일 중요할 package.json 의 내용은 다음과 같음.\n{ \u0026#34;name\u0026#34;: \u0026#34;svelte-test\u0026#34;, \u0026#34;private\u0026#34;: true, \u0026#34;version\u0026#34;: \u0026#34;0.0.0\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;module\u0026#34;, \u0026#34;scripts\u0026#34;: { \u0026#34;dev\u0026#34;: \u0026#34;vite\u0026#34;, \u0026#34;build\u0026#34;: \u0026#34;vite build\u0026#34;, \u0026#34;preview\u0026#34;: \u0026#34;vite preview\u0026#34;, \u0026#34;check\u0026#34;: \u0026#34;svelte-check --tsconfig ./tsconfig.json\u0026#34; }, \u0026#34;devDependencies\u0026#34;: { \u0026#34;@sveltejs/vite-plugin-svelte\u0026#34;: \u0026#34;^1.0.2\u0026#34;, \u0026#34;@tsconfig/svelte\u0026#34;: \u0026#34;^3.0.0\u0026#34;, \u0026#34;svelte\u0026#34;: \u0026#34;^3.49.0\u0026#34;, \u0026#34;svelte-check\u0026#34;: \u0026#34;^2.8.1\u0026#34;, \u0026#34;svelte-preprocess\u0026#34;: \u0026#34;^4.10.7\u0026#34;, \u0026#34;tslib\u0026#34;: \u0026#34;^2.4.0\u0026#34;, \u0026#34;typescript\u0026#34;: \u0026#34;^4.6.4\u0026#34;, \u0026#34;vite\u0026#34;: \u0026#34;^3.1.0\u0026#34; } } vite 라는 패키지를 이용해서 빌드하고 실행하도록 구성되어 있고, check 를 통해 lint 체크등이 일어나는 모양. svelte package 등도 프로젝트 별로 버전을 관리하는 형태로 구성되었다. 모든 dependency 는 devDependency 에 정의되어있으므로, 모든 패키지는 런타임엔 하는 역할이 없다고 봐도 무방.\n생성된 app.svelte 는 대충 이런모양\n\u0026lt;script lang=\u0026#34;ts\u0026#34;\u0026gt; import svelteLogo from \u0026#39;./assets/svelte.svg\u0026#39; import Counter from \u0026#39;./lib/Counter.svelte\u0026#39; \u0026lt;/script\u0026gt; \u0026lt;main\u0026gt; \u0026lt;div\u0026gt; \u0026lt;a href=\u0026#34;https://vitejs.dev\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt; \u0026lt;img src=\u0026#34;/vite.svg\u0026#34; class=\u0026#34;logo\u0026#34; alt=\u0026#34;Vite Logo\u0026#34; /\u0026gt; \u0026lt;/a\u0026gt; \u0026lt;main\u0026gt; \u0026lt;style\u0026gt; .logo { height: 6em; padding: 1.5em; will-change: filter; } .logo:hover { filter: drop-shadow(0 0 2em #646cffaa); } .logo.svelte:hover { filter: drop-shadow(0 0 2em #ff3e00aa); } .read-the-docs { color: #888; } \u0026lt;/style\u0026gt; 즉 다음과 같은 골격을 가지고 있다.\n\u0026lt;script\u0026gt; \u0026lt;main\u0026gt; \u0026lt;style\u0026gt; 이는 vue 에서도 유사한 형태를 가지고 있던것 같다. (@nolleh 의 기억에 의존) 따라서 크게 의아한 점은 없는듯. 해당 app.svelte 를 렌더링하는 부분은 main.ts 인데, 다음과 같이 구성되어 있다.\nimport \u0026#34;./app.css\u0026#34;; import App from \u0026#34;./App.svelte\u0026#34;; const app = new App({ target: document.getElementById(\u0026#34;app\u0026#34;), }); export default app; 역시 vue.js 와 유사한 골격이다. 상대경로에서 필요한 파일들을 가져와서 .svelte 파일에서 생성되는 App 클래스로 인스턴스를 생성하고 export 한다. (이건 좀 신기하다. extends 구문도 없고, 클래스를 정의하는 부분도 없는데 App 이라는 클래스명으로 지정이 된다.\n뭐 어차피 컴파일러도 별도 정의한 것이고, 각 IDE 에서의 에러 여부 판단도 약속만 되어있으면 상관없을 테지만.)\n실행해보면\nVITE v3.1.7 ready in 153 ms ➜ Local: http://127.0.0.1:5173/ ➜ Network: use --host to expose 와 같이 어떤 url 로 접근하면 해당 페이지를 노출할 것인지 보여준다. vite 라는 녀석이 serving 을 해주는 것 같은데, 뭐하는 놈인지 좀 검색해봄.\njavascript 의 태생, 모듈의 니즈 AMD 번들러(webpack)의 등장 esbuild (구현: javascript -\u0026gt; go) 100 배 빠른 빌드 역시 고는 짱짱맨! webpack 이 지원하던 다른 많은 기능들이 4에서는 부재하므로 잘 사용되지 않음 devServer, Loader 를 통한 transfile, HTML, CSS 지원등.. 단순 빌드 도구가 아니라 개발의 통합 툴이었음 snowpack 의 등장 esbuild 를 통한 빌드, 실제 번들은 Webpack vite 의 등장 esbuild 와 브라우저 모듈을 이용한 개발모드,개발서버, 프록시서버, 번들툴, 코드 스프리팅, HMR 등 스노우팩의 컨셉 + 다른 번들도구의 기능을 하나로 모은 도구 Svelte 의 vite 의 차용 \u0026lsquo;2021 년 가장 만족도가 높은 번들툴\u0026rsquo; 로 선정된 vite 의 차용. Dev server + HMR + typescirpt + dev proxy 를 지원하게 되었다. 즉, svelte 에서 사용하는 번들 툴이 되겠다.\n해당 url 로 들어가면 다음과 같은 페이지가 노출 된다.\n","permalink":"https://nolleh.github.io/svelte/overview/","summary":"서론 react, vue, angluar 가 장악하던 FE 진영에서 떠오르고 있는 프레임워크. 주요 철학은 svelte 의 메인 화면에서 보여주고 있는것처럼 \u0026lsquo;보다 짧은 코드\u0026rsquo;, \u0026lsquo;No Virtual DOM\u0026rsquo;, \u0026lsquo;Truely reactive\u0026rsquo; 인 듯하다. 지만 나는 어디까지나 BE 개발자이기 때문에 아직 어떤 의미인지 자세하게는 모르겠고(\u0026hellip;)\n스벨트 컬럼을 새로 생성하며 블로그에 정리를 결심한 것은 어디까지나 호기심이 충만한 나의 심심풀이 변덕이다. (더 정확히는, 팀 내 주니어 개발자와의 원활한 의사 소통을 위해..) 심심할 때 더 자세히 살펴보고 정리할 것.","title":"Overview"},{"content":"서론 예전 회사에서나 현 직장에서나, 면접관으로 들어가다가 C# 이 이력서에 적혀있는 경우 Task 와 async/await 관련하여 동기화 관련한 내용에 대해 물어보곤한다. 그리고 이 질문에서 대부분 깊이가 드러나게 된다. (여담이지만, 대부분의 지원자가 자바스택이라, 이런 재미진? 것들을 물어보기가 어렵다. C# 이랑 C++, 실시간 게임서버는 재미진 질문? 들이 많은데.. ㅎㅎㅎㅎ 면접관으로 들어가기위해서 자바스택의 재미진 토픽들도 좀 찾아봐야겠다\u0026hellip;.\n내 경험에서 질문을 도출하려고 스프링의 라이브러리들을 어떻게 구현할 수 있을지 물어볼수는 없으니\u0026hellip;) 물어보다가 나도 생각도 정리하고, 내가 알고 있는 틀린 부분이 없는지 정리하는겸해서 블로그에 기록해 놓는다.\n내용 출처 - Don\u0026rsquo;t Lock On Async Tasks\n다음과 같이 일반적으로 락을 건다고 하자.\npublic class LockTest{ private readonly object objLock = new object(); public void RecordSuccess(int batchId){ lock(objLock){ // Record a success in database var success = GetCurrentSuccessCountFromDB(); SaveSuccessCountToDB(success+1); } } public void RecordFailure(int batchId){ lock(objLock){ // Record a failure in database var success = GetCurrentFailureCountFromDB(); SaveFailureCountToDB(success+1); } } } 락을 거는 것의 목적은 동시에 해당 영역에 두개이상의 스레드들이 접근 불가하도록 하는것인데, 10 개의 스레드가 락을 얻으려고 한다고 가정할때 순차적으로 락을 얻게 된다.\ntask 와 async/await 으로 위와 같은 코드를 작성하는 경우 async/await 의 이점을 제대로 누리지 못하고 스레드들이 잠기게 될것이다. (it ain\u0026rsquo;t async over here)\n때문에, 컴파일조차 안되게끔 컴파일러에서 막고있다. (이건 nolleh 의 경험상 적은 문구.) 그럼 어떻게 async 하게 wait 할수있을까? 이걸 위해 semapore 와 semaporeslim 이 있음.\n세마포어는 IPC 에서 사용할수 있고 세마포어 슬림은 어플리케이션 레벨에서 사용할 수 있다.\n-\u0026gt; 이제 blocking 에서, suspended 된다. 요렇게 사용하면 됨.\npublic class LockTest{ private readonly SemaphoreSlim _lock= new SemaphoreSlim(1, 1); public async Task RecordSuccess(int batchId){ await _lock.WaitAsync(); try{ // Record a success in database var success = GetCurrentSuccessCountFromDB(); SaveSuccessCountToDB(success+1); } finally{ _lock.Release(); } } public async Task RecordFailure(int batchId){ await _lock.WaitAsync(); try{ // Record a failure in database var success = GetCurrentFailureCountFromDB(); SaveFailureCountToDB(success+1); } finally{ _lock.Release(); } } } nolleh 의 경험상, 여기에서 추가로 더 알아 둬야할 게 있는데, (reentrance 관련) 해당 컬럼은 본 블로그의 같은 카테고리-다음글-에서 찾아볼수 있다. 이어보기 - NeoSmart.AsyncLock 라이브러리에 관하여\n","permalink":"https://nolleh.github.io/csharp/dont-lock-on-async-tasks/","summary":"서론 예전 회사에서나 현 직장에서나, 면접관으로 들어가다가 C# 이 이력서에 적혀있는 경우 Task 와 async/await 관련하여 동기화 관련한 내용에 대해 물어보곤한다. 그리고 이 질문에서 대부분 깊이가 드러나게 된다. (여담이지만, 대부분의 지원자가 자바스택이라, 이런 재미진? 것들을 물어보기가 어렵다. C# 이랑 C++, 실시간 게임서버는 재미진 질문? 들이 많은데.. ㅎㅎㅎㅎ 면접관으로 들어가기위해서 자바스택의 재미진 토픽들도 좀 찾아봐야겠다\u0026hellip;.\n내 경험에서 질문을 도출하려고 스프링의 라이브러리들을 어떻게 구현할 수 있을지 물어볼수는 없으니\u0026hellip;) 물어보다가 나도 생각도 정리하고, 내가 알고 있는 틀린 부분이 없는지 정리하는겸해서 블로그에 기록해 놓는다.","title":"Dont Lock on Async Tasks"},{"content":"role of data analyst sicentist: modeling. analyze data for actionable insight and build ML or DLM anaylsts : data to find trends and patterns, for buisiness decisions. engineer : extract and organie data from different sources, store and manage data repositorioes, so that other data professionals can access it. build your skills as a data analyst Data Analyst Expert view point ","permalink":"https://nolleh.github.io/coursera/data-analyst-ibm/week1/note/","summary":"role of data analyst sicentist: modeling. analyze data for actionable insight and build ML or DLM anaylsts : data to find trends and patterns, for buisiness decisions. engineer : extract and organie data from different sources, store and manage data repositorioes, so that other data professionals can access it. build your skills as a data analyst Data Analyst Expert view point ","title":"Note"},{"content":"복수의 유저 사용하기 맥터미널에서 복수의 유저를 사용하려면 몇가지 신경써야할 부분들이 생긴다.\nhome directory 가 분리 되어 있기 때문에 어떤 유저를 위해 설치한 데이터들은\n다른 유저에서는 사용못할수도 있고 (그러는게 맞고, 그럴려고 격리한거니)\n그러다보니 양쪽에서 같은 데이터를 설치해야하나 ?\n혹은 서로 충돌이 난다거나 하는 불편함들이 생긴다.\n대표적인 예로 brew 에서 이런 문제가 발생하는데,,\n어떤 계정으로 설치한 패키지가 다른 계정에서 권한문제로 접근이 안되게 되면서 엉망이 된다.. (-_\u0026ndash;) dependency 가 있는 다른 패키지 들과도 맞물리게 되면서 내가 설치한 패키지가 아닌 패키지에 대해 데이터를 바꾸려고 하면서 권한 이슈로 연결 되는식.\n트러블 슈팅 진행하면서 겪은 해결책들을 여기에 기록하고자한다.\n1.brew 첫번째(유저그룹변경) / 두번째 (별도 brew 생성) 방법이 있는데 용량 아껴볼려고 첫번째 방법으로 고통받아봤는데,\n잘 해결은 안됐기 때문에 개인적으로 두번째 방법을 추천한다.\nstackoverflow\n1-1. 유저그룹으로 권한 설정 example. brew\necho $(brew --prefix) echo $(groups $(whoami)) sudo dseditgroup -o edit -a $(whoami) -t user admin sudo chgrp -R admin $(brew --prefix) sudo chmod -R g+rwX $(brew --prefix) ls -lah $(brew --prefix) 순서대로,\nbrew install path 확인하고 내 그룹 확인하고. 2에서 어드민 그룹에 없다면 어드민 그룹에 넣고 어드민 그룹으로 폴더 recursive 하게 소유권 변경 어드민 그룹에 있는 유저들에 대해 읽기,쓰기,실행 권한 부여 권한 확인 1-2. 공식 문서 제안법 하나도 사용하지 않거나, 하나의 글로벌 brew 설치를 하고, 모든 다른 유저들에서 지역 버전을 사용하는것이 공식 제안 법.\ncd $HOME git clone https://github.com/Homebrew/brew.git ./brew/bin/brew tap homebrew/core export PATH=$HOME/brew/bin:$PATH \u0026gt;\u0026gt; ~/.zshrc # or ~/.bashrc exec $SHELL which brew ","permalink":"https://nolleh.github.io/env/mac-terminal-multiple-user/","summary":"복수의 유저 사용하기 맥터미널에서 복수의 유저를 사용하려면 몇가지 신경써야할 부분들이 생긴다.\nhome directory 가 분리 되어 있기 때문에 어떤 유저를 위해 설치한 데이터들은\n다른 유저에서는 사용못할수도 있고 (그러는게 맞고, 그럴려고 격리한거니)\n그러다보니 양쪽에서 같은 데이터를 설치해야하나 ?\n혹은 서로 충돌이 난다거나 하는 불편함들이 생긴다.\n대표적인 예로 brew 에서 이런 문제가 발생하는데,,\n어떤 계정으로 설치한 패키지가 다른 계정에서 권한문제로 접근이 안되게 되면서 엉망이 된다.. (-_\u0026ndash;) dependency 가 있는 다른 패키지 들과도 맞물리게 되면서 내가 설치한 패키지가 아닌 패키지에 대해 데이터를 바꾸려고 하면서 권한 이슈로 연결 되는식.","title":"Mac 터미널에서 복수의 유저 사용하기"},{"content":"Overview 개인적으로 업무 진행중 빠르게 DB 데이터를 bulk 로 넣어야할 때에는 function 생성을 선호하는 편이다.\nORM 을 통해 코드로 넣는 방법도 있지만, 코드 수정하고 코드를 다시 실행해서 테스트 코드를 돌리고 데이터 결과를 쿼리로 다시 확인하는것보다. 쿼리를 바로 바로 작성해서 바로 수정하는게 더 생산성이 좋기 때문.\n코드 작성 (IDE) 프로그램 실행 (SVR APP) 테스트 코드 실행 (SWAGGER BROWSER) 데이터 삽입 결과 확인 (DB CLIENT) VS\nfunction 작성 (DB CLIENT) function 실행 (DB CLIENT) 데이터 삽입 결과 확인 (DB CLIENT) 절차는 크게 차이나지 않아보이지만, 화면 이동, 적합한 프로그램 실행등의 과정에서 누적되면 생산성의 차이가 발생한다. (조금이라도 시간을 아끼려는 vimer 들의 습성..이랄까..) 물론, 더미 데이터를 넣는 것 외에도 필요하다고 판단되는 케이스에는 사용하는 편.\n작업시마다 항상 인터넷에서 자료를 찾아서, 비 효율적이므로.. 여기에 정리해둔다.\nCreating Function DROP FUNCTION IF EXISTS database.func DELIMETER $$ CREATE FUNCTION database.func(nums INT) RETURNS INT BEGIN DECLARE i INT DEFAULT 0; DECLARE affected INT DEFAULT 0; DECLARE temp INT DEFAULT 0; WHILE i \u0026lt; nums DO INSERT INTO database.table(name, message) (SELECT name, message FROM database.table_old(name, message)); -- it isn\u0026#39;t good way for in this example, -- but I\u0026#39;ve used this just for showing usage -- for selecting row_count() and set variable in function; SELECT ROW_COUNT() INTO temp; SET affected = affected + temp; SET i = i + 1; END WHILE; RETURN affected; END $$ DELIMETER ; 추후 개인적인 참조를 위해 기본적인 골격만 붙여두어, 이해하는데 어려움은 없을 것.\n","permalink":"https://nolleh.github.io/mysql/functions/","summary":"Overview 개인적으로 업무 진행중 빠르게 DB 데이터를 bulk 로 넣어야할 때에는 function 생성을 선호하는 편이다.\nORM 을 통해 코드로 넣는 방법도 있지만, 코드 수정하고 코드를 다시 실행해서 테스트 코드를 돌리고 데이터 결과를 쿼리로 다시 확인하는것보다. 쿼리를 바로 바로 작성해서 바로 수정하는게 더 생산성이 좋기 때문.\n코드 작성 (IDE) 프로그램 실행 (SVR APP) 테스트 코드 실행 (SWAGGER BROWSER) 데이터 삽입 결과 확인 (DB CLIENT) VS\nfunction 작성 (DB CLIENT) function 실행 (DB CLIENT) 데이터 삽입 결과 확인 (DB CLIENT) 절차는 크게 차이나지 않아보이지만, 화면 이동, 적합한 프로그램 실행등의 과정에서 누적되면 생산성의 차이가 발생한다.","title":"Functions"},{"content":"","permalink":"https://nolleh.github.io/mysql/cheatsheet/","summary":"","title":"Cheatsheet"},{"content":"CronJobs 수동 실행\nkubectl create job -n {namespace} --from=cronjob/{name} {job-name} ","permalink":"https://nolleh.github.io/kubernetes/cheatsheet/","summary":"CronJobs 수동 실행\nkubectl create job -n {namespace} --from=cronjob/{name} {job-name} ","title":"Cheatsheet"},{"content":" 다음에서 발췌 3. Time and Order 순서란 무엇이고, 왜 중요할까요?\n\u0026ldquo;순서란 무엇인가\u0026rdquo; 라는 질문은 무슨 의미 일까요 ?\n애초에 왜 여기에 왜 빠져있는 걸까요? 왜 우리는 A 가 B 이전에 실행되었다는걸 신경 써야할까요? 왜 우리는 다른 주제에는 신경을 안쓸까요 ? 색깔 같은거?\n글쎄, 친구, 일단 이에 답변하기 위해 분산 시스템을 다시 살펴보도록 합시다.\n기억하고 있을지 모르겠는데, 분산프로그래밍을 복수의 컴퓨터를 활용해서 같은 문제를 해결하는 예술이라고 묘사했었습니다.\n이것은, 사실, 순서에 대한 강박(obsession)의 가장주요한 내용입니다. 어떤 시스템이든 한 번에 하나의 작업만 할수있고, 연산들의 모든 순서를 생성하게 됩니다. 사람들이 하나의 문을 통해 지나다니는것처럼, 모든 연산은 잘 정의된 전처리와 후처리로 구성됩니다. 이것이 우리가 보존하기위해 노력하고 있는 기본적인 프로그래밍 모델입니다.\n전통적인 모델은: 하나의 싱글 프로그램, 하나의 프로세스, 하나의 메모리 공간이 하나의 CPU 에서 도는 것입니다. 운영체제는 다중 CPU 와 다중 프로그램에 대한 사실들을 추상화하고, 많은 프로그램들이 실 제로 메모리를 공유하는 것을 추상화 합니다. 저는 스데디드 프로그래밍과 이벤트 기바 프로그래밍이 존재하지 않다고 얘기하지는 않았습니다; 이것은 단지 이것들이 \u0026ldquo;하나/하나/하나\u0026quot;모델들 위에서 특별하게 추상화 되어있다는 것을 이야기하고 있습니다. 프로그램들은 순서대로 실행되도록 쓰여지게 됩니다; 최 상위에서 시작하여, 아래로 점점 내려가게 됩니다.\n속성으로서의 순서는 많은 주목을 받았는데, \u0026ldquo;정확함\u0026quot;을 정의하는 가장 쉬운방법이 \u0026ldquo;하나의 기계에서 작동하듯 동작한다\u0026rdquo; 이기 때문입니다. 그리고 이것은 모동 다음을 의미하는데 a) 우리는 같은 연산을 수행하고 b) 복수의 기계에서도 같은 순서로 실행한다.\n순서를 보존하는 분산시스템의 장점은, (하나의 장비에서 정의된것 처럼) 이들이 일반적이다, 라는 것입니다. 당신은 어떤 연산들인지 고려할 필요가 없는데, 왜냐하면 하나의 머신에서 동작하는 것과 완전히 똑같이 실행될 것이기 때문입니다. 이것은 당신이 어떤 연산들이든 간에 같은 시스템을 사용할 수 있다는 것을 알고있기때문에 훌륭합니다.\nTotal and partial order 분산시스템의 자연적인 상태는 parital order 입니다. 네트워크나 독립적인 노드들 모두 상대적인 순서만을 보장합니다; 그러나 각각의 노드에서는 지역적인 순서를. 관찰할 수 있습니다.\n완전한 순서는 이진 관계(binary relation)인데, 집합의 모든 요소의 순서를 정의합니다.\n두개의 구분된 요소는 그 중의 하나가 다른 것보다 더 클 경우에 비교가 가능합니다. 부분적으로 정렬된 집합은, 요소들의 어떤 쌍이 비교가능하지 않은데, 부분적인 순서는 모든 항목들에 대해 정확한 순서를 지정하지 않기 때문입니다.\n저체 순서와 일부 순서는 전이관계(transitive) 이고 비대칭입니다. 아래의 문구는 전체 순서와 부분순서를 모든 X 의 모든 a,b,c 에 대해 유효합니다.\nIf a \u0026lt;= b and b \u0026lt;= a then a = b (antisymmetry); If a \u0026lt;= b and b \u0026lt;= c then a \u0026lt;= c (transitivy); 그러나, 전체 순서는 \u0026ldquo;전체\u0026ldquo;입니다:\na \u0026lt;= b or b \u0026lt;= a (totality) for all a, b in X 부분순서는 오직 반사적인 반면에요:\na \u0026lt;= a (refelxitvity) for all a in X 전체성은 반사성을 내포하고 있음을 참고해주세요; 따라서, 부분순서는 전체 순서의 더 약한 변종입니다. 모든 부분순서의 어떤 요소들은, 전체정은 보존되지 않을 수 있습니다 - 다시말해, 어떤 요소들은 비교가 불가합니다.\ngit 브랜치가 부분순서의 하나의 예입니다. 당신은 알고 있을지도 모르겠는데, 깃 리비젼은 하나의 기본 브랜치에서 여러 복수 브랜치를 생성할 수 있도록 해줍니다 - 예를 들어, 마스터 브랜치에서요. 각각의 브랜치는 공통의 조상으로부터 기반해서 바생된 소스코드의 변화들의 역사를 나타내게 됩니다.\n[ branch A (1,2,0)] [ master (3,0,0) ] [ branch B (1,0,2) ] [ branch A (1,1,0)] [ master (2,0,0) ] [ branch B (1,0,1) ] \\ [ master (1,0,0) ] / A 와 B 브랜치는 하나의 공통브랜치로부터 파생됐는데, 둘 사이에 어떤 결정적인 순서는 없습니다; 그들은 각각의 다른 역사를 가지고 있고, 추가적인 작업없이 (merging) 하나의 선형으로 좁혀 질 수 없습니다. 물론, 당신은 모든 커밋을 어떤 임의의 순서로 (첫번째로 조상을 두고, 연결들을 부숴서 A 를 B 이전에 두거나, B 를 A 이전에 두거나 하는 방식으로요) - 그러나 이것은 존재하지 않는 전체 순서를 강제로 둠으로써 정보를 잃어버릴 수 있습니다.\n하나의 노드의 시스템에서, 전체 순서는 필수적으로 등장하게 됩니다: 명령들은 실행되고 메시지들은 처리되는데, 하나의 프로그램에서 관측가능하게 됩니다. 우리는 이것을 전체 순서라고 믿을 수 있게 됩니다 - 이것은 프로그램의 동작을 예측가능하게 만들어 줍니다. 이런 순서는 분산시스템에서도 유지 될 수 있지만, 비용을 요구하게 됩니다; 통신은 비싸고, 시간 동기화는 어렵고 깨지기 쉽습니다.\nWhat is time ? 시간은 순서의 원천입니다. - 연산의 순서를 정의할 수 있게 해줍니다. - 동일하게 해석을 갖고 사람들이 이해할 수 있습니다. (초, 분, 하루 등.)\n어떤 감각에서, 시간은 다른 정수 카운터와 유사합니다. 이것은 대부분의 컴퓨터에서 타임 센서(clock)를 할당하고 있기 때문에 중요합니다. 이것은 또 중요한데, 우리는 물리 실세계에서 촛불이나 세슘원자와 같은 완벽하지 않은 카운터로부터 대략적인 것을 어떻게 합성할지에 대해 파악해왔기 때문에 중요합니다. \u0026ldquo;합성\u0026rdquo; 함으로써, 우리는 물리적으로 떨어져있는 것끼리 실제적으로 통신하지 않으면서 대략적으로 정수 카운터의 값을 추축할 수 있었죠.\n타임스탬프는 우주의 시작으로부터 현재의 순간까지의 세계의 상태를 나타내는 값입니다. - 만약 특정 타임스탬프에서 어떤 일이 일어난다면, 잠재적으로 이전에 일어난 것에 대해 영향을 받았을 수 있습니다. 이 아이디어는 단순히 타임스탬프 이전의 모든것이 관련이 있다고 가정하는 대신에 명시적으로 원인(의존성들)들을 추적하는 캐주얼 클락으로 일반화 될 수 있습니다. 물론 일반적인 가정은 우리는 모든 세계를 걱정하는 것대신 특정 시스템의 상태만 걱정하면 됩니다.\n어디에서든 같은 비율로 시간이 흐른다고 가정합시다 - 이것은 대단히 큰 가정인데, 나중에 다시 돌아오겠습니다 - 시간과 타임스탬프들은 몇가지 유용한 해석을 가지고 있는데(프로그램에 있어서) 3가지 해석은 다음과 같습니다:\n순서 기간 해석 Order. 제가 시간은 순서의 원천이라고 얘기했을때, 다음을 의미했었습니다:\n우리는 타임스탬프를 정렬 되지 않은 이벤트를 정렬하기위해 사용할수 있습니다. 우리는 타임스탬프를 연산의 특정 순서로 강제하기 위해서, 혹은 메시지의 전달의 순서를 강제하기 위해 사용할 수 있습니다. (예를 들어서, 순서에 다르게 도달하는 연산은 수행을 딜레이하는 형태로요.) 우리는 타임스탬플의 값을 어떤 것이 다른 것보다 시간순으로 더 빨리 일어난 것인지 확인하기 위해 사용할 수 있습니다. interpretation - 시간은 보편적으로 비교가능한 값입니다. 타임스탬프의 절대값은 날짜로 해석될 수 있으며, 이것은 사람에게 유용합니다. 로그파일로부터 시작된 정지 시가능로 부터 얻어진 타임스탬프는, 천재 지변이 있었던 저번 토요일이었다, 라고 이야기 할 수 있습니다.\nDuration - 기간은 실세계에서 어떤 관계를 갖는 시간으로 측정될 수 있습니다. 알고리즘은 일반적으로 시계의 절대값이나 날짜의 해석등을 고려하지 않으며, 그렇지만 이들은 어떤 판단을 하기위해 기간을 사용할 수도 있습니다. 특별히, 소요된 시간의 양은 단서를 제공하기도 하는데, 시스템이 파티션 되었거나, 단순히 고 지연의 경험으로 인한 것인지 등에 대한 것이 그렇습니다.\n이런 그들의 본성으로, 분산시스템의 컴포넌트 들은 예측가능한 형태로 동작하지 않습니다. 이들은 어떤 순서도 보장하지 않으며, 진행률이나, 지연이없을 수도 있습니다. 각각의 노드들은 지역 순서를 가지고 있습니다. - 실행이 대략 순차적이기 때문에 - 그러나 이 지역 순서들은 각각에 대해서는 독립적입니다.\n순서를 추측하거나, 노출하는것은 가능한 실행의 공간을 줄이는 것의 한 방법입니다. 그리고 가능한 발생을 줄이는 방법의 한 방법입니다. 인류는 어떤 것들이 어떤 순서로든 발생할수 있을때 추리하는것에 어려움을 겪어 왔습니다. - 여기엔 그저 너무 많은 순열들을 고려해야합니다.\nDoes time progress at the same rate everywhere? 우리는 모두 직관적인 시간에 대한개념을 각각의 경험으로 이해하고 있습니다. 불행하게도, 이 직관적인 시간에 대한 개념은 부분순서가 아니라 전체 순서에 대한 상을 그리게끔 합니다. 어떤 것이 동시에 일어나는것보다, 하나다음에 다음것이 일어날 것이라고 상상하게 합니다. 메시지들의 하나의 순서가 다른 순서나 다른 지연을 가지는것 대신 추리하기가쉽습니다.\n그러나, 분산시스템을 구현할때 우리는 시간과 순서에 대한 강한 가정을 갖는것을 피해야합니다. 왜냐하면, 이 강한 가정은, 시간이 맞물린 이슈나, 온보드 클럭 이슈가 발생했을때 깨지기가 쉽기 때문입니다. - 게다가, 순서를 노출하는것은 비용을 요구합니다. 보다 적게 결정적이면 우리는 더 tolerate 해지며, 분산시스템의 이점을 더 활용할 수 있게됩니다.\n\u0026ldquo;시간이 지나는 정도는 어떤 곳이든 같을까? 라는 질문에 대한 세가지 흔한 대답이 있습니다. 그것들은:\n글로벌 클락: yes 지역 클락: no, but No clock: no! 세가지 타이밍 추측이 이전 두번째 챕처에서 언급ㅂ한 내용과 어느정도는 일치함을 나타냅니다: 동기화된 시스템 모델은 글로벌 클락을 가지고 있으며, 지역클락을 가지고 있으면 부분적으로 동기화 되며, 비동기화된 시스템 모델은 클락자체를 가지고 있지 않다. 이제 이것들에 대해 좀 더 살펴 봅시다.\nTime with a \u0026ldquo;global-clock\u0026rdquo; assumption 글로벌 클락의 전제는, 글로벌 클락은 완전히 정밀 하다는 것이며, 모두 여기에 접근가능하다는 것입니다. 이게 우리가 시간에 대해 일반적으로 생각하는 것이며, 시간에 조금 차이가 있어도 사람들사이에 교류는 큰문제가 없기 때문입니다.\n글로벌 클락은 기본적으로 모든 순서의 원천이 됩니다. (정확히 모든 연산들이 모든 노드에서 같은 순서로 실행되고, 서로 통신하지 않더라도.)\n그러나, 이것은 세상을 이상적으로 보는 것입니다: 실 세상에서는, 클락을 동기화하는 것은 제한된 정밀도 안에서만 가능합니다. 이것은 클락이 상용화된 컴퓨터 에서는 완전한 정밀도를 갖기가 어려움을 의미하는데, NTP 와 같은 클락 동기화 프로토콜을 사용하는 경우 지연이 발생되고, 근본적으로 우주 시간의 본성(the nature of spacetime) 때문입니다.\n분산된 노드들 사이에 완전하게 동기화된 클락이 있다고 가정하는것은 클락이 같은 시간에 시작해서, 절대 표류하지 않아야 함을 의미합니다. 이것은 좋은 가정인데, 당신은 타임스탬프를 사용해서 전체적인 완전 순서를 결정하는데 자유롭기 때문입니다. - 지연이 아니라, clock drift 에 묶이는것 - 하지만, 이것은 쉽지않은nontrivial 도전과제이며, 잠재적인 문제의 원인이 됩니다. 단순 실패에도 많은 시나리오 들이 있습니다 - 유저가 실수로 기계의 로컬타임을 변경한다거나, 최신이 아닌 머신이 클러스터에 들어오거나, 동기화된 클락이 살짝 다른 비율로 표류하거나, 문제를 추적하기 어려운 다른 다양한 원인들이 있을 수 있습니다.\n그럼에도 불구하고, 실 세계에서 이런 가정을 하는 것들이 있습니다. 페이스북의 Cassandra는 클락들이 동기화되는 시스템의 하나의 예입니다. 이것은 쓰기들 사이에서 충돌이 일어날때 이를 해결하기 위해 타임스탬프를 활용합니다 - 더 최신의 타임스탬프를 사용하는 쓰기 연산이 승리합니다. 이것은 클락이 표류하면, 새 데이터는 무시되고 이전값으로 쓰여지는 결과를 초래할 수 있음을 의미합니다.; 여기서 다시말하자면, 이것은 운영상의 어려운 문제입니다. 그리고 예전에 들은 바에 의하면, 사람들이 이를 잘 알고 있다고 합니다). 다른 흥미로운 예는 구글의 Spanner 입니다: 이 문서에서는 그들의 시간을 동기화하는 TrueTime API 를 소개하며, 최악의 케이스에 시간이 표류하는 정도를 측정하였습니다.\nTime with a \u0026ldquo;Local-clock\u0026rdquo; assumption 두번째로, 그리고 또한 더 설득력 있는 가정은 각각의 머신들이 로컬 클락을 가지고 있고, 글로벌 클락이 없는 경우입니다. 이것은 로컬 클럭을 원격 타임스탬프가 로컬 타임스탬프의 이전인지, 후인지 순서를 결정하는데 사용할 수 없음을 의미합니다.; 다시 말해, 두 머신사이에서 타임스탬프를 비교하는데 의미있게 사용할 수 없다는 것을 의미합니다.\n로컬클락추정은 실세계와 좀 더 가깝습니다. 이것은 부분 순서를 갖게 됩니다; 각각의 시스템에서 발생한 이벤트들은 정렬되지만, 시스템들 사이에서 발생한이벤트들은 클락만 사용해서는 순서를 보장할 수 없습니다.\n하지만, 당신은 타임스탬프를 하나의 머신에서 발생한 이벤트를 정렬하는 데 사용할 수 있습니다; 그리고 당신은 클락이 어느정도 점프할 수 있다는 것을 허용하고 신중하게 하나의 머신에서 타임아웃을 걸 수도 있습니다. 물론, 엔드유저에 의해 제어되는 머신에 있어서 이것은 너무 많은것을 가정하는 것일 수 있습니다: 예를 들어서, 하나의 사용자가 운영체제의 날짜 컨트롤을 사용하여 실수로 그들의 날짜를 다른 값으로 변경할 수 있기 때문입니다.\nTime with a \u0026ldquo;No-clock\u0026rdquo; assumption 마지막으로, 논리적인 개념이 있습니다. 우리는 클락을 전혀 사용하지 않고, 대신에 인과관계를 추적하기 위해 어떤 다른 방법을 사용합니다. 기억하세요, 타임스탬프는 단순히 세계를 그 지점에서 상태를 표현하는 표기(shorthand)일 뿐입니다. - 따라서, 우리는 카운터와 통신을 사용하여 어떤 것이 이전에 발생하였거나, 후에, 혹은 동시에 발생하였음을 결정할 수 있습니다.\n이 방법은, 우리가 다른 머신들 사이에 발생한 이벤트의 순서를 정할수 있지만, 간격에 대해서 이야기할 수 없고, 타임아웃도 사용할수 없음(타임 센서가 없다고 가정했으므로)습니다. 부분순서를 가지고: 하나의 시스템에서 카운터를 이용하여 통신없이 이벤트를 정렬할 수 있지만, 시스템사이에서 이벤트를 정렬하는 것은 메시지 교환을 요구하게 됩니다.\n분산시스템에 대한 글들에서 가장 많이 인용되는 글중에 하나는 Lamport 의 time, clocks and the ordering of events 라는 paper 입니다. 벡터 클락, 개념의 세대(다음에 좀 더 다루겠습니다)는 클락을 사용하지 않고 인과관계를 추적하는 방법중에 하나입니다. 카산드라의 사촌 Riak (Basho) 와 Voldemort (Linkedin) 은 벡터클락을 완벽한 정밀도를 가진 글로벌클락에 접근하는 노드들을 가정하는 대신 벡터클락을 사용합니다. 이것은 이 시스템들이 이전에 이야기한 클락정밀도 이슈들을 회피할 수 있음을 의미합니다.\n클락이 사용되지 않을때, 이벤트들이 거리가있는 머신들 사이에서 정렬이 되어야할 때 최대의 정밀도는 통신 지연에 의존하게 됩니다.\nHow is time used in a distributed system? 시간의 이점은 무엇일까요?\n시간은 시스템 사이에서 순서를 정의 할 수 있습니다 (통신 없이) 시간은 알고리즘의 경계 조건을 정의 할 수 있습니다. 이벤트의 순서는 분산시스템에서 중요한데, 분산 시스템의 많은 속성들이 연산/이벤트들의 순서의 영역에서 정의 되기 때문입니다. :\n정상 동작(correctness) 이 올바른 이벤트 순서에 의존하는 영역. 예를 들면, 분산 데이터베이스에서의 직렬성. 순서는 연결을 끊어 내는 데 사용될 수 있습니다. 리소스 쟁탈(contention)이 일어 났을때, 예를 들어서 만약 위젯을 위한 두 개의 순서(명령)이 있다면, 먼저것을 충족시키고, 두번째 것을 취소 시킬수 있다. 어떤 글로벌 클럭은 연산들이 두 개의 다른 머신들이 직접적으로 통신하지 않고도 정렬할 수 있도록 합니다. 글로벌 클락이 없다면, 순서를 정리하기 위해 통신이 필요합니다.\n시간은 또 알고리즘에 대한 경계 조건을 정의하는 데 활용 될 수 있습니다. - 더 정확하게는, 구분하기 위해 \u0026ldquo;고 지연\u0026rdquo; 과 \u0026ldquo;서버나 네트워크 연결이 끊겼다\u0026rdquo; 이것은 매우 중요한 사용예입니다.; 대부분의 실세계는 타임아웃을 가지고 있고 원격지의 장비가 실패했는지 판단을 위해 타임아웃을 가지고 있거나, 단순히 네트워크 지연이 길어지고 있는 것인지 판단하기 위해 타임아웃을 가지고 있습니다. 이런 결정을 하는 알고리즘은 실패 판단자(failure detectors)라고 불립니다.; 그리고 이것에 대해서는 곧 다시 다루도록 하겠습니다.\nVector clocks (time for casual order) 이전에, 분산시스템에서 시간이 진행되는 비율에 대해 다른 가정이 있음을 언급한적이 있습니다. 동기화된 정확한 클락을 얻을 수 없음을 가정하거나 우리의 목표를 시스템이 시간동기화에 예민하지 않아야 하는 우리의 시스템의 목표를 달성하기 위해, 어떻게 정렬할 수 있을까요 ?\n램포트의 클락과 벡터 클락은 카운터와 통신에 의존하는 물리적인 클락 대신 분산시스템의 이벤트들을 정렬합니다. 이 클락들은 다른 노드들 사이에서 비교가능한 카운터를 제공합니다.\nA Lamport Clock 은 단순합니다. 각각의 프로세스들은 아래의 규칙에 따라 카운터를 유지합니다.\n프로세스가 동작하는 언제든지, 카운터를 증가시킨다. 프로세스가 메시지를 전송하는 언제 든지, 카운터를 포함한다. 메시지가 도달했을때 , 카운터를 max(local_counter, received_count) + 1 로 설정한다. 코드로 표현하면:\nfunction LamportClock() { this.value = 1; } LamportClock.prototype.get = function () { return this.value; }; LamportClock.prototype.increment = function () { this.value++; }; LamportClock.prototype.merge = function (other) { this.value = Math.max(this.value, other.value) + 1; }; 어떤 Lamport Clock 은 카운터가 다음과 같은 경고(caveat)와 함께 시스템안에서 비교될 수 있도록 합니다.: 램포트 클락은 부분 순서를 제공합니다. if timestamp(a) \u0026lt; timestamp(b):\na는 b 보다 먼저 발생했을 수 있거나 a 는 b 와 비교될 수 없다. 이것은 클락 일관성 조건이라는 것으로 알려져 있습니다: 만약 하나의 이벤트가 다른것보다 이전에 온다면, 그 이벤트들의 논리적인 클락은 다른것에 비해 이전의 것이라는 것입니다. 만약 a 와 b 가 같은 인과 이력으로부터 파생되었다면, 예를들어, 둘다 같은 프로세스에 의해 생성된 타임스탬프 값을 가지고 있거나; 혹은, b가 a 에서 전송된 메시지에 대한 응답인 경우, a 가 b 보다 먼저 일어 났음을 알 수 있습니다.\n직관적으로, 이것은 램포트 클락이 하나의 타임라인에서의 정보를 나르기 때문입니다; 따라서, 램포트 타임스탬프를 서로 통신하지 않는 시스템에서 비교하는것은 실제로 정렬되어있지 않지만 그렇게 보이게하는 동시성 이벤트이슈를 유발할 수 있습니다.\n최초의 기간이 지난 후 분리가 되어 서로 통신하지 않는 부분시스템으로 구성되어버린 시스템을 생각해봅시다.\n각각의 독립적인 시스템에서 모든 이벤트들에 대해 b 이전에 a 가 일어났다면, ts(a) \u0026lt; ts(b) 라고 할 수 있습니다; 그러나, 만약 당신이 두개의 이벤트를 두 독립적인 시스템으로 부터 가져온다면, (두 메시지는 직접적인 연관이 없다고 합시다.) 여기서 상대적인 순서에 대해 어떠한 의미있는 추론도 할 수가 없게 됩니다. 시스템의 각각의 부분들이 이벤트들에 대해 타임스탬프를 부여한다면, 이 타임스탬프 들은 서로 어떤 관계도 없게 됩니다. 두 이벤트는 관계가 없더라도 순서를 가진 것처럼 보이게 될 수 있습니다.\n그러나 - 그리고 여전히 유용한 재산으로 - 싱글 머신의 관점에서, 어떤 메시지가 ts(a) 와 함께 전송되면, ts(b) 값과 함께 응답을 받게 되고, 이것은 \u0026gt; ts(a) 를 만족합니다.\nA vector clock 은 [ t1, t2, .... ] N 의 논리적 클락을 유지하는 램포트 클락의 확장판입니다. - 각각의 노드당 하나- 공통적인 카운터를 증가시키는 것 대신에, 각각의 노드들은 자신의 논리적 클락을 벡터안에서 증가시킵니다. (각각의 내부 이벤트에 따라 하나씩). 따라서, 갱신 룰은 다음과 같습니다:\n프로세스가 동작하는한, 노드의 논리적인 클럭을 벡터안에서 증가시킨다. 프로세스가 메시지를 전송할때마다, 논리클락의 모든 벡터를 포함한다. 메시지가 수신되면: 벡터 안의 각각의 요소들을 다음값이 되도록 갱신한다. max(local, received) 벡터에서 현재 노드를 나타내는 논리 클락을 증가시킨다. 이걸 다시 코드로 표현하면 다음과 같습니다.\nfunction VectorClock(value) { // expressed as a hash keyed by node id: e.g. { node1: 1, node2: 3 } this.value = value || {}; } VectorClock.prototype.get = function () { return this.value; }; VectorClock.prototype.increment = function (nodeId) { if (typeof this.value[nodeId] == \u0026#34;undefined\u0026#34;) { this.value[nodeId] = 1; } else { this.value[nodeId]++; } }; VectorClock.prototype.merge = function (other) { var result = {}, last, a = this.value, b = other.value; // This filters out duplicate keys in the hash Object.keys(a) .concat(b) .sort() .filter(function (key) { var isDuplicate = key == last; last = key; return !isDuplicate; }) .forEach(function (key) { result[key] = Math.max(a[key] || 0, b[key] || 0); }); this.value = result; }; 아래 설명(source) 은 벡터클락을 나타냅니다.\n세 노드(A,B, C)의 각각은 벡터 클락을 추적합니다. 이벤트가 발생할때마다, 그들은 벡터 클락의 현재 값들을 타임스탬핑 합니다. 벡터클락을 조사하는것 (와 같은 { A: 2, B: 4, C: 1}) 은 이 이벤트에 잠재적으로 영향받을 수 있는 메시지들을 특정할 수 있게 해줍니다.\n이 벡터 클락에 대한 이슈는 주로 노드 별로 하나의 엔트리를 요구한다는 점인데, 이것은 잠재적으로 큰 시스템에서는 큰 비용이 될 수 있습니다. 테크닉의 다양성을 유지하는것은 벡터클럭의 사이즈를 줄이기 위해 적용 될 수 있습니다. (주기적인 가비지 콜렉션을 사용한다거나, 사이즈를 제한함으로써 정밀도를 줄인다거나)\n우리는 순서와 인과성을 어떻게 물리적인 클락없이 추적할 수 있을지 살펴봤습니다. 이제, 어떻게 타임 기간이 컷오프를 위해 어떻게 사용될 수 있을지 살펴봅시다.\n","permalink":"https://nolleh.github.io/distributed-systems/3.time-and-order/","summary":"다음에서 발췌 3. Time and Order 순서란 무엇이고, 왜 중요할까요?\n\u0026ldquo;순서란 무엇인가\u0026rdquo; 라는 질문은 무슨 의미 일까요 ?\n애초에 왜 여기에 왜 빠져있는 걸까요? 왜 우리는 A 가 B 이전에 실행되었다는걸 신경 써야할까요? 왜 우리는 다른 주제에는 신경을 안쓸까요 ? 색깔 같은거?\n글쎄, 친구, 일단 이에 답변하기 위해 분산 시스템을 다시 살펴보도록 합시다.\n기억하고 있을지 모르겠는데, 분산프로그래밍을 복수의 컴퓨터를 활용해서 같은 문제를 해결하는 예술이라고 묘사했었습니다.\n이것은, 사실, 순서에 대한 강박(obsession)의 가장주요한 내용입니다.","title":"3.time and Order"},{"content":" 다음에서 발췌 http://book.mixu.net/distsys/abstractions.html\n2. Up and down the level of abstraction 이 챕터에서는, 추상화의 레벨을 여행할 것이며, 몇가지 불가능한 결과를 보고, (CAP 와 FLP), 그리고 나서 성능에 대한 항해를 할 것 입니다.\n만약 어떤 프로그래밍을 완료했다면, 추상화. 수준에 대한 개념은 당신에게 익숙할 겁니다. 당신은 이미 추상화와 함께 했고, 어떤 API 를 통해 더 낮은 레이어와 인터페이싱하고 있을 것이며, 더 높은 레이어에 API 나 인터페이스를 제공하고있을 겁니다. OSI 네트워크 7 계층이 좋은 예죠.\n분산 프로그래밍은, 단언하고 싶은데, 분산의 결과를 다루는 것이 많은 부분을 차지합니다. 이것은, 현실과 긴장이 있는데, 많은 도들들과 우리의 욕구, 시스템에 대한것은 \u0026ldquo;하나의 시스템처럼\u0026rdquo; 이기 때문입니다. 이것은 가능한것과 이해 가능한 것과 성능 사이에서 균형을 잡고 좋은 추상화를 하는 것을 찾아 가는것을 의미합니다.\nX 가 Y 보다 더 추상화가 되어있다는 것의 의미는 무엇일까요? 첫째로, X 는 Y 와 근본적인 차이는 없고, 다른 새로운것을 소개 하는 게 아닙니다. 대신, X 는 Y 의 내용을 제거하고 제시하는것, 더 관리하기 쉬운 형태로 제시하는 것을 의미합니다. 둘째로, X 는 Y 로부터 중요하지 않은 문제들을 제거함으로써, 어떤 감각에 대해 Y 보다 더 직관 적일 수 있습니다.\nNietzsche 는 다음과 같이 이야기 했습니다.\n모든 동등에 대한것으로 부터 나온 개념은 동등하지 않다. 어떤 이파리(leaf) 도 다른 것과 완전이 같지 않으며, 이파리(leaf) 의 개념은 각각의 차이들로부터 차이에 대한 것들을 잊음으로써 임의의 추상화를 통해 형성된것이다; 또한, 이것은 어떤 아이디어를 도출하는데, 이파리들의 본성은 이파리와 다른 어떤것을 가지고 있을 수 있다는 것이다 - 어떤 종류 모든 이파리로부터 다른 어떤 자기만의 형태가 있을 수 있으며, 낡고, 마킹되고, 복제되며, 색이 다르며, 구부러지고, 색이 다를 수 있지만, 기술적이지 않은 손길로 인해, 맞는것으로, 믿을 수 있고, 신뢰할 수 있는 본래의 형태의 이미지가 되는 복제가 없다. (TODO refined)\n추상화는, 근본적으로, 진짜가 아닙니다. 모든 상황들은 유일하며, 모든 노드 또한 그렇습니다. 하지만 추상화는 세상을 관리할 수 있게 해줍니다: 문제 상황들에 대해 더 간단하게 하여 - 현실의 자유 - 더 분석적으로 다룰수있고, 어떤 중요한 것들을 무시하지도 않으면서, 해결책을 넓게 적용할 수 있도록 해줍니다.\n실제로, 우리가 다루는 것들은 필수적이면, 우리가 도출할 수 있는 결과도 넓게 적용 가능합니다. 이것은 왜 불가능한 결과가 그렇게 중한지 알려줍니다; 이것들은 문제의 가능한 공식의 가장 단순한 방법을 취하며, 제약과 가정의 집합내에서 해결할 수 없는 문제임을 우리게 설명해 줍니다.\n모든 추상화는 의도적으로 유일한 것들을 무시합니다. 이 트릭은 중요하지 않는 것들을 제거하는 것인데, 어떻게 어떤것이 필수적인지 알 수 있을까요? 글쎄, 당신은 아마도 선험적으로(priori) 알지 못할 것입니다.\n매 시간 우리는 시스템의 측변에서 제외합니다, 시스템의 특정부분들으세ㅓ. 우리는 에러의 source 로부터 소개하는 리스크를 안고 있습니다. 이것은 왜 때때로 우리가 다른 방향으로 접근해야하는지, 선택적으로 실 하드웨어의 어떤 측변을 선택하고, 실제세계의 문제를 다시 선택적해야하는지. 이 것들은 어떤 하드웨어의 특정 부분들을 (e.g. 물리적인 연속성) 나, 다른 물리적인 특징들이 시스템이 충분히 잘 돌아가도록 충분하다 다시 소개하는 것이.\n이것을 머리속에 생각하면서, 분산시스템에서 동작하고 있다는 것을 인지하면서 최소한의 현실은 어떤 것일까? 하나의 시스템 모델은 우리가 중요하다고 고려하는 특징들입니다; 지정한 것들을 갖고 있으면, 불가능한 결과와 도전들을 살펴볼수 있게 됩니다.\nA System model 분산시스템에서 주요한 속성중의 하나는, \u0026lsquo;분산\u0026rsquo;입니다. 더 정확하게는, 분산시스템에서의 프로그램은:\n각각의 독립적인 노드에서 동시에 실행 됩니다. 네트워크를 토앻 연결되어있고, 메시지가 유실되거나 비정의된 동작으로 이어질 수 있습니다. 공유 메모리나, 공유 시간이 없습니다. (shared memory, shared clock) 여기에는 많은 암시사항들이 있는데요:\n각각의 노드 들은 프로그램을 동시에 실행한다. 지식들은 지역적이다: 노드들은 그들의 로컬 상태에는 빠르게 접근 하지만, 글로벌 상태에 대한 정보는 잠재적으로 최신 값이 아닐 수 있다. 노드들은 실패할수 있으며, 실패로 부터 독립적으로 복구 될 수 있습니다. 메시지들은 지연되거나 유실될 수 있습니다. (노드의 실패와는 독립적으로; 네트워크의 실패와 노드 실패 두개를 구분하는 것은 쉬운 일이 아닙니다.) clock 들은 접근하는 노드들 사이에서 동기화 되어있지 않습니다. (한 로컬의 타임스탬프는 실제 글로벌 타임과 다를 수 있고, 쉽게 파악하기 어렵습니다.) 하나의 시스템 모델은 어떤 특정 시스템 디자인과 관계하여 많은 가정들을 내포합니다.\nSystem model 분산시스템이 구현된 환경과 시설에 대한 가정들의 집합\n시스템 모델들은 그들의 가정, 환경과 시설들에 대한 그들의 가정이 다양합니다. 이 가정은 다음을 포함합니다.\n노드가 어떤 수용량(capabilities)을 가지고 있고 어떻게 실패할 수 있는지 어떻게 통신을 연결하여 동작하고, 어떻게 실패 할 수 있는지 전체 시스템의 속성 - 시간과 순서에 대한 가정같은 것들- 건장한 시스템 모델은 가장 작은 가정을 하는 모델입니다; 어떤 알고리즘이 이런 시스템에 쓰여도, 다른 환경에서도 tolerant 하고, 이는 상당히 작은 가정이 있거나, 거의 없기때문입니다.\n한편으로, 우리는 시스템모델에 많은 가정을 함으로써 시스템을 이해하기 쉽게 만들수 있습니다. 예를 들어서, 알고리즘에 대해 노드들은 실패하지 않는다. 라는것은 노드의 실패를 다룰 필요가 없게 되죠. 하지만, 이런 시스템 모델은 현실적이지 않으므로 적용 할 수가 없죠.\n노드의 속성들을 살펴보고, 시간과 순서에 대해 좀 더 살펴봅시다.\nNodes in our System model 노드들은 연산과 저장소의 호스트로서 동작하게 되는데, 이들은 다음을 갖고 있습니다:\n프로그램을 실행할 수 있는 능력 데이터를 휘발성 메보리에 저장할 수 있는 능력과 (실패시에는 소실될 수 있는) 안정적인 상태로 저장 할 수 있는 능력 (실패 이후에도 읽을 수 있는) a clock (정확하다고 믿거나 믿지 않을 수 있는 시계) 노드들은 결정적인(deterministic) 알고리즘들을 실행합니다; 내부 연산, 연산 이후의 내부 상태, 메시지를 수신한 이후 자체적으로(uniquely) 결정한 메시지를 전송한다거나.\n노드가 실패 했을 때의 동작을 기술한 많은 실패 모델들이 있는데, 실제로는 (in practice), 대부분의 시스템들이 크래쉬-복구 실패 모델을 가정합니다; 이것은, 노드들이 크래쉬가 났을 경우에만 실패하며, 일정 시점 이후에는 복구 할 수 있다 라고 가정합니다.\n다른 대안은 노드는 임의의 다른 의도하지 않은 동작을 하여 실패할 수 있다고 가정하는 것인데요, 이것은 비잔틴 실패 tolerance 라고 알려져 있습니다. 비잔틴 실패는 상용 시스템에서는 거의 다뤄지지 않으며, 임의의 실패에 대응 할 수 있는 알고리즘은 구현하기가 훨씬 복잡하고, 비싸기 때문입니다. 이것에 대해 다루지는 않겠습니다.\nCommunication links in our system model 통신 연결들이 각각의 도드들을 연결하며, 메시지들이 어떤 방향으로도 전송 될 수 있도록 해줍니다. 많은 책들에서 분산 알고리즘들은 각각의 노드 쌍에 대해 각각의 연결, 메시지에 대해 FIFO 를 제공하고 그들이 보낸 메시지만 전달하고, 유실될수 있다고 가정합니다.\n어떤 알고리즘들은 이 네트워크가 신뢰할 수 있다고 믿습니다; 메시지들은 절데 유실되지 않으며 절대 무기한 연기되지 않는다. 이런 가정들은 어떤 실세계의 설정에서는 유효한 가정이지만, 일반적인 경우에는 네트워크는 신뢰할 수 없으며 대상들은 메시지를 유실하거나 지연할 수 있다고 고려하는것이 선호 됩니다.\n네트워크 파티션은 네트워크가 실패하여 다른 노드들 자체들은 연산가능한 상태로 남아 있을 때 발 생합니다. 이것이 일어나게 되면, 메시지들은 유실되거나 네트워크 파티션이 복구 될때까지 지연되게 됩니다. 파티션 된 노드들은 어떤 클라이언트에게는 정상적으로 접근가능하므로, 크래쉬 노드와는 다르게 처리되어야 합니다. 아래의 다이어그램은 노느 실패와 네트워크 파티션을 나타냅니다.:\n통신링크에 대해 더 많은 가정을 하는 것은 드뭅니다. 우리는 연결들이 하나의 방향성만 가진다고 가정하거나, 다른 커뮤니케이션 비용을 소개할 수 도 있습니다. (e.g. 물리적 거리로 인한 지연) . 그러나, 이것들은 상업적 환경에서는 큰 걱정사항이 아니며 (WAN 지연과 같은 긴거리의 연결을 제외하고) 그렇기때문에 여기서 논의 하지 않겠습니다; 더 자세한 비용과 topology 에 대한 모델은 복잡성에 대해 더 나은 최적화를 하게 됩니다.\nTiming / ordering assumtions 각각의 노드들이 물리적인 분리가 되어있다는 것은 세상을 유일한 매너로 볼 수 있게 해 줍니다. 이것은 피할 수 없는데, 광속을 뛰어넘는 정보란 있을 수 없기때문입니다. 만약 노드들이 각각 다른 거리에 있고, 어떤 메시지지들도 하나의 노드에서 다른 노드로 전송되면, 노드들 사이에서 각각 다른 순서와 시간으로 도달 할 수 있습니다.\n타이밍에 대한 가정은 현실을 고려할 때 확장하기에 쉽게 해 줍니다. 주요한 두 대안들은:\nSychronous system model 프로세스들은 락 단계 에서 실행됩니다; 메시지 전송 지연에는 알려진 상한이 있으며; 각각의 프로세스들은 정확한 clock 을 가지고 있습니다.\nAsynchronous system model 타이밍에 대한 가정은 없습니다 -e.g. 프로세스들은 독립적인 비율로 실행합니다; 메시지 전송 지연에 대한 범위는 없으며; 유용한 clocks 도 없습니다.\n동기화된 시스템 모델은 시간과 순서에 대한 많은 제약들을 두고 있습니다. 이것은 필수적으로 노드들이 같은 경험을 하도록 가정합니다; 메시지들은 항상 최대 전송 지연 시간 안에 수신되어야하며, 락 단계( lock-step) 에서 실행 되어야 합니다. 이것은 시스템의 디자이너가 시간과 순서에 대한 많은 가정을 할 수 있게 하므로, 편리한 반면에, 비동기화된 시스템모델은 그렇지 않습니다.\n비동시성은 가정이란 없습니다; 그저 타이밍에 대한 가정을 할수 없다 라는 가정 만이 있습니다.\n동기화된 시스템 모델에서 문제를 푸는 것이 더 쉬운데, 실행 스피드, 최대 메시지 전송지연, 시계 정확성에 대한 가정 모두 문제를 푸는데 도움을 주기 때문인데, 이는 가정에 기반하여 추론을 할 수 있게 해주고, 일어나지 않을 것이라고 가정하는 불편한 실패 시나리오들을 생각할 필요가 없기 때문입니다.\n물론, 동기화된 시스템 모델을 고려하는것은 일부는 현실적이지 않스빈다. 실세계의 네트워크는 실패할 수 있으며, 메시지 딜레이에 대한 강력한 범위도 없스빈다. 실세계의 시스템은 최대한 일부적으로 동기화 되어있습니다: 때때로 올바르게 동작하고 최대 지연 범위를 제공하지만, 메시지가 무한하게 딜레이될 수 있고 시계들은 동작에서 벗어 날 수 있습니다. 여기서 동기화된 시스템의 알고리즘에 대해 다루진 않을 것이며, 분석하기 쉽기 때문에 (현실적이지 않지만) 다른 책들에서 많이 다루고 있을 겁니다.\nThe consensus problem 이 문서의 나머지에서, 우리는 시스템모델의 인자들을 다양화 할 것 입니다. 이후에는, 어떻게 두 시스템 송성들을 다양화 할 것인가에 대한 것을 살펴 봅니다.\n네트워크 파티션이 실패 모델에 포함을 할 것인지, 동시성 vs. 비 동시성의 타이밍 가정을 할 것인지. 시스템 디자인 선택의 영향은 두 불가능한 결과(FLP 와 CAP) 를 논의 하는것에 의해 영향을 받습니다.\n물론, 논의를 하기 위해, 풀어야할 문제를 소개할 필요가 있겠네요. 바로 타협 문제입니다.\n몇몇 컴퓨터 (노드) 들은 그들이 어떤 값들에 대해 모두 동의 할 수 있습니다. 더 격의 적으로 이야기하면:\n동의: 모든 올바른 프로세스들은 같은 값들에 동의 해야합니다. 통합: 모든 올바른 프로세스들은 최대 하나의 값을 결정하고, 어떤 값을 정하면, 어떤 프로세스에 의해 제안 되어야 합니다. 종료: 모든 프로세스들은 결과적으로 결정에 다달아야 합니다. 유효성: 만약 모든 올바른 프로세스들이 같은 값 V 를 제안했다면, 모든 올바른 프로세스들이 V 를 결정한 것입니다. 이 타협 문제는 많은 상업용 분산 시스템에서의 주요 문제 입니다. 결과적으로, 우리는 분산에서의 부작용을 다루지 않고 신뢰성과 성능을 얻고 싶으며, aotmic broadcase 와 atomic commit 같은 타협문제와 관련한 더 발전된 문제들을 풀고 싶어하죠.\nTwo impossibility results 첫번째 불가능한 결과 (FLP imossibility result 로 알려진)는 분산시스템을 설계한 사람에 관계한 불가능한 결과 입니다. 두번째는 - The CAP 이론- 실무자에 더 관계한 결과 입니다; 시스템 디자인을 선택 하는 사람들이 알고리즘 디자인에 대한 직접적인 고려가 없는 경우에 해당합니다.\nThe FLP impossibility result 간략하게 FLP 불가능 결과 에 대해 요약해 보면, (교육계에서는 더 중요하게 고려 되지만) FLP 불가능 결과 (Fishcher, Lynch and Patterson 저자에 의해 지어진 이름입니다.) 비동기 시스템 위에서 타협 문제를(기술적으로, 타협문제의 작은 형태인 동의 문제) 검사합니다. 노드들은 크래쉬에 의해 실패할 수 있다고 가정합니다.; 네트워크는 신뢰할 수 있고, 비동기 모델에서의 일반적인 타이밍 문제는 유지 됩니다: e.g. 메시지 지연에 대한 범위는 없습니다.\n이런 가정하에, FLP 결과는 \u0026ldquo;(deterministic)한 알고리즘은 실패할 수 있는 비동기 모델에서 메시지가 절대 유실되지 않더라도, 최대 하나의 프로세스만이 실패할 수 있더라도, 그 이유가 오로지 크래쉬에 의한 것이라도 존재할 수 없다.\u0026rdquo; 라고 이야기 합니다.\n이 결과는 무한하게 지연될 수 없다.라고 가정한 최소한의 시스템 모델에서는 타협문제를 풀 방법이 없다고 이야기 합니다. 이 논쟁은 이런 알고리즘이 존재한다면, 메시지 전송이 임의의 시간동안 지연될 수 있는 결정되지 않은 상태로 남아있는 (2가의 -bivalent) 알고리즘을 고안 할 수 있을 것이다. 그러므로, 이런 알고리즘은 존재하지 않는다. 에 대한 것입니다.\n이 불가능 결과는 비동기 시스템 모델이 tradeoff 를 가짐에 초점을 맞추고 있기 때문에 중요합니다.: 타협문제를 푸는 알고리즘은 메시지 전송에 관한한 지연 범위를 보장할 수 없을때에는 안정성이나 실시간 성을 포기해야함을 시사하고 있습니다.\n이 통찰은 알고리즘을 디자이낳는 사람들에게 더 관계가 있는데, 비동기 시스템 모델에서 풀 수 있다고 알고 있는 문제에 대해 더 강한 제약을 의미하기 때문입니다. CAP 이론은 실무자에게 더 관련되어 있습니다; 이것은 다소 다른 가정(노드 실패가 아닌 네트워크 실패) 만들고, 시스템 디자인 선택을 할때에 실무자가 더 명확한 의미를 갖도록 합니다.\nThe CAP theorem CAP 이론은 처음에는 컴퓨터 과학자 Eric Brewer 에 의해 추측되었습니다. 시스템 디자인을 정할 때 tradeoff 에 대해 생각하는 꽤 유용하고 유명한 방법입니다. Gilbert 와 Lynch 의 공적인 증명 도 있으며, Nathan Marz 는 논의 사이트 가 생각하는 것에도 불구하고 폭로하지 않았습니다. (TODO refined. It even has a formal proof by Gilbert and Lynch and no, Nathan Marz didn\u0026rsquo;t debunk it, in spite of what a particular discussion site thinks.)\n이 이론은 다음과 같은 세가지 속성을 가집니다.:\n일관성: 모든 노드들은 같은 때에 같은 값을 가진다. 가용성: 노드 실패가 다른 생존자들이 동작하는 것을 막지 않는다. 일부 tolerance: 시스템은 네트워크나 노드 실패로 인한 메시지 유실에도 계속해서 동작한다. 동시에 두개 만이 만족될 수 있습니다. 보기좋게 다이어그램으로 만들어보면, 셋 중에 두 속성을 선택하는 것은 세가지의 시스템 타입을 나타내는데, 각각의 교집합으로 표현 되어 있습니다.\n이 이론은 (모든 세개의 속성에서) 중앙의 조각은 얻어질 수 없음을 이야기 합니다. 세개의 시스템 타입은 다음과 같습니다.\nCA (consistency + availability). 정족수(quorum) 규약을 엄격히 따르는 예제로서, 2 phase commit 과 같은 예를 생각해볼 수 있습니다. CP (consistency + partition tolerance). 다수 정족수를 따르는 경우로, 소수의 파티션은 (Paxos 같은) 사용할 수 없게 됩니다. AP (consistency + partition tolerance). 다이나모 같은 충돌 해결을 사용하는 프로토콜입니다. CA 와 CP 시스템 디자인은 모두 같은 일관성 모델을 제안합니다: 강력한 일관성. 둘의 유일한 차이는 CA 는 노드 실패에 대해 tolerate 하지 않다는 접입니다; CP 시스템은 비잔틴 실패가 없는 2f + 1 노드에서 f 실패까지 tolerant 합니다. (다시 말해서, 다수인 f + 1 이 살아 있는 동안 소수인 f 의 실패까지는 버틸 수 있습니다.) 그 이유는 간단합니다:\nCA 시스템은 도드의 실패와 네트워크 실패를 구분하지 않으며, 따라서 분리(복수의 복제)를 피하기 위해 쓰기를 중지해야합니다. 이것은 원격의 노드가 내려간 것인지, 네트워크 연결이 중지된 것인지 말할 수 없습니다: 따라서 유일한 안전한 방법은 쓰기를 중지하는 것 뿐입니다. CP 시스템은 두 파티션의 비대칭 동작을 강제로 막음으로써 분리(divergence - 한개의 복제 일관성 만을 유지합니다)를 막습니다. 만약 다수의 파티션을 유지하기만 한다면, 소수의 파티션만이 비가용 적이도록 유지한다면, (e.g. 쓰기를 막는다), 가용정도는 유지하면서 여전히 하나의 복제 일관성만을 유지할 수 있습니다. 이 것들에 대해서는 Paxos 에 대에 논의 할때 복제에 대해 더 자세히 다루겠습니다. CP 모델에서 중요한것은 협조적이지 않은 네트워크 파티션은 다수의 파티션과 구분한다는 것입니다. (Paxos, Raft, viewstamped 복제와 같은 알고리즘을 사용하여) CA 시스템은 파티션에 자각적이지 않고, 역사적으로 더 흔한 시스템 입니다; 보통 2-phase 커밋 알고리즘 같은 것들이 전통적인 분산 관계형 데이터 베이스에서 흔히 사용됩니다.\n파티션이 일어 났다고 가정했을때, 이 이론은 가용성과 일관성, 어떤 것을 선택할 것인지로 문제를 줄입니다.\nCAP 이론으로부터 4개의 결론을 낼 수 있을 것 같네요.\n첫째, 전통적인 관계형 데이터베이스와 같은 분산시스템 디자인들은 파티션 tolerance 에 대해 다루지 않았다. (e.g. CA 디자인이었다). 파티션 tolerance 는 현대의 시스템에서는 중요한 속성이며, 네트워크 파티션이 물리적으로 분산되어 더 잘발생할 수 있어졌기 때문입니다.\n둘째, 네트워크 파티션이 발생하였을때 강력한 일관성 모델과 높은 가용 성을 유지하는것 사이에서 긴장이 있다. CAP 이론은 분산 연산에서 강력한 보장을 위해서는 tradeoff 가 있음을 설명하고 있습니다.\n어떤 경우에는, 예측할 수 없는 네트워크로 연결되어있는 독립적인 노드들로 이루어진 분산 시스템에서 \u0026ldquo;비분산 시스템과 구분할수 없는 방식으로 동작하게 할거야\u0026rdquo; 라는 것을 약속하는 것은 꽤 미친 짓이죠!\u0026quot;\n강력한 일관성은 파티션이 발생한 동안은 가용성을 포기합니다. 이것은 두 복제가 서로 통신할 수 없는 상황에서 양쪽 파티션에서 쓰기를 허용하면 분리(divergence)를 막을 수 없기 때문입니다.\n어떻게 이것들 사이에서 일할 수 있을까요? 가정을 더 강화(파티션은 없어!) 하거나, 보장을 약화할 수 밖에 없습니다. 일관성은 가용성과 tradeoff 관계에 있습니다.(또, 오프라인 접근성의 용량과 낮은 지연과 관련해 있습니다). 만약 \u0026ldquo;일관성\u0026rdquo; 이 \u0026ldquo;모든 노드들은 동시에 같은 데이터를 보고 있다\u0026rdquo; 라는 것보다 작은 것이라면, 가용성과 더 (약한) 일관성을 보장 받을 수 있습니다.\n셋째, 일반적인 동작에서, 강력한 일관성과 성능 사이에는 긴장이 있다\n강력한 일관성 / 하나의 복사 일관성은 노드 통신이 되면서 모든 연산에 대해 동의 해야함을 의미합니다. 이것은 일반적인 연산에 있어서 높은 지연으로 이어집니다.\n만약 고전적이지 않은 일관성 모델에서 살고 있다면, 복제의 지연이나 분리를 허용하고 있을것이며, 이후에 일반적인 연산을 하면서 지연을 줄이고 파티션의 존재에 대해 가용성을 유지하고 있을 것입니다.\n더 적은 메시지와 더 적은 노드가 관계할수록 어떤 연산들은 더 빠르게 완료될 수 있습니다. 하지만 이것을 이루기 위해서는 보장을 완화하는 방법밖에 없습니다: 어떤 노드들이 더 적게 접촉할수록 할수 밖에 없는데, 이는 이전 데이터를 갖고 있다는 의미죠.\n이 것은 이상(anomalies) 가 이뤄지게 합니다. 더이상 최신의 값을 보장 받을 수 없습니다. 어떤 보장을 받을지에 의존 함에 따라서, 당신은 기대보다 이전의 데이터를 읽을 수 있으며, 심지어 수차례의 업데이트를 놓칠 수도 있습니다.\n넷째 - 좀 간접적이지만 - 네트워크 파티션으로 인한 가용성을 포기하고 싶지 않다면, 우리의 목적을 위해 강력한 일관성과는 다른 일관성 모델을 찾을 필요가 있다\n예를 들어서, 유저 데이터가 물리적으로 여러 데이터 센터에 있더라도, 두 데이터 센터의 연결이 일시적으로 고장나더라도, 대부분의 경우에 유저가 우리의 웹사이트/서비스를 이용하게 허용하고 싶습니다. 이것은 나중에 두 데이터를 다시 화해( reconciling -비지니스 적으로도 리스키하고 기술적으로도 도전적인 작업인 -) 시켜야함을 의미합니다. 그러나, 이 기술적으로 도전적이고 비즈니스적으로도 리스키한 작업이 종종 관리 될 수 있으며, 고 가용성을 위해 선호 되는 편입니다.\n일관성과 가용성은 강력한 일관성으로 제약하지 않는다면, 사실 완전히 이지선다는 아닙니다. 강력한 일관성은 그저 하나의 일관성 모델일 뿐입니다: 활성화 되어있는 하나만의 데이터를 유지하기 위해서만 가용성을 포기해야할 필요가 있죠. Bewer 자신이 지적한 것처럼, \u0026ldquo;셋 중의 둘\u0026rdquo; 이라는 해석은 잘못된 것이라고 할 수 있습니다.\n만약 이 토론에 대해 하나의 아이디어만 뽑아낸다면, 이것일 것입니다. \u0026ldquo;일관성\u0026rdquo; 은 단수형이나, 모호하지 않은 속성이 아닙니다. 기억하세요.\nACID 일관성 !=\nCAP 일관성 !=\nOatmeal 일관성\n대신에, 일관성은 그걸 사용하는 프로그램에 데이터 저장소가 제공하는 보증입니다.\nConsistency model 시스템은 프로그래머가 어떤 특정한 규칙에 따른다면 시스템이 데이터가 저장되는 결과가 예측가능하도록 보장하는 프로그래머와 시스템 사이의 계약서\nCAP 의 \u0026ldquo;C\u0026rdquo; 는 강력한 일관성이 지만, \u0026ldquo;일관성\u0026quot;은 \u0026ldquo;강력한 일관성\u0026quot;과 같은 말이 아닙니다.\n이제 다른 일관성 모델을 살펴 보죠.\nStrong consistency vs. other consistency models 일관성 모델은 두가지 타입으로 분류 될 수 있습니다: 강력하거나, 약하거나:\n강력한 일관성 모델 (하나의 복사만을 유지함) 선형 적인 일관성 순차적인 일관성 약화된 일관성 모델 (강력하지 않음) 클라이언트 사이드의 일관성 모델 캐주얼한 일관성: 강력한 모델이 가능할 때 결과적으로 일관적인 모델 강력한 일관성 모델은 명확한 순서나, 갱신에 대한 가시성을 보장하여 복제 되지 않은 시스템과 동등한 시스템을 유지합니다. 약화된 일관성 모델은, 반면에, 이런 보장들을 하지 않습니다.\n이것이. 철저한 리스트는 아님을 주지해주세요. 다시 말해서, 일관성 모델은 임의의 계약 (시스템과 프로그래머 사이의) 이어서, 어떤 것이든 될 수 있습니다.\nStrong consistency models 강력한 일관성 모델은 두 비슷한 모델로 나뉘어 질 수 있습니다. (일부가 다릅니다.)\n선형적인 일관성: 이 일관성 모델에서는, 모든 연산들이 아토믹하게 순서대로 이뤄지며 글로벌 실세계의 연산 순서를 따릅니다. (Herilhy \u0026amp; Wing, 1991) 순차적인 일관성: 이 일관성 모델에서는, 모든 연산들은 모든 노드와 동등한 각각의 노드들에 의해 일관적인 순서로 아토믹하게 연산이 이뤄집니다. (Lamport, 1979) 두 일관성 모델의 차이가 되는 열쇠는, 선형적인 일관성에서는 실시간의 연산 순서와 동등하게 연산이 수행 되어야 한다는 점입니다. 순차적인 일관성은 각각의 노드에서 확인 할 수 있는 일관성이 유지 되는한, 연산이 재배치 되는 것을 허용합니다. 이 둘을 구분할수 있는 유일한 방법은 입력이 시스템에 반영되는 타이밍을 관찰하는 것 밖에 없습니다; 노드들과 교류하는 클라이언트의 관점에서는, 둘은 동등합니다.\n두 차이는 중요하지 않은 것 같아 보이지만, 순차적인 일관성이 결합하지 않는 다는 점은 주목할 필요가 있습니다.\n강력한 일관성 모델은 프로그래머가 하나의 서버를 분산된 도드들의 클러스터로 대체하여도 어떤 문제도 없게 해 줍니다.\n모든 다른 일관성 모델은 anomailies (강력한 일관성 모델과 비교해서)가 있으며, 복제되지 않은 시스템과 구별되는 동작을 하기 때문입니다. 하지만, 이런 이상 증상들은 보통 수용가능하며, 일시적인 이슈는 괜찮거나, 비 일관적인 상태를 다루도록 코드를 작성했기 때문입니다.\n약화된 일관성 모델에서 범우주적인 토폴로지는 없다는 것을 명심해주세요. 왜냐하면, \u0026ldquo;강력한 일관성모델이 아닌 모델\u0026rdquo; (e.g. 어떤 방식으로든 복제되지 않는 시스템과 구분가능한것\u0026rdquo;) 은 어떤 모양이든 가질 수 있으니까요.\nclient-centric consistency models client-centric consistency models는 클라이언트나 세션의 개념을 포함한 일관성 모델입니다. 예를 들면, 클라이언트 중심 일관성 모델은 클라이언트는 절대 예전버전을 보지 않음을 보장하는 것이죠. 이것은 종종 클라이언트 라이브러리에서의 추가적인 캐싱을 구현하여 클라이언트가 예전 버전의 복제 노드로 이동하면, 예전 데이터를 보유한 복제본의 데이터를 반환하는 것 대신 캐쉬의 데이터를 반환 하는 형태로 구현됩니다.\n클라이언트는 예전 버전의 데이터를 볼수 있지만, 복제본의 노드가 최신의 데이터를 갖고 잇지않다면, 그렇지만 이전 버전의 재 표면화로 인한 (e.g. 다른 복제본으로 연결 됨으로 인해) 이상현상은 보지 않게 됩니다. 이런 일관 성 모델에는 많은 종류가 있다는 것을 기억해 주세요.\neventual consistency 결과적 일관성 모델은 값을 변경하는 것을 멈춘다면, 정의되지 않은 얼마간의 시간뒤에 모든 복제들은 같은 값을 갖게 됩니다. 이것은 그 시간 전까지는 복제본들 사이에서 정의되지 않은 형태로 일관적이지 않은 데이터를 가질 수 있음을 내포하고 있습니다. 사소하게 만족적 이기 때문에, 보충 정보가 없이는 유효하지 않습니다.\n어떤것을 단순하게 결과적으로 일관적이다. 라고 이야기 할때, \u0026ldquo;사람들은 결과적으로 죽는다\u0026rdquo; 라고 이야기하는 것과 비슷합니다. 이것은 상당히 약한 제약조건이며, 최소한 다음과 같은 두 특징을 얻기를 원할 것입니다.:\n첫째, \u0026ldquo;결과적으로\u0026rdquo; 라는 것은 얼마나 긴 것인지? 이것은 하한선을 정해 두는 것이 유용할 수 있으며, 아니면, 같은 값에 대한 시스템의 커버리지를 일반적으로 얼마나 길것인지 에 대한 최소한의 아이디어를 가져가는 형태입니다.\n둘째로, 어떻게 값에 대한 동의를 할 것 인가? 인데, \u0026ldquo;42\u0026rdquo; 라고 항상 이야기하는 시스템은 결과적으로 일관적 입니다: 모든 복제본들은 같은 값을 통의합니다. 이것은 단지 유용한 값에 대해 커버리지가 없을 뿐입니다. 대신에, 우리는 방법에 대한 더 좋은 아이디어가 있습니다. 예를 들면, 가장 큰 타임스탬프를 가진 값이 항상 이기는 것입니다.\n따라서, 제공자가 \u0026ldquo;결과적으로 일관적이다\u0026rdquo; 라고 이야기하면, 더 정확한 용어를 의미하는 것일 수있습니다. \u0026ldquo;결과적으로 최근값이 이기고, 그동안 가장 최근값으로 관측 되는 값이 일겅진다\u0026rdquo; 일관성과 같이 요. 이 \u0026ldquo;어떻게?\u0026rdquo; 가 관건이며, 좋지 않은 메소드는 쓰기 작업을 잃어버릴 수도 있기 때문입니다. 예를 들어서, 만약 어떤 노드의 시계가. 잘못 설정되어 있었고, 그 타임스탬픅가 사용될 수 도 있죠\u0026hellip;\n이 두가지 질문에 대해 약화된 일관성 보델에 대한 복제 방식 챕터에서 더 자세히 다루겠습니다.\n","permalink":"https://nolleh.github.io/distributed-systems/2.level-of-abstraction/","summary":"다음에서 발췌 http://book.mixu.net/distsys/abstractions.html\n2. Up and down the level of abstraction 이 챕터에서는, 추상화의 레벨을 여행할 것이며, 몇가지 불가능한 결과를 보고, (CAP 와 FLP), 그리고 나서 성능에 대한 항해를 할 것 입니다.\n만약 어떤 프로그래밍을 완료했다면, 추상화. 수준에 대한 개념은 당신에게 익숙할 겁니다. 당신은 이미 추상화와 함께 했고, 어떤 API 를 통해 더 낮은 레이어와 인터페이싱하고 있을 것이며, 더 높은 레이어에 API 나 인터페이스를 제공하고있을 겁니다. OSI 네트워크 7 계층이 좋은 예죠.","title":"2.level of Abstraction"},{"content":"자주 사용하는 서브 모듈 명령어.\nadd submodule git submodule add {remote-repo} update git submodule init\ngit 에서 서브모듈을 관리하기위한 설정파일, gitmodules 를 설정한다. git submodule update remote 저장소로부터 업데이트 내용을 가져와서 적용한다. git submodule update --init remove submodule git submodule deinit -f {path} rm -rf .git/modules/{path} git rm -f {path} ","permalink":"https://nolleh.github.io/git/sub-module/","summary":"자주 사용하는 서브 모듈 명령어.\nadd submodule git submodule add {remote-repo} update git submodule init\ngit 에서 서브모듈을 관리하기위한 설정파일, gitmodules 를 설정한다. git submodule update remote 저장소로부터 업데이트 내용을 가져와서 적용한다. git submodule update --init remove submodule git submodule deinit -f {path} rm -rf .git/modules/{path} git rm -f {path} ","title":"서브 모듈 추가하기"},{"content":"1.12. Active-Passive Messaging Clusters 1.12.1 Overview HA 모듈은 active-passive, hot-standby 메시징 클러스터들을 장애에 tolerent 하도록 제공한다.\nactive-passive 클러스터는 하나의 브로커만 존재하며, 이를 프라이머리라고 부르며, 액티브 하고 클라이언트를 serving 한다. 다른 브로커들은 백업을 위해 존재한다. 프라이머리의 변경은 모든 백업들에 반영되므로, 백업들은 최신상태이거나 \u0026lsquo;hot\u0026rsquo; 상태이다. 백업 브로커들은 클라이언트의 연결을 거부하며, 클라이언트들은 프라이머리에 연결해야한다.\n만약 프라이머리가 실패하는 경우, 백업중의 하나가 새로운 프라이머리가 되기위해 자리를 차지한다. 클라이언트는 새로운 프라이머리에 자동으로 연결한다.\n만약 복수개의 백업이 있다면, 다른 백업들은 새로운 프라이머리의 백업이 되도록 장애처리를 진행한다.\n이 접근은 외부의 클러스터 리소스 매니저가 장애를 탐지하고, 새로운 프라이머리를 선택하며, 네트워크 파티션을 핸들링하는 것을 믿는것이다. rgmanager 는 이를 기본적으로 지원하며, 다른 것들은 미래에 제공될 것이다.\n1.12.1.1. Avoiding message loss 메시지가 모든 백업 브로커들에 대해 복제되는 것을 대기하거나 프라이머리 큐에서 consumed 되고 클라이언트로 응답(acknowledgement) 을 줌으로써 메시지의 유실을 회피한다.\n이것은 응답이 돌아온 모든 메시지들은 \u0026lsquo;safe\u0026rsquo; 하다는 것을 보장한다. : consumed 되거나, 다른 모든 브로커로 복제 되었음을. 복제 되기전에 consumed 된 메시지들은 복제가 될 필요가 없다. 액티브한 컨슈머가 있는 큐에 복제하는 부담을 줄여준다.\nprimary 에 의해 응답을 받기 전까지 버퍼에 미응답상태의 메시지를 보관해야한다. 만약 프라이머리가 실패하면, 클라이언트는 새로운 프라이머리에 연결하고 다시 메시지를 전송하는 장애처리를 수행해야한다.\n만약 프라이머리에 크래쉬가 발생하는 경우, 모든 응답을 받은 메시지들은 백업에 의해 가용하고, 이중에 새로운 프라이머리가 있을 것이다. 그래서 유실은 발생하지 않는다.\n하나 알아두어야 할것은, 메시지가 중복되서 전송될 수 있다는 것이다. 장애 발생시에 새로운 프라이머리에 의해 클라이언트로 다시 메시지를 전송하는 것이 가능하다. 이를 감지하고 중복을 제거하는 것은 어플리케이션의 몫이다.\n프라이머리가 새로 승격하는경우, 처음에 \u0026ldquo;recovering\u0026rdquo; 모드에 진입한다. 이 모드에서는, 모든 백업들이 프라이머리에 성공적으로 연결할때까지 메시지들에 대한 응답들을 지연한다.\n백업브로커에 모든 메시지가 복제될 필요는 없다. 만약 메시지가 consumed 되고 응답을 받은경우 복제될 필요는 없다.\nHA Broker State\nStand-alone cluster 의 일부가 아니다 Joining 새로 시작된 브로커이고, 어떤 프라이머리에도 아직 연결되지 않았다. Catch-up 프라이머리에 연결되었고, 상태를 다운로드 받는 중이다 (queues, messages.. ) Ready catch-up 을 완료했고 프라이머리가 될 준비가 되었다. Recovering 새로 승격한 프라이머리이며, 백업들이 연결하여 catchup 하도록 기다리고 있다. 클라이언트들은 연결할 수 있지만 프라이머리가 액티브 상태가 될때까지 엔진을 멈춘다. Active 모든 백업들이 연결되고 캐치업된 프라이머리 브로커 1.12.1.2. Limitations 현재 구현상 알려진 제한이 있다. 새 버전에서는 수정될 것.\n","permalink":"https://nolleh.github.io/qpid/1.12.active-passive-messaging-clusters/","summary":"1.12. Active-Passive Messaging Clusters 1.12.1 Overview HA 모듈은 active-passive, hot-standby 메시징 클러스터들을 장애에 tolerent 하도록 제공한다.\nactive-passive 클러스터는 하나의 브로커만 존재하며, 이를 프라이머리라고 부르며, 액티브 하고 클라이언트를 serving 한다. 다른 브로커들은 백업을 위해 존재한다. 프라이머리의 변경은 모든 백업들에 반영되므로, 백업들은 최신상태이거나 \u0026lsquo;hot\u0026rsquo; 상태이다. 백업 브로커들은 클라이언트의 연결을 거부하며, 클라이언트들은 프라이머리에 연결해야한다.\n만약 프라이머리가 실패하는 경우, 백업중의 하나가 새로운 프라이머리가 되기위해 자리를 차지한다. 클라이언트는 새로운 프라이머리에 자동으로 연결한다.\n만약 복수개의 백업이 있다면, 다른 백업들은 새로운 프라이머리의 백업이 되도록 장애처리를 진행한다.","title":"Active Passive Messaging Clusters"},{"content":"1.4 Broker Federation 메시지 라우트를 정의하여 하나의 브로커에서 다른 브로커로 자동으로 전달하게 한다.\n일반적으로 일방향이며, 라우트는 durable 하고 tansient 한다.\n연결이 소실되면 메시지는 누적되다가 재연결이 되면 다시 전송한다.\n라우팅에 사용되는 룰은 서버가 변경됨에 따라 동적으로 변경할 수 있으며, 변경의 책임은 다른 변경조건에 맞게 반영된다,.\n1.4.1 Message Routes pull / push 방식이 있음.\npull 은 dest 에서.\npush 는 src 에서 설정함\nqueue \u0026lt;-\u0026gt; exchage exchange \u0026lt;-\u0026gt; exchange excg \u0026lt;-\u0026gt; excg 는 다음과 같은 라우트를 가질 수 있다.\n1.4.1.1 Queue Routes 모든 메시지를 src 에서 dest 로.\n1.4.1.2 Exchange Routes 바인딩키에 따라 라우트함\n실제로는 내부적으로 큐가 (auto-delete, exclusive) 만들어지고, 이를 통해 연결하는 것.\n1.4.1.3 Dynamic Exchange Routes 클라이언트가 바인딩을 맺고, 이 exchange 만이 아니라 dynamic exchange route 를 통해 생성된 다른 exchange 도 수신한다. 바인딩 변경시, 이 exhcange 와 관련한 다른 exchange routes 또한 변경한다.\nsource 에 연결 된 모든 dest exchange 에 대해 적용되는데, 하나의 메시지라도 매치가 되면 dest 에 라우트되도록한다. dest 에서 바인딩들이 추가되거나 삭제되는경우, 이 변화는 DER 에 적용이 된다. dest 브로커가 바인딩을 주어진 바인딩키를 만들경우 라우트에 반영이되고 바인딩키를 제거할 경우 라우트는 더이상 메시지를 브로커들에게 전달하는 오버헤드를 갖지 않는다. 만약 두 excg 가 der 을 서로에 대해 갖는경우, 각각의 excg 에 대한 모든 바인딩은 der 에 반영된다. DER 에서, source 와 destination exchages 들은 같은 excage 타입을 가지고 있어야하고, 같은 이름을 가져야 한다. 내부적으로 dynamic exchage routes 는 exchage 라우트와 동일하게 구현되어 있는데, 다른점은 DEST Excg 에 바인딩이 있는 경우 DER 을 구현하는데 사용한 바인딩들이 수정됐다는것. (? except that the bindings used to implement dynamic exchange routes are modified if the bindings in the destination exchange change.)\nDER 은 항상 pull route 형식이다.\n1.4.2 Federation Topolpogies 보통 이 네트워크는 트리구조, 스타구조, 선형, 양방향 링크, 로 구성된다. 링 형태도 가능하지만, 이때는 단방향링크들만 사용하여야 한다.\n메시지를 빨리 전달 받기 위해서는 브로커 사이 홉을 줄이는 것이 중요. 그래서 대부분의 경우 트리나 스타 토폴로지가 최고다.\nA, B 가 있다고 할 때 서로를 연결하는 경로는 하나만이 있어야 할 것.\n만약 하나 이상의 경로가 있으면 중복된 메시지 전송을 야기하고 네트워크의 홍수를 일으킬 것.\n1.4.3 Federation among High Availablity Message Clusters fedration 은 일반적으로 High Availability Message Clusters 와 사용이 되는데, 클러스터들이 각각의 LAN 에 대해 고 안정성을 얻게끔한다.\n메시지 상태가 클러스터에서 복제 되기 때문에,\n같은 클러스터의 다른 브로커 사이에서 메시지 라우트를 정의하는 작은 개념을 만들어 준다.\n두 클러스터 사이에서 메시지를 생성하기 위해, 첫번째 클러스터에서 다른 클러스터의 브로커로 라우터를 만들어주면된다.\n1.4.4 The qpid-route Utility $ qpid-route [OPTIONS] dynamic add \u0026lt;dest-broker\u0026gt; \u0026lt;src-broker\u0026gt; \u0026lt;exchange\u0026gt; $ qpid-route [OPTIONS] dynamic del \u0026lt;dest-broker\u0026gt; \u0026lt;src-broker\u0026gt; \u0026lt;exchange\u0026gt; $ qpid-route [OPTIONS] route add \u0026lt;dest-broker\u0026gt; \u0026lt;src-broker\u0026gt; \u0026lt;exchange\u0026gt; \u0026lt;routing-key\u0026gt; $ qpid-route [OPTIONS] route del \u0026lt;dest-broker\u0026gt; \u0026lt;src-broker\u0026gt; \u0026lt;exchange\u0026gt; \u0026lt;routing-key\u0026gt; $ qpid-route [OPTIONS] queue add \u0026lt;dest-broker\u0026gt; \u0026lt;src-broker\u0026gt; \u0026lt;dest-exchange\u0026gt; \u0026lt;src-queue\u0026gt; $ qpid-route [OPTIONS] queue del \u0026lt;dest-broker\u0026gt; \u0026lt;src-broker\u0026gt; \u0026lt;dest-exchange\u0026gt; \u0026lt;src-queue\u0026gt; $ qpid-route [OPTIONS] list [\u0026lt;broker\u0026gt;] $ qpid-route [OPTIONS] flush [\u0026lt;broker\u0026gt;] $ qpid-route [OPTIONS] map [\u0026lt;broker\u0026gt;] $ qpid-route [OPTIONS] list connections [\u0026lt;broker\u0026gt;] The syntax for broker, dest-broker, and src-broker is as follows:\n[username/password@] hostname | ip-address [:\u0026lt;port\u0026gt;] The following are all valid examples of the above syntax: localhost, 10.1.1.7:10000, broker-host:10000, guest/guest@localhost.\nTable 1.9. qpid-route options\n-v Verbose output. -q Quiet output, will not print duplicate warnings. -d Make the route durable. \u0026ndash;timeout N Maximum time to wait when qpid-route connects to a broker, in seconds. Default is 10 seconds. \u0026ndash;ack N Acknowledge transfers of routed messages in batches of N. Default is 0 (no acknowledgements). Setting to 1 or greater enables acknowledgements; when using acknowledgements, values of N greater than 1 can significnantly improve performance, especially if there is significant network latency between the two brokers. -s [ \u0026ndash;src-local ] Configure the route in the source broker (create a push route). -t \u0026lt;transport\u0026gt; [ --transport \u0026lt;transport\u0026gt;] Transport protocol to be used for the route. _ tcp (default) _ ssl * rdma 1.4.4.1. Creating and Deleting Queue Routes $ qpid-route [OPTIONS] queue add \u0026lt;dest-broker\u0026gt; \u0026lt;src-broker\u0026gt; \u0026lt;dest-exchange\u0026gt; \u0026lt;src-queue\u0026gt; $ qpid-route [OPTIONS] queue del \u0026lt;dest-broker\u0026gt; \u0026lt;src-broker\u0026gt; \u0026lt;dest-exchange\u0026gt; \u0026lt;src-queue\u0026gt; 1.4.4.2. Exchange Routes ","permalink":"https://nolleh.github.io/qpid/1.4.broker-federation/","summary":"1.4 Broker Federation 메시지 라우트를 정의하여 하나의 브로커에서 다른 브로커로 자동으로 전달하게 한다.\n일반적으로 일방향이며, 라우트는 durable 하고 tansient 한다.\n연결이 소실되면 메시지는 누적되다가 재연결이 되면 다시 전송한다.\n라우팅에 사용되는 룰은 서버가 변경됨에 따라 동적으로 변경할 수 있으며, 변경의 책임은 다른 변경조건에 맞게 반영된다,.\n1.4.1 Message Routes pull / push 방식이 있음.\npull 은 dest 에서.\npush 는 src 에서 설정함\nqueue \u0026lt;-\u0026gt; exchage exchange \u0026lt;-\u0026gt; exchange excg \u0026lt;-\u0026gt; excg 는 다음과 같은 라우트를 가질 수 있다.","title":"Broker Federation"},{"content":" time_wait 종료 시간 확인 : ndd -get /dev/tcp tcp_time_wait_interval time_wait 종료 시간 30초로 설정 : ndd -set /dev/tcp tcp_time_wait_interval 30000 fin_wait_2 타임 아웃 시간 확인 : ndd -get /dev/tcp tcp_fin_wait_2_timeout fin_wait_2 타임 아웃 시간 5분으로 설정 : ndd -set /dev/tcp tcp_fin_wait_2_timeout 300000 출처: https://hyeonstorage.tistory.com/287 [개발이 하고 싶어요]\n","permalink":"https://nolleh.github.io/cheatsheet/network/","summary":"time_wait 종료 시간 확인 : ndd -get /dev/tcp tcp_time_wait_interval time_wait 종료 시간 30초로 설정 : ndd -set /dev/tcp tcp_time_wait_interval 30000 fin_wait_2 타임 아웃 시간 확인 : ndd -get /dev/tcp tcp_fin_wait_2_timeout fin_wait_2 타임 아웃 시간 5분으로 설정 : ndd -set /dev/tcp tcp_fin_wait_2_timeout 300000 출처: https://hyeonstorage.tistory.com/287 [개발이 하고 싶어요]","title":"Network"},{"content":"Docker Cheat Sheet 1. docker conntainer 내부 소켓 상태 확인 $ docker inspect -f \u0026#39;{{.State.Pid}}\u0026#39; cb2939r52s22 5645 [ec2-user@ip-10-100-77-76 ~]$ sudo nsenter -t 5645 -n netstat Active Internet connections (w/o servers) Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 0 ip-172-17-0-2.ec2.:webcache ip-10-100-77-225.ec2.:45104 ESTABLISHED tcp 0 0 ip-172-17-0-2.ec2.:webcache ip-10-100-77-225.ec2.:14804 TIME_WAIT tcp 0 0 ip-172-17-0-2.ec2.:webcache ip-10-100-76-6:seclayer-tls TIME_WAIT tcp 0 0 ip-172-17-0-2.ec2.:webcache ip-10-100-76-65.ec:plethora TIME_WAIT tcp 0 0 ip-172-17-0-2.ec2.:webcache ip-10-100-77-225.ec2.:14830 TIME_WAIT tcp 0 0 ip-172-17-0-2.ec2.:webcache ip-10-100-76-65.ec2.i:23284 ESTABLISHED tcp 0 0 ip-172-17-0-2.ec2.:webcache ip-10-100-76-65.ec2.i:27948 ESTABLISHED tcp 0 0 ip-172-17-0-2.ec2.:webcache ip-10-100-77-225.ec2.:14848 TIME_WAIT tcp 0 0 ip-172-17-0-2.ec2.:webcache ip-10-100-77-225.ec2.:45544 ESTABLISHED Active UNIX domain sockets (w/o servers) Proto RefCnt Flags Type State I-Node Path docker container 의 ulimit 가 호스트를 따라가지 않을 수 있음.\n빠르게 open 하고 close 시, 사용하는 ORM 솔루션에 따라 기대하는 동작과 다를 수 있음.\nsmall idle connection.. -\u0026gt; cause high reconnect rate.\n","permalink":"https://nolleh.github.io/cheatsheet/docker/","summary":"Docker Cheat Sheet 1. docker conntainer 내부 소켓 상태 확인 $ docker inspect -f \u0026#39;{{.State.Pid}}\u0026#39; cb2939r52s22 5645 [ec2-user@ip-10-100-77-76 ~]$ sudo nsenter -t 5645 -n netstat Active Internet connections (w/o servers) Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 0 ip-172-17-0-2.ec2.:webcache ip-10-100-77-225.ec2.:45104 ESTABLISHED tcp 0 0 ip-172-17-0-2.ec2.:webcache ip-10-100-77-225.ec2.:14804 TIME_WAIT tcp 0 0 ip-172-17-0-2.ec2.:webcache ip-10-100-76-6:seclayer-tls TIME_WAIT tcp 0 0 ip-172-17-0-2.ec2.:webcache ip-10-100-76-65.ec:plethora TIME_WAIT tcp 0 0 ip-172-17-0-2.ec2.:webcache ip-10-100-77-225.ec2.:14830 TIME_WAIT tcp 0 0 ip-172-17-0-2.","title":"Docker"},{"content":"한개 이상의 노드들의 논리적인 그룹을 의미하며, 각각은 유저와, 가상 호스트, 큐, exchanges, bindings 을 공유한다.\nCluster Formation 다음 방법들로 구성 가능\nDeclaratively by listing cluster nodes in config file Declaratively using DNS-based discovery Declaratively using AWS (EC2) instance discovery (via a plugin) Declaratively using Kubernetes discovery (via a plugin) Declaratively using Consul-based discovery (via a plugin) Declaratively using etcd-based discovery (via a plugin) Manually with rabbitmqctl 구성은 동적으로 변경 될수 있고, 모든 RabbitMQ 브로커는 하나의 노드로부터 시작해서 클러스터에 참여시키거나, 다시 개별의 브로커로 돌아갈 수 있다.\nNode Names (Identifiers) 클러스터 내에서 서로 구분할 수 있는 고유 값이어야함.\n환경 변수로 지정. RABBITMQ_NODENAME\nfully qulified domain names (FQDNs)를 사용하는 경우 RABBITMQ_USE_LONGNAME true 로 지정\nNodes in a Cluster 정상적으로 동작하기위해 모든 노드에 걸쳐 데이터와 상태가 복제 되어야 한다. 하나의 예외는 메시지 큐인데, 기본적으로 하나의 노드에서만 존재하지만 다른 노드들 사이에서 visible 하고 reachable 하다. 이마저도 복제하고 싶다면 HA 를 참고하라.\nNodes are Equal Peers 어떤 분산시스템들은 leader 와 follower 가 있지만 rabbitMQ 에서는 일반적으로 그렇지 않다. 모든 노드는 동등하다. 다만, 이주제는 queue mirroring 과 연관이 되면 미묘해진다.\nHOW CLI Tools Authenticate to Nodes (And Nodes to Each Other): the Erlang Cookie erlang cookie 라고 부르는 대칭키를 함께 보유하고 있어야한다.\n로컬키에 저장해둠.\n소유자에게 접근권한이 있어야함. (600 이나 유사 권한)\n파일이 없으면 생성하나, 이 방식은 모든 노드가 각자의 데이터를 생성하니, 개발단계에서 사용할 것.\n쿠키 생성은 클러스터 배포단계에서 완료되어야하며, 자동화와 오케스트레이션 툴을 이용하는 것을 추천한다.\nNode Counts and Quorum consensus 를 요구하는 플러그인들이 있으므로, 홀수개의 노드 추천.\nClustrering and Clients 모든 멤버가 정상적으로 동작할때 클라이언트는 어느노드나 붙어서 작업을 수행할 수 있다. 노드들은 연산을 큐 마스터 노드 (HA) 로 투명히 전달, 클라이언트로 돌려준다.\n실패한 경우 클라이언트는 다른 노드에 재연결하여 토폴로지를 복구하고, 다시 연산을 재개해야 한다. 이가 여의치 않은 경우 \u0026lsquo;미러링 되지 않은 큐가 실패한 노드에 있을 경우\u0026rsquo; 참고.\nClustering and Observability 클라이언트 연결과 채널, 큐들은 클러스터 노드들에 나뉘어져 있다.\n운영자들은 모든 클러스터 노드에 걸쳐 이를 관찰하고 모니터 할 필요가 있다.\nrabbitmq-diagnostics 와 rabbitmqctl 과 같은 CLI 툴의 경우 클러스터 단위의 리소스를 관찰하는 명령어들을 제공한다.\n어떤 커맨드들은 하나의 노드에 집중하기도 한다.0\n(e.g. rabbitmq-diagnostics environment and rabbitmq-diagnostics status)\nNode Failure Handling 각 개별의 노드의 장애에 대해서는 tolerate 하다.\n노드는 다른 클러스터 멤버 노드에 연결을 할 수 있는한, 원하면 실행되거나 중지될 수 있다.\n큐 미러링은 큐의 데이터가 복수의 클러스터 노드에 복제 될 수 있도록 한다.\n미러링 되지 않은 큐들도 클러스터에 사용될 수 있는데, 이런 큐들의 경우 노드 장애시 큐 durability 속성에 의해 동작이 정해진다.\nrabbitmq 클러스터링은 네트워크 파티션을 다루기 위한 (주로 일관성을 중시하는) 몇가지 모드가 있다.\nDisk and RAM Nodes 노드는 디스크 노드이거나 램 노드 일 수 있다. 램 노드들은 램에만 데이터베이스 테이블을 저장한다.\n여기에 메시지들은 포함하지 않는다.\n메시지는 색인, 큐 색인과 다른 노드 상태를 저장한다.\n대부분 디스크 노드를 사용하는 것을 원할 것이다. 램 노드는 큐, exchange, bind 가 많을때 성능 개선을 원하는 경우에 사용할 것이다. 램노드를 사용한다고 해서 메시지 비율이 개선 되진 않는다.\n램노드는 내부 데이터베이스테이블을 사용하기 때문에 peer 노드가 구동되는 경우 sync 해 줘야한다. 이는 하나의 디스크 노드는 필요하다는 것.\n","permalink":"https://nolleh.github.io/rabbitmq/clustering-guide/","summary":"한개 이상의 노드들의 논리적인 그룹을 의미하며, 각각은 유저와, 가상 호스트, 큐, exchanges, bindings 을 공유한다.\nCluster Formation 다음 방법들로 구성 가능\nDeclaratively by listing cluster nodes in config file Declaratively using DNS-based discovery Declaratively using AWS (EC2) instance discovery (via a plugin) Declaratively using Kubernetes discovery (via a plugin) Declaratively using Consul-based discovery (via a plugin) Declaratively using etcd-based discovery (via a plugin) Manually with rabbitmqctl 구성은 동적으로 변경 될수 있고, 모든 RabbitMQ 브로커는 하나의 노드로부터 시작해서 클러스터에 참여시키거나, 다시 개별의 브로커로 돌아갈 수 있다.","title":"Clustering Guide"},{"content":"","permalink":"https://nolleh.github.io/crypto/ssl/","summary":"","title":"SSL"},{"content":"ECDSA ref. https://m.blog.naver.com/aepkoreanet/221178375642\nec (타원곡선) 을 이용한 기술들의 집합 - ECC,\n이중에 디지털서명 관련 기술이 ECDSA\nTerms 유한체\n집합에 속해있는 원소의 수가 한정되어 있고 덧셈, 곱셈에 대해 닫혀있는 집합 유한체 F 표기법\n원소의 개수가 p 인 유한체 F 는 Fp 혹은 GF(p) 로 표기 유한체 상에 정의된 타원 곡선\nE(Fp) 암호학에서 사용되는 유한체 - Prime Field 원소의 개수가 소수 ECC 사용시 타원 곡선을 정의하는 domain parameter 를 정의해야함. (p, a, b, G, n, h) 를 정의해야하는건데, 여러 표준단체에서 Field Size 에 맞는 타원곡선에 대한 파라미터 발표.\np : Modulo Prime Number a : 타원곡선 방정식에서 사용되는 계수 b : 타원곡선 방정식에서 사용되는 계수 Base point 또는 Generator Point, G 는 E(Fp) 에 속해있는 point n : the order of point G (G 를 n번 더하면 무한원점이 되는값 : nG = ∞) H : cofactor 타원 곡선이란, 타원 곡선 방정식을 만족하는 집합을 곡선 그래프로 표시한 것\ny^2 = x^3 + ax + b\nsecp256k1 곡선의 경우 a = 0, b = 7 을 사용\nECC 의 privateKey 와 publicKey Private Key d : P 보다 적은 소수 (Prime) 로, 난수 생성기로 생성 Public Key Q : Q(x, y) = d x G(x0, y0) ECDSA 와 secp256k1 ECDSA 의 파라메터로 secp256k1 curve 를 사용 secp256k1\nsec - standard for Efficient Cryptography\np - parameter p over Fp\n256 - field size p 의 bit 수\nk - koblitz curve 변형\n1 - sequence number\nDomain Parameter T = (p,a,b,G,n,h) p : FFFFFFFF FFFFFFFF FFFFFFFF FFFFFFFF FFFFFFFF FFFFFFFF FFFFFFFF FFFFFC2F a : 00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000 b : 00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000007 G : 02 79BE667E F9DCBBAC 55A06295 CE870B07 029BFCDB 2DCE28D9 59F2815B 16F81798 또는 G : 04 79BE667E F9DCBBAC 55A06295 CE870B07 029BFCDB 2DCE28D9 59F2815B 16F81798 483ADA77 26A3C465 5DA4FBFC 0E1108A8 FD17B448 A6855419 9C47D08F FB10D4B8 N : FFFFFFFF FFFFFFFF FFFFFFFF FFFFFFFE BAAEDCE6 AF48A03B BFD25E8C D0364141 h : 01 서명은 어떻게 이루어지는가 ? https://ko.wikipedia.org/wiki/%ED%83%80%EC%9B%90%EA%B3%A1%EC%84%A0_DSA\ndomain parameter 로 (CURVE, g, n) 을 사용한다.\nCurve : 타원곡선의 체 (field) 와 여기 사용된 수식. g : 타원 곡선의 기준점 (base point). 해당 타원곡선의 생성원(generator) 이다. n : g 의 차수이다. n X g = 0 이며, 반드시 소수여야한다. 보통 충분히 큰 소수를 사용한다. privateKey, d 생성. - RNG 로 생성된 무작위로 선택된 1~ n-1 사이의 정수\npublicKey, Q 생성 - Q = dg 를 만족하는 정수. (g 를 d 번 더한 값)\n서명 프로세스\n필요한 것: E(Fp), d, Q, m\n1. e = H(m). 메시지를 해쉬하고 이를 e 라고 한다. 2. z = Ln(e) e 의 binary 값에서 왼쪽으로부터 n 번째 까지 잘라낸 값을 z 라고 한다. (left most n\u0026#39;th bit) 3. 암호학적으로 안전한 난수 k 를 [1, n-1] 사이에서 무작위로 선택한다. 4. 곡선 위의 점 (x1, y1) = k * g 를 계산한다. - 타원곡선에서의 덧셈은, 결국 다시 점이 된다. - 위 k * g 는 g 를 k 번 더하는 것을 의미하고, 결국 점이 된다. 5. r = x1 (mod n) 을 계산 한다. r 이 0 인 경우, k 를 다시 선택한다. 6. s = k^(-1)(z + rd) (mod n) 을 계산. s = 0 이면 3 으로 되돌아가 다른 k 를 선택, 순서대로 진행한다. 완성된 서명은 (r, s) 이다. 검증 프로세스\n필요한 것: E(Fp), (r,s), m\n- 곡선위의 점 인증 1. Q =/= O (identity element) 2. Q 가 곡선 위의 점인지 3. n x Q = O 인지 확인 - 서명 유효성 인증 1. r,s 가 1부터 n-1 사이의 정수인지 확인. 2. e = H(m) 을 계산. 3. z 계산 4. w = s^(-1)(mod n) 계산, u1 = zw, u2 = rw (mod n) 계산 5. shamir\u0026#39;s trick 을 사용해서 (x1, y1) = u1 x g + u2 x Q 를 계산. (x1, y1) = O 이면 무효 6. r = x1 (mod n) 일때만 유효. 즉, 서명 프로세스는 타원 곡선에서 새로운 k 와 (x1, y1) 을 구한 후\nECDSA 시그니쳐에서 어떻게 public key 를 복원할 수 있는가 ? stack exchange link\nECDSA signature (r,s)\n사실 곡선과 사용된 해쉬 함수, 서명된 메시지 원본을 알고 있더라도 signature 로부터 public key 를 recover 하는 것은 불가능하다.\n그러나, signature 와 원본 메시지, 곡선에 대한 정보로 두개의 public key 를 생성하는게 가능하다. (이 중에 private key 가 사용된 public key 가 있을 것)\n동작 원리는 다음과 같다.\nR 과 R\u0026rsquo; x 좌표로 r 값을 갖는 좌표를 찾는다. r^-1 을 연산하는데, 이는 시그니쳐의 r 의 곱셈 역원이다. (mod n) z 메시지 해쉬의 하위 n bit 인 z 를 연산한다. public key 는 r^(−1)(sR−zG) and r^(−1)(sR′−zG) 가 된다.\n","permalink":"https://nolleh.github.io/crypto/ecdsa/","summary":"ECDSA ref. https://m.blog.naver.com/aepkoreanet/221178375642\nec (타원곡선) 을 이용한 기술들의 집합 - ECC,\n이중에 디지털서명 관련 기술이 ECDSA\nTerms 유한체\n집합에 속해있는 원소의 수가 한정되어 있고 덧셈, 곱셈에 대해 닫혀있는 집합 유한체 F 표기법\n원소의 개수가 p 인 유한체 F 는 Fp 혹은 GF(p) 로 표기 유한체 상에 정의된 타원 곡선\nE(Fp) 암호학에서 사용되는 유한체 - Prime Field 원소의 개수가 소수 ECC 사용시 타원 곡선을 정의하는 domain parameter 를 정의해야함. (p, a, b, G, n, h) 를 정의해야하는건데, 여러 표준단체에서 Field Size 에 맞는 타원곡선에 대한 파라미터 발표.","title":"ECDSA"},{"content":"Best Practices for Using Cloud Storage 버킷에 변화가 있을때 반응하게 할 수 있다. https://cloud.google.com/storage/docs/pubsub-notifications\nDemo coldline 은 일년에 한번 접근하는것과 같은 문제발생시 복구하는 용도로 사용하면 좋다..\nhttps://cloud.google.com/storage/docs/managing-lifecycles\nDemo2 - Cors cors - https://developer.mozilla.org/en-US/docs/Web/HTTP/CORS cross-origin-resource sharing\ninstance 만들고 / apache 깔고 / cors 설정 여는 데모..\nBest Practices for cloud Storage request rate 가 초당 1000 쓰기 요청 이나 5000 읽기 요청을 넘어가면 ..\n이 기준 요청량내에서 요청을 시작해서 20 분마다 요청을 두배로 해라. ","permalink":"https://nolleh.github.io/coursera/gcp/6.datastorage/","summary":"Best Practices for Using Cloud Storage 버킷에 변화가 있을때 반응하게 할 수 있다. https://cloud.google.com/storage/docs/pubsub-notifications\nDemo coldline 은 일년에 한번 접근하는것과 같은 문제발생시 복구하는 용도로 사용하면 좋다..\nhttps://cloud.google.com/storage/docs/managing-lifecycles\nDemo2 - Cors cors - https://developer.mozilla.org/en-US/docs/Web/HTTP/CORS cross-origin-resource sharing\ninstance 만들고 / apache 깔고 / cors 설정 여는 데모..\nBest Practices for cloud Storage request rate 가 초당 1000 쓰기 요청 이나 5000 읽기 요청을 넘어가면 ..\n이 기준 요청량내에서 요청을 시작해서 20 분마다 요청을 두배로 해라.","title":"6. DataStorage"},{"content":"Cloud Datastore Concepts and Indexes Cloud Data Store concepts 데이터 오브젝트는 엔터티라고 불림 엔터티들은 하나이상의 프로퍼티로 구성됨 프로퍼티들은 하나이상의 값(values) 를 가질수 있음 각각의 엔터티는 구분되는 하나의 키를 가지고 있는데, 다음으로 구성 된다. 네임스페이스 엔터티 Kind 식별자 (스트링 or 숫자) 부모 ID 하나 이상의 엔터티에 대한 동작은 트랜잭션으로 불린다. Datastore has two types of indexes Built-in indexes Composite indexes 각각의 엔터티 Kind의 각각의 프로퍼티에 대해 자동으로 정의 인덱싱된 엔터티에 대해 다중의 프로퍼티 값을 인덱스함 간단한 쿼리에 적합 컴플렉스 쿼리에 적합 인덱스 설정파일에 정의 concept cloud datastore relational database 오브젝트 카테고리 Kind Table 한개 오브젝트 entity row 하나의 오브젝트를 위한 개별 데이터 프로퍼티 field 유니크 ID Key PrimaryKey Design Considerations \u0026amp; Sharding Design Your application for scale 엔터티 그룹에 대한 최대 쓰기율은 1/초 사전적으로 가까운 키에 대한 읽기와 쓰기를 너무 자주하지 말것. 구글의 noSQL 데이터베이스 Bigtable 을 이용해서 구현되어있는데 확장할때 로우들을 별도 테이블로 샤딩하는데 이 로우들이 키에 대해 사전적으로 정렬되어있기 때문. 점진적으로 ramp up traffic 을 새로운 클라우드 데이터 스토어에.. 빅테이블이 테이블을 분리하기에 충분할 시간을 주도록.. 클라우드 데이터스토어의 엔터티를 적은 범위의 키로 삭제하는 동작을 피해라 컴팩션(삭제된 엔트리를 제거하고 데이터를 재구성하여 읽기와 쓰기가 더 효율적으로 동작하도록 주기적으로 테이블을 다시쓰는 작업) 타임스탬프가 비슷해서 함께 있을 엔터티들을 많이 삭제하면, 이에 대한 쿼리가 컴팩션이 완료되기 전까지 늦을 수 있다. 핫 클라우드 데이터 스토어 키들에 대해 : use sharding, 쓰기가 빈번한 키 range 에. use replication, 읽기가 빈번한 키 range. When sharding, remember: 트랜잭션 스루풋은 1 write/sec per entity group 복수의 kinds 에 걸쳐 자주 업데이트 되는 엔터티는 분리하라. Shared counters to avoid contention with high writes contention 을 줄이기 위해:\nsharded counter 를 구축하라 (카운터를 N 개의 다른 카운터로 쪼개라) - 카운터를 올리기 위해 임의의 샤드를 선택하여 올린다 - 전체 카운트를 알기위해, 모든 샤드카운터를 읽어서 더해라. 샤드의 넘버를 올리는 것은 스루풋을 올리는 것.. increasing the number of shards will increase the throughput you will have for increments on you counter. Replicaion, Query Types, Transactions, and Handling Errors Use replication to read a portion of the key range 읽기 비율이 높은데에 사용. 엔터티에 대한 사본을 N 개에 대해 두면, 읽기 연산에 대해 N 배 빠르다.\nDevices -\u0026gt; Cloud Load Balance -\u0026gt; Front end App (AppEngine - auto scailiing)\nUse qurey types based on your needs Keys-only Projection (엔터티에서 프로퍼티를 얻어옴.) Ancester - 쿼리의 강한 일관성을 요할때. select * from task where __key__ has ancestor key(TaskList, \u0026lsquo;default\u0026rsquo;) Entity select * from task where done = FALSE Improve Your query latency by using cursors instead of offsets Demo: Use Cloud Dataflow to bulk-load data into Cloud data store pip install apache-beam\nlab git clone https://github.com/GoogleCloudPlatform/training-data-analyst\nSummary 조상을 지정하는 것으로 엔터티 그룹을 설정할수 있다.\n이렇게 해서 모든 관계된 엔터티들이 하나의 트랜잭션으로 업데이트 될 수 있다. 트래픽 램프업을 위해 555 룰을 따라라. 처음엔 초당 500 정도를 쓰다가 5분마다 50퍼센트씩 증가 시키는 것.\n","permalink":"https://nolleh.github.io/coursera/gcp/5.datastore/","summary":"Cloud Datastore Concepts and Indexes Cloud Data Store concepts 데이터 오브젝트는 엔터티라고 불림 엔터티들은 하나이상의 프로퍼티로 구성됨 프로퍼티들은 하나이상의 값(values) 를 가질수 있음 각각의 엔터티는 구분되는 하나의 키를 가지고 있는데, 다음으로 구성 된다. 네임스페이스 엔터티 Kind 식별자 (스트링 or 숫자) 부모 ID 하나 이상의 엔터티에 대한 동작은 트랜잭션으로 불린다. Datastore has two types of indexes Built-in indexes Composite indexes 각각의 엔터티 Kind의 각각의 프로퍼티에 대해 자동으로 정의 인덱싱된 엔터티에 대해 다중의 프로퍼티 값을 인덱스함 간단한 쿼리에 적합 컴플렉스 쿼리에 적합 인덱스 설정파일에 정의 concept cloud datastore relational database 오브젝트 카테고리 Kind Table 한개 오브젝트 entity row 하나의 오브젝트를 위한 개별 데이터 프로퍼티 field 유니크 ID Key PrimaryKey Design Considerations \u0026amp; Sharding Design Your application for scale 엔터티 그룹에 대한 최대 쓰기율은 1/초 사전적으로 가까운 키에 대한 읽기와 쓰기를 너무 자주하지 말것.","title":"5. Cloud DataStore Concepts and Indexes"},{"content":"Cloud Storage 크고 자주 사용되지 않은 비구조화된 데이터\nOverview ideal for 완전히 관리되고 고 신뢰가능 이미지와 비디오 비용절감. 확장가능한 오브젝트/블롭 저장 오브젝트와 블롭 http 로 접근 구조화되어있지 않은 데이터 오브젝트 이름이 키 정적 웹사이트 호스팅 Ideal for Cloud Datastore 관계형이나 데이터 분석에는 적합하지 않고 GAE 앱이나 구조화된 순수 제공 사용례에 적합한 구조화된 제공을 위한 스케일러블 저장소.\nOverView ideal for NoSQL 도큐먼트 데이터베이스 세미구조의 어플리케이션 데이터 확장가능 내구성이 필요한 키 밸류 데이터 계층구조 데이터 복수 인덱스 매니징 트랜잭션 Cloud Bigtable 고구조화 / 트랜잭셔널 데이터에는 적합하지 않고, flat 하고 많은 read/write 연산이나 분석을 위한 데이터에 적합한 큰 용량의 저지연 데이터베이스.\nOverview ideal for 고성능의 wide 컬럼의 NoSQL 동작가능한 어플리케이션 성긴 테이블 분석적 어플리케이션 백억의 로우, 수천컬럼으로 확장가능 단일키의 데이터가 크다 TB 나 PB 데이터 저장가능 맵리듀스 동작 Cloud SQL 확장성/분석/큰 쓰기 연산에는 적합하지 않은, 웹 프레임워크의 기존에 존재하는 어플리케이션에 적용 가능한 잘알려진 VM 용 RDBMS\nOverview idealfor 관리되는 서비스 (복제/페일오버/백업) 웹프레임워크 MySQL 과 PostgreSQL 구조화된 데이터 RDBMS OLTP 워크로드 프록시가 안전한 second 생성 인스턴스에 접근하도록 해줌(화이트리스팅없이.) MySQL/PGS 를 사용하는 어플리케이션 Cloud Spanner 분석적인 데이터에는 적합하지 않고, 저 지연의 트랜잭션적 시스템의 관계형 DB service\nOverview ideal for 미션 크리티컬 DB 미션크리티컬 어플리케이션 트랜잭션 일관성 높은 트랜잭션 글로벌 확장 확장과 일관성있는 요구사항들 고 사용성 멀티리젼 복제 99.999% SLA BigQuery 빠른 앱 빌딩에는 적합하지 않고, 정적 데이터 집합과의 분석을 위한 데에 사용되는 오토스케일링 분석 데이터 저장소\nOverview ideal for 저 비용의 엔터프라이즈 데이터 창고 온라인 분석 처리 (OLAP) 워크로드 완전히 관리됨 빅 데이터 탐색과 처리 페타바이트 스케일 비지니스 지능 툴을 통한 리포팅 빠른 응답성 서버리스 Run Microsoft SQL Server on GCP 구글 컴퓨트 엔진에서 SQL 서버 이미지 선택가능. 컴퓨트 엔진 VM 에 SQL Server 를 프리로드 할수있음 라이센싱은 자동으로 포함됨 지원 버전은 SQL Server Standard SQL Server Web SQL Server Enterprise ","permalink":"https://nolleh.github.io/coursera/gcp/4.db-overview/","summary":"Cloud Storage 크고 자주 사용되지 않은 비구조화된 데이터\nOverview ideal for 완전히 관리되고 고 신뢰가능 이미지와 비디오 비용절감. 확장가능한 오브젝트/블롭 저장 오브젝트와 블롭 http 로 접근 구조화되어있지 않은 데이터 오브젝트 이름이 키 정적 웹사이트 호스팅 Ideal for Cloud Datastore 관계형이나 데이터 분석에는 적합하지 않고 GAE 앱이나 구조화된 순수 제공 사용례에 적합한 구조화된 제공을 위한 스케일러블 저장소.\nOverView ideal for NoSQL 도큐먼트 데이터베이스 세미구조의 어플리케이션 데이터 확장가능 내구성이 필요한 키 밸류 데이터 계층구조 데이터 복수 인덱스 매니징 트랜잭션 Cloud Bigtable 고구조화 / 트랜잭셔널 데이터에는 적합하지 않고, flat 하고 많은 read/write 연산이나 분석을 위한 데이터에 적합한 큰 용량의 저지연 데이터베이스.","title":"4.Cloud Storage, Cloud Datastore, Cloud Bigtable, Cloud SQL, and Cloud Spanner"},{"content":"What are the Google Cloud Client Libraries? 관용적인 코드를 각각의 랭귀지에 대해 제공 gRPC 에서 성능 효과를 보는 라이브러리도 있다.\ngithub repo\ngcloud - 커맨드 라인툴, gcp를 위한.\nGC cloud 빅쿼리를 위한 커맨드라인 툴\ngsuitl 버킷이랑 통신하기 위한 커맨드라인 툴\ngcloud init (initialize )\nCloud Shell 브라우저 베이스 커맨드라인툴. 일시적인 vm에 대한 접근을 제공. 5GB 디스크 SDK 에 이미 설치되어있음\n구글클라우드 콘솔프로젝트에대한 authorization /리소스 제공\n코드 에디터가 포함 (beta)\nModule Review Api Explore: google cloud api 를 테스트하기위한 샌드박스로 사용 Google Cloud Client Library : GCP 서비스와 커뮤니케이션 GCP Service 의 스크립트 작성 : Google Cloud SDK\n","permalink":"https://nolleh.github.io/coursera/gcp/3.sdk/","summary":"What are the Google Cloud Client Libraries? 관용적인 코드를 각각의 랭귀지에 대해 제공 gRPC 에서 성능 효과를 보는 라이브러리도 있다.\ngithub repo\ngcloud - 커맨드 라인툴, gcp를 위한.\nGC cloud 빅쿼리를 위한 커맨드라인 툴\ngsuitl 버킷이랑 통신하기 위한 커맨드라인 툴\ngcloud init (initialize )\nCloud Shell 브라우저 베이스 커맨드라인툴. 일시적인 vm에 대한 접근을 제공. 5GB 디스크 SDK 에 이미 설치되어있음\n구글클라우드 콘솔프로젝트에대한 authorization /리소스 제공\n코드 에디터가 포함 (beta)\nModule Review Api Explore: google cloud api 를 테스트하기위한 샌드박스로 사용 Google Cloud Client Library : GCP 서비스와 커뮤니케이션 GCP Service 의 스크립트 작성 : Google Cloud SDK","title":"3.SDK"},{"content":"12 Best Practices for user saccount https://cloud.google.com/blog/products/gcp/12-best-practices-for-user-account GCP 에서는 유저 계정에 대한 안전한 핸들링과 인증을 위한 툴을 게공한다. 웹사이트가 구글 쿠버네티스엔진에 호스트 되는 웹사이트를 담당하든, apigee 의 api 를 담당하든, firebase 를 사용하든, 어떤 다른 서비스를 통해 유저를 인증하든, 이 포스트는 좋은 연습을 제공해서, 안전하고 확장가능하고 쓸만한 계정 인증 시스템을 사용할 수 있게 도와줄 것이다.\n1. 패스워드를 해시하라. 패스워드를 포함해서, 예민한 개인정보를 어떻게 저장할 것인가가 계정관리의 가장 중요한 규칙이다. 이 데이터를 신성하게 다뤄야한다. 다시 reverse 될 수 없는 강력한 해쉬로되어야한다. 예를들면, PBKDF2, Argon2, Scripy, Bcrypt .. 또한, 이 해쉬는 salted 되어야 한다. MD5 나 SHA1 같은 deprecate 된 해쉬기술은 사용하면 안되며, revirsiable 될 수 있는 인크립션을 사용해야하는 상황은 어디에도 없으며, 직접 해쉬 알고리즘을 개발할 필요도 없다. 라고 생각하자.\n2. 서드파티 식별 제공자를 허락하자. 믿을수 있게한다. 구글, 페이스북, 트위터등이 흔히 사용된다. firebase Auth 시스템을 통해 인증처리를 할 수도 있다. -다른 사례들을 보면, 반나절만에 적용하고 그렇다. fabulas?\n3. 유저 식별의 개념을 유저 계정의 개념과 분리하라. 유저는 이메일 어드레스도, 핸드폰 번호도, OAUTH 응답의 unique ID 도 아니다. 유저 유저는 유일성의 최고점에 있으며, 당신 서비스의 개인화된 데이터와 경험이다. 잘 디자인된 유저관리 체계는 low 커플링 되어있으며, 고수준으로 응집되어있다.\n유저 계정과 보안을 분리하는 개념을 고수하는 것은 서드파티의 식별제공자를 구현하는 과정을 크게 단순화 할 수 있다. 유저는 유저 이름이나 다중의 정체성을 하나의 유저 계정에 연결 할 수도 있게 된다. 실제 용어로 옮기면, 내부의 전역 식별자를 모든 유저와 그들의 프로필과, 인증에 연결할 수도 있다.\n4. 하나의 계정에 복수의 정체성을 허용할 수 있도록 제공하라. 한 유저는 유저명과 패스워드를 사용하여 인증한후에, 이 과정이 계정을 생성할 수 있는지 모르고 구글 사이닝을 선택할 수있다. 유사하게, 어떤 유저는 복수의 이메일 주서를 당신의 서비스에 연결할 이유가 있었을 수도 있습니다. 만약 유저 식별과 인증을 분리해 두었다면, 하나의 유저에 대해 다양한 식별 정보를 연결하는게 간단하다.\n사용자가 기존 계정에 연결되지 않은 서드파티 아이디를 사용하고 있다는 것을 깨닫기전에 새로 가입하는 프로세스를 수행할 수 있는 가능성을 고려해야 한다. 흔한 식별 정보를 제공하도록 묻는것 만으로도 해결될 수 있다. 이메일어드레스, 폰이나 유저명 등.. 시스템에 존재한다면, 인증 후 새로운 아이디를 존재하는 계정에 연결하자.\n5. 길거나 복잡한 패스워드를 막지 말자. NIST 는 최근에 패스워드 복잡도와 강인함에 대해 가이드라인을 제공했다. 패스워드 길이를 막아서 얻을 수 있는건 POST 사이즈 뿐.. (끽해봐야 1MB?)\n해쉬된 패스워드는 알려진 적은 ASCII문자의 선택으로 압축될 수 있고, 그렇지 않으면 그냥 바이너리 해쉬를 Base64 로 변경해도 된다.\n6. user name 에 타당치 않은 규칙을 강요하지 마라 ","permalink":"https://nolleh.github.io/coursera/gcp/1-1.12-tips/","summary":"12 Best Practices for user saccount https://cloud.google.com/blog/products/gcp/12-best-practices-for-user-account GCP 에서는 유저 계정에 대한 안전한 핸들링과 인증을 위한 툴을 게공한다. 웹사이트가 구글 쿠버네티스엔진에 호스트 되는 웹사이트를 담당하든, apigee 의 api 를 담당하든, firebase 를 사용하든, 어떤 다른 서비스를 통해 유저를 인증하든, 이 포스트는 좋은 연습을 제공해서, 안전하고 확장가능하고 쓸만한 계정 인증 시스템을 사용할 수 있게 도와줄 것이다.\n1. 패스워드를 해시하라. 패스워드를 포함해서, 예민한 개인정보를 어떻게 저장할 것인가가 계정관리의 가장 중요한 규칙이다. 이 데이터를 신성하게 다뤄야한다.","title":"1-1. 계정관리를 위한 12 tips"},{"content":"3. Security, Reliablitiy, and Migration Use federated identity management firebase authentication~ 외부의 identity provider 를 통해 ..\nImplement health-check endpoint Stackdriver monitoring (helth monitoring agent) -\u0026gt; /health upcheck. 어디에 ? storage / database, network connection, 다른 의존들 .. 실패하면 자동으로 알림을 준다.\n로깅과 모니터를 어플리케이션의 성능에 대해 두라. 로그를 이벤트 스트림으로 취급하라. 어플리케이션에서는 건들지 말고 stdout 등으로 노출되는 데이터를 다른애가 후처리 해라 . 구글의 스택드라이버를 통해 어플리케이션을 디버그할 수 있고, 에러 모니터링을 설정할 수 있다.\n사소한 에러와 오래 지속되는 에러를 우아하게 다뤄라. trasient erros: 지수적으로 backoff 하여 재시도 해라. 구글클라이언트 클라이언트라이브러리는 재시도에 대해 자동적으로 수행한다.\n서비스 가용성 에러: 서킷브레이커를 구현해라. 유저에게 에러를 매번 노출하는 것은 피하는 것노출하는 것도 고려. .\n데이터 sovereignnty 와 compliance 요구사항을 고려하라. 어떤 나라에서 데이터보관에 대해 어떻게 규정하고 있는지\u0026hellip;\n가능한 테스팅과 재앙으로부터 복구계획을 구상하고 어플을 테스트하라. 실패시나리오의 예: 연결 실패 데이터 센터나 클라우드 제공자의 실패 GCP 존이나 리전 실패 배포 롤백 네트워크나 어플리케이션 이슈의 데이터 파괴\n계속되는 통합모델 (CI) 을 구현하고 파이프라인으로 배송하라. (CD) 강력한 devops 모델을 구현하라.\n코드 저장소 -\u0026gt; 빌드시스템 (배포아티팩트빌드/유닛테스트 실행) -\u0026gt; 배포시스템 (실환경과 테스트환경에 아티팩트를 배포) -\u0026gt; 1. 테스트환경 (통합테스트, 보안, 퍼포먼스 테스트.) / 2. 실환경 (성능 관찰)\n큰 수정이 있을때 배포하는 것이 아니라 작은 수정이 이씅ㄹ때마다 배포가 자동화되어 regression 의 리스크를 줄이며 디버그를 재빨리 하며, 이전 테이블의 빌드로 쉽게 롤백할 수 있게한다.\nStrangler 패턴을 새로 어플리케이션을 구조화하는데 사용하라. 이패턴: 구버전의 어플리케이션을 조금씩 새로운 서비스의 컴포넌트로 교체해 나가는것.\n","permalink":"https://nolleh.github.io/coursera/gcp/2.security-reliability-migration/","summary":"3. Security, Reliablitiy, and Migration Use federated identity management firebase authentication~ 외부의 identity provider 를 통해 ..\nImplement health-check endpoint Stackdriver monitoring (helth monitoring agent) -\u0026gt; /health upcheck. 어디에 ? storage / database, network connection, 다른 의존들 .. 실패하면 자동으로 알림을 준다.\n로깅과 모니터를 어플리케이션의 성능에 대해 두라. 로그를 이벤트 스트림으로 취급하라. 어플리케이션에서는 건들지 말고 stdout 등으로 노출되는 데이터를 다른애가 후처리 해라 . 구글의 스택드라이버를 통해 어플리케이션을 디버그할 수 있고, 에러 모니터링을 설정할 수 있다.","title":"2.Security-Reliability-Migration"},{"content":"Loosely Coupled Microservices and API gateway 모놀리틱에서는 기본 코드가 부풀게 되서, 어디를 고쳐야하는지 알기가 어렵다. 패키지들의 의존성들이 얼키고 설킨다.\n작은 기본 코드를 고쳐도 전체 프로그램이 배포되어 테스트될 필요가 있다.\n원격지에 의한 제어는 비동기 처리를 하자.\n가능한한 이벤트 드리븐 처리를 하자. -\u0026gt; 예를들어 구글 클라우드서비스에 이미지를 업데이트하고~ 이 이벤트에 반응하여 동작하는 어플리케이션을 만들 수 있다.\n커플링을 줄이기 위해 메시지 큐 등을 사용할 수 있다. 토픽에 대해 발송, 받아 처리.\nCache content 반응성을 위해 컨텐츠를 캐싱해서, TTL 이 지나기전의 캐쉬 데이터를 준다. 없거나 만료됐으면 새로 계산(이후 캐시에 저장) 멤캐시나 레디스에 저장한다.\nImplement API gateway, 컨슈머 어플리케이션에 백엔드 기능이 동작할 수 있도록..\n","permalink":"https://nolleh.github.io/coursera/gcp/1.msaandapigateway/","summary":"Loosely Coupled Microservices and API gateway 모놀리틱에서는 기본 코드가 부풀게 되서, 어디를 고쳐야하는지 알기가 어렵다. 패키지들의 의존성들이 얼키고 설킨다.\n작은 기본 코드를 고쳐도 전체 프로그램이 배포되어 테스트될 필요가 있다.\n원격지에 의한 제어는 비동기 처리를 하자.\n가능한한 이벤트 드리븐 처리를 하자. -\u0026gt; 예를들어 구글 클라우드서비스에 이미지를 업데이트하고~ 이 이벤트에 반응하여 동작하는 어플리케이션을 만들 수 있다.\n커플링을 줄이기 위해 메시지 큐 등을 사용할 수 있다. 토픽에 대해 발송, 받아 처리.\nCache content 반응성을 위해 컨텐츠를 캐싱해서, TTL 이 지나기전의 캐쉬 데이터를 준다.","title":"1.MSA and ApiGateway"},{"content":" 다음에서 발췌 ()[]\nSmart Contract 블록은 트랜잭션을 포함한다. 트랜잭션은 액션의 기록이다. 액션은 컨트랙트의 동작이다. 스마트컨트랙트의 사용\neos.io 의 컨트랙트는 abi 로 표현된다. 어플리케이션 코드는 json data 를 이용한 http 를 통해 contract 를 트리거 한다. EOS.IO 는 컨트랙트를 간단히 스크립팅하거나 테스팅하기위한 커맨드라인 인터페이스를 제공한다. Intro Smart Contracts EOS.IO 스마트 컨트랙트는 WebAssembly 로 구동된다. (WASM)\nweb 표준으로 떠오르는중 c/c++ 로부터 clang/llvm 을 통해 생성된다. 다른 언어들도 언젠가 지원될 것 Transaction - 실행되는 하나이상의 액션의 집합.\n하나의 액션이라도 실패하면 모든 트랜잭션이 실패한다 Action - 스마트컨트랙트를 실행하는 고수준의 함수\n데이터를 컨트랙트에 전송하기 위해서는 payload 를 포함해야한다. cloes 는 http 를 호출하는 syntatic sugar~\ntransaction json 을 살펴보면. signature 가 있고, 이 특정한 트랜잭션의 시그니쳐를 표현한다.\naction json 은 이런 형태\nactions : [{ \u0026quot;account\u0026quot;: \u0026quot;eosio\u0026quot;, \u0026quot;name\u0026quot;: \u0026quot;newaccount\u0026quot;,\u0026quot;actor\u0026quot;: \u0026quot;eosio\u0026quot;, \u0026quot;permission\u0026quot;: \u0026quot;acitve\u0026quot; }], \u0026quot;Data\u0026quot;: \u0026quot;000000000ea30550 .. 000a8ed32320100\u0026quot; }]\naccount : 액션을 실행하는 계정의 이름 (스마트 컨트랙트가 올라가있는 계정. 어떻게 action 을 실행할지에 대해 알고있다.) name : \u0026ldquo;authroization\u0026rdquo;: [{ // 어떤 시그니쳐가 필요한지 나타낸다. data : hex 로 표현된 값 table 을 업데이트할때, payer 에 대해 0 를 전달하면 이전 payer 를 그대로 사용한다.\nunittest - test_api -\u0026gt; tests directories . - api_tests.cpp\n#include \u0026lt;boost/test/unit_test.hpp\u0026gt; #inclue \u0026lt;eosio.token/eosio.token.wast.hpp\u0026gt; abi.hpp\u0026gt; BOOST_AUTO_TEST_SUITE(dice_tests) BOOST_FIXTURE_TEST_CASE(dice_test, dice_tester) try { create_accounts( {N(eosio.token), N(dice), N(alice), N(bob), false}); set_code(N(eosio.token), eosio_token_wast); set_abi(N(eosio.token), eosio_token_abi); push_action(N(eosio.token), N(create), N(eosio.toekn), mvo() (\u0026#34;issuer\u0026#34;, \u0026#34;eosio.token\u0026#34;)) } load balcancing 을 담당하는 릴레이노드 / producer node 가 별개로 있다\n특정노드에 컨트랙트를 전송 ? host 지정 하면 된다.\ncontext free action 를 어디서배우면 되나~ //\ntransaction 을 트랙킹하기위해 플러그인을 사용해도 된다. mongodb plugin 등.\n","permalink":"https://nolleh.github.io/block-chain-youtube/building-distributed-app/","summary":"다음에서 발췌 ()[]\nSmart Contract 블록은 트랜잭션을 포함한다. 트랜잭션은 액션의 기록이다. 액션은 컨트랙트의 동작이다. 스마트컨트랙트의 사용\neos.io 의 컨트랙트는 abi 로 표현된다. 어플리케이션 코드는 json data 를 이용한 http 를 통해 contract 를 트리거 한다. EOS.IO 는 컨트랙트를 간단히 스크립팅하거나 테스팅하기위한 커맨드라인 인터페이스를 제공한다. Intro Smart Contracts EOS.IO 스마트 컨트랙트는 WebAssembly 로 구동된다. (WASM)\nweb 표준으로 떠오르는중 c/c++ 로부터 clang/llvm 을 통해 생성된다. 다른 언어들도 언젠가 지원될 것 Transaction - 실행되는 하나이상의 액션의 집합.","title":"Building Distributed App"},{"content":" 다음에서 발췌 http://book.mixu.net/distsys/intro.html\n1. Distributed systems at a highlevel 분산 프로그래밍은 같은 문제를 하나의 컴퓨터에서 해결할 수 있는 문제를 여러 컴퓨터에서 해결하는 예술이다. 컴퓨터 시스템이라면 해결해야 하는 두개의 문제가 있습니다.\n저장소 연산 분산 프로그래밍은 하나의 컴퓨터에서 해결할 수 있는 문제를 여러 컴퓨터를 통해 해결하는 예술입니다. 보통 하나의 컴퓨터에서 해결하기에는 적합하지 않은 문제를 위해서입니다.\n실세계에서의 어떤것도 분산시스템을 요구하지는 않습니다. 무한한 돈과 무한한 실시간 연구 시간이 있다면, 분산시스템은 필요없습니다. 모든 연산과 모든 저장소는 매직박스 안에서 실행 될 수 있습니다 - 하나의, 믿을 수 없을정도로 빠르고, 믿을 수 없을정도로 신뢰할 수 있는 시스템은 누군가에게 돈을 지불하거나 당신이 직접 디자인할 필요가 있겟죠.\n하지만, 그렇게 무한한 자원을 가지고 있는 사람은 별로 없습니다. 때문에, 그들은 좋은 장소와실제 세계에서, 비용적인 측면에서 고려할 수 있는 적합한 실세계의 장소를 찾아야 합니다. 작은 사이즈 에서는 하드웨어를 업그레이드 하는 것은 필수적인 전략입니다. 하지만, 문제의 사이즈가 커짐에 따라 싱글 노드의 하드웨어 업그레이드 만으로는 문제를 해결할수 없거나, 비용적으로 막히는 지점이 오게 됩니다. 이 포인트에서, 분산 시스템으로 오신것을 환영할 때가 된것 같네요!\n이것은 현재의 현실이고 어떤 현실이냐면 가장 가치있는 중앙 범위, 상업적인 소프트웨어 - 유지보수 비용이 문제가 발생했을때도 괜찮은 소프트웨어로 유지될 수 있도록 해줍니다.\n연산(computations)은 대부분 고수준의 하드웨어가 네트워크 접근을 내부 메모리 접근으로 변경했을때 혜택을 본다고 할 수 있습니다. 노드들 사이에서의 방대한 커뮤니케이션을 요구하는 작업들로 인해 제한 되던 하드웨어들에서 효과를 볼 수 있겠죠.\n위의 Barroso, Cildaras \u0026amp; Holzle 피규어에서 보여주듯, 고수준과 상품(commodity) 하드웨어의 성능 차이가\n모든 노드에 걸쳐 하나의 메모리 접근으로 가게 됨에 따라 줄어듦을 살펴 볼수 있습니다.\n이상적으로, 하나의 머신을 추가하는 것은 시스템의 생산력과(capacity) 성능을 선형적으로 올려줄겁니다. 그러나 물론 이것은 불가능하며, 분리된 컴퓨터들 사이에 오버헤드가 추가 됨으로써 야기 됩니다. 데이터들은 복사될 필요가 있고, 연산 작업들은 조정되어야 하는 등의 작업들이 그렇습니다. 이 때문에 분산 알고리즘을 공부하는 것에 가치가 생기게 됩니다. - 어떤 문제들에 있어서 효율적인 솔루션을 제공하고, 가능하다면 올바르게 구현함을 통해 최소한의 비용만 사용할 수 있도록 가이드 해주거나, 불가능함을 알 수 있게 됩니다.\n이 문서의 목적은 일반적인 경우의 분산 프로그래밍에 대해 초점을 둘 것 이지만, 상업적에 관련한 설정에 대해서도 관심을 둘겁니다: 데이터 센터. 예를 들어서, 괴짜적인 네트워크 설정에 대해서는 논의 하지 않을것이며, 공유 메모리를 위한 설정에 대해서도 이야기 하지 않을 겁니다. 또한, 이 문서에서는 어떤 특정 디자인에 대해 최적화를 하기보다, 시스템 디자인 공간을 탐험하는데 시간을 할애할 겁니다. - 특정 디자인에 대한 최적화는 보다 특화된 주제 입니다.\nWhat we want to achieve: Scalability and other good things 모든 것은 결국 사이즈를 다루는 데서 시작합니다.\n대부분의 것들은 사소하고, 작은 스케일에서 시작되도 됩니다. - 그리고 같은 문제들은 어떤 특정사이즈, 볼륨, 물리적인 제약을 초과하게 되면서 점점 어려워지게 됩니다. 초콜릿을 들어올리는 것은 쉽지만, 산을 들어올리는 것은 어려워 집니다. 한 방에 몇명이 있는지 세는 것은 쉽지만, 한 나라에 얼마나 많은 사람들이 있는지 세는것은 어려워 지듯이요.\n그래서, 모든것은 사이즈에서 시작합니다 - 확장성. 공식적으로 말해서, 문제들이 크게 나빠지지 않도록 작은 시스템에서 큰 시스템으로 확장될 수 있는 시스템. 여기 다른 정의가 있습니다.\nScalability: 어떤 시스템, 네트워크, 프로세스의 늘어나는 작업을 핸들링 하거나, 수용력을 확장할 수 있도록 하는 능력.\n\u0026lsquo;늘어난다\u0026rsquo;는 것은 무엇인가? \u0026lsquo;성장\u0026rsquo;을 어떤 용어로는 측정할 수 있습니다. (사람이 늘어난다, 전력량이 늘어난다 등등). 하지만, 다음과 같이 특히 관심게 봐두면 좋을 것들이 있습니다.\n사이즈의 확장성: 노드를 추가하면, 시스템을 선형적으로 빠르게 만들어야 한다; 데이터집합의 증가가 지연을 만들지 않아야 한다. 지역적인 확장성: 복수의 데이터 센터를 사용하여 유저의 쿼리에 대한 응답성을 유지해야하며, 데이터 센터의 교점에 있어서는 감각적인 방법으로 잘 처리해야할 것. 운영적인 확장성: 노드를 추가하는것 운영 코스트를 증대 시키지 않아야한다. (운영자-장비 비율) 물론, 실제 시스템의 증대는 다른 차원의(여러 축의) 문제이긴 합니다.; 각각의 메트릭(요소)들이 성장의 한 측면을 캡쳐하고 있습니다.\n확장 가능한 시스템은 유저가 증대됨에도 지속적으로 요구를 충족시킴을 의미합니다. 이것에 관련한 두개의 관점이 있습니다. - 성능과 가용성 - 이것들은 다양한 방법으로 측정될 수 있습니다.\nPerformance (and latency) Performance 는 시간과 리소스 측면에서 유용한 작업의 양으로 특징할 수 있다.\n문맥에 따라, 아래의 내용과 한 개 이상 관여할 수 있습니다.\n주어진 작업 수행을 위한 응답성/적은 지연 높은 처리량 (처리량의 비율) 낮은 리소스 사용률 이런 결과를 얻기 위해 포기해야할 비용들이 있기 마련입니다. 연산 오버헤드를 줄이고 높은 처리량을 위해 더 큰 배치를 처리하는경우, 개별의 작업에 대한 응답은 더 늦어지는 결과로 이어지게 되는것처럼요.\n낮은 지연 - 빠른 응답성 - 은 성능에 있어서, 물리적(비용적인 측면보다는)인 제약에 크게 영향받기 때문에 가장 관심있는 요소가 됩니다. 성능의 다른 요소들에 비해 비용을 투자해서 \u0026lsquo;지연\u0026rsquo;을 다루기엔 어렵죠.\n지연에 대한 많은 정의가 있지만, 다음과 같이 연상되는 아이디어를 좋아합니다.\nLatency 지연된다; 지연, 어떤 것이 개시된 시점으로부터 일어나기까지의 시간\n그럼 \u0026rsquo;latent\u0026rsquo; 란?\nLatent 라틴어 lateo (숨겨져 있는) 의 현재 분사형인 latens, latentis 로부터 유래. 비활성화 되어있거나, 숨겨져 있음을 나타내는데 사용된다.\n이 정의는 꽤 멋진데, 왜냐하면 지연이라는 것이 어떻게 시작되고 영향을 주고 볼수있게 되는지 에 대한 시간간격을 나타내는데 초점을 두고 있기 때문입니다.\n예를들어서, 당신이 에어본 바이러스에 감염되어 사람들을 좀비로 만들고 있다고 해봅시다. 이 지연 시간은 당신이 감염되었을때 시작되어 당신이 좀비로 변하는 시간이 됩니다. 이것이 지연입니다: 이미 일어난 어떤것이 숨겨져서 보이지 않는것.\n우리 분산시스템이 하나의 큰 작업을 필요로 한다고 생각해봅시다: 시스템의 모든 데이터를 읽어 하나의 결과를 연산해야합니다. 다른 말로 하면, 하나의 분산 시스템을 데이터 저장소로 생각하고 하나의 연산을 해야하는데, 현재 저장된 데이터들에 대해 수행해야 합니다. :\nresult = query(all data in the system)\n어떤일이 일어날까요? 과거데이터가 아니라 현재의 새로운 데이터에 처리되어야한다면요. 사용자에게 보여지기 까지의 시간으로 지연을 측정할 수 있겠습니다.\n또 다른 키포인트는, 아무일도 일어나지 않은것에 대한 정의에 기반할 수 있는데, 여기엔 \u0026lsquo;지연시간\u0026rsquo;이 없습니다.\n분산시스템에서, 최소한의 지연은 극복될 수 없습니다: 광속의 한계, 하드웨어 컴포넌트들이 최소한의 지연 비용이 연산마다 있기 때문입니다. (램과 하드드라이브, CPU 도 생각해보세요.)\n최소한의 지연시간이 어느 정도냐가 전송되어야하는 물리적거리, 쿼리의 본질에 영향을 받아 당신의 쿼리의 지연시간에 영향을 줄겁니다.\nAvailability (and fault tolerance) 확장 가능한 시스템에 두번째로 고려해 볼 것은 가용성입니다.\nAvailablility 기능적인 측면(상태, condition) 에서의 시스템의 시간 비율. 만약 유저가 시스템에 접근할 수 없다면, 가용적이지 않다. 라고 이야기 할 수 있다.\n분산 시스템은 하나의 시스템에서 이루기 어려운일을 이룰수 있게 해줍니다. 예를 들면, 하나의 머신으로 구성된 시스템은 실패하거나, 동작하지 않기때문에 (or doesn\u0026rsquo;t) 어떤 오류에도 tolerant 하지 않습니다.\n분산 시스템은 \u0026lsquo;신뢰성 없는 묶음\u0026rsquo; 으로 신뢰성 있는 시스템을 만들어냅니다.\n불필요하게 장황하지 않은 시스템은 아래 구성되어있는 요소들만큼 가용성이 있습니다. 불필요하게 장황하게 구성된 시스템은 일부의 실패에 대해서도 tolerant 하고, 따라서 더 가용성이 있습니다. \u0026lsquo;불필요하게 장황하다\u0026rsquo;라는 말이 어떤 시각으로 보느냐에 따라 다른 의미를 가질 수 있겠네요 - 컴포넌트, 서버, 데이터센터, 등등..\n공식화해보자면, 가용성이란: Availability = uptime / (uptime + downtime)\n기술적인 측면에서 가용성이란, fault tolerant 를 의미합니다. 컴포넌트의 구성 요소들이 늘어남에 따라 실패의 확률이 늘어나기 때문에, 시스템은 컴포넌트의 숫자와 신뢰성이 반비례 하지 않도록 구성되어야합니다.\n예를 들어서:\nAvailability % 일년에 downtime 이 얼마나 허용될 수 있을까 ? 90% (one nine) More Than a month 99% (two nines) Less than 4 days 99.9 % (three nines) Less than 9 hours 99.99% (four nines) Less than an hour 99.999% (five nines) ~ 5 minues 99.99999% (six nines) ~ 31 seconds 가용성은 uptime 이라는 개념보다 더 넓은 개념으로 널리 사용되기도 하는데, 이는 서비스의 가용성은 네트워크의 outage 나 서비스를 책임지는 회사의 영향을 받기 때문입니다. (fault tolerance 와 실질적으로 연관되어있지는 않지만 시스템의 가용성에 영향을 줄 수 있음). 그러나 시스템의 면면을 알고 있지 않으면, 우리가 할 수 있는 건 fault tolerance 겠네요.\nfault tolerant 하다는건 어떤 말일까요.\nFault tolerance 시스템에 fault 가 발생했을때 잘정의된 방식으로 동작하는 것\nfault tolerance 는 이렇게 정리할 수 있습니다: 어떤 실패가 있을것이라 예상하고 시스템이나 알고리즘을 디자인하는가. 실패를 예상하지 못하면, 고려될 수도 없다.\nWhat prevent us from acheving good things? 분산 시스템은 두 물리적 요소로 인해 제약됩니다.\n노드의 개수 (요구되는 저장소와 연산 용량에 영향) 노드간의 거리 (정보가 전달되기 위함. 최대속도는 광속) 이 제약들 위에서 작업하기 위해:\n독립된 노드의 수들의 증가는 시스템의 실패율을 올린다. (가용성을 줄이고 운영 비용을 높임) 독립된 노드의 수의 증가는 노드들간의 통신 필요성을 높일수 있다. (스케일이 커짐에 따라 성능이 줄어든다.) 서로 떨어진 노드들 끼리의 물리적인 거리의 증가는 최소한의 통신지연을 높인다. (어떤 동작들의 퍼포먼스를 저해한다.) 이런 경향들을 넘어서 - 물리적인 제약의 결과 - 는 것이 시스템 디자인의 세계입니다.\n퍼포먼스와 가용성 시스템이 구성하는 외부적인 보증에 의해 정의됩니다. 고수준의 시스템에서, SLA (서비스 레벨 동의?) 를 통해 보장되고 있습니다; 데이터를 쓰면, 얼마나 빨리 다른 곳에서 접근할 수 있을까? 데이터가 쓰여지고 나면, 내구성이 있음은 어떻게보 장받을수 있을까 ? 시스템이 연산을 하도록 요청하면, 얼마나 빨리 결과를 돌려줄까 ? 구성 요소가 실패하면, 혹은, 동작에서 제외 되면, 시스템에 어떤 영향을 줄까?\n다른 기준이 있는데, 명시적으로 언급되진 않았지만, 내포되어있습니다; 이해성인데, 보장하는 내용이 얼마나 수용가능한가? 물론, 무엇이 수용가능한지 쉽게 정의할 수 있는 단순한 메트릭은 없습니다.\n저는 \u0026lsquo;이해성\u0026rsquo;을 물리적인 제한으로 분류하는 경향이 있습니다. 결국에는, 하드웨어의 제한이 우리가 우리 손가락 이상으로 움직이는 것들을 (외국 속담인듯. 예상이상의 일들을 일컫는것으로 추측된다) 이해하는걸 어렵게 하고 있죠. 에러와 변칙의 차이가 될겁니다 - 에러는 정상적이지 않은 동작, 변칙적인것은 예상치 못한 동작. 만약 당신이 똑똑하다면, 변칙적인 동작도 예상할 수 있을 겁니다.\nAbstractions and models 추상화와 모델이 역할을 할 때가 됐군요. 추상화는 문제를 해결하는 데 필요없는 문제들을 제거함으로써 문제를 더 통제할 수 있도록 만들어 줍니다. 모델들은 분산시스템의 속성들의 주요 속성들을 꽤 적합한 매너로 묘사합니다. 다음 챕터에서 더 많은 모델에 대해 다룰 건데, 이런겁니다.\n시스템 모델 (비동기/동기) 실패 모델 (크래쉬-실패, 파티셔닝, 비잔틴) 지속성 모델 (강하거나, 이벤트 기반이거나) 좋은 추상화는 시스템을 이해하기 쉽게 만들고, 특정 목적에 관련한 요소들을 제한(capture) 하는데 도움을 줍니다.\n많은 노드들과 다른 우리의 욕구.. \u0026lsquo;하나의 시스템처럼 동작\u0026rsquo;을 유지하는 데에는 긴장이 있습니다. 종종, 우리가 익숙한 대부분은(예를들어 분산시스템에서 추상화된 공유 메모리를 구현하는것) 너무 비용이 많이 듭니다.\n더 작은 보장을 할수록, 동작에 대 많은 자유를 보장하고, 잠재적으로 더 높은 퍼포 먼스를 제공하게 됩니다 - 그러나 이것 역시 잠재적으로 이유를 알아내기가 어렵습니다. 사람들은 단일 시스템에 대해 추리(리즈닝)하는 데 더 낫고, 노드들의 집합에는 상대적으로 약하죠.\n보통 시스템의 내부에 대해 디테일을 노출하는 것으로 성능을 얻기도 합니다. 예를 들면, columnar storage 에서, 유저는 추측할수 있다. 키밸류 페어의 지역성에 대하여, 그리고 결정할 수 있다.일반적인 쿼리의 성능의 영향성을. 시스템은 이런 디테일을 숨기는 시스템은 더 쉽다 이해하기가. (왜냐하면, 그들은 하나의 단위로 동작하는 것과 같고, 디테일에 대해 생각할 게 더 적다). 반면에 더 실세계의 디테일을 노출하는 것은 더 좋은 수행자다.(실세계에 더 가까우니까)\n몇몇의 실패의 유형에서, 단일 시스템으로 구성된것처럼 분산시스템에서 동작하도록 하는 것은 어렵습니다. 네트워크 지연과 네트워크 파티션 (노드들 사이의 모든 네트워크 실패) 은 시스템이 가용하게 유지하지만 어떤 중대한 보장을 강제하지 못하는 것을 감수 할지, 혹은 안전하게, 요청을 거절할지 선택해야할 수 있습니다.\nCAP 이론 - 다음 챕터에서 다룰 - 은 이런 긴장을 다룹니다(captures). 마지막에는, 이상적인 시스템은 프로그래머의 필요(클린한 의도)와 비즈니스 요구 (가용성/지속성/지연성). 을 만족시킵니다.\nDesign techniques: partition and replicate 어떤 데이터 집합이 복수의 노드에 분산되도록 하는 매너는 상당히 어려운 주제 입니다. 어떤 연산이 수행되도록 하기 위해서는, 우리는 데이터를 위치시키고, 여기에 동작할 필요가 있습니다.\n데이터 집합에 적용될 수 있는 두가지 기본 테크닉이있는데, 다양한 노드들에 분할 하여, (partitioning) 동시에 실행 될 수 있는 양을 늘리는 겁니다. 이것은 또한 다른 노드에 복사되거나 캐쉬 되어 클라이언트와 서버 사이의 거리를 줄여, 더 큰 fault tolerance 를 얻는 방법이 있습니다. (replication).\nDivide and conquer - I mean, partition and replicate. 아래의 그림은 이 두개의 차이점을 보여줍니다.: 파티션데이터 (A 와 B). 독립된 두개집합으로 나뉘었으며, 복제 데이터는 두 위치에 복사되어 위치되어 있습니다.\n이 것은 분산시스템에서 어떤 문제든 해결하는 원-투 펀치 입니다. 물론, 트릭은 구체적인 구현에 따라 올바른 테크닉을 선택하는 겁니다; 복제와 파티셔닝을 구현하는 많은 알고리즘들이 있고, 각각은 다른 제한과 이점이있어 원하는 디자인 목표를 이루기 위해 적절한 평가가 이뤄져야 합니다.\nPartitioning 파티셔닝은 데이터셋을 작은 구분된 집합으로 나눕닙니다; 이것은 데이터 집합의 성장을 줄이는데, 각각의 파티션이 데이터의 서브셋이기 때문입니다.\n파티셔닝은 측정되어야하는 데이터의 양을 제한하고, 관련한 데이터들을 함께 위치시켜 성능을 증대시킵니다. 파티셔닝은 파티션들은 독립적으로 실패하도록 허용함으로써, 가용성을 증대시키고, 가용성이 희생되기 전에 실패해야하는 노드 수를 증가 시킵니다. 파티셔닝은 또한 상당히 어플리케이션 특화되어 있어서, 세부 내용을 알지 못하면 자세히 이야기 할 수 없습니다. 그렇기때문에 복제가 대부분의 문서에서 다뤄지게 됩니다. (이 문서를 포함해서)\n파티셔닝은 대부분 당신이 주로 접근하는 패턴이라 생각하는 것에 기반해서 파티션을 정의하게 되며, 독립적인 파티션을 갖게 됨에 따라 오게 되는 제한들을 다루게 되게 됩니다. (e.g. 효율적이지 않은 파티션의 접근, 성장 비율과 다른 비율, 등등 )\nReplication 복제는 같은 데이터를 복수의 장비에 위치시킵니다; 이것은 연산에 더 많은 장비가 참여할 수 있도록 합니다.\n호머 제이 심슨을 인용해 보겠습니다.\n복제를 하기 위해! 모든 인생의 문제의 원인, 해결책이다.\n복제 - 복사나 어떤것의 재현 - 은 우리가 지연과 함께 싸울 수 있는 주요한 방법 입니다.\n복제는 새 데이터의 복사본에 적용가능한 추가적인 컴퓨팅 파워와 대역폭을 통해 추가적인 성능을 얻습니다.\n복제는 데이터의 복사를 생성함으로써 가용성을 향상시키고, 가용성이 희생 되기 전에 노드의 수를 증가 시킵니다.\n복제는 추가적인 대역폭을 제공하는 것이며, 캐싱이 의존하는 형태가 됩니다 이것은 또한 일관성을 유지하며 지속성모델에 따라 유지 합니다.\n복제는 확장을, 퍼포먼스를, fault tolerance 를 가능하게 합니다. 가용성의 손실이나 저해된 성능이 걱정되시나요? 데이터를 복제하는것이 한 지점에서의 실패나 병목 현상을 회피 할 수 있게 해줍니다. 낮은 연산? 복수의 시스템에서 연산하도록 복제하세요. 낮은 I/O? 로컬캐쉬를 데이터에 적용하여 지연을 줄이거나 복수의 장비에 적용하여 대역폭을 증대시킬 수 있도록 복제하세요.\n복제는 또한 많은 문제들의 원인이기도 한데, 복사된 데이터들은 이제 독립적이기때문에, 동기화가 이뤄져야하기 때문입니다 - 이것은 복제가 일관성 모델을 따라야함을 의미합니다.\n일관성 모델을 선택하는 것은 중대합니다: 좋은 일관성 모델은 프로그래머에게 간결한 의미를 제공합니다. (다른 말로하면, 이해하기 쉬운 형태로 유지가 된다는 이야기힙니다.) 또한 고가용성/강력한 일관성에 대한 비지니스/디자인 목표를 충족합니다.\n복제에 대한 하나의 일관성 모델 - 강력한 일관성 - 은 프로그램이 복제되지 않은 것 처럼 동작하게 합니다. 다른 일관성 모델은 내부적인 처리를 프로그래머가 감안하도록 합니다. 그러나, 더 약한 일관성 모델룰 수록 낮은 지연과 높은 가용성을 제공합니다 - 그리고 이해하기 어려운것이 아니라, 다를 뿐입니다.\n","permalink":"https://nolleh.github.io/distributed-systems/1.highlevel/","summary":"다음에서 발췌 http://book.mixu.net/distsys/intro.html\n1. Distributed systems at a highlevel 분산 프로그래밍은 같은 문제를 하나의 컴퓨터에서 해결할 수 있는 문제를 여러 컴퓨터에서 해결하는 예술이다. 컴퓨터 시스템이라면 해결해야 하는 두개의 문제가 있습니다.\n저장소 연산 분산 프로그래밍은 하나의 컴퓨터에서 해결할 수 있는 문제를 여러 컴퓨터를 통해 해결하는 예술입니다. 보통 하나의 컴퓨터에서 해결하기에는 적합하지 않은 문제를 위해서입니다.\n실세계에서의 어떤것도 분산시스템을 요구하지는 않습니다. 무한한 돈과 무한한 실시간 연구 시간이 있다면, 분산시스템은 필요없습니다. 모든 연산과 모든 저장소는 매직박스 안에서 실행 될 수 있습니다 - 하나의, 믿을 수 없을정도로 빠르고, 믿을 수 없을정도로 신뢰할 수 있는 시스템은 누군가에게 돈을 지불하거나 당신이 직접 디자인할 필요가 있겟죠.","title":"1. Distributed systems at a highlevel"},{"content":"hello 라는 이름의 디렉토리를 contracts directory 에 생성하자.\ncd CONTRACTS_DIR mkdir hello cd hello hello.cpp 를 생성하고 에디터로 열자.\ntouch hello.cpp 필요한 라이브러리를 이 파일에 include 한다.\n#include \u0026lt;eosiolib/eosio.hpp\u0026gt; #include \u0026lt;eosiolib/print.hpp\u0026gt; 코드를 간결하게 해줄 eosio 네임스페이스를 contract 에 추가한다.\nusing namespace eosio; eosiolib/eosio.hpp 가 EOSIO C 와 C++ API 를 당신의 contract 스코프에 로드한다. 표준 C++11 클래스를 생성한다. 이 contract class 는 eosio::contract 를 확장해야한다.\n#include \u0026lt;eosiolib/eosio.hpp\u0026gt; #include \u0026lt;eosiolib/print.hpp\u0026gt; using namespace eosio; class hello : public contract {}; 비어있는 contract 는 좋지 않으니, public 접근 지정자와 using 선언을 추가하자. 이 using 선언은 좀 더 간결한 코드를 쓸 수 있도록 도움을 줄것이다.\n이제 contract 는 어떤 작업을 하도록 구성한다. hello world 의 정신을 받아 \u0026ldquo;name\u0026rdquo; 파라메터를 수신하고, 파라메터를 출력하는 작업을 해보자.\n#include \u0026lt;eosiolib/eosio.hpp\u0026gt; #include \u0026lt;eosiolib/print.hpp\u0026gt; using namespace eosio; class hello : public contract { public: using contract::contract; [[eosio::action]] void hi( name user ) { print( \u0026#34;Hello, \u0026#34;, name{user}); } }; 위의 동작은 user 라는 이름의 파라메터를 name type 으로 전달 받는다.\nEOSIO 는 몇개의 typedef 를 선언하고 있는데, 이 중에 흔한 하나가 바로 이 name 이다.\neosio::print를 사용함으로써, 문자열을 user 파라미터와 붙여 출력한다.\n괄호를 이용한 초기화 name{user} 는 user 파라메터가 출력될 수 있도록 해준다.\neosio.cdt 의 abi 생성자는 atttrubite 없이는 hi() 의 동작을 알 수 없다. c++11 스타일의 attribute 를 action 의 상위에 추가하여 abi generator 가 신뢰 할 수 있는 출력을 할 수 있도록 한다.\n#include \u0026lt;eosiolib/eosio.hpp\u0026gt; #include \u0026lt;eosiolib/print.hpp\u0026gt; using namespace eosio; class hello : public contract { public: using contract::contract; [[eosio::action]] void hi( name user ) { print( \u0026#34;Hello, \u0026#34;, user); } }; EOSIO_DISPATCH( hello, (hi)) 마지막으로, EOSIO_DISPATCH 매크로를 추가하여 hello contract 의 dispatch 액션을 처리하도록 한다.\n이제 web assembly 를 통해 컴파일해보자.\neosio-cpp -o hello.wasm hello.cpp --abigen contract 가 배포되면, 계정으로 배포되어 이 계정이 contract 의 인터페이스가 된다.\n이 튜토리얼의 이전에 언급하였듯, 같은 public key 를 모든계정에서 사용하여 간단히 할 수 있다.\ncleos wallet keys 이 contract 를 위한 계정을 생성하기 위해 cleos create account 를 사용한다.\ncleos create account eosio hello YOUR_PUBLIC_KEY -p eosio@active 컴파일된 wasm 을 cleos set contract 를 통해 블록체인으로 broadcast 한다.\ncleos set contract hello CONTRACTS_DIR/hello -p hello@active 훌륭하다! 이제 contract 가 설정 되었고, action 을 push 해보자.\ncleos push action hello hi \u0026#39;[\u0026#34;bob\u0026#34;]\u0026#39; -p bob@active executed transaction: 28d92256c8ffd8b0255be324e4596b7c745f50f85722d0c4400471bc184b9a16 244 bytes 1000 cycles # hello.code \u0026lt;= hello.code::hi {\u0026#34;user\u0026#34;:\u0026#34;bob\u0026#34;} \u0026gt;\u0026gt; Hello, bob 예상했던대로 hello, bob 이 출력된다.\n이번 경우, \u0026ldquo;alice\u0026rdquo; 가 권한이 있고 user 는 단순한 argument 이다. contract 를 수정하여 권한이 있는 유저가 \u0026ldquo;hi\u0026rdquo; 를 받을 유저와 동일한 경우에만 동작하도록 해보자.\nrequire_auth 메소드를 사용한다.\n이 메소드는 name 을 파라메터로 받아서 action 을 수행하는 사용자가 제공된 파라메터와 일치하는지 확인한다.\nvoid hi( name user ) { require_auth( user ); print( \u0026#34;Hello, \u0026#34;, name{user} ); } 다시 컴파일 한다.\neosio-cpp -o hello.wasm hello.cpp --abigen 그리고 update 한다.\ncleos set contract hello CONTRACTS_DIR/hello -p hello@active 실행하되, 이번에는 권한이 일치 않도록 한다.\ncleos push action hello hi \u0026#39;[\u0026#34;bob\u0026#34;]\u0026#39; -p alice@active Error 3090004: Missing required authority Ensure that you have the related authority inside your transaction!; If you are currently using \u0026#39;cleos push action\u0026#39; command, try to add the [relevant](**http://google.com**) authority using -p option. 우리의 contract 수정으로, 제공된 name user 가 승인 유저와 동일한지 확인한다.\n다시 실행하되, 이번엔 alice account 의 권한으로 실행해보자.\ncleos push action hello hi \u0026#39;[\u0026#34;alice\u0026#34;]\u0026#39; -p alice@active executed transaction: 235bd766c2097f4a698cfb948eb2e709532df8d18458b92c9c6aae74ed8e4518 244 bytes 1000 cycles # hello \u0026lt;= hello::hi {\u0026#34;user\u0026#34;:\u0026#34;alice\u0026#34;} \u0026gt;\u0026gt; Hello, alice ","permalink":"https://nolleh.github.io/block-chain/2.1-helloworld/","summary":"hello 라는 이름의 디렉토리를 contracts directory 에 생성하자.\ncd CONTRACTS_DIR mkdir hello cd hello hello.cpp 를 생성하고 에디터로 열자.\ntouch hello.cpp 필요한 라이브러리를 이 파일에 include 한다.\n#include \u0026lt;eosiolib/eosio.hpp\u0026gt; #include \u0026lt;eosiolib/print.hpp\u0026gt; 코드를 간결하게 해줄 eosio 네임스페이스를 contract 에 추가한다.\nusing namespace eosio; eosiolib/eosio.hpp 가 EOSIO C 와 C++ API 를 당신의 contract 스코프에 로드한다. 표준 C++11 클래스를 생성한다. 이 contract class 는 eosio::contract 를 확장해야한다.\n#include \u0026lt;eosiolib/eosio.hpp\u0026gt; #include \u0026lt;eosiolib/print.hpp\u0026gt; using namespace eosio; class hello : public contract {}; 비어있는 contract 는 좋지 않으니, public 접근 지정자와 using 선언을 추가하자.","title":"EOSIO - 2.1/Hello World!"},{"content":" 다음에서 발췌 EOSIO - 1.7 Create Test Accounts\nWhat is an account? 블록체인에 저장되어 송신자와 수신자를 구분하는데 사용되는 승인의 집합체라 할 수 있다. 유연한 권한 승인 구조를 가질 수 있는데, 권한이 어떻게 설정되느냐에 따른 개인이나 그룹에 의해 소유될 수 있다.\n하나의 계정은 블록체인의 트랜잭션을 보내거나 받기 위해 요구된다.\n이 튜토리얼에서는 두개의 user 계정, bob 과 alice, 그리고 설정을 위한 기본 eosio 계정을 사용한다. 추가로 계정들은 다양한 contracts 를 위해 이 튜토리얼 시리즈에서 만들어 질 수 있다.\nStep 1: Create Test Accounts 이전 단계에서, wallet 과 개발키 쌍을 생성하였다. form 에 public key 를 지정하도록 요청받았지만, 이 단계를 넘기거나 쿠키를 사용하지 않도록 설정하였을 수있다. 생성된 publickey 를 YOUR_PUBLIC_KEY 에 기입하여 진행하자.\n이 튜토리얼동안 유저 bob 가 alice 가 사용된다. 두 계정은 cleos create accounts 를 통해 생성된다.\ncleos create account eosio bob YOUR_PUBLIC_KEY cleos create account eosio alice YOUR_PUBLIC_KEY 트랜잭션이 발송 되었음을 나타내는 다음과 같은 메시지가 노출된다.\nexecuted transaction: 40c605006de... 200 bytes 153 us # eosio \u0026lt;= eosio::newaccount {\u0026#34;creator\u0026#34;:\u0026#34;eosio\u0026#34;,\u0026#34;name\u0026#34;:\u0026#34;alice\u0026#34;,\u0026#34;owner\u0026#34;:{\u0026#34;threshold\u0026#34;:1,\u0026#34;keys\u0026#34;:[{\u0026#34;key\u0026#34;:\u0026#34;EOS5rti4LTL53xptjgQBXv9HxyU... warning: transaction executed locally, but may not be confirmed by the network yet ] Using Different Keys for Active/Owner on a PRODUCTION Network EOSIO has a unique authorization structure that has added security for you account. You can minimize the exposure of your account by keeping the owner key cold, while using the key associated with your active permission. This way, if your active key were every compromised, you could regain control over your account with your owner key.\n","permalink":"https://nolleh.github.io/block-chain/1.7-createtestaccount/","summary":"다음에서 발췌 EOSIO - 1.7 Create Test Accounts\nWhat is an account? 블록체인에 저장되어 송신자와 수신자를 구분하는데 사용되는 승인의 집합체라 할 수 있다. 유연한 권한 승인 구조를 가질 수 있는데, 권한이 어떻게 설정되느냐에 따른 개인이나 그룹에 의해 소유될 수 있다.\n하나의 계정은 블록체인의 트랜잭션을 보내거나 받기 위해 요구된다.\n이 튜토리얼에서는 두개의 user 계정, bob 과 alice, 그리고 설정을 위한 기본 eosio 계정을 사용한다. 추가로 계정들은 다양한 contracts 를 위해 이 튜토리얼 시리즈에서 만들어 질 수 있다.","title":"EOSIO - 1.7/Test 계정 생성하기"},{"content":"Step 1: Wallet 생성하기 먼저 wallet 을 생성한다. cleos wallet create 를 통해 기본 wallet 을 --to-console 옵션을 사용하여 간단하게 생성한다.\ncleos 를 production 환경에서 사용한다면, 대신 --to-file 옵션을 사용하여 wallet 의 패스워드를 배쉬 기록에 남지않도록 한다.\n개발 목적으로 사용하는 production 환경의 키가 아니기때문에 \u0026ndash;to-console 으로 보안 위협없이 사용할 수 있다.\ncleos wallet create --to-console cleos 는 패스워드를 반환하며, 이 패스워드를 다음 튜토리얼에서 이용할 수 있도록 저장하자.\nCreating wallet: default Save password to use in the future to unlock this wallet. Without password imported keys will not be retrievable. \u0026#34;PW5Kewn9L76X8Fpd....................t42S9XCw2\u0026#34; wallet 에 대해 wallet 의 암호 해독성에 대한 흔한 오해중의 하나는 토큰을 저장할 것이라는 것이다. wallet 은 토큰을 저장하지 않는다. wallet 은 private key 를 암호화된 파일에 저장하고 사이닝 트랜젝션에 활용한다.\n유저는 주로 인터페이스를 통해 트랜잭션 오브젝트를 빌드하고, 그 오브젝트를 서명될 수 있도록 wallet 에 전송하여, wallet 이 이후 시그니쳐와 함께 오브젝트를 네트워크를 통해 반환한다. 네트워크가 트랜잭션을 유효하다고 판단하면, 이를 블록체인의 블록에 포함시킨다.\nStep2: Open the wallet keosd 인스턴스를 시작하고 다면 wallet은 닫히게 된다. 실행시키고 싶다면 다음 명령어를 활용한다.\ncleos wallet open 다시 리스트를 조회해보면\ncleos wallet list 다음과 같이 반환된다.\nWallets: [ \u0026#34;default\u0026#34; ] Step 3: Unlock it keosd wallet 은 열려있지만 여전히 잠겨있다. 좀전에 비밀번호를 제공받았으므로, 이를 이제 사용한다.\ncleos wallet unlock 비밀번호를 입력하고 다시 리스트를 조회해보면\nWallets: [ \u0026#34;default *\u0026#34; ] 열렸음을 의미하는 * 가 붙어있다.\nStep 4: Import keys into your wallet private key 를 생성하기 위한 cleos 명령어가 있다.\ncleos wallet create_key Step 5: Follow this tutorial series more easily 얻은 public key 를 입력하자.\nStep 6:Import the Development Key 새로운 EOSIO 체인마다 \u0026ldquo;eosio\u0026rdquo; 라 불리는 기본적인 \u0026ldquo;system\u0026rdquo; 유저를 보유한다.\n이 계정은 시스템 contracts 들을 로딩함으로써 governance 와 EOSIO 체인의 컨센서스를 지휘하는 체인을 설정하는데 사용된다.\n모든 EOSIO 체인은 development key 와 함께 제공되는데, 모두 동일하다. 이 키를 로드하여 시스템유저(eosio) 대신 트랜잭션을 서명해보자.\ncleos wallet import private key 를 질의 할텐데, 다음을 입력한다.\n5KQwrPbwdL6PhXujxW37FSSQZ1JiwsST4cqQzDeyXtP79zkvFD3 이제 default wallet 이 해금되고 key 로 load 되었으니, 다음을 진행 할 수 있게 되었다.\n","permalink":"https://nolleh.github.io/block-chain/1.6-createdevelopmentwallet/","summary":"Step 1: Wallet 생성하기 먼저 wallet 을 생성한다. cleos wallet create 를 통해 기본 wallet 을 --to-console 옵션을 사용하여 간단하게 생성한다.\ncleos 를 production 환경에서 사용한다면, 대신 --to-file 옵션을 사용하여 wallet 의 패스워드를 배쉬 기록에 남지않도록 한다.\n개발 목적으로 사용하는 production 환경의 키가 아니기때문에 \u0026ndash;to-console 으로 보안 위협없이 사용할 수 있다.\ncleos wallet create --to-console cleos 는 패스워드를 반환하며, 이 패스워드를 다음 튜토리얼에서 이용할 수 있도록 저장하자.\nCreating wallet: default Save password to use in the future to unlock this wallet.","title":"EOSIO - 1.6/개발 Wallet 생성하기"},{"content":" 다음에서 발췌 - EOSIO - 1.5 Install The CDT\nEOSIO Contract Development Toolkit, CDT 는 contract 컴파일을 위한 툴의 집합이다. 뒤따를 튜토리얼들은 contract 들을 컴파일하고 ABI 를 생성하는 주요 CDT 를 사용한다.\n1.3.x 버전부터, CDT 는 Mac OS X brew, linux debian 과 RPM 패키지들을 지원한다. 설치하기 위한 가장쉬운 선택지는 이 패키지 시스템들을 이용하는 것이다. 하나의 방법을 선택하자.\nHomeBrew (Mac OS X) Install brew tap eosio/eosio.cdt brew install eosio.cdt Uninstall brew remove eosio.cdt ","permalink":"https://nolleh.github.io/block-chain/1.5-installthecdt/","summary":"다음에서 발췌 - EOSIO - 1.5 Install The CDT\nEOSIO Contract Development Toolkit, CDT 는 contract 컴파일을 위한 툴의 집합이다. 뒤따를 튜토리얼들은 contract 들을 컴파일하고 ABI 를 생성하는 주요 CDT 를 사용한다.\n1.3.x 버전부터, CDT 는 Mac OS X brew, linux debian 과 RPM 패키지들을 지원한다. 설치하기 위한 가장쉬운 선택지는 이 패키지 시스템들을 이용하는 것이다. 하나의 방법을 선택하자.\nHomeBrew (Mac OS X) Install brew tap eosio/eosio.cdt brew install eosio.cdt Uninstall brew remove eosio.","title":"EOSIO - 1.5/CDT 설치하기"},{"content":" 다음에서 발췌 - Step 1: Boot Node And Wallet Step 1.1: Start keosd 먼저 keosd 를 시작한다.\nkeosd \u0026amp; 다음과 유사한 결과를 얻게 된다.\ninfo 2018-11-26T06:54:24.789 thread-0 wallet_plugin.cpp:42 plugin_initialize ] initializing wallet plugin info 2018-11-26T06:54:24.795 thread-0 http_plugin.cpp:554 add_handler ] add api url: /v1/keosd/stop info 2018-11-26T06:54:24.796 thread-0 wallet_api_plugin.cpp:73 plugin_startup ] starting wallet_api_plugin info 2018-11-26T06:54:24.796 thread-0 http_plugin.cpp:554 add_handler ] add api url: /v1/wallet/create info 2018-11-26T06:54:24.796 thread-0 http_plugin.cpp:554 add_handler ] add api url: /v1/wallet/create_key info 2018-11-26T06:54:24.796 thread-0 http_plugin.cpp:554 add_handler ] add api url: /v1/wallet/get_public_keys enter 를 치면 종료 된다.\nStep 1.2: Start nodeos nodeos -e -p eosio \\ --plugin eosio::producer_plugin \\ --plugin eosio::chain_api_plugin \\ --plugin eosio::http_plugin \\ --plugin eosio::history_plugin \\ --plugin eosio::history_api_plugin \\ --data-dir CONTRACTS_DIR/eosio/data \\ --config-dir CONTRACTS_DIR/eosio/config \\ --access-control-allow-origin=\u0026#39;*\u0026#39; \\ --contracts-console \\ --http-validate-host=false \\ --verbose-http-errors \\ --filter-on=\u0026#39;*\u0026#39; \u0026gt;\u0026gt; nodeos.log 2\u0026gt;\u0026amp;1 \u0026amp; 이 설정은 다음과 같은 작업을 진행한다.\n개발 디렉토리 하위의 eosio 디렉토리안에서 블록체인 데이터와 설정 데이터를 사용 할수 있도록 지정. eosio/data 와 eosio/config 을 각각 사용하게 된다. nodeos 를 실행한다. 이 커맨드는 기본적인 플러그인을 로드하고, 서버 주소를 설정하며, CORS 를 사용가능하게 하며 일부 contract 디버깅과 로깅을 가능케한다. CORS 가 (*) 에 대한 제약이 없도록 한다. CORS 의 _ 에 대한 제약제거는 개발 과정에서만 사용하도록 한다. 어떤 노드에 대해 public 하게 _ 에 접근하도록 하는 것은 지양해야한다!\nStep 2: Check the installation Step 2.1: Check That Nodeos is Producing Blocks 아래의 명령어를 실행한다.\ntail -f nodeos.log 아래와 유사한 출력 결과를 볼 수 있다.\n1929001ms thread-0 producer_plugin.cpp:585 block_production_loo ] Produced block 0000366974ce4e2a... #13929 @ 2018-05-23T16:32:09.000 signed by eosio [trxs: 0, lib: 13928, confirmed: 0] 1929502ms thread-0 producer_plugin.cpp:585 block_production_loo ] Produced block 0000366aea085023... #13930 @ 2018-05-23T16:32:09.500 signed by eosio [trxs: 0, lib: 13929, confirmed: 0] 1930002ms thread-0 producer_plugin.cpp:585 block_production_loo ] Produced block 0000366b7f074fdd... #13931 @ 2018-05-23T16:32:10.000 signed by eosio [trxs: 0, lib: 13930, confirmed: 0] 1930501ms thread-0 producer_plugin.cpp:585 block_production_loo ] Produced block 0000366cd8222adb... #13932 @ 2018-05-23T16:32:10.500 signed by eosio [trxs: 0, lib: 13931, confirmed: 0] 1931002ms thread-0 producer_plugin.cpp:585 block_production_loo ] Produced block 0000366d5c1ec38d... #13933 @ 2018-05-23T16:32:11.000 signed by eosio [trxs: 0, lib: 13932, confirmed: 0] 1931501ms thread-0 producer_plugin.cpp:585 block_production_loo ] Produced block 0000366e45c1f235... #13934 @ 2018-05-23T16:32:11.500 signed by eosio [trxs: 0, lib: 13933, confirmed: 0] 1932001ms thread-0 producer_plugin.cpp:585 block_production_loo ] Produced block 0000366f98adb324... #13935 @ 2018-05-23T16:32:12.000 signed by eosio [trxs: 0, lib: 13934, confirmed: 0] 1932501ms thread-0 producer_plugin.cpp:585 block_production_loo ] Produced block 00003670a0f01daa... #13936 @ 2018-05-23T16:32:12.500 signed by eosio [trxs: 0, lib: 13935, confirmed: 0] 1933001ms thread-0 producer_plugin.cpp:585 block_production_loo ] Produced block 00003671e8b36e1e... #13937 @ 2018-05-23T16:32:13.000 signed by eosio [trxs: 0, lib: 13936, confirmed: 0] 1933501ms thread-0 producer_plugin.cpp:585 block_production_loo ] Produced block 0000367257fe1623... #13938 @ 2018-05-23T16:32:13.500 signed by eosio [trxs: 0, lib: 13937, confirmed: 0] 로그를 닫기 위해 Ctrl + c 를 누르자.\nStep 2.2: Check the wallet 쉘을 열고 아래 명령어를 기입한다.\ncleos wallet list 다음과 같은 결과가 노출된다.\nWallets: [] 이 시점에서 앞으로, 당신의 로컬시스템에서 이 명령어들을 칠 것이라 기대한다.\nStep 2.3: Check Nodeos endpoints 다음은 RPC API 가 정상적으로 동작하는지 확인할 것이다. 하나를 선택하자.\n다음 브라우저에서 chain_api_plugin 을 통해 제공되는 get_info 를 확인해본다. : http://localhost:8888/v1/chain/get_info 같은 것을 확인하지만, 호스트머신의 콘솔에서 확인한다. curl http://localhost:8888/v1/chain/get_info ","permalink":"https://nolleh.github.io/block-chain/1.4-startyournodeandsetup/","summary":"다음에서 발췌 - Step 1: Boot Node And Wallet Step 1.1: Start keosd 먼저 keosd 를 시작한다.\nkeosd \u0026amp; 다음과 유사한 결과를 얻게 된다.\ninfo 2018-11-26T06:54:24.789 thread-0 wallet_plugin.cpp:42 plugin_initialize ] initializing wallet plugin info 2018-11-26T06:54:24.795 thread-0 http_plugin.cpp:554 add_handler ] add api url: /v1/keosd/stop info 2018-11-26T06:54:24.796 thread-0 wallet_api_plugin.cpp:73 plugin_startup ] starting wallet_api_plugin info 2018-11-26T06:54:24.796 thread-0 http_plugin.cpp:554 add_handler ] add api url: /v1/wallet/create info 2018-11-26T06:54:24.796 thread-0 http_plugin.cpp:554 add_handler ] add api url: /v1/wallet/create_key info 2018-11-26T06:54:24.","title":"EOSIO - 1.4/노드 시작하고 설정하기"},{"content":" 발췌 - EOSIO - 1.3 About The Stack\n방금 설치한 툴들을 시작하기 전에, 각각의 컴포넌트들이 어떻게 상호작용하는지 이해하는게 좋다.\nnodeos (node + eos = nodeos) - 노드를 실행하기 위한 플러그인들로 설정될 수 있는 Core EOSIO 데몬. 예제는 로컬개발과 API 종단점을 위해 블록제품을 사용한다.\ncleos (cli + eos = cleos) - 블록 체인과 상호작용하고 wallet 을 관리하기위한 커맨드 라인 인터페이스.\nkeosd (key + eos = keosd) - wallet 안의 EOSIO key 를 안전하게 저장 하기 위한 컴포넌트\neosio-cpp - eosio.cdt 의 일부로, C++ 코드를 WASM 로 컴파일하고 ABI 들을 생성한다.\n","permalink":"https://nolleh.github.io/block-chain/1.3-aboutthestack/","summary":"발췌 - EOSIO - 1.3 About The Stack\n방금 설치한 툴들을 시작하기 전에, 각각의 컴포넌트들이 어떻게 상호작용하는지 이해하는게 좋다.\nnodeos (node + eos = nodeos) - 노드를 실행하기 위한 플러그인들로 설정될 수 있는 Core EOSIO 데몬. 예제는 로컬개발과 API 종단점을 위해 블록제품을 사용한다.\ncleos (cli + eos = cleos) - 블록 체인과 상호작용하고 wallet 을 관리하기위한 커맨드 라인 인터페이스.\nkeosd (key + eos = keosd) - wallet 안의 EOSIO key 를 안전하게 저장 하기 위한 컴포넌트","title":"EOSIO - 1.3/스택에 대해"},{"content":" 발췌 - (EOSIO - 1.2 Before You Begin)[https://developers.eos.io/eosio-home/docs/setting-up-your-environment]\nStep 1: Install Binaries 이 튜토리얼은 선빌드된 바이너리를 사용한다.\n가장 빨리 시작하는 방법은 이게 가장 좋은 선택지 일것이다. 소스로부터 빌드하는 것도 하나의 선택지이지만, 한시간 이상 걸릴 수 도 있으며 빌드 에러가 발생 할 수도 있다.\n아래의 명령어들이 각각의 OS 에서 바이너리를 다운로드 할 것이다.\nbrew tap eosio/eosio brew install eosio Step 2: Setup a development directory, stick to it 작업을 진행할 디렉토리를 선택할 필요가 있다.\ncontracts 폴더를 로컬드라이브 어딘가에 생성하는 것을 추천한다.\nmkdir contracts cd contracts Step 3: Enter your local directory below. 그 폴더의 경로를 얻어 저장해둬서 필요할 때 사용 할 수 있도록 다음 명령어를 통하면 된다.\npwd 절대 경로를 아래에 기입하면 문서의 내용에 반영, 더 읽기 편하게 만들어 줄 것이다. 이 기능은 쿠키를 사용한다.\n","permalink":"https://nolleh.github.io/block-chain/1.2-beforeyoubegin/","summary":"발췌 - (EOSIO - 1.2 Before You Begin)[https://developers.eos.io/eosio-home/docs/setting-up-your-environment]\nStep 1: Install Binaries 이 튜토리얼은 선빌드된 바이너리를 사용한다.\n가장 빨리 시작하는 방법은 이게 가장 좋은 선택지 일것이다. 소스로부터 빌드하는 것도 하나의 선택지이지만, 한시간 이상 걸릴 수 도 있으며 빌드 에러가 발생 할 수도 있다.\n아래의 명령어들이 각각의 OS 에서 바이너리를 다운로드 할 것이다.\nbrew tap eosio/eosio brew install eosio Step 2: Setup a development directory, stick to it 작업을 진행할 디렉토리를 선택할 필요가 있다.","title":"EOSIO - 1.2/시작하기 전에"},{"content":" 발췌 EOSIO - 1.1 Introduction\n배울 수 있는 것 노드로 얼마나 빨리 갖고 놀 수 있는가 Wallet 과 Key 를 어떻게 관리할 수 있는가 계정을 만드는 법 contract 작성법 컴파일과 ABI contract 배포 C / C++ 경험 EOSIO 기반 블록체인은 WebAssembly 를 이용하여 유저가 생성한 어플리케이션과 코드를 실행한다.\nWASM 은 구글, 마이크로소프트, 애플, 그리고 다른 주요 업체의 지원을 받는 떠오르는 웹 표준이다.\n오늘날 WASM 을 빌드하기위해 사용되는 성숙된 도구는 C/C++ 컴파일러를 통한 clang/llvm 이다.\n최고의 호환성을 위해, EOSIO C++ 툴체인을 사용하도록 권장한다.\n서드파티에 의해 개발중인 다른 툴체인들은 다음과 같다: Rust, Python, Solidity. 이들의 언어는 단순해 보이지만, 성능은 당신이 빌드하는 어플리케이션의 규모에 따라 다르다. C++ 가 가장 안전하고 고성능일 것이라고 기대한다.\nLinux / Mac OS Experience Amazon 2017.09 CentOS 7 Fedora 25 Mint 18 Ubuntu 16.04 (16.10 추천) Ubuntu 18.04 MacOS Darwin 10.12+ (10.13 추천) Command Line Knowlege EOSIO 의 다양한 툴을 이용하기 위해서는 기본적인 커맨드라인 지식이 필요하다.\nC++ Environment Setup C++ 문법 하이라이팅을 지원하는 어떤 텍스트 에디터를 사용해도 되지만 주요한 에디터는 Sublime Text, Atom 이 있다. 다른 선택지는 철학적인 코드 완성과 개발 경험이 더 많은 철학적인 IDE 를 선택해서 사용하면된다. 개인 선호에 따라 작업하면 되지만, 확신이 없다면 다음 선택지 중에서 살펴보면 된다.\nPotential Editors and IDEs Sublime Text Atom Editor CLion Eclips Visual Studio Code Operating System of Development Enviornment linux 향의 OS 를 사용한다면 튜토리얼을 따를 수 있다. 다음을 포함하지만, 여기에 제한된건 아니다.\nMac OS Ubuntu Debian Fedora Windows 현재는 powershell 포트등에 대해 지원하지 않는다. 미래에는 powershell 명령어를 지원할 계획이지만, 그전까지는 Ubuntu VM 을 활용하여 개발환경을 구성하는 편이 최선이다. Linux 명령에 익숙한 개발자라면 적은 어려움 만이 있을 것이다.\n","permalink":"https://nolleh.github.io/block-chain/1.1-introduction/","summary":"발췌 EOSIO - 1.1 Introduction\n배울 수 있는 것 노드로 얼마나 빨리 갖고 놀 수 있는가 Wallet 과 Key 를 어떻게 관리할 수 있는가 계정을 만드는 법 contract 작성법 컴파일과 ABI contract 배포 C / C++ 경험 EOSIO 기반 블록체인은 WebAssembly 를 이용하여 유저가 생성한 어플리케이션과 코드를 실행한다.\nWASM 은 구글, 마이크로소프트, 애플, 그리고 다른 주요 업체의 지원을 받는 떠오르는 웹 표준이다.\n오늘날 WASM 을 빌드하기위해 사용되는 성숙된 도구는 C/C++ 컴파일러를 통한 clang/llvm 이다.","title":"EOSIO - 1.1/소개"},{"content":"개요 다음에서 발췌\n비동기 프로그램의 제어 흐름\n코드 public partial class MainWindow : Window { // . . . private async void startButton_Click(object sender, RoutedEventArgs e) { // ONE Task\u0026lt;int\u0026gt; getLengthTask = AccessTheWebAsync(); // FOUR int contentLength = await getLengthTask; // SIX resultsTextBox.Text += $\u0026#34;\\r\\nLength of the downloaded string: {contentLength}.\\r\\n\u0026#34;; } async Task\u0026lt;int\u0026gt; AccessTheWebAsync() { // TWO HttpClient client = new HttpClient(); Task\u0026lt;string\u0026gt; getStringTask = client.GetStringAsync(\u0026#34;https://msdn.microsoft.com\u0026#34;); // THREE string urlContents = await getStringTask; // FIVE return urlContents.Length; } } Three 에서 yield 되어 Four.\n","permalink":"https://nolleh.github.io/csharp/async-control-flow-msdn/","summary":"개요 다음에서 발췌\n비동기 프로그램의 제어 흐름\n코드 public partial class MainWindow : Window { // . . . private async void startButton_Click(object sender, RoutedEventArgs e) { // ONE Task\u0026lt;int\u0026gt; getLengthTask = AccessTheWebAsync(); // FOUR int contentLength = await getLengthTask; // SIX resultsTextBox.Text += $\u0026#34;\\r\\nLength of the downloaded string: {contentLength}.\\r\\n\u0026#34;; } async Task\u0026lt;int\u0026gt; AccessTheWebAsync() { // TWO HttpClient client = new HttpClient(); Task\u0026lt;string\u0026gt; getStringTask = client.GetStringAsync(\u0026#34;https://msdn.microsoft.com\u0026#34;); // THREE string urlContents = await getStringTask; // FIVE return urlContents.","title":"비동기 프로그램의 제어 흐름"},{"content":"개요 다음에서 발췌 MSDN\n반응성을 향상시키는 비동기 잠재적인 차단 작업 완료 될때까지 다른 작업을 게속 수행\n작성이 간편한 비동기 메서드 반환 형식은 다음 중 하나\nTask Task void - 비동기 이벤트 처리기 작성 GetAwaiter 포함 모든 기타 형식 await 을 만나면 yield 함 (호출자로 제어가 돌아감) 이때, Task 가 호출자에게 반환되고 이는 언젠가 다운로드된 문자열의 길이가 반환된다는 약속 (future) 을 의미한다. await 전에 작업이 완료된다면 제어가 돌아가지 않는다. 스레드 비동기 메서드의 await 식은 대기한 작업이 실행되는 동안 현재 스레드를 차단하지 않는다. 대신, 메서드의 나머지를 연속으로 등록하고 비동기 메서드 호출자에 반환.\nasync / await 으로 인해 스레드가 추가로 생성되지 않는다.\n비동기 메서드는 자체 스레드에서 실행되지 않고 현재 동기화 컨텍스트에서 실행되며,\n활성화된 경우에만 스레드에서 시간을 사용.\n","permalink":"https://nolleh.github.io/csharp/async-await-msdn/","summary":"개요 다음에서 발췌 MSDN\n반응성을 향상시키는 비동기 잠재적인 차단 작업 완료 될때까지 다른 작업을 게속 수행\n작성이 간편한 비동기 메서드 반환 형식은 다음 중 하나\nTask Task void - 비동기 이벤트 처리기 작성 GetAwaiter 포함 모든 기타 형식 await 을 만나면 yield 함 (호출자로 제어가 돌아감) 이때, Task 가 호출자에게 반환되고 이는 언젠가 다운로드된 문자열의 길이가 반환된다는 약속 (future) 을 의미한다. await 전에 작업이 완료된다면 제어가 돌아가지 않는다. 스레드 비동기 메서드의 await 식은 대기한 작업이 실행되는 동안 현재 스레드를 차단하지 않는다.","title":"Async Await 을 사용한 비동기 프로그래밍"},{"content":"Dispose 에 대한 여러가지 MSDN Implementing a Dispose method\nthreadSafety stackoverflow dispose 의 threadsafety\n많은 경우 어떤 스레드든지 다른 스레드가 dispose 를 시작했을때 오브젝트에 대해 작업을 하고 있을 수 있기 때문에, interlocked.Exchange 를 통해 배제하는게 옳아 보인다.\n물론, 좋은 생각이고 표준 dispose 패턴의 일부가 되어야 한다고 생각한다.\n(champareExchange가 base class 에 봉인됨으로써 derived class 에서 private 한 disposed flag 를 사용하는 것을 피해야한다.)\n하지만 불행히도, dispose 가 정확히 어떤것을 하는지 생각해보면 문제는 좀 더 복잡해진다.\nDispose 의 진짜 목적은 그 오브젝트가 버려지게 하는 목적이라기보다, 그 오브젝트가 들고 있는 레퍼런스를 비우는데 목적이 있다.\n이 엔터티 들은 managed objects 일 수도 있고, system object 일수도 있고, 다른 어떤 것일 수도 있다; 심지어 같은 컴퓨터에 존재하지 않을 수도 있다.\nthread-safe 하려면, 이 Dispose 가 정리하는 동시에 다른 스레드가 이를 가지고 다른 일을 할 수 있도록 다른 엔티티들이 허용해야한다.\n어떤 객체들은 이렇게 할 수 있지만, 그렇지 않은 객체들도 있다.\n짜증나는 예를 들어보자: 객체들은 thread-safe 하지 않은 RemoveHandler 이벤트를 갖도록 허용되어있다. 결과적으로, 구독이 이루어졌던 그 스레드에서만 Dispose 를 호출하도록 해야한다.\n","permalink":"https://nolleh.github.io/csharp/dispose/","summary":"Dispose 에 대한 여러가지 MSDN Implementing a Dispose method\nthreadSafety stackoverflow dispose 의 threadsafety\n많은 경우 어떤 스레드든지 다른 스레드가 dispose 를 시작했을때 오브젝트에 대해 작업을 하고 있을 수 있기 때문에, interlocked.Exchange 를 통해 배제하는게 옳아 보인다.\n물론, 좋은 생각이고 표준 dispose 패턴의 일부가 되어야 한다고 생각한다.\n(champareExchange가 base class 에 봉인됨으로써 derived class 에서 private 한 disposed flag 를 사용하는 것을 피해야한다.)\n하지만 불행히도, dispose 가 정확히 어떤것을 하는지 생각해보면 문제는 좀 더 복잡해진다.","title":"Dispose"},{"content":"NeoSmart.AsyncLock 라이브러리에 관하여 다음에서 발췌, 번역 - Neosmart Docs.\n개요 semaporeslim 은 reentrance 를 지원하지 않는다. 따라서, recursion 에서 적절히 사용되지 않으면 데드락이 발생한다.\nasynclock 은 reentrance 기능을 semaphoreslim 에 추가한거.\n대안 간단한 방법은 semaphoreslim 으로 교체하고, recursion 인 경우를 스레드 아이디로 확인 하는 것.\n이 경우의 문제는\nasync / await 의 가장 기본적인 목적인 ui 의 불필요한 블럭킹 없이 작업의 완료를 기다린다는 문제를 그대로 안고 있다.\nawait 코드를 넣어도 다른 코드가 실행 될 수 없다.\nclass ThreadIdConflict { BadAsyncLock _lock = new BadAsyncLock(); async void Button1_Click() { using (_lock.Lock()) { await Task.Delay(-1); //at this point, control goes back to the UI thread } } async void Button2_Click() { using (_lock.Lock()) { await Task.Delay(-1); //at this point, control goes back to the UI thread } } } 원래 메인스레드는 메시지 펌핑을 하면서 콜백을 호출해주는 구조로 되어 있고,\n\u0026ldquo;hard\u0026rdquo; await 을 마주쳐서 메인 ui 로 돌아갈때도\n이벤트 핸들러의 실행을 일시 정지하지만 실제 스레드가 동작을 멈추지는 않는다.\nawait 이 완료 되고 나면, continuation 이 다시 main 스레드에서 실행된다.\n여기에서 중요한 것은, 항상 같은 스레드가 실행된다는 것이다. (non- awaited async 함수 호출을 제외하고.) Button1_Click() 을 실행한 스레드가 await 을 만나 동작을 정지하고, 이후 Button2_cllick 을 호출한다. Button1_click() 의 남은 코드는 옆에 놓여지는거지, 실제로 정지 되는것이 아니다. 이 의미는, Button2_click 이 실행되어야할 때 Button1_click() 은 세마포어를 통해 상호 배제적인 접근을 하고 있으므로 접근 불가해야하나, owningthreadId 가 같으므로 두 메소드가 동시에 실행된다.\nAsyncLock 그럼 어떻게 해야하는가? recursion 을 체크하기위해 뭔가 다른 방법을 찾아야한다. Envrionment 클래스를 통해 스택 트레이스에 접근 할 수 있다. 이를 락을 얻기 위한 요건으로 사용할 수 있지 않을까 ?\nUpdate 5/25/2017 (AsyncLock 은 이제는 taskid 를 통해 확인하고 있다. )\nList _stackTraces = new List(); async Task Lock() { if (!lock.locked) { _stackTraces.Add(Environment.StackTrace); lock.Wait(); return true; } else if (_stackTraces.Peek().IsParentOf(Environment.StackTrace)) { _stackTraces.Add(Environment.StackTrace); return true; } else { //wait for the lock to become available somehow return true; } } Lock() 의 호출이 스택추적을 낭비하지 않는다고 가정하면,(?) isParentOf 메소드가 현재 호출이 저장된 스택트레이스의 자식인지 확인한다.\n하지만 이런 접근은 첫번째 솔루션으로는 쉽게 해결 됐을 다음 코드를 처리하지 못한다.\nclass StackTraceConflict { BadAsyncLock _lock = new BadAsyncLock(); async void DoSomething() { using (_lock.Lock()) { await Task.Delay(-1); } } void DoManySomethings() { while(true) { DoSomething(); //no wait here! } } } 모두 같은 지점에서 실행되기 때문에 다른 스레드에서 같은 스택트레이스를 갖게 되고 완벽하게 실패하게 된다!\n따라서 적절한 솔루션은, 두 솔루션을 결합하는 것이다.\nclass AsyncLockTest { AsyncLock _lock = new AsyncLock(); void Test() { //the code below will be run immediately (and asynchronously, in a new thread) Task.Run(async () =\u0026gt; { //this first call to LockAsync() will obtain the lock without blocking using (await _lock.LockAsync()) { //this second call to LockAsync() will be recognized as being a reëntrant call and go through using (await _lock.LockAsync()) { //we now hold the lock exclusively and no one else can use it for 1 minute await Task.Delay(TimeSpan.FromMinutes(1)); } } }).Wait(TimeSpan.FromSeconds(30)); //this call to obtain the lock is synchronously made from the main thread //It will, however, block until the asynchronous code which obtained the lock above finishes using (_lock.Lock()) { //now we have obtained exclusive access } } } task 가 먼저 실행되도록 하기위해 30 초를 대기했다가 평범하게 락을 건다.\n첫번째 락은 평범하게 얻어진 뒤에, 다시 reentrant call 이 발생하고, 이것 또한 넘어가게 된다. (# await 실행된 스레드아이디 + 실행된 콜스택의 부모)\nTask.Delay 를 마주쳐서 스레드는 pause 상태로 전환되고, 이 시간동안 공유되는 리소스에 대해 배제적 접근을 하게 된다.\n30 초 뒤에 lock 을 얻으려고 시도할때, 이 시도는 실패하게 되고\n다시 30초 뒤에 task 가 완료되어 lock 을 release 하게 되면 메인스레드가 락을 얻어 동작이 재개 된다.\n이 코드 조각은 두개의 락 옵션을 사용하고 있다. Lock() 과 LockAsync() 인데, 이들은 둘다 기본 개념은 같고, async 메소드는 async/ await 패러다임을 품어 이 실행이 lock 이 사용 가능할때에 새로 얻을 수 있도록 한 개념이다. 이렇게 해서 await lock.LockAsync() 가 블러킹 되지 않도록 한 것이다.\n","permalink":"https://nolleh.github.io/csharp/async-await/","summary":"NeoSmart.AsyncLock 라이브러리에 관하여 다음에서 발췌, 번역 - Neosmart Docs.\n개요 semaporeslim 은 reentrance 를 지원하지 않는다. 따라서, recursion 에서 적절히 사용되지 않으면 데드락이 발생한다.\nasynclock 은 reentrance 기능을 semaphoreslim 에 추가한거.\n대안 간단한 방법은 semaphoreslim 으로 교체하고, recursion 인 경우를 스레드 아이디로 확인 하는 것.\n이 경우의 문제는\nasync / await 의 가장 기본적인 목적인 ui 의 불필요한 블럭킹 없이 작업의 완료를 기다린다는 문제를 그대로 안고 있다.\nawait 코드를 넣어도 다른 코드가 실행 될 수 없다.","title":"Async Await"},{"content":" Nancy 에 대한 문서 번역 #1. By Nolleh\nIntroduction 가장 먼저, Nancy 의 세계에 온것을 환영합니다!\n루비의 sinatra 프레임워크에 영감을 받아 Nancy 라는 이름을 붙이게 되었습니다. (Frank Sinatra 의 딸이름이 Nancy 니까요!)\nNancyFx 의 Fx 에 대해 많은 사람들이 궁금해하여 여기에 붙입니다만, framework 라는 뜻입니다 :)\nNancyFx 는 모든 컴포넌트들을 포함하는 umbrella project 입니다. (#역자주: 우산효과의 우산처럼, 포괄적인 프로젝트라는 의미로 쓴게 아닐까? )\n이 가이드는 앞으로 개괄적이고 빠르게 Nancy 의 특징들을 살펴 독자 스스로 Nancy 의 세계를 탐험해 볼 수 있는 시야를 제공할겁니다.\nNancy 는 가볍고, 적은 준비의식(#역자주: 라이브러리를 쓰기 위한 선제 작업)의 HTTP 기반의 서비스를 개발할 수 있는 .Net 과 Mono 기반 프레임 워크입니다.\n이 프레임워크의 목적은 모든 상호 통신(ineractions)을 신경쓰지 않으면서도 동시에 슈퍼-엄청-행복한 방법으로-(super-duper-happy-path) 제공하는 것입니다.\n이 말은 Nancy 를 통한 모든 것들이 당신을 개고생하게 만드는 설정 지옥에서 벗어날 수 있도록 관습적이고/기본적인 설정 값을 적극 활용하는 것을 의미합니다.\nNancy 와 함께라면 아무것도 없는 상태에서 수 분안에 웹사이트를 만들 수 있습니다. 문자 그대로요!!\nNancy 는 DELETE, GET, HEAD, OPTIONS, POST, PUT, PATH 요청을 단순하고 우아한 Domain Specific Language (DSL) 을 몇번의 타이핑만으로 응답으로 전달하도록 디자인 되어 있어 당신은 다른 좀 더 중요한 당신의 코드, 당신의 어플리케이션에 집중 할 수 있도록 하였습니다.\n이 모든 것들은 MIT License 의 오픈 소스 입니다.\nNuget, our TeamCity Server 와 github repository 로부터 살펴 보실 수 있습니다.\nBuilt to run anywhere 원하는 곳 어디에서든 빌드되고 실행될 수 있습니다.\nNancy 는 어떤 존재하는 프레임워크에도 의존성이 없도록 디자인 되었습니다.\nrequest / response 객체 전부 자체에 포함되어 있으므로, .NET framework client profile 을 통해 빌드하여 Nancy 는 당신이 원하는 곳 어디에서든 사용될 수 있습니다.\nNancy 의 핵심 개념중의 하나로 hosts 가 있습니다. 하나의 호스트는 nancy 와 호스팅 환경의 어댑터로서 동작하게 되므로 Nancy 를 기존의 존재하는 - ASP.Net, WCF, OWIN, 다른 통합 응용프로그램 - 기술에서 활용해보십시오.\n특정 호스트 구현은 Nancy 프레임워크의 핵심 기능을 제공하지 않을 수 있습니다. 이런 추가기능들 - 인증과 같은- 은 개별로 제공됩니다.\nNancy 응용 프로그램을 빌드하는 것은 웹프레임워크의 buffet 으로부터 가장 좋아하는 부분을 뽑아내는 것과 같습니다! Nancy 서비스를 빌드하는데 사용할 최소한의 부분은 핵심 프레임워크와 host 가 될 것입니다.\nThe super-duper-happy-path 그 \u0026ldquo;super-duper-happy-path\u0026rdquo; (말을 줄이길 좋아하는 요새 사람들을 따르자면 SDHP 랄까요?) 란, Nancy 의 정신을 바로 짚는 용어라 하겠습니다;동시에 Nancy 의 API 를 이용하는 동안 \u0026ldquo;슈퍼-엄청-행복한-길\u0026rdquo; 에 대한 경험을 당신에게 제공하는 것이라 할 수도 있겠네요.\n결국에는 대단히 감정적 용어이기때문에 정확히 어떤 것인지 짚어보기 전에 이 배후의 아이디어를 살펴보도록합시다.\n\u0026ldquo;그냥 동작해\u0026rdquo; - 이것 저것 할것 없이 하나 집어서 사용하면 됩니다. 새로운 모듈을 추가한다? 이것들은 다 당신을 위해 자동으로 이뤄집니다. 새로운 뷰 엔진을 쓴다? 당신은 아무것도 할 것 없이, 미리 준비되어 있습니다. 당신 모듈에 새로운 의존성을 추가하는 것마저 자동으로 injection 해줄겁니다! - 설정노노해!-\n\u0026ldquo;쉬운 커스터 마이즈\u0026rdquo; - \u0026ldquo;그냥 동작해\u0026rdquo; 와 같은 기능이 커스터마이즈를 어렵게 할 것 같지만 그렇지 않습니다. 다른 컨테이너를 원하세요? 문제 없어요! 라우딩 되는 다른 경로를 원하세요 ? 하세요! 우리의 bootstrapper 가 이 모든 것들을 누워서 떡먹게 해줍니다.\n\u0026ldquo;적은 준비 의식\u0026rdquo; - 당신의 응용 프로그램을 위한 Nancy code 의 양은 아주 적습니다. Nancy 응용프로그램의 중요한 부분은 당신의 코드입니다. 실제 동작하는 Nancy 어플리케이션이 다음의 한 개의 트위터 글로 작성될 수 있다는 게 바로 그 증거죠.\n\u0026ldquo;적은 마찰\u0026rdquo; - Nancy 로 소프트웨어를 빌드할때 API 들이 도와줄 것입니다. 이름은 명확하고 요구되는 설정은 최소한이지만 강력한 성능과 확장성은 당신이 필요로 할 때 여전히 그 자리에 있어 줄 겁니다 :)\n위 내용들을 종합해 볼때, Nancy 로 응용프로그램을 작성하는 것은 즐겁고 재밌을거예요! 하지만 응용프로그램이 성장할 수록 성능이나 확장성을 포기해야할 때가 올 수도 있죠..\nCreating your first Nancy application 이야기는 이제 충분합니다. 이제 코드를 봅시다! Nuget (혹은 Mono) 은 설치되어 있을 것이라 가정하겠습니다.\n(우리곁의 어디에나 있는) 유비쿼터스 \u0026ldquo;Hello World\u0026rdquo; 응용프로그램을 Nancy 와 Nancy 의 ASP.NET 호스팅으로 빌드해보겠습니다.\nvisual studio 2012 이상이라면 SideWaffle Template Pack for Visual Studio 을, 2010 사용자라면 Nancy project templates 을 설치합시다.\nNancy empty project with ASP.NET host 메뉴 (sidewaffle) / Nancy Empty Web Application with ASP.NET Hosting 메뉴 (Nancy project template) 를 선택합니다.\nNancy Module 을 C# 클래스로 추가하고 root url 에 라우트 핸들러를 생성자에 작은 코드를 넣어 정의합니다:\nCompile and run to see result !\n강제하진 않지만 권장하는 내용으로, 새로운 업데이트를 체크하기 위해 Nuget Package Manager 를 사용해보세요.\nThe HelloModule.cs code\npublic class HelloModule : NancyModule { public HelloModule() { Get[\u0026#34;/\u0026#34;] = parameters =\u0026gt; \u0026#34;Hello World\u0026#34;; } } 모듈을 public 으로 선언하지 않으면 NancyFx 가 찾을 수 없으므로, 잊지마세요!\nMore Info - Why use NancyFX?\n","permalink":"https://nolleh.github.io/nancy/introduction/","summary":"Nancy 에 대한 문서 번역 #1. By Nolleh\nIntroduction 가장 먼저, Nancy 의 세계에 온것을 환영합니다!\n루비의 sinatra 프레임워크에 영감을 받아 Nancy 라는 이름을 붙이게 되었습니다. (Frank Sinatra 의 딸이름이 Nancy 니까요!)\nNancyFx 의 Fx 에 대해 많은 사람들이 궁금해하여 여기에 붙입니다만, framework 라는 뜻입니다 :)\nNancyFx 는 모든 컴포넌트들을 포함하는 umbrella project 입니다. (#역자주: 우산효과의 우산처럼, 포괄적인 프로젝트라는 의미로 쓴게 아닐까? )\n이 가이드는 앞으로 개괄적이고 빠르게 Nancy 의 특징들을 살펴 독자 스스로 Nancy 의 세계를 탐험해 볼 수 있는 시야를 제공할겁니다.","title":"Nancy Introduction"},{"content":" 네트워킹의 바이블이라 할 수 있는 Unix Network Programming 의 내용 정리\nBooks Introduction Socket 을 통해 통신하는 프로그램을 작성하는 개발자를 위해 쓰여진 책.\n시작하는 사람에게나, 프로페셔널에게나 유용한 책.\n물론 유지보수를 하거나, 새로 작성하는 사람, 네트워크 시스템 함수를 이해하는 모두에게 유용하다.\n실제 텍스트들은 유닉스 시스템에서 구동가능하나, OS 에 독립적인 socket api 를 지원하는 다른 OS 에서도, 본문에서 제안하는 일반적인 개념을 활용가능하다.\n많은 OS 는 셀수 없이 많은 네트워크 응용프로그램을 제공하고 있으며 - 예컨데 웹브라우저, email.. 이 프로그램들을 클라이언트와 / 서버로 분류하여 언급할 것이다.\nUsing This Book 초심자와 전문 프로그래머 모두 활용가능하다. 튜토리얼이 목적이라면 Part2 에 포커스를 맞추면 좋으며, 여기서 TCP 와 UDP, SCTP 모두에 대한 소켓 함수를 다루고 I/O multiplexing, socket options, basic name, address conversion 등을 다룬다.\nSection 1.4 에서는 본문 전체에서 다루는 래퍼펑션들이 소개된다.\nPart 3 에서는 \u0026ldquo;진화된 소켓\u0026rdquo; 에 대해 다루므로 아무나 읽어도 된다.\n소스코드는, 여기\nunpbook\n","permalink":"https://nolleh.github.io/network/unix-01-intro/","summary":"네트워킹의 바이블이라 할 수 있는 Unix Network Programming 의 내용 정리\nBooks Introduction Socket 을 통해 통신하는 프로그램을 작성하는 개발자를 위해 쓰여진 책.\n시작하는 사람에게나, 프로페셔널에게나 유용한 책.\n물론 유지보수를 하거나, 새로 작성하는 사람, 네트워크 시스템 함수를 이해하는 모두에게 유용하다.\n실제 텍스트들은 유닉스 시스템에서 구동가능하나, OS 에 독립적인 socket api 를 지원하는 다른 OS 에서도, 본문에서 제안하는 일반적인 개념을 활용가능하다.\n많은 OS 는 셀수 없이 많은 네트워크 응용프로그램을 제공하고 있으며 - 예컨데 웹브라우저, email.","title":"Unix 01 Intro"},{"content":" 어쩌다보니 그동안 손댈 일이 없던 웹서버에 좀 손을 대게 되서 (게임서버, 클라이언트, 그리고 웹서버..정녕 풀스택 개발자가 되는것인가..ㅋ), 예전 선배님이 버리고 간(?) 스프링 책을 꺼내서 읽어 보며 정리한 내용이므로 본 글을 처음 접한 사람이 이해하기에 많은 내용을 담지 않을 수 있음.\nSpring Bean 객체 스프링에서 생성하여 관리하여 주는 스프링 빈 객체 혹은 빈 객체라고 부른다. res/applicationContext.xml 에 태그로 선언할 수도 있다. 이렇게 선언한경우, 리플렉션을 활용하여 bean id 클래스의 인스턴스를 지정한 세부 태그의 속성으로 메서드를 호출하여 객체를 초기화한다.\nApplicationContext 스프링에서 제공하는 인터페이스. 컨테이너가 제공해야할 기본 기능 정의. BeanFactory 인터페이스를 상위에 두고 있다.\nApplicationContext::getBean 인자는 이름/타입. 이를 통해 빈객체를 얻어올 수 있다.\nSpring DI 설명이 장황한데, 여기서의 의존은 (composite 패턴으로) 다른 객체를 요할때를 의미한다.\n생성자를 통해 객체를 받거나 다른 멤버메서드를 통해 객체를 받거나 DI 의존성을 주입하는 방식으로, 외부로부터 의존객체를 전달 받는 구현 방식을 의미한다.\n스프링은, 결국 DI 컨테이너다.\nXML 을 통한 DI 설정 \u0026lt;beans xmlns=\u0026#34;http://www.springframework.org/scheme/beans\u0026#34;...\u0026gt; \u0026lt;bean id=\u0026#34;식별자\u0026#34; class=\u0026#34;클래스명\u0026#34;\u0026gt; \u0026lt;constructor-arg value=\u0026#34;test\u0026#34;/\u0026gt; \u0026lt;constructor-arg ref=\u0026#34;Other Bean\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;프로퍼티명\u0026#34;\u0026gt; \u0026lt;value\u0026gt;프로퍼티값\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;/beans\u0026gt; 프로퍼티 지정시, 역시 리플렉션을 활용, set{PropertyName}() 을 이용하여 값을 설정한다.\n스프링의 property 태그는 자바빈 규약에 따른다. 자바코드를 이용한 DI 설정 org.stringframework.annotation.AnnotationConfigApplicationContext 빈컨테이너 사용\n@Configuration 클래스를 스프링 설정으로 사용함을 의미\n@Bean 메서드의 리턴값을 빈 객체로 사용함을 의미\nexample @configuration public class Config { @Bean public User user1() { return new User(\u0026#34;nolleh\u0026#34;); } } 요렇게 선언하고\nAnnotationConfigApplicationContext ctx = new AnnotationConfigApplicationContext(Config.class); User user1 = ctx.getBean(\u0026#34;user1\u0026#34;, User.class); 요렇게 쓴다.\n생성자나 프로퍼티 값 설정시 직접 호출하면 된다.\nset{프로퍼티}(..);\n끝\n","permalink":"https://nolleh.github.io/web/fund-spring/","summary":"어쩌다보니 그동안 손댈 일이 없던 웹서버에 좀 손을 대게 되서 (게임서버, 클라이언트, 그리고 웹서버..정녕 풀스택 개발자가 되는것인가..ㅋ), 예전 선배님이 버리고 간(?) 스프링 책을 꺼내서 읽어 보며 정리한 내용이므로 본 글을 처음 접한 사람이 이해하기에 많은 내용을 담지 않을 수 있음.\nSpring Bean 객체 스프링에서 생성하여 관리하여 주는 스프링 빈 객체 혹은 빈 객체라고 부른다. res/applicationContext.xml 에 태그로 선언할 수도 있다. 이렇게 선언한경우, 리플렉션을 활용하여 bean id 클래스의 인스턴스를 지정한 세부 태그의 속성으로 메서드를 호출하여 객체를 초기화한다.","title":"스프링 기본 용어/정리"},{"content":" 다음에서 발췌, 번역\nhttps://msdn.microsoft.com/en-gb/library/windows/desktop/cc644950(v=vs.85).aspx File Buffering 파일버퍼링 - unbuffered file I/O.\n본문에선 시스템에 의해 캐싱되지 않는 (buffered) 데이터를\n어떻게 유저 모드의 응용프로그램에서 데이터를 활용할 수 (interact) 있을지에 대해 다룬다.\nFILE_FLAG_NO_BUFFERING 플래그를 통해 CreateFile 을 Open 하면,\n파일을 읽거나 쓸때 시스템의 캐싱을 비활성화 하도록 제어할 수 있다.\nI/O 버퍼링을 사용한것과 같은 효과를 내려면, 데이터 alignment 가 반드시 고려되어야 한다.\nNote 파일에 대해 Seeking 과 위치포인터, offsets 의 개념을 사용하는 파일에 대해 alignment 정보가 고려될 필요가 있다. 물리 디스크와 파일 시스템 저장소의 계층에서 write 연산은 alignment 기준을 맞추지 못한다면 실패 할 것이다.\nAlignment and File Access Requirement 다음을 만족시켜야한다.\n파일 접근 사이즈. OVERLAPPED 구조체의 offset 을 포함해서,\n지정된다면 volume 의 섹터사이즈의 정수배로 지정되어야한다. 읽기/쓰기 연산의 버퍼주소는 물리적 섹터에 aligned 되어있어야 한다.\n즉, 물리 섹터 사이즈의 정수배로 메모리가 주소에 정렬되어 있어야함을 의미한다.\n디스크에 따라 강제사항이 아닐 수도 있다. 4096 byte 의 미디어 섹터사이즈가 시장에 나온 것을 고려해야하는데,\n일시적인 방안으로, ATA / SCSI 명령어를 통해 일반적인 512 바이트의 섹터 저장소가\n에뮬레이트 되도록 할 수 있다.\n이 에뮬레이트를 사용할때, 다음 두 가지를 알아야한다.\n논리섹터: 미디어에 접근할때 사용되는 논리 블럭의 단위. 이 부분이 바로 \u0026ldquo;emulation\u0026rdquo; 물리섹터: 읽기/쓰기가 하나의 연산으로 이뤄지는 단위. 최적의 성능과 신뢰성을 위해 unbuffered I/O 가 aligned 되어야하는 단위이기도 하다. IOCTL_DISK_GET_DRIVE_GEOMETRY 와 GetDiskFreeSpace 를 통해 논리 섹터사이즈를 알 수 있으며,\nIOCTL_STORAGE_QUERY_PROPERTY 제어코드와\nSTORAGE_ACCESS_ALIGNMENT_DESCRIPTOR 구조체의\nBytesPerPhysicalSector 멤버의 사용을 통해 물리 섹터 사이즈를 구할 수 있다.\nWindows Server 2003 과 XP 에서는 STORAGE_ACCESS_ALIGNMENT_DESCRIPTOR 가 지원되지 않는다. 섹터 align 버퍼를 얻기 위해 VirtualAlloc 함수를 사용할 수 있다.\nVertualAlloc 은 메모리를 시스템페이지의 정수배의 사이즈로 align 되도록 메모리를 할당한다.\nx64 나 x86 에서는 4,096 바이트이며, Itanium-기반 시스템에서는 8,192 이다.\n더 자세한 정보는 GetSystemInfo 함수를 통해 얻을 수 있다. 직접 접근하는 저장소의 일반적인 섹터사이즈는 512 ~ 4,096 byte 이며, CD-ROM 에서는 2,048 바이트. 페이지/섹터사이즈 모두 2의 거듭제곱. 섹터사이즈가 페이지사이즈보다 큰 경우는 적기 때문에,\n대부분의 경우 page 에 align 된 메모리는 sector 에 대해서도 align 되어있다.\n수동으로 align 된 메모리버퍼를 얻는 또하나의 방법은 _aligned_malloc 함수를 사용하는 것이다.\n수동으로 align 된 버퍼를 사용하는 방법은 WriteFile 절의 예제코드를 살펴보라.\n","permalink":"https://nolleh.github.io/operating-system/file-buffering/","summary":"다음에서 발췌, 번역\nhttps://msdn.microsoft.com/en-gb/library/windows/desktop/cc644950(v=vs.85).aspx File Buffering 파일버퍼링 - unbuffered file I/O.\n본문에선 시스템에 의해 캐싱되지 않는 (buffered) 데이터를\n어떻게 유저 모드의 응용프로그램에서 데이터를 활용할 수 (interact) 있을지에 대해 다룬다.\nFILE_FLAG_NO_BUFFERING 플래그를 통해 CreateFile 을 Open 하면,\n파일을 읽거나 쓸때 시스템의 캐싱을 비활성화 하도록 제어할 수 있다.\nI/O 버퍼링을 사용한것과 같은 효과를 내려면, 데이터 alignment 가 반드시 고려되어야 한다.\nNote 파일에 대해 Seeking 과 위치포인터, offsets 의 개념을 사용하는 파일에 대해 alignment 정보가 고려될 필요가 있다.","title":"파일 버퍼링"},{"content":" concurrent 프로그램을 작성할 때 고려해야할 몇가지 사항. 그리고 idiom.\n여러 서적에서 발췌하였으며, 정리 차원에서 작성한 내용이므로 본 글을 처음 접한 사람이 이해하기에 많은 내용을 담지 않을 수 있음.\n어쩌면 작성자의 부사수를 위한 자재가 될지도 모르겠\u0026hellip;(..)\nConcurrent ISSUE - Stack 이번엔 스택.\nif (!s.empty()) { item = s.top(); s.pop(); } 인터페이스상의 문제이기 때문에 empty 와 top 사이의 safety 를 보장할 수 없다.\ntop() / pop() 도 마찬가지 -\u0026raquo; 조회되지 못하는 아이템이 있을 수 있다. (생각해보자.)\n해결을 위해 ?? -\u0026gt; Returning Pop ? \u0026ndash;\u0026raquo; 역시, 생각해보자. (Hint. Exception)\nOptions Reference 호출전 인스턴스 생성 필요. 생성자의 인자가 항상 제공 가능한 경우가 아닐때도.\n그리고 assign 필요. (Q. 이것이 무엇을 의미하는가? - C++ 개발지식이 있다면 대답할 수 있어야 한다.)\nMove Exception 만이 문제라면 이 선택으로 회피 가능할 수 있지 않은가.\n하지만.. 위와 마찬가지. (Q. 역시, 대답할 수 있어야 한다. )\nPointer 유저에게 메모리 관리 작업을 맡기는 것. (Q. 이게 문제라면, 어떻게 해결할 수 있겠는가?) 간단한 타입에 대해서는 오버헤드.\nCompounded Options 말그대로, 결합.\n끝\n","permalink":"https://nolleh.github.io/concurrency/concurrent-idiom-1-stack/","summary":"concurrent 프로그램을 작성할 때 고려해야할 몇가지 사항. 그리고 idiom.\n여러 서적에서 발췌하였으며, 정리 차원에서 작성한 내용이므로 본 글을 처음 접한 사람이 이해하기에 많은 내용을 담지 않을 수 있음.\n어쩌면 작성자의 부사수를 위한 자재가 될지도 모르겠\u0026hellip;(..)\nConcurrent ISSUE - Stack 이번엔 스택.\nif (!s.empty()) { item = s.top(); s.pop(); } 인터페이스상의 문제이기 때문에 empty 와 top 사이의 safety 를 보장할 수 없다.\ntop() / pop() 도 마찬가지 -\u0026raquo; 조회되지 못하는 아이템이 있을 수 있다.","title":"Concurrent Idiom 1 - Stack"},{"content":"GitHub-Page 이런게 있다더라 ~ 라고 주변으로부터 처음 들은건 1~2년전이었던것 같은데\n갑자기 꽂혀서 git page 를 만들었다. (!!)\ngithub 에서는 1계정당 1 호스트를 제공하는 것 같고\n\u0026lt;ID\u0026gt;.github.io 뭐 이런식? github 의 제공 영역은 repo 에 존재하는 index.html 을 repo 에 지정된 1 도메인과\n연결해주는 정도인 것 같다.\nRepository git 을 사용해 본 적이 있다면 간단하다.\n그렇다면 다음 절로 넘어가고, 그렇지 않다면, 다음을 따라하자.\ngithub 가입 이 항목에 있어 더 이상의 자세한 설명은 생략한다.\ngithub\nsshKey 여기를 따라하자.\ngithub-gen-sshkey\ngithub repo 생성 github 본인 메인 페이지에서 Repositories New 버튼 안내에 따라 따라하기 즉, 로컬의 git repo 대상 폴더에서 git init git add -A git commit -m \u0026ldquo;some-message\u0026rdquo; git remote add origin git@github.com:/.git git push -u origin master 이제 github 에 repository 를 올릴수 있게 되었다!\n내 Repo 를 GithubPage 로 지정하기 본 repo 에서 .github.com 의 index.html 을 찾도록 github 에 알려주자.\nMarkDown-To-HTML 잘은 모르겠지만.. github 페이지에서는 유독 MarkDown 을 통해\nhtml 을 작성하는게 잘 권장? 되어있는거 같고,\n아마도 git page 의 최초 제공 목적 자체가 블로그가 아니라 위키 정리와 같은 마크업 언어로 간단하게 문서를 작성하는 데에 있었기 때문일거다 - jekyll 이나 hugo 를 통해 MarkDown 으로 작성된 문서를 자동으로 html 로 생성할 수 있다.\nHugo 사실 jekyll 을 많이들 쓰고 있는 것 같고 공식적으로 지원? 하는 것 같은데 내 맥 PC 의 버전으로 ruby 가 잘 설치가 안되서 괴로워하던 중에 지인이 hugo 를 사용하는 것을 보고 그냥 hugo 를 선택했다. 나름 괜찮은 듯.\n공식 가이드는 다음을 살펴보면 되고,\nQuick-Start\n내가 따라가면서 확인한 주요한 내용은 다음과 같다.\nHugo OneStep # 휴고 설치 $ brew install hugo # 사이트 생성 this/is/my/github/repo$ hugo new site # 포스트 생성 this/is/my/github/repo$ hugo new post/hello-world.md # 포스트 수정 this/is/my/github/repo$ vim content/post/hello-world.md # 로컬에서 확인하기 this/is/my/github/repo$ hugo server ## http://localhost:1313 에서 확인 Hugo - 사이트 꾸미기 hugo 가 올바르게 generate 하기 위한 설정 값 지정 this/is/my/github/repo$ vim config.toml ### .... config.toml baseurl = \u0026#34;https://nolleh.github.io\u0026#34; languageCode = \u0026#34;ko-KR\u0026#34; title = \u0026#34;The Computer Programmer, Nolleh\u0026#34; theme = \u0026#34;hello-programmer\u0026#34; Paginate = 2 # the number of posts per page disqusShortname = \u0026#34;your-disqus-short-name\u0026#34; [params] author = \u0026#34;nolleh\u0026#34; locale = \u0026#34;ko-KR\u0026#34; hugo 의 테마 페이지를 예쁘게 구성하기 위해, 많은 개발자들이 오픈소스로 공개한 테마를 활용할 수 있다.\nHugo-Theme-ShowCase All-Themes-Github 1 에서 각 테마의 섬네일을,\n2 에서 각 테마의 repository 를 확인하여 clone 받을 수 있다.\n본인의 gitpage repo root/themes 로 이동하여 2의 repo 를 clone, 위에서 기술한 config.toml 의 theme 항목을 지정하는 것으로 테마를 변경 할 수 있다.\nHugo - Generate 휴고 명령어를 통해 html 파일을 generate 한다. 기본적으로 public 폴더에 데이터가 생성되므로, 해당 repo 를 submodule 로 github page 에 연결해두어도 괜찮다. 즉, 이런 느낌\n---- hugo contents repo (git@github.com:nolleh/nolleh.github.io-hugo) | |----- content | |---- my-posts... | |----- @public (git@github.com:nolleh/nolleh.github.io) 실행은 다음과 같은 휴고 명령어를 사용한다.\n@DEPRECATED\n$ sudo hugo server --baseUrl=https://nolleh.github.io --destination=public/ --port=80 --appendPort=false edited. 휴고 특정버전(?)부터, 다음과 같이 generate 하도록 변경되었다.\n-D 옵션은 draft (작성중) 파일의 포함 여부.\n$ hugo -D Deploy Generate 할때, destination 을 public 으로 지정하였으므로 public 디렉토리에 생성된다. 이 폴더 전체를 다시 github repo 를 생성해서 올려두자.\nthis/is/my/github/repo/public$ git init this/is/my/github/repo/public$ git add -A this/is/my/github/repo/public$ git commit -m \u0026#34;my awesome site\u0026#34; this/is/my/github/repo/public$ git push ... 끝!\n","permalink":"https://nolleh.github.io/env/how-to-make-git-page/","summary":"GitHub-Page 이런게 있다더라 ~ 라고 주변으로부터 처음 들은건 1~2년전이었던것 같은데\n갑자기 꽂혀서 git page 를 만들었다. (!!)\ngithub 에서는 1계정당 1 호스트를 제공하는 것 같고\n\u0026lt;ID\u0026gt;.github.io 뭐 이런식? github 의 제공 영역은 repo 에 존재하는 index.html 을 repo 에 지정된 1 도메인과\n연결해주는 정도인 것 같다.\nRepository git 을 사용해 본 적이 있다면 간단하다.\n그렇다면 다음 절로 넘어가고, 그렇지 않다면, 다음을 따라하자.\ngithub 가입 이 항목에 있어 더 이상의 자세한 설명은 생략한다.","title":"How To Make Git Page"},{"content":"Let\u0026rsquo;s 사족 처음 회사에 입사 했을 때 자리에는 Mac PC 만이 덩그러니 있었고, Mac 을 사용해본적 없던 꼬꼬마는 자연스럽게 윈도우 CD 를 인사팀에서 받아와서 깔고 있었드랬다.\n\u0026ldquo;기껏 좋은 컴퓨터 줬더니 넌 뭘하고 있는거니?\u0026rdquo;\n라는 선배의 말을 듣고 그제야 맥에서도 안드로이드 개발이 되는거구나.. (이때는 현업 안드로이드 개발자였다.)\n하곤 윈도우 설치페이지를 취소하고 다시 맥 OS 를 부팅했었지.\n이때가, Mac OS 와의 첫 만남이었드랬다.\nBrew 뭐 전혀 관계 없는 얘기로 포스트를 열었지만.\n어쨌거나 그때부터 Mac 을 수년간 사용하면서 - 그때 쓰던 회사 Mac 은 여전히 내 사무실 책상의 한켠을 차지하고 있다 -\nMac 을 비롯한 Linux 계통에서 Windows 를 압도하는 장점을 들자면,\n개발자를 위한 환경 설정이 간편하다\n가 되겠다.\nMac 에서는 그 역할을 충실히 하는 요소 중에 하나가 \u0026ldquo;HomeBrew\u0026rdquo; 라 하겠고.\n[HomeBrew] (http://docs.brew.sh/)\nBrew 설치 다음 라인을 터미널에서 실행하자. brew 설치 자체도 이렇게 간편하다니.. Linux 계통은 보통 이렇게 one line 으로 다 해결이 된다.\nmkdir homebrew \u0026amp;\u0026amp; curl -L https://github.com/Homebrew/brew/tarball/master | tar xz --strip 1 -C homebrew Brew 를 통해 설치하기 Formula 라고 지칭하고 있는게 맞는지는 잘 모르겠지만.\nbrew 를 통해 프로그램/binary 를 설치할 경우 다음과 같이 실행\n최초 설치 $ Brew install ${Formula} 업데이트 $ Brew upgrade ${Formula} Brew Install 이 구 버전만 다운로드 받을 때 이건.. 맥을 사용한 지금까지 잘 모르고 있었던 건데,\nBrew 자체를 업데이트해서 formular 를 갱신할 필요가 있나보다.\n다음을 통한다.\n$ Brew update 업데이트시 다음 에러 노출시 $ Error: /usr/local must be writable! 다음 실행\nsudo chown -R $(whoami) /usr/local ","permalink":"https://nolleh.github.io/env/brew-update/","summary":"Let\u0026rsquo;s 사족 처음 회사에 입사 했을 때 자리에는 Mac PC 만이 덩그러니 있었고, Mac 을 사용해본적 없던 꼬꼬마는 자연스럽게 윈도우 CD 를 인사팀에서 받아와서 깔고 있었드랬다.\n\u0026ldquo;기껏 좋은 컴퓨터 줬더니 넌 뭘하고 있는거니?\u0026rdquo;\n라는 선배의 말을 듣고 그제야 맥에서도 안드로이드 개발이 되는거구나.. (이때는 현업 안드로이드 개발자였다.)\n하곤 윈도우 설치페이지를 취소하고 다시 맥 OS 를 부팅했었지.\n이때가, Mac OS 와의 첫 만남이었드랬다.\nBrew 뭐 전혀 관계 없는 얘기로 포스트를 열었지만.\n어쨌거나 그때부터 Mac 을 수년간 사용하면서 - 그때 쓰던 회사 Mac 은 여전히 내 사무실 책상의 한켠을 차지하고 있다 -","title":"Brew Install 이 구버전만 설치할 때"},{"content":"마크다운으로 포스팅하는 Git 페이지를 생성하였으니, 자주 사용되는 대표 문법 정리\n마크다운 문법\nHeading \u0026lsquo;#\u0026rsquo; 으로 처리하며, 단계별로 더 많은 \u0026lsquo;#\u0026rsquo; 을 사용한다.\n# Title ## Heading 1 ### Heading 2 결과\nTitle Heading 1 Heading 2 Listing Asterisk (*) 를 사용하여 순서 없는 목록을, 숫자를 사용하여 순서 있는 목록을 나타낸다.\n순서 없는 경우 이거닷 이거 중요해! 순서가 있는 경우 첫번째 순서 두번째~ 셋!! Fonts **Bold** _Italic_ ~~CANCEL_LINE~~ Bold Italic CANCEL_LINE\nSRC ![Alt](경로 \u0026#34;Optional Tooltip MSG\u0026#34;) TABLE | Day | Meal | Price | | --------|---------|-------| | Monday | pasta | $6 | | Tuesday | chicken | $8 | Day Meal Price Monday pasta $6 Tuesday chicken $8 ","permalink":"https://nolleh.github.io/env/mark-down-syntax/","summary":"마크다운으로 포스팅하는 Git 페이지를 생성하였으니, 자주 사용되는 대표 문법 정리\n마크다운 문법\nHeading \u0026lsquo;#\u0026rsquo; 으로 처리하며, 단계별로 더 많은 \u0026lsquo;#\u0026rsquo; 을 사용한다.\n# Title ## Heading 1 ### Heading 2 결과\nTitle Heading 1 Heading 2 Listing Asterisk (*) 를 사용하여 순서 없는 목록을, 숫자를 사용하여 순서 있는 목록을 나타낸다.\n순서 없는 경우 이거닷 이거 중요해! 순서가 있는 경우 첫번째 순서 두번째~ 셋!! Fonts **Bold** _Italic_ ~~CANCEL_LINE~~ Bold Italic CANCEL_LINE","title":"markDown 문법"},{"content":"파라미터가 없다면 DelegateToPointer 로 마샬링해서 전달하면되는데,\n이러면 파라미터를 마샬링할 기회가 주어지지 않는다는게 문제다.\n좀 구글링을 해봤는데,\n이런 포스트가 있었다.\n스택오버플로-파라미터와 함께 unmanaged 콜백으로 변환하기\n채택된 답변을 살펴보면 클래스 구조는 대략 다음과 같다.\n클래스 구조 NativeCallbackHandler - msclr::gcroot\u0026lt;OutputManaged^\u0026gt; m_owner (OutputLogManaged) 를 멤버로 보유. OutputLogManaged - native OutputLog* (m_nativeOutputLog) / 1의 Holder 를 보유 (m_nativeHandler)] / 그리고 managed 콜백을 보유 OutputLog - Native Callback 과 void* UserData 를 멤버로 보유. 이해하는데 주요한 클래스는 위 내용 정도인 듯.\nMain 함수에서는 managed 로거와 native 에 적당한 콜백을 등록해 두고(OnError/GetNative()), Test 함수를 통해 콜백을 호출한다.\nOutputLogManaged 에는 생성시에 1의 NativeCallbackHandler 가 생성되며 여기에 정의된 native callback 을 OutputLog 의 Callback 멤버변수에 세팅한다. 동시에 NativeCallbackHandler 를 this 로 해서 함께 UserData 라는 객체로 OutputLog 의 멤버로 등록을 한 상태이다.\n(다시 말해 OutputLog 의 UserData 에는 1의 인스턴스가, 같은 객체의 멤버 변수인 NativeCallback 타입에는 그 인스턴스의 함수가 등록이 되어있다.)\n1의 콜백을 지닌 3 의 객체의 함수를 등록해두었고, 이 함수에서 1의 콜백을 호출하고 있으므로 1의 콜백이 호출이 되는데 (등록해두었던 umanaged 콜백이 호출되는 단순한 전개라 하겠다.)\n이때 OutputLog(3) 의 객체의 멤버함수(최초로 호출되는 콜백)에서 멤버변수로 보유한 NativeCallbackHandler(1) 객체를 1의 콜백의 파라미터로 전달, 콜백 등록 당시의 NativeCallbackHandler(1) 의 인스턴스를 얻어온다 (물론, 콜백을 여러개 등록할 수 있으므로. 각 인스턴스를 별도로 두는 것이 자연스럽다.)\n이 인스턴스의 멤버인 m_owner 를 통해 OutputLogManaged 의 managed 콜백을 호출한다.\n내용을 말로 설명하려고하니 불필요하게 복잡해진 느낌인데,\n정리하면 다음과 같다.\nSummary unmanged 에서 Managed 의 객체를 들고 있다가 unmanaged 의 콜백이 호출될때 마샬링하여 Managed 의 콜백을 호출한다.\nC++/CLR 을 처음 접하고 필요에 따라 구글링으로 작업을 하다보니 managed 와 unmanged 사이에서 서로 멤버로 두려고 하면 컴파일 에러가 나길래 안되는 거구나..했는데.. 이런 기능이 있었나보다\u0026hellip;\nmsclr::gcroot\u0026lt;...\u0026gt; gcroot 는 unmanaged 에서 managed 를 참조하는 방법이며, interop 에서는 레퍼런스 카운트를 하나 증가시킨다.\n참고 - gcroot 의 역할\n약간 허무하군.. (그래 안되면 어떻게 쓰겠냐만서도.. )\n참고 - MSDN / How to: Declare Handles in Native Types\n","permalink":"https://nolleh.github.io/etc/managed_cb_to_unmanaged/","summary":"파라미터가 없다면 DelegateToPointer 로 마샬링해서 전달하면되는데,\n이러면 파라미터를 마샬링할 기회가 주어지지 않는다는게 문제다.\n좀 구글링을 해봤는데,\n이런 포스트가 있었다.\n스택오버플로-파라미터와 함께 unmanaged 콜백으로 변환하기\n채택된 답변을 살펴보면 클래스 구조는 대략 다음과 같다.\n클래스 구조 NativeCallbackHandler - msclr::gcroot\u0026lt;OutputManaged^\u0026gt; m_owner (OutputLogManaged) 를 멤버로 보유. OutputLogManaged - native OutputLog* (m_nativeOutputLog) / 1의 Holder 를 보유 (m_nativeHandler)] / 그리고 managed 콜백을 보유 OutputLog - Native Callback 과 void* UserData 를 멤버로 보유. 이해하는데 주요한 클래스는 위 내용 정도인 듯.","title":"C++ CLI 에서 managed 콜백을 unmanaged 로 전달하기"}]