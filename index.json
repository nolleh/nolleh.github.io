[{"content":"자주 사용하는 서브 모듈 명령어.\nadd submodule git submodule add {remote-repo} update git submodule init\n git 에서 서브모듈을 관리하기위한 설정파일, gitmodules 를 설정한다.  git submodule update  remote 저장소로부터 업데이트 내용을 가져와서 적용한다.  git submodule update --init remove submodule git submodule deinit -f {path} rm -rf .git/modules/{path} git rm -f {path} ","permalink":"https://nolleh.github.io/git/sub-module/","summary":"자주 사용하는 서브 모듈 명령어.\nadd submodule git submodule add {remote-repo} update git submodule init\n git 에서 서브모듈을 관리하기위한 설정파일, gitmodules 를 설정한다.  git submodule update  remote 저장소로부터 업데이트 내용을 가져와서 적용한다.  git submodule update --init remove submodule git submodule deinit -f {path} rm -rf .git/modules/{path} git rm -f {path} ","title":"서브 모듈 추가하기"},{"content":"1.12. Active-Passive Messaging Clusters 1.12.1 Overview HA 모듈은 active-passive, hot-standby 메시징 클러스터들을 장애에 tolerent 하도록 제공한다.\nactive-passive 클러스터는 하나의 브로커만 존재하며, 이를 프라이머리라고 부르며, 액티브 하고 클라이언트를 serving 한다. 다른 브로커들은 백업을 위해 존재한다. 프라이머리의 변경은 모든 백업들에 반영되므로, 백업들은 최신상태이거나 \u0026lsquo;hot\u0026rsquo; 상태이다. 백업 브로커들은 클라이언트의 연결을 거부하며, 클라이언트들은 프라이머리에 연결해야한다.\n만약 프라이머리가 실패하는 경우, 백업중의 하나가 새로운 프라이머리가 되기위해 자리를 차지한다. 클라이언트는 새로운 프라이머리에 자동으로 연결한다.\n만약 복수개의 백업이 있다면, 다른 백업들은 새로운 프라이머리의 백업이 되도록 장애처리를 진행한다.\n이 접근은 외부의 클러스터 리소스 매니저가 장애를 탐지하고, 새로운 프라이머리를 선택하며, 네트워크 파티션을 핸들링하는 것을 믿는것이다. rgmanager 는 이를 기본적으로 지원하며, 다른 것들은 미래에 제공될 것이다.\n1.12.1.1. Avoiding message loss 메시지가 모든 백업 브로커들에 대해 복제되는 것을 대기하거나 프라이머리 큐에서 consumed 되고 클라이언트로 응답(acknowledgement) 을 줌으로써 메시지의 유실을 회피한다.\n이것은 응답이 돌아온 모든 메시지들은 \u0026lsquo;safe\u0026rsquo; 하다는 것을 보장한다. : consumed 되거나, 다른 모든 브로커로 복제 되었음을. 복제 되기전에 consumed 된 메시지들은 복제가 될 필요가 없다. 액티브한 컨슈머가 있는 큐에 복제하는 부담을 줄여준다.\nprimary 에 의해 응답을 받기 전까지 버퍼에 미응답상태의 메시지를 보관해야한다. 만약 프라이머리가 실패하면, 클라이언트는 새로운 프라이머리에 연결하고 다시 메시지를 전송하는 장애처리를 수행해야한다.\n만약 프라이머리에 크래쉬가 발생하는 경우, 모든 응답을 받은 메시지들은 백업에 의해 가용하고, 이중에 새로운 프라이머리가 있을 것이다. 그래서 유실은 발생하지 않는다.\n하나 알아두어야 할것은, 메시지가 중복되서 전송될 수 있다는 것이다. 장애 발생시에 새로운 프라이머리에 의해 클라이언트로 다시 메시지를 전송하는 것이 가능하다. 이를 감지하고 중복을 제거하는 것은 어플리케이션의 몫이다.\n프라이머리가 새로 승격하는경우, 처음에 \u0026ldquo;recovering\u0026rdquo; 모드에 진입한다. 이 모드에서는, 모든 백업들이 프라이머리에 성공적으로 연결할때까지 메시지들에 대한 응답들을 지연한다.\n백업브로커에 모든 메시지가 복제될 필요는 없다. 만약 메시지가 consumed 되고 응답을 받은경우 복제될 필요는 없다.\nHA Broker State\n Stand-alone  cluster 의 일부가 아니다   Joining  새로 시작된 브로커이고, 어떤 프라이머리에도 아직 연결되지 않았다.   Catch-up  프라이머리에 연결되었고, 상태를 다운로드 받는 중이다 (queues, messages.. )   Ready  catch-up 을 완료했고 프라이머리가 될 준비가 되었다.   Recovering  새로 승격한 프라이머리이며, 백업들이 연결하여 catchup 하도록 기다리고 있다. 클라이언트들은 연결할 수 있지만 프라이머리가 액티브 상태가 될때까지 엔진을 멈춘다.   Active  모든 백업들이 연결되고 캐치업된 프라이머리 브로커    1.12.1.2. Limitations 현재 구현상 알려진 제한이 있다. 새 버전에서는 수정될 것.\n","permalink":"https://nolleh.github.io/qpid/1.12.active-passive-messaging-clusters/","summary":"1.12. Active-Passive Messaging Clusters 1.12.1 Overview HA 모듈은 active-passive, hot-standby 메시징 클러스터들을 장애에 tolerent 하도록 제공한다.\nactive-passive 클러스터는 하나의 브로커만 존재하며, 이를 프라이머리라고 부르며, 액티브 하고 클라이언트를 serving 한다. 다른 브로커들은 백업을 위해 존재한다. 프라이머리의 변경은 모든 백업들에 반영되므로, 백업들은 최신상태이거나 \u0026lsquo;hot\u0026rsquo; 상태이다. 백업 브로커들은 클라이언트의 연결을 거부하며, 클라이언트들은 프라이머리에 연결해야한다.\n만약 프라이머리가 실패하는 경우, 백업중의 하나가 새로운 프라이머리가 되기위해 자리를 차지한다. 클라이언트는 새로운 프라이머리에 자동으로 연결한다.\n만약 복수개의 백업이 있다면, 다른 백업들은 새로운 프라이머리의 백업이 되도록 장애처리를 진행한다.","title":"Active Passive Messaging Clusters"},{"content":"1.4 Broker Federation 메시지 라우트를 정의하여 하나의 브로커에서 다른 브로커로 자동으로 전달하게 한다.\n일반적으로 일방향이며, 라우트는 durable 하고 tansient 한다.\n연결이 소실되면 메시지는 누적되다가 재연결이 되면 다시 전송한다.\n라우팅에 사용되는 룰은 서버가 변경됨에 따라 동적으로 변경할 수 있으며, 변경의 책임은 다른 변경조건에 맞게 반영된다,.\n1.4.1 Message Routes pull / push 방식이 있음.\npull 은 dest 에서.\npush 는 src 에서 설정함\n queue \u0026lt;-\u0026gt; exchage exchange \u0026lt;-\u0026gt; exchange  excg \u0026lt;-\u0026gt; excg 는 다음과 같은 라우트를 가질 수 있다.\n1.4.1.1 Queue Routes 모든 메시지를 src 에서 dest 로.\n1.4.1.2 Exchange Routes 바인딩키에 따라 라우트함\n실제로는 내부적으로 큐가 (auto-delete, exclusive) 만들어지고, 이를 통해 연결하는 것.\n1.4.1.3 Dynamic Exchange Routes 클라이언트가 바인딩을 맺고, 이 exchange 만이 아니라 dynamic exchange route 를 통해 생성된 다른 exchange 도 수신한다. 바인딩 변경시, 이 exhcange 와 관련한 다른 exchange routes 또한 변경한다.\n source 에 연결 된 모든 dest exchange 에 대해 적용되는데, 하나의 메시지라도 매치가 되면 dest 에 라우트되도록한다. dest 에서 바인딩들이 추가되거나 삭제되는경우, 이 변화는 DER 에 적용이 된다.  dest 브로커가 바인딩을 주어진 바인딩키를 만들경우 라우트에 반영이되고 바인딩키를 제거할 경우 라우트는 더이상 메시지를 브로커들에게 전달하는 오버헤드를 갖지 않는다.   만약 두 excg 가 der 을 서로에 대해 갖는경우, 각각의 excg 에 대한 모든 바인딩은 der 에 반영된다. DER 에서, source 와 destination exchages 들은 같은 excage 타입을 가지고 있어야하고, 같은 이름을 가져야 한다.  내부적으로 dynamic exchage routes 는 exchage 라우트와 동일하게 구현되어 있는데, 다른점은 DEST Excg 에 바인딩이 있는 경우 DER 을 구현하는데 사용한 바인딩들이 수정됐다는것. (? except that the bindings used to implement dynamic exchange routes are modified if the bindings in the destination exchange change.)\nDER 은 항상 pull route 형식이다.\n1.4.2 Federation Topolpogies 보통 이 네트워크는 트리구조, 스타구조, 선형, 양방향 링크, 로 구성된다. 링 형태도 가능하지만, 이때는 단방향링크들만 사용하여야 한다.\n메시지를 빨리 전달 받기 위해서는 브로커 사이 홉을 줄이는 것이 중요. 그래서 대부분의 경우 트리나 스타 토폴로지가 최고다.\nA, B 가 있다고 할 때 서로를 연결하는 경로는 하나만이 있어야 할 것.\n만약 하나 이상의 경로가 있으면 중복된 메시지 전송을 야기하고 네트워크의 홍수를 일으킬 것.\n1.4.3 Federation among High Availablity Message Clusters fedration 은 일반적으로 High Availability Message Clusters 와 사용이 되는데, 클러스터들이 각각의 LAN 에 대해 고 안정성을 얻게끔한다.\n메시지 상태가 클러스터에서 복제 되기 때문에,\n같은 클러스터의 다른 브로커 사이에서 메시지 라우트를 정의하는 작은 개념을 만들어 준다.\n두 클러스터 사이에서 메시지를 생성하기 위해, 첫번째 클러스터에서 다른 클러스터의 브로커로 라우터를 만들어주면된다.\n1.4.4 The qpid-route Utility $ qpid-route [OPTIONS] dynamic add \u0026lt;dest-broker\u0026gt; \u0026lt;src-broker\u0026gt; \u0026lt;exchange\u0026gt; $ qpid-route [OPTIONS] dynamic del \u0026lt;dest-broker\u0026gt; \u0026lt;src-broker\u0026gt; \u0026lt;exchange\u0026gt; $ qpid-route [OPTIONS] route add \u0026lt;dest-broker\u0026gt; \u0026lt;src-broker\u0026gt; \u0026lt;exchange\u0026gt; \u0026lt;routing-key\u0026gt; $ qpid-route [OPTIONS] route del \u0026lt;dest-broker\u0026gt; \u0026lt;src-broker\u0026gt; \u0026lt;exchange\u0026gt; \u0026lt;routing-key\u0026gt; $ qpid-route [OPTIONS] queue add \u0026lt;dest-broker\u0026gt; \u0026lt;src-broker\u0026gt; \u0026lt;dest-exchange\u0026gt; \u0026lt;src-queue\u0026gt; $ qpid-route [OPTIONS] queue del \u0026lt;dest-broker\u0026gt; \u0026lt;src-broker\u0026gt; \u0026lt;dest-exchange\u0026gt; \u0026lt;src-queue\u0026gt; $ qpid-route [OPTIONS] list [\u0026lt;broker\u0026gt;] $ qpid-route [OPTIONS] flush [\u0026lt;broker\u0026gt;] $ qpid-route [OPTIONS] map [\u0026lt;broker\u0026gt;] $ qpid-route [OPTIONS] list connections [\u0026lt;broker\u0026gt;] The syntax for broker, dest-broker, and src-broker is as follows:\n [username/password@] hostname | ip-address [:\u0026lt;port\u0026gt;]  The following are all valid examples of the above syntax: localhost, 10.1.1.7:10000, broker-host:10000, guest/guest@localhost.\nTable 1.9. qpid-route options\n         -v Verbose output.   -q Quiet output, will not print duplicate warnings.   -d Make the route durable.   \u0026ndash;timeout N Maximum time to wait when qpid-route connects to a broker, in seconds. Default is 10 seconds.   \u0026ndash;ack N Acknowledge transfers of routed messages in batches of N. Default is 0 (no acknowledgements). Setting to 1 or greater enables acknowledgements; when using acknowledgements, values of N greater than 1 can significnantly improve performance, especially if there is significant network latency between the two brokers.   -s [ \u0026ndash;src-local ] Configure the route in the source broker (create a push route).   -t \u0026lt;transport\u0026gt; [ --transport \u0026lt;transport\u0026gt;] Transport protocol to be used for the route. _ tcp (default) _ ssl * rdma    1.4.4.1. Creating and Deleting Queue Routes $ qpid-route [OPTIONS] queue add \u0026lt;dest-broker\u0026gt; \u0026lt;src-broker\u0026gt; \u0026lt;dest-exchange\u0026gt; \u0026lt;src-queue\u0026gt; $ qpid-route [OPTIONS] queue del \u0026lt;dest-broker\u0026gt; \u0026lt;src-broker\u0026gt; \u0026lt;dest-exchange\u0026gt; \u0026lt;src-queue\u0026gt; 1.4.4.2. Exchange Routes ","permalink":"https://nolleh.github.io/qpid/1.4.broker-federation/","summary":"1.4 Broker Federation 메시지 라우트를 정의하여 하나의 브로커에서 다른 브로커로 자동으로 전달하게 한다.\n일반적으로 일방향이며, 라우트는 durable 하고 tansient 한다.\n연결이 소실되면 메시지는 누적되다가 재연결이 되면 다시 전송한다.\n라우팅에 사용되는 룰은 서버가 변경됨에 따라 동적으로 변경할 수 있으며, 변경의 책임은 다른 변경조건에 맞게 반영된다,.\n1.4.1 Message Routes pull / push 방식이 있음.\npull 은 dest 에서.\npush 는 src 에서 설정함\n queue \u0026lt;-\u0026gt; exchage exchange \u0026lt;-\u0026gt; exchange  excg \u0026lt;-\u0026gt; excg 는 다음과 같은 라우트를 가질 수 있다.","title":"Broker Federation"},{"content":" time_wait 종료 시간 확인 : ndd -get /dev/tcp tcp_time_wait_interval time_wait 종료 시간 30초로 설정 : ndd -set /dev/tcp tcp_time_wait_interval 30000 fin_wait_2 타임 아웃 시간 확인 : ndd -get /dev/tcp tcp_fin_wait_2_timeout fin_wait_2 타임 아웃 시간 5분으로 설정 : ndd -set /dev/tcp tcp_fin_wait_2_timeout 300000  출처: https://hyeonstorage.tistory.com/287 [개발이 하고 싶어요]\n","permalink":"https://nolleh.github.io/cheatsheet/network/","summary":"time_wait 종료 시간 확인 : ndd -get /dev/tcp tcp_time_wait_interval time_wait 종료 시간 30초로 설정 : ndd -set /dev/tcp tcp_time_wait_interval 30000 fin_wait_2 타임 아웃 시간 확인 : ndd -get /dev/tcp tcp_fin_wait_2_timeout fin_wait_2 타임 아웃 시간 5분으로 설정 : ndd -set /dev/tcp tcp_fin_wait_2_timeout 300000  출처: https://hyeonstorage.tistory.com/287 [개발이 하고 싶어요]","title":"Network"},{"content":"Docker Cheat Sheet 1. docker conntianer 내부 소켓 상태 확인 \n$ docker inspect -f \u0026#39;{{.State.Pid}}\u0026#39; cb2939r52s22 5645 [ec2-user@ip-10-100-77-76 ~]$ sudo nsenter -t 5645 -n netstat Active Internet connections (w/o servers) Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 0 ip-172-17-0-2.ec2.:webcache ip-10-100-77-225.ec2.:45104 ESTABLISHED tcp 0 0 ip-172-17-0-2.ec2.:webcache ip-10-100-77-225.ec2.:14804 TIME_WAIT tcp 0 0 ip-172-17-0-2.ec2.:webcache ip-10-100-76-6:seclayer-tls TIME_WAIT tcp 0 0 ip-172-17-0-2.ec2.:webcache ip-10-100-76-65.ec:plethora TIME_WAIT tcp 0 0 ip-172-17-0-2.ec2.:webcache ip-10-100-77-225.ec2.:14830 TIME_WAIT tcp 0 0 ip-172-17-0-2.ec2.:webcache ip-10-100-76-65.ec2.i:23284 ESTABLISHED tcp 0 0 ip-172-17-0-2.ec2.:webcache ip-10-100-76-65.ec2.i:27948 ESTABLISHED tcp 0 0 ip-172-17-0-2.ec2.:webcache ip-10-100-77-225.ec2.:14848 TIME_WAIT tcp 0 0 ip-172-17-0-2.ec2.:webcache ip-10-100-77-225.ec2.:45544 ESTABLISHED Active UNIX domain sockets (w/o servers) Proto RefCnt Flags Type State I-Node Path docker container 의 ulimit 가 호스트를 따라가지 않을 수 있음.\n빠르게 open 하고 close 시, 사용하는 ORM 솔루션에 따라 기대하는 동작과 다를 수 있음.\nsmall idle connection.. -\u0026gt; cause high reconnect rate.\n","permalink":"https://nolleh.github.io/cheatsheet/docker/","summary":"Docker Cheat Sheet 1. docker conntianer 내부 소켓 상태 확인 \n$ docker inspect -f \u0026#39;{{.State.Pid}}\u0026#39; cb2939r52s22 5645 [ec2-user@ip-10-100-77-76 ~]$ sudo nsenter -t 5645 -n netstat Active Internet connections (w/o servers) Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 0 ip-172-17-0-2.ec2.:webcache ip-10-100-77-225.ec2.:45104 ESTABLISHED tcp 0 0 ip-172-17-0-2.ec2.:webcache ip-10-100-77-225.ec2.:14804 TIME_WAIT tcp 0 0 ip-172-17-0-2.ec2.:webcache ip-10-100-76-6:seclayer-tls TIME_WAIT tcp 0 0 ip-172-17-0-2.ec2.:webcache ip-10-100-76-65.ec:plethora TIME_WAIT tcp 0 0 ip-172-17-0-2.ec2.:webcache ip-10-100-77-225.ec2.:14830 TIME_WAIT tcp 0 0 ip-172-17-0-2.","title":"Docker"},{"content":"한개 이상의 노드들의 논리적인 그룹을 의미하며, 각각은 유저와, 가상 호스트, 큐, exchanges, bindings 을 공유한다.\nCluster Formation 다음 방법들로 구성 가능\n Declaratively by listing cluster nodes in config file Declaratively using DNS-based discovery Declaratively using AWS (EC2) instance discovery (via a plugin) Declaratively using Kubernetes discovery (via a plugin) Declaratively using Consul-based discovery (via a plugin) Declaratively using etcd-based discovery (via a plugin) Manually with rabbitmqctl  구성은 동적으로 변경 될수 있고, 모든 RabbitMQ 브로커는 하나의 노드로부터 시작해서 클러스터에 참여시키거나, 다시 개별의 브로커로 돌아갈 수 있다.\nNode Names (Identifiers) 클러스터 내에서 서로 구분할 수 있는 고유 값이어야함.\n환경 변수로 지정. RABBITMQ_NODENAME\nfully qulified domain names (FQDNs)를 사용하는 경우 RABBITMQ_USE_LONGNAME true 로 지정\nNodes in a Cluster 정상적으로 동작하기위해 모든 노드에 걸쳐 데이터와 상태가 복제 되어야 한다. 하나의 예외는 메시지 큐인데, 기본적으로 하나의 노드에서만 존재하지만 다른 노드들 사이에서 visible 하고 reachable 하다. 이마저도 복제하고 싶다면 HA 를 참고하라.\nNodes are Equal Peers 어떤 분산시스템들은 leader 와 follower 가 있지만 rabbitMQ 에서는 일반적으로 그렇지 않다. 모든 노드는 동등하다. 다만, 이주제는 queue mirroring 과 연관이 되면 미묘해진다.\nHOW CLI Tools Authenticate to Nodes (And Nodes to Each Other): the Erlang Cookie erlang cookie 라고 부르는 대칭키를 함께 보유하고 있어야한다.\n로컬키에 저장해둠.\n소유자에게 접근권한이 있어야함. (600 이나 유사 권한)\n파일이 없으면 생성하나, 이 방식은 모든 노드가 각자의 데이터를 생성하니, 개발단계에서 사용할 것.\n쿠키 생성은 클러스터 배포단계에서 완료되어야하며, 자동화와 오케스트레이션 툴을 이용하는 것을 추천한다.\nNode Counts and Quorum consensus 를 요구하는 플러그인들이 있으므로, 홀수개의 노드 추천.\nClustrering and Clients 모든 멤버가 정상적으로 동작할때 클라이언트는 어느노드나 붙어서 작업을 수행할 수 있다. 노드들은 연산을 큐 마스터 노드 (HA) 로 투명히 전달, 클라이언트로 돌려준다.\n실패한 경우 클라이언트는 다른 노드에 재연결하여 토폴로지를 복구하고, 다시 연산을 재개해야 한다. 이가 여의치 않은 경우 \u0026lsquo;미러링 되지 않은 큐가 실패한 노드에 있을 경우\u0026rsquo; 참고.\nClustering and Observability 클라이언트 연결과 채널, 큐들은 클러스터 노드들에 나뉘어져 있다.\n운영자들은 모든 클러스터 노드에 걸쳐 이를 관찰하고 모니터 할 필요가 있다.\nrabbitmq-diagnostics 와 rabbitmqctl 과 같은 CLI 툴의 경우 클러스터 단위의 리소스를 관찰하는 명령어들을 제공한다.\n어떤 커맨드들은 하나의 노드에 집중하기도 한다.0\n(e.g. rabbitmq-diagnostics environment and rabbitmq-diagnostics status)\nNode Failure Handling 각 개별의 노드의 장애에 대해서는 tolerate 하다.\n노드는 다른 클러스터 멤버 노드에 연결을 할 수 있는한, 원하면 실행되거나 중지될 수 있다.\n큐 미러링은 큐의 데이터가 복수의 클러스터 노드에 복제 될 수 있도록 한다.\n미러링 되지 않은 큐들도 클러스터에 사용될 수 있는데, 이런 큐들의 경우 노드 장애시 큐 durability 속성에 의해 동작이 정해진다.\nrabbitmq 클러스터링은 네트워크 파티션을 다루기 위한 (주로 일관성을 중시하는) 몇가지 모드가 있다.\nDisk and RAM Nodes 노드는 디스크 노드이거나 램 노드 일 수 있다. 램 노드들은 램에만 데이터베이스 테이블을 저장한다.\n여기에 메시지들은 포함하지 않는다.\n메시지는 색인, 큐 색인과 다른 노드 상태를 저장한다.\n대부분 디스크 노드를 사용하는 것을 원할 것이다. 램 노드는 큐, exchange, bind 가 많을때 성능 개선을 원하는 경우에 사용할 것이다. 램노드를 사용한다고 해서 메시지 비율이 개선 되진 않는다.\n램노드는 내부 데이터베이스테이블을 사용하기 때문에 peer 노드가 구동되는 경우 sync 해 줘야한다. 이는 하나의 디스크 노드는 필요하다는 것.\n","permalink":"https://nolleh.github.io/rabbitmq/clustering-guide/","summary":"한개 이상의 노드들의 논리적인 그룹을 의미하며, 각각은 유저와, 가상 호스트, 큐, exchanges, bindings 을 공유한다.\nCluster Formation 다음 방법들로 구성 가능\n Declaratively by listing cluster nodes in config file Declaratively using DNS-based discovery Declaratively using AWS (EC2) instance discovery (via a plugin) Declaratively using Kubernetes discovery (via a plugin) Declaratively using Consul-based discovery (via a plugin) Declaratively using etcd-based discovery (via a plugin) Manually with rabbitmqctl  구성은 동적으로 변경 될수 있고, 모든 RabbitMQ 브로커는 하나의 노드로부터 시작해서 클러스터에 참여시키거나, 다시 개별의 브로커로 돌아갈 수 있다.","title":"Clustering Guide"},{"content":"","permalink":"https://nolleh.github.io/crypto/ssl/","summary":"","title":"SSL"},{"content":"ECDSA ref. https://m.blog.naver.com/aepkoreanet/221178375642\nec (타원곡선) 을 이용한 기술들의 집합 - ECC,\n이중에 디지털서명 관련 기술이 ECDSA\nTerms   유한체\n집합에 속해있는 원소의 수가 한정되어 있고 덧셈, 곱셈에 대해 닫혀있는 집합  유한체 F 표기법\n원소의 개수가 p 인 유한체 F 는 Fp 혹은 GF(p) 로 표기 유한체 상에 정의된 타원 곡선\nE(Fp) 암호학에서 사용되는 유한체      - Prime Field 원소의 개수가 소수  ECC 사용시 타원 곡선을 정의하는 domain parameter 를 정의해야함. (p, a, b, G, n, h) 를 정의해야하는건데, 여러 표준단체에서 Field Size 에 맞는 타원곡선에 대한 파라미터 발표.\n p : Modulo Prime Number a : 타원곡선 방정식에서 사용되는 계수 b : 타원곡선 방정식에서 사용되는 계수 Base point 또는 Generator Point, G 는 E(Fp) 에 속해있는 point n : the order of point G (G 를 n번 더하면 무한원점이 되는값 : nG = ∞) H : cofactor  타원 곡선이란, 타원 곡선 방정식을 만족하는 집합을 곡선 그래프로 표시한 것\ny^2 = x^3 + ax + b\nsecp256k1 곡선의 경우 a = 0, b = 7 을 사용\nECC 의 privateKey 와 publicKey   Private Key d : P 보다 적은 소수 (Prime) 로, 난수 생성기로 생성 Public Key Q : Q(x, y) = d x G(x0, y0)   ECDSA 와 secp256k1 ECDSA 의 파라메터로 secp256k1 curve 를 사용 secp256k1\nsec - standard for Efficient Cryptography\np - parameter p over Fp\n256 - field size p 의 bit 수\nk - koblitz curve 변형\n1 - sequence number\nDomain Parameter T = (p,a,b,G,n,h) p : FFFFFFFF FFFFFFFF FFFFFFFF FFFFFFFF FFFFFFFF FFFFFFFF FFFFFFFF FFFFFC2F a : 00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000 b : 00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000007 G : 02 79BE667E F9DCBBAC 55A06295 CE870B07 029BFCDB 2DCE28D9 59F2815B 16F81798 또는 G : 04 79BE667E F9DCBBAC 55A06295 CE870B07 029BFCDB 2DCE28D9 59F2815B 16F81798 483ADA77 26A3C465 5DA4FBFC 0E1108A8 FD17B448 A6855419 9C47D08F FB10D4B8 N : FFFFFFFF FFFFFFFF FFFFFFFF FFFFFFFE BAAEDCE6 AF48A03B BFD25E8C D0364141 h : 01 서명은 어떻게 이루어지는가 ? https://ko.wikipedia.org/wiki/%ED%83%80%EC%9B%90%EA%B3%A1%EC%84%A0_DSA\ndomain parameter 로 (CURVE, g, n) 을 사용한다.\n Curve : 타원곡선의 체 (field) 와 여기 사용된 수식. g : 타원 곡선의 기준점 (base point). 해당 타원곡선의 생성원(generator) 이다. n : g 의 차수이다. n X g = 0 이며, 반드시 소수여야한다. 보통 충분히 큰 소수를 사용한다.  privateKey, d 생성. - RNG 로 생성된 무작위로 선택된 1~ n-1 사이의 정수\npublicKey, Q 생성 - Q = dg 를 만족하는 정수. (g 를 d 번 더한 값)\n서명 프로세스\n필요한 것: E(Fp), d, Q, m\n1. e = H(m). 메시지를 해쉬하고 이를 e 라고 한다. 2. z = Ln(e) e 의 binary 값에서 왼쪽으로부터 n 번째 까지 잘라낸 값을 z 라고 한다. (left most n\u0026#39;th bit) 3. 암호학적으로 안전한 난수 k 를 [1, n-1] 사이에서 무작위로 선택한다. 4. 곡선 위의 점 (x1, y1) = k * g 를 계산한다. - 타원곡선에서의 덧셈은, 결국 다시 점이 된다. - 위 k * g 는 g 를 k 번 더하는 것을 의미하고, 결국 점이 된다. 5. r = x1 (mod n) 을 계산 한다. r 이 0 인 경우, k 를 다시 선택한다. 6. s = k^(-1)(z + rd) (mod n) 을 계산. s = 0 이면 3 으로 되돌아가 다른 k 를 선택, 순서대로 진행한다. 완성된 서명은 (r, s) 이다. 검증 프로세스\n필요한 것: E(Fp), (r,s), m\n- 곡선위의 점 인증 1. Q =/= O (identity element) 2. Q 가 곡선 위의 점인지 3. n x Q = O 인지 확인 - 서명 유효성 인증 1. r,s 가 1부터 n-1 사이의 정수인지 확인. 2. e = H(m) 을 계산. 3. z 계산 4. w = s^(-1)(mod n) 계산, u1 = zw, u2 = rw (mod n) 계산 5. shamir\u0026#39;s trick 을 사용해서 (x1, y1) = u1 x g + u2 x Q 를 계산. (x1, y1) = O 이면 무효 6. r = x1 (mod n) 일때만 유효. 즉, 서명 프로세스는 타원 곡선에서 새로운 k 와 (x1, y1) 을 구한 후\nECDSA 시그니쳐에서 어떻게 public key 를 복원할 수 있는가 ? stack exchange link\nECDSA signature (r,s)\n사실 곡선과 사용된 해쉬 함수, 서명된 메시지 원본을 알고 있더라도 signature 로부터 public key 를 recover 하는 것은 불가능하다.\n그러나, signature 와 원본 메시지, 곡선에 대한 정보로 두개의 public key 를 생성하는게 가능하다. (이 중에 private key 가 사용된 public key 가 있을 것)\n동작 원리는 다음과 같다.\n R 과 R\u0026rsquo; x 좌표로 r 값을 갖는 좌표를 찾는다. r^-1 을 연산하는데, 이는 시그니쳐의 r 의 곱셈 역원이다. (mod n) z 메시지 해쉬의 하위 n bit 인 z 를 연산한다.  public key 는 r^(−1)(sR−zG) and r^(−1)(sR′−zG) 가 된다.\n","permalink":"https://nolleh.github.io/crypto/ecdsa/","summary":"ECDSA ref. https://m.blog.naver.com/aepkoreanet/221178375642\nec (타원곡선) 을 이용한 기술들의 집합 - ECC,\n이중에 디지털서명 관련 기술이 ECDSA\nTerms   유한체\n집합에 속해있는 원소의 수가 한정되어 있고 덧셈, 곱셈에 대해 닫혀있는 집합  유한체 F 표기법\n원소의 개수가 p 인 유한체 F 는 Fp 혹은 GF(p) 로 표기 유한체 상에 정의된 타원 곡선\nE(Fp) 암호학에서 사용되는 유한체      - Prime Field 원소의 개수가 소수  ECC 사용시 타원 곡선을 정의하는 domain parameter 를 정의해야함.","title":"ECDSA"},{"content":"Best Practices for Using Cloud Storage  버킷에 변화가 있을때 반응하게 할 수 있다. https://cloud.google.com/storage/docs/pubsub-notifications\nDemo  coldline 은 일년에 한번 접근하는것과 같은 문제발생시 복구하는 용도로 사용하면 좋다..\nhttps://cloud.google.com/storage/docs/managing-lifecycles\nDemo2 - Cors  cors - https://developer.mozilla.org/en-US/docs/Web/HTTP/CORS cross-origin-resource sharing\ninstance 만들고 / apache 깔고 / cors 설정 여는 데모..\nBest Practices for cloud Storage  request rate 가 초당 1000 쓰기 요청 이나 5000 읽기 요청을 넘어가면 ..\n 이 기준 요청량내에서 요청을 시작해서 20 분마다 요청을 두배로 해라.  ","permalink":"https://nolleh.github.io/coursera/gcp/6.datastorage/","summary":"Best Practices for Using Cloud Storage  버킷에 변화가 있을때 반응하게 할 수 있다. https://cloud.google.com/storage/docs/pubsub-notifications\nDemo  coldline 은 일년에 한번 접근하는것과 같은 문제발생시 복구하는 용도로 사용하면 좋다..\nhttps://cloud.google.com/storage/docs/managing-lifecycles\nDemo2 - Cors  cors - https://developer.mozilla.org/en-US/docs/Web/HTTP/CORS cross-origin-resource sharing\ninstance 만들고 / apache 깔고 / cors 설정 여는 데모..\nBest Practices for cloud Storage  request rate 가 초당 1000 쓰기 요청 이나 5000 읽기 요청을 넘어가면 ..\n 이 기준 요청량내에서 요청을 시작해서 20 분마다 요청을 두배로 해라.","title":"6. DataStorage"},{"content":"Cloud Datastore Concepts and Indexes  Cloud Data Store concepts  데이터 오브젝트는 엔터티라고 불림 엔터티들은 하나이상의 프로퍼티로 구성됨 프로퍼티들은 하나이상의 값(values) 를 가질수 있음 각각의 엔터티는 구분되는 하나의 키를 가지고 있는데, 다음으로 구성 된다.  네임스페이스 엔터티 Kind 식별자 (스트링 or 숫자) 부모 ID   하나 이상의 엔터티에 대한 동작은 트랜잭션으로 불린다.  Datastore has two types of indexes    Built-in indexes Composite indexes     각각의 엔터티 Kind의 각각의 프로퍼티에 대해 자동으로 정의 인덱싱된 엔터티에 대해 다중의 프로퍼티 값을 인덱스함   간단한 쿼리에 적합 컴플렉스 쿼리에 적합    인덱스 설정파일에 정의       concept cloud datastore relational database     오브젝트 카테고리 Kind Table   한개 오브젝트 entity row   하나의 오브젝트를 위한 개별 데이터 프로퍼티 field   유니크 ID Key PrimaryKey    Design Considerations \u0026amp; Sharding  Design Your application for scale  엔터티 그룹에 대한 최대 쓰기율은 1/초 사전적으로 가까운 키에 대한 읽기와 쓰기를 너무 자주하지 말것. 구글의 noSQL 데이터베이스 Bigtable 을 이용해서 구현되어있는데 확장할때 로우들을 별도 테이블로 샤딩하는데 이 로우들이 키에 대해 사전적으로 정렬되어있기 때문. 점진적으로 ramp up traffic 을 새로운 클라우드 데이터 스토어에.. 빅테이블이 테이블을 분리하기에 충분할 시간을 주도록.. 클라우드 데이터스토어의 엔터티를 적은 범위의 키로 삭제하는 동작을 피해라 컴팩션(삭제된 엔트리를 제거하고 데이터를 재구성하여 읽기와 쓰기가 더 효율적으로 동작하도록 주기적으로 테이블을 다시쓰는 작업) 타임스탬프가 비슷해서 함께 있을 엔터티들을 많이 삭제하면, 이에 대한 쿼리가 컴팩션이 완료되기 전까지 늦을 수 있다. 핫 클라우드 데이터 스토어 키들에 대해 :  use sharding, 쓰기가 빈번한 키 range 에. use replication, 읽기가 빈번한 키 range.    When sharding, remember:  트랜잭션 스루풋은 1 write/sec per entity group 복수의 kinds 에 걸쳐 자주 업데이트 되는 엔터티는 분리하라.  Shared counters to avoid contention with high writes contention 을 줄이기 위해:\n sharded counter 를 구축하라 (카운터를 N 개의 다른 카운터로 쪼개라) - 카운터를 올리기 위해 임의의 샤드를 선택하여 올린다 - 전체 카운트를 알기위해, 모든 샤드카운터를 읽어서 더해라. 샤드의 넘버를 올리는 것은 스루풋을 올리는 것.. increasing the number of shards will increase the throughput you will have for increments on you counter.  Replicaion, Query Types, Transactions, and Handling Errors  Use replication to read a portion of the key range 읽기 비율이 높은데에 사용. 엔터티에 대한 사본을 N 개에 대해 두면, 읽기 연산에 대해 N 배 빠르다.\nDevices -\u0026gt; Cloud Load Balance -\u0026gt; Front end App (AppEngine - auto scailiing)\nUse qurey types based on your needs  Keys-only Projection (엔터티에서 프로퍼티를 얻어옴.) Ancester - 쿼리의 강한 일관성을 요할때. select * from task where __key__ has ancestor key(TaskList, \u0026lsquo;default\u0026rsquo;) Entity select * from task where done = FALSE  Improve Your query latency by using cursors instead of offsets Demo: Use Cloud Dataflow to bulk-load data into Cloud data store  pip install apache-beam\nlab git clone https://github.com/GoogleCloudPlatform/training-data-analyst\nSummary 조상을 지정하는 것으로 엔터티 그룹을 설정할수 있다.\n이렇게 해서 모든 관계된 엔터티들이 하나의 트랜잭션으로 업데이트 될 수 있다. 트래픽 램프업을 위해 555 룰을 따라라. 처음엔 초당 500 정도를 쓰다가 5분마다 50퍼센트씩 증가 시키는 것.\n","permalink":"https://nolleh.github.io/coursera/gcp/5.datastore/","summary":"Cloud Datastore Concepts and Indexes  Cloud Data Store concepts  데이터 오브젝트는 엔터티라고 불림 엔터티들은 하나이상의 프로퍼티로 구성됨 프로퍼티들은 하나이상의 값(values) 를 가질수 있음 각각의 엔터티는 구분되는 하나의 키를 가지고 있는데, 다음으로 구성 된다.  네임스페이스 엔터티 Kind 식별자 (스트링 or 숫자) 부모 ID   하나 이상의 엔터티에 대한 동작은 트랜잭션으로 불린다.  Datastore has two types of indexes    Built-in indexes Composite indexes     각각의 엔터티 Kind의 각각의 프로퍼티에 대해 자동으로 정의 인덱싱된 엔터티에 대해 다중의 프로퍼티 값을 인덱스함   간단한 쿼리에 적합 컴플렉스 쿼리에 적합    인덱스 설정파일에 정의       concept cloud datastore relational database     오브젝트 카테고리 Kind Table   한개 오브젝트 entity row   하나의 오브젝트를 위한 개별 데이터 프로퍼티 field   유니크 ID Key PrimaryKey    Design Considerations \u0026amp; Sharding  Design Your application for scale  엔터티 그룹에 대한 최대 쓰기율은 1/초 사전적으로 가까운 키에 대한 읽기와 쓰기를 너무 자주하지 말것.","title":"5. Cloud DataStore Concepts and Indexes"},{"content":"Cloud Storage  크고 자주 사용되지 않은 비구조화된 데이터\n   Overview ideal for     완전히 관리되고 고 신뢰가능 이미지와 비디오   비용절감. 확장가능한 오브젝트/블롭 저장 오브젝트와 블롭   http 로 접근 구조화되어있지 않은 데이터   오브젝트 이름이 키 정적 웹사이트 호스팅    Ideal for Cloud Datastore  관계형이나 데이터 분석에는 적합하지 않고 GAE 앱이나 구조화된 순수 제공 사용례에 적합한 구조화된 제공을 위한 스케일러블 저장소.\n   OverView ideal for     NoSQL 도큐먼트 데이터베이스 세미구조의 어플리케이션 데이터   확장가능 내구성이 필요한 키 밸류 데이터    계층구조 데이터    복수 인덱스 매니징    트랜잭션    Cloud Bigtable  고구조화 / 트랜잭셔널 데이터에는 적합하지 않고, flat 하고 많은 read/write 연산이나 분석을 위한 데이터에 적합한 큰 용량의 저지연 데이터베이스.\n   Overview ideal for     고성능의 wide 컬럼의 NoSQL 동작가능한 어플리케이션   성긴 테이블 분석적 어플리케이션   백억의 로우, 수천컬럼으로 확장가능 단일키의 데이터가 크다   TB 나 PB 데이터 저장가능 맵리듀스 동작    Cloud SQL  확장성/분석/큰 쓰기 연산에는 적합하지 않은, 웹 프레임워크의 기존에 존재하는 어플리케이션에 적용 가능한 잘알려진 VM 용 RDBMS\n   Overview idealfor     관리되는 서비스 (복제/페일오버/백업) 웹프레임워크   MySQL 과 PostgreSQL 구조화된 데이터   RDBMS OLTP 워크로드   프록시가 안전한 second 생성 인스턴스에 접근하도록 해줌(화이트리스팅없이.) MySQL/PGS 를 사용하는 어플리케이션    Cloud Spanner  분석적인 데이터에는 적합하지 않고, 저 지연의 트랜잭션적 시스템의 관계형 DB service\n   Overview ideal for     미션 크리티컬 DB 미션크리티컬 어플리케이션   트랜잭션 일관성 높은 트랜잭션   글로벌 확장 확장과 일관성있는 요구사항들   고 사용성    멀티리젼 복제    99.999% SLA     BigQuery  빠른 앱 빌딩에는 적합하지 않고, 정적 데이터 집합과의 분석을 위한 데에 사용되는 오토스케일링 분석 데이터 저장소\n   Overview ideal for     저 비용의 엔터프라이즈 데이터 창고 온라인 분석 처리 (OLAP) 워크로드   완전히 관리됨 빅 데이터 탐색과 처리   페타바이트 스케일 비지니스 지능 툴을 통한 리포팅   빠른 응답성    서버리스     Run Microsoft SQL Server on GCP   구글 컴퓨트 엔진에서 SQL 서버 이미지 선택가능. 컴퓨트 엔진 VM 에 SQL Server 를 프리로드 할수있음 라이센싱은 자동으로 포함됨 지원 버전은  SQL Server Standard SQL Server Web SQL Server Enterprise    ","permalink":"https://nolleh.github.io/coursera/gcp/4.db-overview/","summary":"Cloud Storage  크고 자주 사용되지 않은 비구조화된 데이터\n   Overview ideal for     완전히 관리되고 고 신뢰가능 이미지와 비디오   비용절감. 확장가능한 오브젝트/블롭 저장 오브젝트와 블롭   http 로 접근 구조화되어있지 않은 데이터   오브젝트 이름이 키 정적 웹사이트 호스팅    Ideal for Cloud Datastore  관계형이나 데이터 분석에는 적합하지 않고 GAE 앱이나 구조화된 순수 제공 사용례에 적합한 구조화된 제공을 위한 스케일러블 저장소.","title":"4.Cloud Storage, Cloud Datastore, Cloud Bigtable, Cloud SQL, and Cloud Spanner"},{"content":"What are the Google Cloud Client Libraries? 관용적인 코드를 각각의 랭귀지에 대해 제공 gRPC 에서 성능 효과를 보는 라이브러리도 있다.\ngithub repo\ngcloud - 커맨드 라인툴, gcp를 위한.\nGC cloud 빅쿼리를 위한 커맨드라인 툴\ngsuitl 버킷이랑 통신하기 위한 커맨드라인 툴\ngcloud init (initialize )\nCloud Shell 브라우저 베이스 커맨드라인툴. 일시적인 vm에 대한 접근을 제공. 5GB 디스크 SDK 에 이미 설치되어있음\n구글클라우드 콘솔프로젝트에대한 authorization /리소스 제공\n코드 에디터가 포함 (beta)\nModule Review Api Explore: google cloud api 를 테스트하기위한 샌드박스로 사용 Google Cloud Client Library : GCP 서비스와 커뮤니케이션 GCP Service 의 스크립트 작성 : Google Cloud SDK\n","permalink":"https://nolleh.github.io/coursera/gcp/3.sdk/","summary":"What are the Google Cloud Client Libraries? 관용적인 코드를 각각의 랭귀지에 대해 제공 gRPC 에서 성능 효과를 보는 라이브러리도 있다.\ngithub repo\ngcloud - 커맨드 라인툴, gcp를 위한.\nGC cloud 빅쿼리를 위한 커맨드라인 툴\ngsuitl 버킷이랑 통신하기 위한 커맨드라인 툴\ngcloud init (initialize )\nCloud Shell 브라우저 베이스 커맨드라인툴. 일시적인 vm에 대한 접근을 제공. 5GB 디스크 SDK 에 이미 설치되어있음\n구글클라우드 콘솔프로젝트에대한 authorization /리소스 제공\n코드 에디터가 포함 (beta)\nModule Review Api Explore: google cloud api 를 테스트하기위한 샌드박스로 사용 Google Cloud Client Library : GCP 서비스와 커뮤니케이션 GCP Service 의 스크립트 작성 : Google Cloud SDK","title":"3.SDK"},{"content":"12 Best Practices for user saccount https://cloud.google.com/blog/products/gcp/12-best-practices-for-user-account GCP 에서는 유저 계정에 대한 안전한 핸들링과 인증을 위한 툴을 게공한다. 웹사이트가 구글 쿠버네티스엔진에 호스트 되는 웹사이트를 담당하든, apigee 의 api 를 담당하든, firebase 를 사용하든, 어떤 다른 서비스를 통해 유저를 인증하든, 이 포스트는 좋은 연습을 제공해서, 안전하고 확장가능하고 쓸만한 계정 인증 시스템을 사용할 수 있게 도와줄 것이다.\n1. 패스워드를 해시하라. 패스워드를 포함해서, 예민한 개인정보를 어떻게 저장할 것인가가 계정관리의 가장 중요한 규칙이다. 이 데이터를 신성하게 다뤄야한다. 다시 reverse 될 수 없는 강력한 해쉬로되어야한다. 예를들면, PBKDF2, Argon2, Scripy, Bcrypt .. 또한, 이 해쉬는 salted 되어야 한다. MD5 나 SHA1 같은 deprecate 된 해쉬기술은 사용하면 안되며, revirsiable 될 수 있는 인크립션을 사용해야하는 상황은 어디에도 없으며, 직접 해쉬 알고리즘을 개발할 필요도 없다. 라고 생각하자.\n2. 서드파티 식별 제공자를 허락하자. 믿을수 있게한다. 구글, 페이스북, 트위터등이 흔히 사용된다. firebase Auth 시스템을 통해 인증처리를 할 수도 있다. -다른 사례들을 보면, 반나절만에 적용하고 그렇다. fabulas?\n3. 유저 식별의 개념을 유저 계정의 개념과 분리하라. 유저는 이메일 어드레스도, 핸드폰 번호도, OAUTH 응답의 unique ID 도 아니다. 유저 유저는 유일성의 최고점에 있으며, 당신 서비스의 개인화된 데이터와 경험이다. 잘 디자인된 유저관리 체계는 low 커플링 되어있으며, 고수준으로 응집되어있다.\n유저 계정과 보안을 분리하는 개념을 고수하는 것은 서드파티의 식별제공자를 구현하는 과정을 크게 단순화 할 수 있다. 유저는 유저 이름이나 다중의 정체성을 하나의 유저 계정에 연결 할 수도 있게 된다. 실제 용어로 옮기면, 내부의 전역 식별자를 모든 유저와 그들의 프로필과, 인증에 연결할 수도 있다.\n4. 하나의 계정에 복수의 정체성을 허용할 수 있도록 제공하라. 한 유저는 유저명과 패스워드를 사용하여 인증한후에, 이 과정이 계정을 생성할 수 있는지 모르고 구글 사이닝을 선택할 수있다. 유사하게, 어떤 유저는 복수의 이메일 주서를 당신의 서비스에 연결할 이유가 있었을 수도 있습니다. 만약 유저 식별과 인증을 분리해 두었다면, 하나의 유저에 대해 다양한 식별 정보를 연결하는게 간단하다.\n사용자가 기존 계정에 연결되지 않은 서드파티 아이디를 사용하고 있다는 것을 깨닫기전에 새로 가입하는 프로세스를 수행할 수 있는 가능성을 고려해야 한다. 흔한 식별 정보를 제공하도록 묻는것 만으로도 해결될 수 있다. 이메일어드레스, 폰이나 유저명 등.. 시스템에 존재한다면, 인증 후 새로운 아이디를 존재하는 계정에 연결하자.\n5. 길거나 복잡한 패스워드를 막지 말자. NIST 는 최근에 패스워드 복잡도와 강인함에 대해 가이드라인을 제공했다. 패스워드 길이를 막아서 얻을 수 있는건 POST 사이즈 뿐.. (끽해봐야 1MB?)\n해쉬된 패스워드는 알려진 적은 ASCII문자의 선택으로 압축될 수 있고, 그렇지 않으면 그냥 바이너리 해쉬를 Base64 로 변경해도 된다.\n6. user name 에 타당치 않은 규칙을 강요하지 마라 ","permalink":"https://nolleh.github.io/coursera/gcp/1-1.12-tips/","summary":"12 Best Practices for user saccount https://cloud.google.com/blog/products/gcp/12-best-practices-for-user-account GCP 에서는 유저 계정에 대한 안전한 핸들링과 인증을 위한 툴을 게공한다. 웹사이트가 구글 쿠버네티스엔진에 호스트 되는 웹사이트를 담당하든, apigee 의 api 를 담당하든, firebase 를 사용하든, 어떤 다른 서비스를 통해 유저를 인증하든, 이 포스트는 좋은 연습을 제공해서, 안전하고 확장가능하고 쓸만한 계정 인증 시스템을 사용할 수 있게 도와줄 것이다.\n1. 패스워드를 해시하라. 패스워드를 포함해서, 예민한 개인정보를 어떻게 저장할 것인가가 계정관리의 가장 중요한 규칙이다. 이 데이터를 신성하게 다뤄야한다.","title":"1-1. 계정관리를 위한 12 tips"},{"content":"3. Security, Reliablitiy, and Migration Use federated identity management firebase authentication~ 외부의 identity provider 를 통해 ..\nImplement health-check endpoint Stackdriver monitoring (helth monitoring agent) -\u0026gt; /health upcheck. 어디에 ? storage / database, network connection, 다른 의존들 .. 실패하면 자동으로 알림을 준다.\n로깅과 모니터를 어플리케이션의 성능에 대해 두라. 로그를 이벤트 스트림으로 취급하라. 어플리케이션에서는 건들지 말고 stdout 등으로 노출되는 데이터를 다른애가 후처리 해라 . 구글의 스택드라이버를 통해 어플리케이션을 디버그할 수 있고, 에러 모니터링을 설정할 수 있다.\n사소한 에러와 오래 지속되는 에러를 우아하게 다뤄라. trasient erros: 지수적으로 backoff 하여 재시도 해라. 구글클라이언트 클라이언트라이브러리는 재시도에 대해 자동적으로 수행한다.\n서비스 가용성 에러: 서킷브레이커를 구현해라. 유저에게 에러를 매번 노출하는 것은 피하는 것노출하는 것도 고려. .\n데이터 sovereignnty 와 compliance 요구사항을 고려하라. 어떤 나라에서 데이터보관에 대해 어떻게 규정하고 있는지\u0026hellip;\n가능한 테스팅과 재앙으로부터 복구계획을 구상하고 어플을 테스트하라. 실패시나리오의 예: 연결 실패 데이터 센터나 클라우드 제공자의 실패 GCP 존이나 리전 실패 배포 롤백 네트워크나 어플리케이션 이슈의 데이터 파괴\n계속되는 통합모델 (CI) 을 구현하고 파이프라인으로 배송하라. (CD) 강력한 devops 모델을 구현하라.\n코드 저장소 -\u0026gt; 빌드시스템 (배포아티팩트빌드/유닛테스트 실행) -\u0026gt; 배포시스템 (실환경과 테스트환경에 아티팩트를 배포) -\u0026gt; 1. 테스트환경 (통합테스트, 보안, 퍼포먼스 테스트.) / 2. 실환경 (성능 관찰)\n큰 수정이 있을때 배포하는 것이 아니라 작은 수정이 이씅ㄹ때마다 배포가 자동화되어 regression 의 리스크를 줄이며 디버그를 재빨리 하며, 이전 테이블의 빌드로 쉽게 롤백할 수 있게한다.\nStrangler 패턴을 새로 어플리케이션을 구조화하는데 사용하라. 이패턴: 구버전의 어플리케이션을 조금씩 새로운 서비스의 컴포넌트로 교체해 나가는것.\n","permalink":"https://nolleh.github.io/coursera/gcp/2.security-reliability-migration/","summary":"3. Security, Reliablitiy, and Migration Use federated identity management firebase authentication~ 외부의 identity provider 를 통해 ..\nImplement health-check endpoint Stackdriver monitoring (helth monitoring agent) -\u0026gt; /health upcheck. 어디에 ? storage / database, network connection, 다른 의존들 .. 실패하면 자동으로 알림을 준다.\n로깅과 모니터를 어플리케이션의 성능에 대해 두라. 로그를 이벤트 스트림으로 취급하라. 어플리케이션에서는 건들지 말고 stdout 등으로 노출되는 데이터를 다른애가 후처리 해라 . 구글의 스택드라이버를 통해 어플리케이션을 디버그할 수 있고, 에러 모니터링을 설정할 수 있다.","title":"2.Security-Reliability-Migration"},{"content":"Loosely Coupled Microservices and API gateway 모놀리틱에서는 기본 코드가 부풀게 되서, 어디를 고쳐야하는지 알기가 어렵다. 패키지들의 의존성들이 얼키고 설킨다.\n작은 기본 코드를 고쳐도 전체 프로그램이 배포되어 테스트될 필요가 있다.\n원격지에 의한 제어는 비동기 처리를 하자.\n가능한한 이벤트 드리븐 처리를 하자. -\u0026gt; 예를들어 구글 클라우드서비스에 이미지를 업데이트하고~ 이 이벤트에 반응하여 동작하는 어플리케이션을 만들 수 있다.\n커플링을 줄이기 위해 메시지 큐 등을 사용할 수 있다. 토픽에 대해 발송, 받아 처리.\nCache content 반응성을 위해 컨텐츠를 캐싱해서, TTL 이 지나기전의 캐쉬 데이터를 준다. 없거나 만료됐으면 새로 계산(이후 캐시에 저장) 멤캐시나 레디스에 저장한다.\nImplement API gateway, 컨슈머 어플리케이션에 백엔드 기능이 동작할 수 있도록..\n","permalink":"https://nolleh.github.io/coursera/gcp/1.msaandapigateway/","summary":"Loosely Coupled Microservices and API gateway 모놀리틱에서는 기본 코드가 부풀게 되서, 어디를 고쳐야하는지 알기가 어렵다. 패키지들의 의존성들이 얼키고 설킨다.\n작은 기본 코드를 고쳐도 전체 프로그램이 배포되어 테스트될 필요가 있다.\n원격지에 의한 제어는 비동기 처리를 하자.\n가능한한 이벤트 드리븐 처리를 하자. -\u0026gt; 예를들어 구글 클라우드서비스에 이미지를 업데이트하고~ 이 이벤트에 반응하여 동작하는 어플리케이션을 만들 수 있다.\n커플링을 줄이기 위해 메시지 큐 등을 사용할 수 있다. 토픽에 대해 발송, 받아 처리.\nCache content 반응성을 위해 컨텐츠를 캐싱해서, TTL 이 지나기전의 캐쉬 데이터를 준다.","title":"1.MSA and ApiGateway"},{"content":" 다음에서 발췌 ()[]\n Smart Contract  블록은 트랜잭션을 포함한다. 트랜잭션은 액션의 기록이다. 액션은 컨트랙트의 동작이다.  스마트컨트랙트의 사용\n eos.io 의 컨트랙트는 abi 로 표현된다. 어플리케이션 코드는 json data 를 이용한 http 를 통해 contract 를 트리거 한다. EOS.IO 는 컨트랙트를 간단히 스크립팅하거나 테스팅하기위한 커맨드라인 인터페이스를 제공한다.  Intro Smart Contracts   EOS.IO 스마트 컨트랙트는 WebAssembly 로 구동된다. (WASM)\n web 표준으로 떠오르는중 c/c++ 로부터 clang/llvm 을 통해 생성된다. 다른 언어들도 언젠가 지원될 것    Transaction - 실행되는 하나이상의 액션의 집합.\n 하나의 액션이라도 실패하면 모든 트랜잭션이 실패한다    Action - 스마트컨트랙트를 실행하는 고수준의 함수\n 데이터를 컨트랙트에 전송하기 위해서는 payload 를 포함해야한다.    cloes 는 http 를 호출하는 syntatic sugar~\ntransaction json 을 살펴보면. signature 가 있고, 이 특정한 트랜잭션의 시그니쳐를 표현한다.\naction json 은 이런 형태\nactions : [{ \u0026quot;account\u0026quot;: \u0026quot;eosio\u0026quot;, \u0026quot;name\u0026quot;: \u0026quot;newaccount\u0026quot;,\u0026quot;actor\u0026quot;: \u0026quot;eosio\u0026quot;, \u0026quot;permission\u0026quot;: \u0026quot;acitve\u0026quot; }], \u0026quot;Data\u0026quot;: \u0026quot;000000000ea30550 .. 000a8ed32320100\u0026quot; }]\n  account : 액션을 실행하는 계정의 이름 (스마트 컨트랙트가 올라가있는 계정. 어떻게 action 을 실행할지에 대해 알고있다.) name : \u0026ldquo;authroization\u0026rdquo;: [{ // 어떤 시그니쳐가 필요한지 나타낸다. data : hex 로 표현된 값   table 을 업데이트할때, payer 에 대해 0 를 전달하면 이전 payer 를 그대로 사용한다.\nunittest - test_api -\u0026gt; tests directories . - api_tests.cpp\n#include \u0026lt;boost/test/unit_test.hpp\u0026gt;#inclue \u0026lt;eosio.token/eosio.token.wast.hpp\u0026gt; abi.hpp\u0026gt;  BOOST_AUTO_TEST_SUITE(dice_tests) BOOST_FIXTURE_TEST_CASE(dice_test, dice_tester) try { create_accounts( {N(eosio.token), N(dice), N(alice), N(bob), false}); set_code(N(eosio.token), eosio_token_wast); set_abi(N(eosio.token), eosio_token_abi); push_action(N(eosio.token), N(create), N(eosio.toekn), mvo() (\u0026#34;issuer\u0026#34;, \u0026#34;eosio.token\u0026#34;)) } load balcancing 을 담당하는 릴레이노드 / producer node 가 별개로 있다\n특정노드에 컨트랙트를 전송 ? host 지정 하면 된다.\ncontext free action 를 어디서배우면 되나~ //\ntransaction 을 트랙킹하기위해 플러그인을 사용해도 된다. mongodb plugin 등.\n","permalink":"https://nolleh.github.io/block-chain-youtube/building-distributed-app/","summary":"다음에서 발췌 ()[]\n Smart Contract  블록은 트랜잭션을 포함한다. 트랜잭션은 액션의 기록이다. 액션은 컨트랙트의 동작이다.  스마트컨트랙트의 사용\n eos.io 의 컨트랙트는 abi 로 표현된다. 어플리케이션 코드는 json data 를 이용한 http 를 통해 contract 를 트리거 한다. EOS.IO 는 컨트랙트를 간단히 스크립팅하거나 테스팅하기위한 커맨드라인 인터페이스를 제공한다.  Intro Smart Contracts   EOS.IO 스마트 컨트랙트는 WebAssembly 로 구동된다. (WASM)\n web 표준으로 떠오르는중 c/c++ 로부터 clang/llvm 을 통해 생성된다.","title":"Building Distributed App"},{"content":" 다음에서 발췌 http://book.mixu.net/distsys/intro.html\n 1. Distributed systems at a highlevel  분산 프로그래밍은 같은 문제를 하나의 컴퓨터에서 해결할 수 있는 문제를 여러 컴퓨터에서 해결하는 예술이다.  컴퓨터 시스템이라면 해결해야 하는 두개의 문제가 있습니다.\n 저장소 연산  분산 프로그래밍은 하나의 컴퓨터에서 해결할 수 있는 문제를 여러 컴퓨터를 통해 해결하는 예술입니다. 보통 하나의 컴퓨터에서 해결하기에는 적합하지 않은 문제를 위해서입니다.\n실세계에서의 어떤것도 분산시스템을 요구하지는 않습니다. 무한한 돈과 무한한 실시간 연구 시간이 있다면, 분산시스템은 필요없습니다. 모든 연산과 모든 저장소는 매직박스 안에서 실행 될 수 있습니다 - 하나의, 믿을 수 없을정도로 빠르고, 믿을 수 없을정도로 신뢰할 수 있는 시스템은 누군가에게 돈을 지불하거나 당신이 직접 디자인할 필요가 있겟죠.\n하지만, 그렇게 무한한 자원을 가지고 있는 사람은 별로 없습니다. 때문에, 그들은 좋은 장소와실제 세계에서, 비용적인 ㅈ측면에서 고려할 수 있는 적합한 실세계 의 장소를 찾아야 합니다. 작은 사이즈 에서는 하드웨어를 업그레이드 하는 것은 필ㅅ적인 전략입니다. 하지만, 문제의 사이즈가 커짐에 따라 싱글 노드의 하드웨어 업그레이드 만으로는 문제를 해결할수 없거나, 비용적으로 막히는 지점이 오게 됩니다. 이 포인트에서, 분산 시스템으로 오신것을 환영할 때가 된것 같네요!\n이것은 현재의 현실이고 어떤 현실이냐면 가장 가치있는 중앙 범위, 상업적인 소프트웨어 - 유지보수 비용이 문제가 발생했을때도 괜찮은 소프트웨어로 유지될 수 있도록 해줍니다.\n연산은 일반적으로\n","permalink":"https://nolleh.github.io/distributed-systems/1.highlevel/","summary":"다음에서 발췌 http://book.mixu.net/distsys/intro.html\n 1. Distributed systems at a highlevel  분산 프로그래밍은 같은 문제를 하나의 컴퓨터에서 해결할 수 있는 문제를 여러 컴퓨터에서 해결하는 예술이다.  컴퓨터 시스템이라면 해결해야 하는 두개의 문제가 있습니다.\n 저장소 연산  분산 프로그래밍은 하나의 컴퓨터에서 해결할 수 있는 문제를 여러 컴퓨터를 통해 해결하는 예술입니다. 보통 하나의 컴퓨터에서 해결하기에는 적합하지 않은 문제를 위해서입니다.\n실세계에서의 어떤것도 분산시스템을 요구하지는 않습니다. 무한한 돈과 무한한 실시간 연구 시간이 있다면, 분산시스템은 필요없습니다.","title":"고수준의 분산 시스템"},{"content":"hello 라는 이름의 디렉토리를 contracts directory 에 생성하자.\ncd CONTRACTS_DIR mkdir hello cd hello hello.cpp 를 생성하고 에디터로 열자.\ntouch hello.cpp 필요한 라이브러리를 이 파일에 include 한다.\n#include \u0026lt;eosiolib/eosio.hpp\u0026gt;#include \u0026lt;eosiolib/print.hpp\u0026gt;코드를 간결하게 해줄 eosio 네임스페이스를 contract 에 추가한다.\nusing namespace eosio;  eosiolib/eosio.hpp 가 EOSIO C 와 C++ API 를 당신의 contract 스코프에 로드한다.  표준 C++11 클래스를 생성한다. 이 contract class 는 eosio::contract 를 확장해야한다.\n#include \u0026lt;eosiolib/eosio.hpp\u0026gt;#include \u0026lt;eosiolib/print.hpp\u0026gt; using namespace eosio;  class hello : public contract {}; 비어있는 contract 는 좋지 않으니, public 접근 지정자와 using 선언을 추가하자. 이 using 선언은 좀 더 간결한 코드를 쓸 수 있도록 도움을 줄것이다.\n이제 contract 는 어떤 작업을 하도록 구성한다. hello world 의 정신을 받아 \u0026ldquo;name\u0026rdquo; 파라메터를 수신하고, 파라메터를 출력하는 작업을 해보자.\n#include \u0026lt;eosiolib/eosio.hpp\u0026gt;#include \u0026lt;eosiolib/print.hpp\u0026gt; using namespace eosio;  class hello : public contract {  public:  using contract::contract;   [[eosio::action]]  void hi( name user ) {  print( \u0026#34;Hello, \u0026#34;, name{user});  } }; 위의 동작은 user 라는 이름의 파라메터를 name type 으로 전달 받는다.\nEOSIO 는 몇개의 typedef 를 선언하고 있는데, 이 중에 흔한 하나가 바로 이 name 이다.\neosio::print를 사용함으로써, 문자열을 user 파라미터와 붙여 출력한다.\n괄호를 이용한 초기화 name{user} 는 user 파라메터가 출력될 수 있도록 해준다.\neosio.cdt 의 abi 생성자는 atttrubite 없이는 hi() 의 동작을 알 수 없다. c++11 스타일의 attribute 를 action 의 상위에 추가하여 abi generator 가 신뢰 할 수 있는 출력을 할 수 있도록 한다.\n#include \u0026lt;eosiolib/eosio.hpp\u0026gt;#include \u0026lt;eosiolib/print.hpp\u0026gt; using namespace eosio;  class hello : public contract {  public:  using contract::contract;   [[eosio::action]]  void hi( name user ) {  print( \u0026#34;Hello, \u0026#34;, user);  } };  EOSIO_DISPATCH( hello, (hi)) 마지막으로, EOSIO_DISPATCH 매크로를 추가하여 hello contract 의 dispatch 액션을 처리하도록 한다.\n이제 web assembly 를 통해 컴파일해보자.\neosio-cpp -o hello.wasm hello.cpp --abigen contract 가 배포되면, 계정으로 배포되어 이 계정이 contract 의 인터페이스가 된다.\n이 튜토리얼의 이전에 언급하였듯, 같은 public key 를 모든계정에서 사용하여 간단히 할 수 있다.\ncleos wallet keys 이 contract 를 위한 계정을 생성하기 위해 cleos create account 를 사용한다.\ncleos create account eosio hello YOUR_PUBLIC_KEY -p eosio@active 컴파일된 wasm 을 cleos set contract 를 통해 블록체인으로 broadcast 한다.\ncleos set contract hello CONTRACTS_DIR/hello -p hello@active 훌륭하다! 이제 contract 가 설정 되었고, action 을 push 해보자.\ncleos push action hello hi \u0026#39;[\u0026#34;bob\u0026#34;]\u0026#39; -p bob@active executed transaction: 28d92256c8ffd8b0255be324e4596b7c745f50f85722d0c4400471bc184b9a16 244 bytes 1000 cycles # hello.code \u0026lt;= hello.code::hi {\u0026#34;user\u0026#34;:\u0026#34;bob\u0026#34;} \u0026gt;\u0026gt; Hello, bob 예상했던대로 hello, bob 이 출력된다.\n이번 경우, \u0026ldquo;alice\u0026rdquo; 가 권한이 있고 user 는 단순한 argument 이다. contract 를 수정하여 권한이 있는 유저가 \u0026ldquo;hi\u0026rdquo; 를 받을 유저와 동일한 경우에만 동작하도록 해보자.\nrequire_auth 메소드를 사용한다.\n이 메소드는 name 을 파라메터로 받아서 action 을 수행하는 사용자가 제공된 파라메터와 일치하는지 확인한다.\nvoid hi( name user ) {  require_auth( user );  print( \u0026#34;Hello, \u0026#34;, name{user} ); } 다시 컴파일 한다.\neosio-cpp -o hello.wasm hello.cpp --abigen 그리고 update 한다.\ncleos set contract hello CONTRACTS_DIR/hello -p hello@active 실행하되, 이번에는 권한이 일치 않도록 한다.\ncleos push action hello hi \u0026#39;[\u0026#34;bob\u0026#34;]\u0026#39; -p alice@active Error 3090004: Missing required authority Ensure that you have the related authority inside your transaction!; If you are currently using \u0026#39;cleos push action\u0026#39; command, try to add the [relevant](**http://google.com**) authority using -p option. 우리의 contract 수정으로, 제공된 name user 가 승인 유저와 동일한지 확인한다.\n다시 실행하되, 이번엔 alice account 의 권한으로 실행해보자.\ncleos push action hello hi \u0026#39;[\u0026#34;alice\u0026#34;]\u0026#39; -p alice@active executed transaction: 235bd766c2097f4a698cfb948eb2e709532df8d18458b92c9c6aae74ed8e4518 244 bytes 1000 cycles # hello \u0026lt;= hello::hi {\u0026#34;user\u0026#34;:\u0026#34;alice\u0026#34;} \u0026gt;\u0026gt; Hello, alice ","permalink":"https://nolleh.github.io/block-chain/2.1-helloworld/","summary":"hello 라는 이름의 디렉토리를 contracts directory 에 생성하자.\ncd CONTRACTS_DIR mkdir hello cd hello hello.cpp 를 생성하고 에디터로 열자.\ntouch hello.cpp 필요한 라이브러리를 이 파일에 include 한다.\n#include \u0026lt;eosiolib/eosio.hpp\u0026gt;#include \u0026lt;eosiolib/print.hpp\u0026gt;코드를 간결하게 해줄 eosio 네임스페이스를 contract 에 추가한다.\nusing namespace eosio;  eosiolib/eosio.hpp 가 EOSIO C 와 C++ API 를 당신의 contract 스코프에 로드한다.  표준 C++11 클래스를 생성한다. 이 contract class 는 eosio::contract 를 확장해야한다.\n#include \u0026lt;eosiolib/eosio.hpp\u0026gt;#include \u0026lt;eosiolib/print.hpp\u0026gt; using namespace eosio;  class hello : public contract {}; 비어있는 contract 는 좋지 않으니, public 접근 지정자와 using 선언을 추가하자.","title":"EOSIO - 2.1/Hello World!"},{"content":" 다음에서 발췌 EOSIO - 1.7 Create Test Accounts\n What is an account?  블록체인에 저장되어 송신자와 수신자를 구분하는데 사용되는 승인의 집합체라 할 수 있다. 유연한 권한 승인 구조를 가질 수 있는데, 권한이 어떻게 설정되느냐에 따른 개인이나 그룹에 의해 소유될 수 있다.\n하나의 계정은 블록체인의 트랜잭션을 보내거나 받기 위해 요구된다.\n이 튜토리얼에서는 두개의 user 계정, bob 과 alice, 그리고 설정을 위한 기본 eosio 계정을 사용한다. 추가로 계정들은 다양한 contracts 를 위해 이 튜토리얼 시리즈에서 만들어 질 수 있다.\nStep 1: Create Test Accounts  이전 단계에서, wallet 과 개발키 쌍을 생성하였다. form 에 public key 를 지정하도록 요청받았지만, 이 단계를 넘기거나 쿠키를 사용하지 않도록 설정하였을 수있다. 생성된 publickey 를 YOUR_PUBLIC_KEY 에 기입하여 진행하자.\n이 튜토리얼동안 유저 bob 가 alice 가 사용된다. 두 계정은 cleos create accounts 를 통해 생성된다.\ncleos create account eosio bob YOUR_PUBLIC_KEY cleos create account eosio alice YOUR_PUBLIC_KEY 트랜잭션이 발송 되었음을 나타내는 다음과 같은 메시지가 노출된다.\nexecuted transaction: 40c605006de... 200 bytes 153 us # eosio \u0026lt;= eosio::newaccount {\u0026#34;creator\u0026#34;:\u0026#34;eosio\u0026#34;,\u0026#34;name\u0026#34;:\u0026#34;alice\u0026#34;,\u0026#34;owner\u0026#34;:{\u0026#34;threshold\u0026#34;:1,\u0026#34;keys\u0026#34;:[{\u0026#34;key\u0026#34;:\u0026#34;EOS5rti4LTL53xptjgQBXv9HxyU... warning: transaction executed locally, but may not be confirmed by the network yet ]  Using Different Keys for Active/Owner on a PRODUCTION Network EOSIO has a unique authorization structure that has added security for you account. You can minimize the exposure of your account by keeping the owner key cold, while using the key associated with your active permission. This way, if your active key were every compromised, you could regain control over your account with your owner key.\n ","permalink":"https://nolleh.github.io/block-chain/1.7-createtestaccount/","summary":"다음에서 발췌 EOSIO - 1.7 Create Test Accounts\n What is an account?  블록체인에 저장되어 송신자와 수신자를 구분하는데 사용되는 승인의 집합체라 할 수 있다. 유연한 권한 승인 구조를 가질 수 있는데, 권한이 어떻게 설정되느냐에 따른 개인이나 그룹에 의해 소유될 수 있다.\n하나의 계정은 블록체인의 트랜잭션을 보내거나 받기 위해 요구된다.\n이 튜토리얼에서는 두개의 user 계정, bob 과 alice, 그리고 설정을 위한 기본 eosio 계정을 사용한다. 추가로 계정들은 다양한 contracts 를 위해 이 튜토리얼 시리즈에서 만들어 질 수 있다.","title":"EOSIO - 1.7/Test 계정 생성하기"},{"content":"Step 1: Wallet 생성하기  먼저 wallet 을 생성한다. cleos wallet create 를 통해 기본 wallet 을 --to-console 옵션을 사용하여 간단하게 생성한다.\ncleos 를 production 환경에서 사용한다면, 대신 --to-file 옵션을 사용하여 wallet 의 패스워드를 배쉬 기록에 남지않도록 한다.\n개발 목적으로 사용하는 production 환경의 키가 아니기때문에 \u0026ndash;to-console 으로 보안 위협없이 사용할 수 있다.\ncleos wallet create --to-console cleos 는 패스워드를 반환하며, 이 패스워드를 다음 튜토리얼에서 이용할 수 있도록 저장하자.\nCreating wallet: default Save password to use in the future to unlock this wallet. Without password imported keys will not be retrievable. \u0026#34;PW5Kewn9L76X8Fpd....................t42S9XCw2\u0026#34;  wallet 에 대해 wallet 의 암호 해독성에 대한 흔한 오해중의 하나는 토큰을 저장할 것이라는 것이다. wallet 은 토큰을 저장하지 않는다. wallet 은 private key 를 암호화된 파일에 저장하고 사이닝 트랜젝션에 활용한다.\n유저는 주로 인터페이스를 통해 트랜잭션 오브젝트를 빌드하고, 그 오브젝트를 서명될 수 있도록 wallet 에 전송하여, wallet 이 이후 시그니쳐와 함께 오브젝트를 네트워크를 통해 반환한다. 네트워크가 트랜잭션을 유효하다고 판단하면, 이를 블록체인의 블록에 포함시킨다.\n Step2: Open the wallet  keosd 인스턴스를 시작하고 다면 wallet은 닫히게 된다. 실행시키고 싶다면 다음 명령어를 활용한다.\ncleos wallet open 다시 리스트를 조회해보면\ncleos wallet list 다음과 같이 반환된다.\nWallets: [  \u0026#34;default\u0026#34; ] Step 3: Unlock it  keosd wallet 은 열려있지만 여전히 잠겨있다. 좀전에 비밀번호를 제공받았으므로, 이를 이제 사용한다.\ncleos wallet unlock 비밀번호를 입력하고 다시 리스트를 조회해보면\nWallets: [  \u0026#34;default *\u0026#34; ] 열렸음을 의미하는 * 가 붙어있다.\nStep 4: Import keys into your wallet  private key 를 생성하기 위한 cleos 명령어가 있다.\ncleos wallet create_key Step 5: Follow this tutorial series more easily  얻은 public key 를 입력하자.\nStep 6:Import the Development Key  새로운 EOSIO 체인마다 \u0026ldquo;eosio\u0026rdquo; 라 불리는 기본적인 \u0026ldquo;system\u0026rdquo; 유저를 보유한다.\n이 계정은 시스템 contracts 들을 로딩함으로써 governance 와 EOSIO 체인의 컨센서스를 지휘하는 체인을 설정하는데 사용된다.\n모든 EOSIO 체인은 development key 와 함께 제공되는데, 모두 동일하다. 이 키를 로드하여 시스템유저(eosio) 대신 트랜잭션을 서명해보자.\ncleos wallet import private key 를 질의 할텐데, 다음을 입력한다.\n5KQwrPbwdL6PhXujxW37FSSQZ1JiwsST4cqQzDeyXtP79zkvFD3 이제 default wallet 이 해금되고 key 로 load 되었으니, 다음을 진행 할 수 있게 되었다.\n","permalink":"https://nolleh.github.io/block-chain/1.6-createdevelopmentwallet/","summary":"Step 1: Wallet 생성하기  먼저 wallet 을 생성한다. cleos wallet create 를 통해 기본 wallet 을 --to-console 옵션을 사용하여 간단하게 생성한다.\ncleos 를 production 환경에서 사용한다면, 대신 --to-file 옵션을 사용하여 wallet 의 패스워드를 배쉬 기록에 남지않도록 한다.\n개발 목적으로 사용하는 production 환경의 키가 아니기때문에 \u0026ndash;to-console 으로 보안 위협없이 사용할 수 있다.\ncleos wallet create --to-console cleos 는 패스워드를 반환하며, 이 패스워드를 다음 튜토리얼에서 이용할 수 있도록 저장하자.\nCreating wallet: default Save password to use in the future to unlock this wallet.","title":"EOSIO - 1.6/개발 Wallet 생성하기"},{"content":" 다음에서 발췌 - EOSIO - 1.5 Install The CDT\n EOSIO Contract Development Toolkit, CDT 는 contract 컴파일을 위한 툴의 집합이다. 뒤따를 튜토리얼들은 contract 들을 컴파일하고 ABI 를 생성하는 주요 CDT 를 사용한다.\n1.3.x 버전부터, CDT 는 Mac OS X brew, linux debian 과 RPM 패키지들을 지원한다. 설치하기 위한 가장쉬운 선택지는 이 패키지 시스템들을 이용하는 것이다. 하나의 방법을 선택하자.\nHomeBrew (Mac OS X)  Install brew tap eosio/eosio.cdt brew install eosio.cdt Uninstall brew remove eosio.cdt ","permalink":"https://nolleh.github.io/block-chain/1.5-installthecdt/","summary":"다음에서 발췌 - EOSIO - 1.5 Install The CDT\n EOSIO Contract Development Toolkit, CDT 는 contract 컴파일을 위한 툴의 집합이다. 뒤따를 튜토리얼들은 contract 들을 컴파일하고 ABI 를 생성하는 주요 CDT 를 사용한다.\n1.3.x 버전부터, CDT 는 Mac OS X brew, linux debian 과 RPM 패키지들을 지원한다. 설치하기 위한 가장쉬운 선택지는 이 패키지 시스템들을 이용하는 것이다. 하나의 방법을 선택하자.\nHomeBrew (Mac OS X)  Install brew tap eosio/eosio.cdt brew install eosio.","title":"EOSIO - 1.5/CDT 설치하기"},{"content":" 다음에서 발췌 - \n Step 1: Boot Node And Wallet  Step 1.1: Start keosd 먼저 keosd 를 시작한다.\nkeosd \u0026amp; 다음과 유사한 결과를 얻게 된다.\ninfo 2018-11-26T06:54:24.789 thread-0 wallet_plugin.cpp:42 plugin_initialize ] initializing wallet plugin info 2018-11-26T06:54:24.795 thread-0 http_plugin.cpp:554 add_handler ] add api url: /v1/keosd/stop info 2018-11-26T06:54:24.796 thread-0 wallet_api_plugin.cpp:73 plugin_startup ] starting wallet_api_plugin info 2018-11-26T06:54:24.796 thread-0 http_plugin.cpp:554 add_handler ] add api url: /v1/wallet/create info 2018-11-26T06:54:24.796 thread-0 http_plugin.cpp:554 add_handler ] add api url: /v1/wallet/create_key info 2018-11-26T06:54:24.796 thread-0 http_plugin.cpp:554 add_handler ] add api url: /v1/wallet/get_public_keys enter 를 치면 종료 된다.\nStep 1.2: Start nodeos nodeos -e -p eosio \\ --plugin eosio::producer_plugin \\ --plugin eosio::chain_api_plugin \\ --plugin eosio::http_plugin \\ --plugin eosio::history_plugin \\ --plugin eosio::history_api_plugin \\ --data-dir CONTRACTS_DIR/eosio/data \\ --config-dir CONTRACTS_DIR/eosio/config \\ --access-control-allow-origin=\u0026#39;*\u0026#39; \\ --contracts-console \\ --http-validate-host=false \\ --verbose-http-errors \\ --filter-on=\u0026#39;*\u0026#39; \u0026gt;\u0026gt; nodeos.log 2\u0026gt;\u0026amp;1 \u0026amp; 이 설정은 다음과 같은 작업을 진행한다.\n 개발 디렉토리 하위의 eosio 디렉토리안에서 블록체인 데이터와 설정 데이터를 사용 할수 있도록 지정. eosio/data 와 eosio/config 을 각각 사용하게 된다. nodeos 를 실행한다. 이 커맨드는 기본적인 플러그인을 로드하고, 서버 주소를 설정하며, CORS 를 사용가능하게 하며 일부 contract 디버깅과 로깅을 가능케한다. CORS 가 (*) 에 대한 제약이 없도록 한다.   CORS 의 * 에 대한 제약제거는 개발 과정에서만 사용하도록 한다. 어떤 노드에 대해 public 하게 * 에 접근하도록 하는 것은 지양해야한다!\n Step 2: Check the installation  Step 2.1: Check That Nodeos is Producing Blocks 아래의 명령어를 실행한다.\ntail -f nodeos.log 아래와 유사한 출력 결과를 볼 수 있다.\n1929001ms thread-0 producer_plugin.cpp:585 block_production_loo ] Produced block 0000366974ce4e2a... #13929 @ 2018-05-23T16:32:09.000 signed by eosio [trxs: 0, lib: 13928, confirmed: 0] 1929502ms thread-0 producer_plugin.cpp:585 block_production_loo ] Produced block 0000366aea085023... #13930 @ 2018-05-23T16:32:09.500 signed by eosio [trxs: 0, lib: 13929, confirmed: 0] 1930002ms thread-0 producer_plugin.cpp:585 block_production_loo ] Produced block 0000366b7f074fdd... #13931 @ 2018-05-23T16:32:10.000 signed by eosio [trxs: 0, lib: 13930, confirmed: 0] 1930501ms thread-0 producer_plugin.cpp:585 block_production_loo ] Produced block 0000366cd8222adb... #13932 @ 2018-05-23T16:32:10.500 signed by eosio [trxs: 0, lib: 13931, confirmed: 0] 1931002ms thread-0 producer_plugin.cpp:585 block_production_loo ] Produced block 0000366d5c1ec38d... #13933 @ 2018-05-23T16:32:11.000 signed by eosio [trxs: 0, lib: 13932, confirmed: 0] 1931501ms thread-0 producer_plugin.cpp:585 block_production_loo ] Produced block 0000366e45c1f235... #13934 @ 2018-05-23T16:32:11.500 signed by eosio [trxs: 0, lib: 13933, confirmed: 0] 1932001ms thread-0 producer_plugin.cpp:585 block_production_loo ] Produced block 0000366f98adb324... #13935 @ 2018-05-23T16:32:12.000 signed by eosio [trxs: 0, lib: 13934, confirmed: 0] 1932501ms thread-0 producer_plugin.cpp:585 block_production_loo ] Produced block 00003670a0f01daa... #13936 @ 2018-05-23T16:32:12.500 signed by eosio [trxs: 0, lib: 13935, confirmed: 0] 1933001ms thread-0 producer_plugin.cpp:585 block_production_loo ] Produced block 00003671e8b36e1e... #13937 @ 2018-05-23T16:32:13.000 signed by eosio [trxs: 0, lib: 13936, confirmed: 0] 1933501ms thread-0 producer_plugin.cpp:585 block_production_loo ] Produced block 0000367257fe1623... #13938 @ 2018-05-23T16:32:13.500 signed by eosio [trxs: 0, lib: 13937, confirmed: 0] 로그를 닫기 위해 Ctrl + c 를 누르자.\nStep 2.2: Check the wallet 쉘을 열고 아래 명령어를 기입한다.\ncleos wallet list 다음과 같은 결과가 노출된다.\nWallets: [] 이 시점에서 앞으로, 당신의 로컬시스템에서 이 명령어들을 칠 것이라 기대한다.\nStep 2.3: Check Nodeos endpoints 다음은 RPC API 가 정상적으로 동작하는지 확인할 것이다. 하나를 선택하자.\n 다음 브라우저에서 chain_api_plugin 을 통해 제공되는 get_info 를 확인해본다. : http://localhost:8888/v1/chain/get_info 같은 것을 확인하지만, 호스트머신의 콘솔에서 확인한다.  curl http://localhost:8888/v1/chain/get_info ","permalink":"https://nolleh.github.io/block-chain/1.4-startyournodeandsetup/","summary":"다음에서 발췌 - \n Step 1: Boot Node And Wallet  Step 1.1: Start keosd 먼저 keosd 를 시작한다.\nkeosd \u0026amp; 다음과 유사한 결과를 얻게 된다.\ninfo 2018-11-26T06:54:24.789 thread-0 wallet_plugin.cpp:42 plugin_initialize ] initializing wallet plugin info 2018-11-26T06:54:24.795 thread-0 http_plugin.cpp:554 add_handler ] add api url: /v1/keosd/stop info 2018-11-26T06:54:24.796 thread-0 wallet_api_plugin.cpp:73 plugin_startup ] starting wallet_api_plugin info 2018-11-26T06:54:24.796 thread-0 http_plugin.cpp:554 add_handler ] add api url: /v1/wallet/create info 2018-11-26T06:54:24.796 thread-0 http_plugin.cpp:554 add_handler ] add api url: /v1/wallet/create_key info 2018-11-26T06:54:24.","title":"EOSIO - 1.4/노드 시작하고 설정하기"},{"content":" 발췌 - EOSIO - 1.3 About The Stack\n 방금 설치한 툴들을 시작하기 전에, 각각의 컴포넌트들이 어떻게 상호작용하는지 이해하는게 좋다.\n  nodeos (node + eos = nodeos) - 노드를 실행하기 위한 플러그인들로 설정될 수 있는 Core EOSIO 데몬. 예제는 로컬개발과 API 종단점을 위해 블록제품을 사용한다.\n  cleos (cli + eos = cleos) - 블록 체인과 상호작용하고 wallet 을 관리하기위한 커맨드 라인 인터페이스.\n  keosd (key + eos = keosd) - wallet 안의 EOSIO key 를 안전하게 저장 하기 위한 컴포넌트\n  eosio-cpp - eosio.cdt 의 일부로, C++ 코드를 WASM 로 컴파일하고 ABI 들을 생성한다.\n  ","permalink":"https://nolleh.github.io/block-chain/1.3-aboutthestack/","summary":"발췌 - EOSIO - 1.3 About The Stack\n 방금 설치한 툴들을 시작하기 전에, 각각의 컴포넌트들이 어떻게 상호작용하는지 이해하는게 좋다.\n  nodeos (node + eos = nodeos) - 노드를 실행하기 위한 플러그인들로 설정될 수 있는 Core EOSIO 데몬. 예제는 로컬개발과 API 종단점을 위해 블록제품을 사용한다.\n  cleos (cli + eos = cleos) - 블록 체인과 상호작용하고 wallet 을 관리하기위한 커맨드 라인 인터페이스.\n  keosd (key + eos = keosd) - wallet 안의 EOSIO key 를 안전하게 저장 하기 위한 컴포넌트","title":"EOSIO - 1.3/스택에 대해"},{"content":" 발췌 - (EOSIO - 1.2 Before You Begin)[https://developers.eos.io/eosio-home/docs/setting-up-your-environment]\n Step 1: Install Binaries  이 튜토리얼은 선빌드된 바이너리를 사용한다.\n가장 빨리 시작하는 방법은 이게 가장 좋은 선택지 일것이다. 소스로부터 빌드하는 것도 하나의 선택지이지만, 한시간 이상 걸릴 수 도 있으며 빌드 에러가 발생 할 수도 있다.\n아래의 명령어들이 각각의 OS 에서 바이너리를 다운로드 할 것이다.\nbrew tap eosio/eosio brew install eosio Step 2: Setup a development directory, stick to it  작업을 진행할 디렉토리를 선택할 필요가 있다.\ncontracts 폴더를 로컬드라이브 어딘가에 생성하는 것을 추천한다.\nmkdir contracts cd contracts Step 3: Enter your local directory below.  그 폴더의 경로를 얻어 저장해둬서 필요할 때 사용 할 수 있도록 다음 명령어를 통하면 된다.\npwd 절대 경로를 아래에 기입하면 문서의 내용에 반영, 더 읽기 편하게 만들어 줄 것이다. 이 기능은 쿠키를 사용한다.\n","permalink":"https://nolleh.github.io/block-chain/1.2-beforeyoubegin/","summary":"발췌 - (EOSIO - 1.2 Before You Begin)[https://developers.eos.io/eosio-home/docs/setting-up-your-environment]\n Step 1: Install Binaries  이 튜토리얼은 선빌드된 바이너리를 사용한다.\n가장 빨리 시작하는 방법은 이게 가장 좋은 선택지 일것이다. 소스로부터 빌드하는 것도 하나의 선택지이지만, 한시간 이상 걸릴 수 도 있으며 빌드 에러가 발생 할 수도 있다.\n아래의 명령어들이 각각의 OS 에서 바이너리를 다운로드 할 것이다.\nbrew tap eosio/eosio brew install eosio Step 2: Setup a development directory, stick to it  작업을 진행할 디렉토리를 선택할 필요가 있다.","title":"EOSIO - 1.2/시작하기 전에"},{"content":" 발췌 EOSIO - 1.1 Introduction\n 배울 수 있는 것   노드로 얼마나 빨리 갖고 놀 수 있는가 Wallet 과 Key 를 어떻게 관리할 수 있는가 계정을 만드는 법 contract 작성법 컴파일과 ABI contract 배포  C / C++ 경험  EOSIO 기반 블록체인은 WebAssembly 를 이용하여 유저가 생성한 어플리케이션과 코드를 실행한다.\nWASM 은 구글, 마이크로소프트, 애플, 그리고 다른 주요 업체의 지원을 받는 떠오르는 웹 표준이다.\n오늘날 WASM 을 빌드하기위해 사용되는 성숙된 도구는 C/C++ 컴파일러를 통한 clang/llvm 이다.\n최고의 호환성을 위해, EOSIO C++ 툴체인을 사용하도록 권장한다.\n서드파티에 의해 개발중인 다른 툴체인들은 다음과 같다: Rust, Python, Solidity. 이들의 언어는 단순해 보이지만, 성능은 당신이 빌드하는 어플리케이션의 규모에 따라 다르다. C++ 가 가장 안전하고 고성능일 것이라고 기대한다.\nLinux / Mac OS Experience   Amazon 2017.09 CentOS 7 Fedora 25 Mint 18 Ubuntu 16.04 (16.10 추천) Ubuntu 18.04 MacOS Darwin 10.12+ (10.13 추천)  Command Line Knowlege  EOSIO 의 다양한 툴을 이용하기 위해서는 기본적인 커맨드라인 지식이 필요하다.\nC++ Environment Setup  C++ 문법 하이라이팅을 지원하는 어떤 텍스트 에디터를 사용해도 되지만 주요한 에디터는 Sublime Text, Atom 이 있다. 다른 선택지는 철학적인 코드 완성과 개발 경험이 더 많은 철학적인 IDE 를 선택해서 사용하면된다. 개인 선호에 따라 작업하면 되지만, 확신이 없다면 다음 선택지 중에서 살펴보면 된다.\nPotential Editors and IDEs   Sublime Text Atom Editor CLion Eclips Visual Studio Code  Operating System of Development Enviornment  linux 향의 OS 를 사용한다면 튜토리얼을 따를 수 있다. 다음을 포함하지만, 여기에 제한된건 아니다.\n Mac OS Ubuntu Debian Fedora  Windows 현재는 powershell 포트등에 대해 지원하지 않는다. 미래에는 powershell 명령어를 지원할 계획이지만, 그전까지는 Ubuntu VM 을 활용하여 개발환경을 구성하는 편이 최선이다. Linux 명령에 익숙한 개발자라면 적은 어려움 만이 있을 것이다.\n","permalink":"https://nolleh.github.io/block-chain/1.1-introduction/","summary":"발췌 EOSIO - 1.1 Introduction\n 배울 수 있는 것   노드로 얼마나 빨리 갖고 놀 수 있는가 Wallet 과 Key 를 어떻게 관리할 수 있는가 계정을 만드는 법 contract 작성법 컴파일과 ABI contract 배포  C / C++ 경험  EOSIO 기반 블록체인은 WebAssembly 를 이용하여 유저가 생성한 어플리케이션과 코드를 실행한다.\nWASM 은 구글, 마이크로소프트, 애플, 그리고 다른 주요 업체의 지원을 받는 떠오르는 웹 표준이다.\n오늘날 WASM 을 빌드하기위해 사용되는 성숙된 도구는 C/C++ 컴파일러를 통한 clang/llvm 이다.","title":"EOSIO - 1.1/소개"},{"content":"개요   다음에서 발췌\n비동기 프로그램의 제어 흐름\n 코드  public partial class MainWindow : Window {  // . . .  private async void startButton_Click(object sender, RoutedEventArgs e)  {  // ONE  Task\u0026lt;int\u0026gt; getLengthTask = AccessTheWebAsync();   // FOUR  int contentLength = await getLengthTask;   // SIX  resultsTextBox.Text +=  $\u0026#34;\\r\\nLength of the downloaded string: {contentLength}.\\r\\n\u0026#34;;  }   async Task\u0026lt;int\u0026gt; AccessTheWebAsync()  {  // TWO  HttpClient client = new HttpClient();  Task\u0026lt;string\u0026gt; getStringTask =  client.GetStringAsync(\u0026#34;https://msdn.microsoft.com\u0026#34;);   // THREE  string urlContents = await getStringTask;   // FIVE  return urlContents.Length;  } } Three 에서 yield 되어 Four.\n","permalink":"https://nolleh.github.io/csharp/async-control-flow-msdn/","summary":"개요   다음에서 발췌\n비동기 프로그램의 제어 흐름\n 코드  public partial class MainWindow : Window {  // . . .  private async void startButton_Click(object sender, RoutedEventArgs e)  {  // ONE  Task\u0026lt;int\u0026gt; getLengthTask = AccessTheWebAsync();   // FOUR  int contentLength = await getLengthTask;   // SIX  resultsTextBox.Text +=  $\u0026#34;\\r\\nLength of the downloaded string: {contentLength}.\\r\\n\u0026#34;;  }   async Task\u0026lt;int\u0026gt; AccessTheWebAsync()  {  // TWO  HttpClient client = new HttpClient();  Task\u0026lt;string\u0026gt; getStringTask =  client.","title":"비동기 프로그램의 제어 흐름"},{"content":"개요   다음에서 발췌 MSDN\n 반응성을 향상시키는 비동기  잠재적인 차단 작업 완료 될때까지 다른 작업을 게속 수행\n작성이 간편한 비동기 메서드  반환 형식은 다음 중 하나\n Task Task void - 비동기 이벤트 처리기 작성 GetAwaiter 포함 모든 기타 형식   await 을 만나면 yield 함 (호출자로 제어가 돌아감)  이때, Task가 호출자에게 반환되고 이는 언젠가 다운로드된 문자열의 길이가 반환된다는 약속 (future) 을 의미한다. await 전에 작업이 완료된다면 제어가 돌아가지 않는다.    스레드  비동기 메서드의 await 식은 대기한 작업이 실행되는 동안 현재 스레드를 차단하지 않는다. 대신, 메서드의 나머지를 연속으로 등록하고 비동기 메서드 호출자에 반환.\nasync / await 으로 인해 스레드가 추가로 생성되지 않는다.\n비동기 메서드는 자체 스레드에서 실행되지 않고 현재 동기화 컨텍스트에서 실행되며,\n활성화된 경우에만 스레드에서 시간을 사용.\n","permalink":"https://nolleh.github.io/csharp/async-await-msdn/","summary":"개요   다음에서 발췌 MSDN\n 반응성을 향상시키는 비동기  잠재적인 차단 작업 완료 될때까지 다른 작업을 게속 수행\n작성이 간편한 비동기 메서드  반환 형식은 다음 중 하나\n Task Task void - 비동기 이벤트 처리기 작성 GetAwaiter 포함 모든 기타 형식   await 을 만나면 yield 함 (호출자로 제어가 돌아감)  이때, Task가 호출자에게 반환되고 이는 언젠가 다운로드된 문자열의 길이가 반환된다는 약속 (future) 을 의미한다. await 전에 작업이 완료된다면 제어가 돌아가지 않는다.","title":"Async Await 을 사용한 비동기 프로그래밍"},{"content":"Dispose 에 대한 여러가지 MSDN  Implementing a Dispose method\n threadSafety  stackoverflow dispose 의 threadsafety\n 많은 경우 어떤 스레드든지 다른 스레드가 dispose 를 시작했을때 오브젝트에 대해 작업을 하고 있을 수 있기 때문에, interlocked.Exchange 를 통해 배제하는게 옳아 보인다.\n물론, 좋은 생각이고 표준 dispose 패턴의 일부가 되어야 한다고 생각한다.\n(champareExchange가 base class 에 봉인됨으로써 derived class 에서 private 한 disposed flag 를 사용하는 것을 피해야한다.)\n하지만 불행히도, dispose 가 정확히 어떤것을 하는지 생각해보면 문제는 좀 더 복잡해진다.\nDispose 의 진짜 목적은 그 오브젝트가 버려지게 하는 목적이라기보다, 그 오브젝트가 들고 있는 레퍼런스를 비우는데 목적이 있다.\n이 엔터티 들은 managed objects 일 수도 있고, system object 일수도 있고, 다른 어떤 것일 수도 있다; 심지어 같은 컴퓨터에 존재하지 않을 수도 있다.\nthread-safe 하려면, 이 Dispose 가 정리하는 동시에 다른 스레드가 이를 가지고 다른 일을 할 수 있도록 다른 엔티티들이 허용해야한다.\n어떤 객체들은 이렇게 할 수 있지만, 그렇지 않은 객체들도 있다.\n짜증나는 예를 들어보자: 객체들은 thread-safe 하지 않은 RemoveHandler 이벤트를 갖도록 허용되어있다. 결과적으로, 구독이 이루어졌던 그 스레드에서만 Dispose 를 호출하도록 해야한다.\n","permalink":"https://nolleh.github.io/csharp/dispose/","summary":"Dispose 에 대한 여러가지 MSDN  Implementing a Dispose method\n threadSafety  stackoverflow dispose 의 threadsafety\n 많은 경우 어떤 스레드든지 다른 스레드가 dispose 를 시작했을때 오브젝트에 대해 작업을 하고 있을 수 있기 때문에, interlocked.Exchange 를 통해 배제하는게 옳아 보인다.\n물론, 좋은 생각이고 표준 dispose 패턴의 일부가 되어야 한다고 생각한다.\n(champareExchange가 base class 에 봉인됨으로써 derived class 에서 private 한 disposed flag 를 사용하는 것을 피해야한다.)\n하지만 불행히도, dispose 가 정확히 어떤것을 하는지 생각해보면 문제는 좀 더 복잡해진다.","title":"Dispose"},{"content":"NeoSmart.AsyncLock 라이브러리에 관하여  다음에서 발췌, 번역 - Neosmart Docs.\n 개요  semaporeslim 은 reentrance 를 지원하지 않는다. 따라서, recursion 에서 적절히 사용되지 않으면 데드락이 발생한다.\nasynclock 은 reentrance 기능을 semaphoreslim 에 추가한거.\n대안  간단한 방법은 semaphoreslim 으로 교체하고, recursion 인 경우를 스레드 아이디로 확인 하는 것.\n이 경우의 문제는\nasync / await 의 가장 기본적인 목적인 ui 의 불필요한 블럭킹 없이 작업의 완료를 기다린다는 문제를 그대로 안고 있다.\nawait 코드를 넣어도 다른 코드가 실행 될 수 없다.\nclass ThreadIdConflict { BadAsyncLock _lock = new BadAsyncLock(); async void Button1_Click() { using (_lock.Lock()) { await Task.Delay(-1); //at this point, control goes back to the UI thread } } async void Button2_Click() { using (_lock.Lock()) { await Task.Delay(-1); //at this point, control goes back to the UI thread } } } 원래 메인스레드는 메시지 펌핑을 하면서 콜백을 호출해주는 구조로 되어 있고,\n\u0026ldquo;hard\u0026rdquo; await 을 마주쳐서 메인 ui 로 돌아갈때도\n이벤트 핸들러의 실행을 일시 정지하지만 실제 스레드가 동작을 멈추지는 않는다.\nawait 이 완료 되고 나면, continuation 이 다시 main 스레드에서 실행된다.\n여기에서 중요한 것은, 항상 같은 스레드가 실행된다는 것이다. (non- awaited async 함수 호출을 제외하고.) Button1_Click() 을 실행한 스레드가 await 을 만나 동작을 정지하고, 이후 Button2_cllick 을 호출한다. Button1_click() 의 남은 코드는 옆에 놓여지는거지, 실제로 정지 되는것이 아니다. 이 의미는, Button2_click 이 실행되어야할 때 Button1_click() 은 세마포어를 통해 상호 배제적인 접근을 하고 있으므로 접근 불가해야하나, owningthreadId 가 같으므로 두 메소드가 동시에 실행된다.\nAsyncLock  그럼 어떻게 해야하는가? recursion 을 체크하기위해 뭔가 다른 방법을 찾아야한다. Envrionment 클래스를 통해 스택 트레이스에 접근 할 수 있다. 이를 락을 얻기 위한 요건으로 사용할 수 있지 않을까 ?\n Update 5/25/2017 (AsyncLock 은 이제는 taskid 를 통해 확인하고 있다. )\n List _stackTraces = new List(); async Task Lock() {  if (!lock.locked)  {  _stackTraces.Add(Environment.StackTrace);  lock.Wait();  return true;  }  else if (_stackTraces.Peek().IsParentOf(Environment.StackTrace))  {  _stackTraces.Add(Environment.StackTrace);  return true;  }  else  {  //wait for the lock to become available somehow  return true;  } } Lock() 의 호출이 스택추적을 낭비하지 않는다고 가정하면,(?) isParentOf 메소드가 현재 호출이 저장된 스택트레이스의 자식인지 확인한다.\n하지만 이런 접근은 첫번째 솔루션으로는 쉽게 해결 됐을 다음 코드를 처리하지 못한다.\nclass StackTraceConflict {  BadAsyncLock _lock = new BadAsyncLock();   async void DoSomething()  {  using (_lock.Lock())  {  await Task.Delay(-1);  }  }   void DoManySomethings()  {  while(true)  {  DoSomething(); //no wait here!  }  } } 모두 같은 지점에서 실행되기 때문에 다른 스레드에서 같은 스택트레이스를 갖게 되고 완벽하게 실패하게 된다!\n따라서 적절한 솔루션은, 두 솔루션을 결합하는 것이다.\nclass AsyncLockTest {  AsyncLock _lock = new AsyncLock();  void Test()  {  //the code below will be run immediately (and asynchronously, in a new thread)  Task.Run(async () =\u0026gt;  {  //this first call to LockAsync() will obtain the lock without blocking  using (await _lock.LockAsync())  {  //this second call to LockAsync() will be recognized as being a reëntrant call and go through  using (await _lock.LockAsync())  {  //we now hold the lock exclusively and no one else can use it for 1 minute  await Task.Delay(TimeSpan.FromMinutes(1));  }  }  }).Wait(TimeSpan.FromSeconds(30));   //this call to obtain the lock is synchronously made from the main thread  //It will, however, block until the asynchronous code which obtained the lock above finishes  using (_lock.Lock())  {  //now we have obtained exclusive access  }  } } task 가 먼저 실행되도록 하기위해 30 초를 대기했다가 평범하게 락을 건다.\n첫번째 락은 평범하게 얻어진 뒤에, 다시 reentrant call 이 발생하고, 이것 또한 넘어가게 된다. (# await 실행된 스레드아이디 + 실행된 콜스택의 부모)\nTask.Delay 를 마주쳐서 스레드는 pause 상태로 전환되고, 이 시간동안 공유되는 리소스에 대해 배제적 접근을 하게 된다.\n30 초 뒤에 lock 을 얻으려고 시도할때, 이 시도는 실패하게 되고\n다시 30초 뒤에 task 가 완료되어 lock 을 release 하게 되면 메인스레드가 락을 얻어 동작이 재개 된다.\n이 코드 조각은 두개의 락 옵션을 사용하고 있다. Lock() 과 LockAsync() 인데, 이들은 둘다 기본 개념은 같고, async 메소드는 async/ await 패러다임을 품어 이 실행이 lock 이 사용 가능할때에 새로 얻을 수 있도록 한 개념이다. 이렇게 해서 await lock.LockAsync() 가 블러킹 되지 않도록 한 것이다.\n","permalink":"https://nolleh.github.io/csharp/async-await/","summary":"NeoSmart.AsyncLock 라이브러리에 관하여  다음에서 발췌, 번역 - Neosmart Docs.\n 개요  semaporeslim 은 reentrance 를 지원하지 않는다. 따라서, recursion 에서 적절히 사용되지 않으면 데드락이 발생한다.\nasynclock 은 reentrance 기능을 semaphoreslim 에 추가한거.\n대안  간단한 방법은 semaphoreslim 으로 교체하고, recursion 인 경우를 스레드 아이디로 확인 하는 것.\n이 경우의 문제는\nasync / await 의 가장 기본적인 목적인 ui 의 불필요한 블럭킹 없이 작업의 완료를 기다린다는 문제를 그대로 안고 있다.","title":"Async Await"},{"content":" Nancy 에 대한 문서 번역 #1. By Nolleh\n Introduction  가장 먼저, Nancy 의 세계에 온것을 환영합니다!\n루비의 sinatra 프레임워크에 영감을 받아 Nancy 라는 이름을 붙이게 되었습니다. (Frank Sinatra 의 딸이름이 Nancy 니까요!)\nNancyFx 의 Fx 에 대해 많은 사람들이 궁금해하여 여기에 붙입니다만, framework 라는 뜻입니다 :)\nNancyFx 는 모든 컴포넌트들을 포함하는 umbrella project 입니다. (#역자주: 우산효과의 우산처럼, 포괄적인 프로젝트라는 의미로 쓴게 아닐까? )\n이 가이드는 앞으로 개괄적이고 빠르게 Nancy 의 특징들을 살펴 독자 스스로 Nancy 의 세계를 탐험해 볼 수 있는 시야를 제공할겁니다.\nNancy 는 가볍고, 적은 준비의식(#역자주: 라이브러리를 쓰기 위한 선제 작업)의 HTTP 기반의 서비스를 개발할 수 있는 .Net 과 Mono 기반 프레임 워크입니다.\n이 프레임워크의 목적은 모든 상호 통신(ineractions)을 신경쓰지 않으면서도 동시에 슈퍼-엄청-행복한 방법으로-(super-duper-happy-path) 제공하는 것입니다.\n이 말은 Nancy 를 통한 모든 것들이 당신을 개고생하게 만드는 설정 지옥에서 벗어날 수 있도록 관습적이고/기본적인 설정 값을 적극 활용하는 것을 의미합니다.\nNancy 와 함께라면 아무것도 없는 상태에서 수 분안에 웹사이트를 만들 수 있습니다. 문자 그대로요!!\nNancy 는 DELETE, GET, HEAD, OPTIONS, POST, PUT, PATH 요청을 단순하고 우아한 Domain Specific Language (DSL) 을 몇번의 타이핑만으로 응답으로 전달하도록 디자인 되어 있어 당신은 다른 좀 더 중요한 당신의 코드, 당신의 어플리케이션에 집중 할 수 있도록 하였습니다.\n이 모든 것들은 MIT License 의 오픈 소스 입니다.\nNuget, our TeamCity Server 와 github repository 로부터 살펴 보실 수 있습니다.\nBuilt to run anywhere  원하는 곳 어디에서든 빌드되고 실행될 수 있습니다.\nNancy 는 어떤 존재하는 프레임워크에도 의존성이 없도록 디자인 되었습니다.\nrequest / response 객체 전부 자체에 포함되어 있으므로, .NET framework client profile 을 통해 빌드하여 Nancy 는 당신이 원하는 곳 어디에서든 사용될 수 있습니다.\nNancy 의 핵심 개념중의 하나로 hosts 가 있습니다. 하나의 호스트는 nancy 와 호스팅 환경의 어댑터로서 동작하게 되므로 Nancy 를 기존의 존재하는 - ASP.Net, WCF, OWIN, 다른 통합 응용프로그램 - 기술에서 활용해보십시오.\n특정 호스트 구현은 Nancy 프레임워크의 핵심 기능을 제공하지 않을 수 있습니다. 이런 추가기능들 - 인증과 같은- 은 개별로 제공됩니다.\nNancy 응용 프로그램을 빌드하는 것은 웹프레임워크의 buffet 으로부터 가장 좋아하는 부분을 뽑아내는 것과 같습니다! Nancy 서비스를 빌드하는데 사용할 최소한의 부분은 핵심 프레임워크와 host 가 될 것입니다.\nThe super-duper-happy-path  그 \u0026ldquo;super-duper-happy-path\u0026rdquo; (말을 줄이길 좋아하는 요새 사람들을 따르자면 SDHP 랄까요?) 란, Nancy 의 정신을 바로 짚는 용어라 하겠습니다;동시에 Nancy 의 API 를 이용하는 동안 \u0026ldquo;슈퍼-엄청-행복한-길\u0026rdquo; 에 대한 경험을 당신에게 제공하는 것이라 할 수도 있겠네요.\n결국에는 대단히 감정적 용어이기때문에 정확히 어떤 것인지 짚어보기 전에 이 배후의 아이디어를 살펴보도록합시다.\n  \u0026ldquo;그냥 동작해\u0026rdquo; - 이것 저것 할것 없이 하나 집어서 사용하면 됩니다. 새로운 모듈을 추가한다? 이것들은 다 당신을 위해 자동으로 이뤄집니다. 새로운 뷰 엔진을 쓴다? 당신은 아무것도 할 것 없이, 미리 준비되어 있습니다. 당신 모듈에 새로운 의존성을 추가하는 것마저 자동으로 injection 해줄겁니다! - 설정노노해!-\n  \u0026ldquo;쉬운 커스터 마이즈\u0026rdquo; - \u0026ldquo;그냥 동작해\u0026rdquo; 와 같은 기능이 커스터마이즈를 어렵게 할 것 같지만 그렇지 않습니다. 다른 컨테이너를 원하세요? 문제 없어요! 라우딩 되는 다른 경로를 원하세요 ? 하세요! 우리의 bootstrapper 가 이 모든 것들을 누워서 떡먹게 해줍니다.\n  \u0026ldquo;적은 준비 의식\u0026rdquo; - 당신의 응용 프로그램을 위한 Nancy code 의 양은 아주 적습니다. Nancy 응용프로그램의 중요한 부분은 당신의 코드입니다. 실제 동작하는 Nancy 어플리케이션이 다음의 한 개의 트위터 글로 작성될 수 있다는 게 바로 그 증거죠.\n  \u0026ldquo;적은 마찰\u0026rdquo; - Nancy 로 소프트웨어를 빌드할때 API 들이 도와줄 것입니다. 이름은 명확하고 요구되는 설정은 최소한이지만 강력한 성능과 확장성은 당신이 필요로 할 때 여전히 그 자리에 있어 줄 겁니다 :)\n  위 내용들을 종합해 볼때, Nancy 로 응용프로그램을 작성하는 것은 즐겁고 재밌을거예요! 하지만 응용프로그램이 성장할 수록 성능이나 확장성을 포기해야할 때가 올 수도 있죠..\nCreating your first Nancy application  이야기는 이제 충분합니다. 이제 코드를 봅시다! Nuget (혹은 Mono) 은 설치되어 있을 것이라 가정하겠습니다.\n(우리곁의 어디에나 있는) 유비쿼터스 \u0026ldquo;Hello World\u0026rdquo; 응용프로그램을 Nancy 와 Nancy 의 ASP.NET 호스팅으로 빌드해보겠습니다.\n  visual studio 2012 이상이라면 SideWaffle Template Pack for Visual Studio 을, 2010 사용자라면 Nancy project templates 을 설치합시다.\n  Nancy empty project with ASP.NET host 메뉴 (sidewaffle) / Nancy Empty Web Application with ASP.NET Hosting 메뉴 (Nancy project template) 를 선택합니다.\n  Nancy Module 을 C# 클래스로 추가하고 root url 에 라우트 핸들러를 생성자에 작은 코드를 넣어 정의합니다:\n  Compile and run to see result !\n  강제하진 않지만 권장하는 내용으로, 새로운 업데이트를 체크하기 위해 Nuget Package Manager 를 사용해보세요.\n  The HelloModule.cs code\npublic class HelloModule : NancyModule {  public HelloModule()  {  Get[\u0026#34;/\u0026#34;] = parameters =\u0026gt; \u0026#34;Hello World\u0026#34;;  } } 모듈을 public 으로 선언하지 않으면 NancyFx 가 찾을 수 없으므로, 잊지마세요!\nMore Info  - Why use NancyFX?\n","permalink":"https://nolleh.github.io/nancy/introduction/","summary":"Nancy 에 대한 문서 번역 #1. By Nolleh\n Introduction  가장 먼저, Nancy 의 세계에 온것을 환영합니다!\n루비의 sinatra 프레임워크에 영감을 받아 Nancy 라는 이름을 붙이게 되었습니다. (Frank Sinatra 의 딸이름이 Nancy 니까요!)\nNancyFx 의 Fx 에 대해 많은 사람들이 궁금해하여 여기에 붙입니다만, framework 라는 뜻입니다 :)\nNancyFx 는 모든 컴포넌트들을 포함하는 umbrella project 입니다. (#역자주: 우산효과의 우산처럼, 포괄적인 프로젝트라는 의미로 쓴게 아닐까? )\n이 가이드는 앞으로 개괄적이고 빠르게 Nancy 의 특징들을 살펴 독자 스스로 Nancy 의 세계를 탐험해 볼 수 있는 시야를 제공할겁니다.","title":"Nancy Introduction"},{"content":" 네트워킹의 바이블이라 할 수 있는 Unix Network Programming 의 내용 정리\n Books Introduction Socket 을 통해 통신하는 프로그램을 작성하는 개발자를 위해 쓰여진 책.\n시작하는 사람에게나, 프로페셔널에게나 유용한 책.\n물론 유지보수를 하거나, 새로 작성하는 사람, 네트워크 시스템 함수를 이해하는 모두에게 유용하다.\n실제 텍스트들은 유닉스 시스템에서 구동가능하나, OS 에 독립적인 socket api 를 지원하는 다른 OS 에서도, 본문에서 제안하는 일반적인 개념을 활용가능하다.\n많은 OS 는 셀수 없이 많은 네트워크 응용프로그램을 제공하고 있으며 - 예컨데 웹브라우저, email.. 이 프로그램들을 클라이언트와 / 서버로 분류하여 언급할 것이다.\nUsing This Book 초심자와 전문 프로그래머 모두 활용가능하다. 튜토리얼이 목적이라면 Part2 에 포커스를 맞추면 좋으며, 여기서 TCP 와 UDP, SCTP 모두에 대한 소켓 함수를 다루고 I/O multiplexing, socket options, basic name, address conversion 등을 다룬다.\nSection 1.4 에서는 본문 전체에서 다루는 래퍼펑션들이 소개된다.\nPart 3 에서는 \u0026ldquo;진화된 소켓\u0026rdquo; 에 대해 다루므로 아무나 읽어도 된다.\n소스코드는, 여기\nunpbook\n","permalink":"https://nolleh.github.io/network/unix-01-intro/","summary":"네트워킹의 바이블이라 할 수 있는 Unix Network Programming 의 내용 정리\n Books Introduction Socket 을 통해 통신하는 프로그램을 작성하는 개발자를 위해 쓰여진 책.\n시작하는 사람에게나, 프로페셔널에게나 유용한 책.\n물론 유지보수를 하거나, 새로 작성하는 사람, 네트워크 시스템 함수를 이해하는 모두에게 유용하다.\n실제 텍스트들은 유닉스 시스템에서 구동가능하나, OS 에 독립적인 socket api 를 지원하는 다른 OS 에서도, 본문에서 제안하는 일반적인 개념을 활용가능하다.\n많은 OS 는 셀수 없이 많은 네트워크 응용프로그램을 제공하고 있으며 - 예컨데 웹브라우저, email.","title":"Unix 01 Intro"},{"content":" 어쩌다보니 그동안 손댈 일이 없던 웹서버에 좀 손을 대게 되서 (게임서버, 클라이언트, 그리고 웹서버..정녕 풀스택 개발자가 되는것인가..ㅋ), 예전 선배님이 버리고 간(?) 스프링 책을 꺼내서 읽어 보며 정리한 내용이므로 본 글을 처음 접한 사람이 이해하기에 많은 내용을 담지 않을 수 있음.\n Spring Bean 객체 스프링에서 생성하여 관리하여 주는 스프링 빈 객체 혹은 빈 객체라고 부른다. res/applicationContext.xml 에 태그로 선언할 수도 있다. 이렇게 선언한경우, 리플렉션을 활용하여 bean id 클래스의 인스턴스를 지정한 세부 태그의 속성으로 메서드를 호출하여 객체를 초기화한다.\nApplicationContext 스프링에서 제공하는 인터페이스. 컨테이너가 제공해야할 기본 기능 정의. BeanFactory 인터페이스를 상위에 두고 있다.\nApplicationContext::getBean 인자는 이름/타입. 이를 통해 빈객체를 얻어올 수 있다.\nSpring DI 설명이 장황한데, 여기서의 의존은 (composite 패턴으로) 다른 객체를 요할때를 의미한다.\n 생성자를 통해 객체를 받거나 다른 멤버메서드를 통해 객체를 받거나  DI 의존성을 주입하는 방식으로, 외부로부터 의존객체를 전달 받는 구현 방식을 의미한다.\n스프링은, 결국 DI 컨테이너다.\nXML 을 통한 DI 설정  \u0026lt;beans xmlns=\u0026#34;http://www.springframework.org/scheme/beans\u0026#34;...\u0026gt;  \u0026lt;bean id=\u0026#34;식별자\u0026#34; class=\u0026#34;클래스명\u0026#34;\u0026gt;  \u0026lt;constructor-arg value=\u0026#34;test\u0026#34;/\u0026gt;  \u0026lt;constructor-arg ref=\u0026#34;Other Bean\u0026#34;/\u0026gt;  \u0026lt;property name=\u0026#34;프로퍼티명\u0026#34;\u0026gt;  \u0026lt;value\u0026gt;프로퍼티값\u0026lt;/value\u0026gt;  \u0026lt;/property\u0026gt;  \u0026lt;/bean\u0026gt; \u0026lt;/beans\u0026gt; 프로퍼티 지정시, 역시 리플렉션을 활용, set{PropertyName}() 을 이용하여 값을 설정한다.\n 스프링의 property 태그는 자바빈 규약에 따른다.  자바코드를 이용한 DI 설정 org.stringframework.annotation.AnnotationConfigApplicationContext 빈컨테이너 사용\n@Configuration 클래스를 스프링 설정으로 사용함을 의미\n@Bean 메서드의 리턴값을 빈 객체로 사용함을 의미\nexample @configuration public class Config {  @Bean  public User user1() {  return new User(\u0026#34;nolleh\u0026#34;);  } } 요렇게 선언하고\nAnnotationConfigApplicationContext ctx =  new AnnotationConfigApplicationContext(Config.class);  User user1 = ctx.getBean(\u0026#34;user1\u0026#34;, User.class); 요렇게 쓴다.\n생성자나 프로퍼티 값 설정시 직접 호출하면 된다.\nset{프로퍼티}(..);\n끝\n","permalink":"https://nolleh.github.io/web/fund-spring/","summary":"어쩌다보니 그동안 손댈 일이 없던 웹서버에 좀 손을 대게 되서 (게임서버, 클라이언트, 그리고 웹서버..정녕 풀스택 개발자가 되는것인가..ㅋ), 예전 선배님이 버리고 간(?) 스프링 책을 꺼내서 읽어 보며 정리한 내용이므로 본 글을 처음 접한 사람이 이해하기에 많은 내용을 담지 않을 수 있음.\n Spring Bean 객체 스프링에서 생성하여 관리하여 주는 스프링 빈 객체 혹은 빈 객체라고 부른다. res/applicationContext.xml 에 태그로 선언할 수도 있다. 이렇게 선언한경우, 리플렉션을 활용하여 bean id 클래스의 인스턴스를 지정한 세부 태그의 속성으로 메서드를 호출하여 객체를 초기화한다.","title":"스프링 기본 용어/정리"},{"content":" 다음에서 발췌, 번역\n https://msdn.microsoft.com/en-gb/library/windows/desktop/cc644950(v=vs.85).aspx   File Buffering 파일버퍼링 - unbuffered file I/O.\n본문에선 시스템에 의해 캐싱되지 않는 (buffered) 데이터를\n어떻게 유저 모드의 응용프로그램에서 데이터를 활용할 수 (interact) 있을지에 대해 다룬다.\nFILE_FLAG_NO_BUFFERING 플래그를 통해 CreateFile 을 Open 하면,\n파일을 읽거나 쓸때 시스템의 캐싱을 비활성화 하도록 제어할 수 있다.\nI/O 버퍼링을 사용한것과 같은 효과를 내려면, 데이터 alignment 가 반드시 고려되어야 한다.\nNote 파일에 대해 Seeking 과 위치포인터, offsets 의 개념을 사용하는 파일에 대해 alignment 정보가 고려될 필요가 있다.  물리 디스크와 파일 시스템 저장소의 계층에서 write 연산은 alignment 기준을 맞추지 못한다면 실패 할 것이다.\nAlignment and File Access Requirement 다음을 만족시켜야한다.\n 파일 접근 사이즈. OVERLAPPED 구조체의 offset 을 포함해서,\n지정된다면 volume 의 섹터사이즈의 정수배로 지정되어야한다. 읽기/쓰기 연산의 버퍼주소는 물리적 섹터에 aligned 되어있어야 한다.\n즉, 물리 섹터 사이즈의 정수배로 메모리가 주소에 정렬되어 있어야함을 의미한다.\n디스크에 따라 강제사항이 아닐 수도 있다.  4096 byte 의 미디어 섹터사이즈가 시장에 나온 것을 고려해야하는데,\n일시적인 방안으로, ATA / SCSI 명령어를 통해 일반적인 512 바이트의 섹터 저장소가\n에뮬레이트 되도록 할 수 있다.\n이 에뮬레이트를 사용할때, 다음 두 가지를 알아야한다.\n 논리섹터: 미디어에 접근할때 사용되는 논리 블럭의 단위. 이 부분이 바로 \u0026ldquo;emulation\u0026rdquo; 물리섹터: 읽기/쓰기가 하나의 연산으로 이뤄지는 단위. 최적의 성능과 신뢰성을 위해 unbuffered I/O 가 aligned 되어야하는 단위이기도 하다.  IOCTL_DISK_GET_DRIVE_GEOMETRY 와 GetDiskFreeSpace 를 통해 논리 섹터사이즈를 알 수 있으며,\nIOCTL_STORAGE_QUERY_PROPERTY 제어코드와\nSTORAGE_ACCESS_ALIGNMENT_DESCRIPTOR 구조체의\nBytesPerPhysicalSector 멤버의 사용을 통해 물리 섹터 사이즈를 구할 수 있다.\nWindows Server 2003 과 XP 에서는 STORAGE_ACCESS_ALIGNMENT_DESCRIPTOR 가 지원되지 않는다.  섹터 align 버퍼를 얻기 위해 VirtualAlloc 함수를 사용할 수 있다.\n VertualAlloc 은 메모리를 시스템페이지의 정수배의 사이즈로 align 되도록 메모리를 할당한다.\nx64 나 x86 에서는 4,096 바이트이며, Itanium-기반 시스템에서는 8,192 이다.\n더 자세한 정보는 GetSystemInfo 함수를 통해 얻을 수 있다. 직접 접근하는 저장소의 일반적인 섹터사이즈는 512 ~ 4,096 byte 이며, CD-ROM 에서는 2,048 바이트. 페이지/섹터사이즈 모두 2의 거듭제곱.  섹터사이즈가 페이지사이즈보다 큰 경우는 적기 때문에,\n대부분의 경우 page 에 align 된 메모리는 sector 에 대해서도 align 되어있다.\n수동으로 align 된 메모리버퍼를 얻는 또하나의 방법은 _aligned_malloc 함수를 사용하는 것이다.\n수동으로 align 된 버퍼를 사용하는 방법은 WriteFile 절의 예제코드를 살펴보라.\n","permalink":"https://nolleh.github.io/operating-system/file-buffering/","summary":"다음에서 발췌, 번역\n https://msdn.microsoft.com/en-gb/library/windows/desktop/cc644950(v=vs.85).aspx   File Buffering 파일버퍼링 - unbuffered file I/O.\n본문에선 시스템에 의해 캐싱되지 않는 (buffered) 데이터를\n어떻게 유저 모드의 응용프로그램에서 데이터를 활용할 수 (interact) 있을지에 대해 다룬다.\nFILE_FLAG_NO_BUFFERING 플래그를 통해 CreateFile 을 Open 하면,\n파일을 읽거나 쓸때 시스템의 캐싱을 비활성화 하도록 제어할 수 있다.\nI/O 버퍼링을 사용한것과 같은 효과를 내려면, 데이터 alignment 가 반드시 고려되어야 한다.\nNote 파일에 대해 Seeking 과 위치포인터, offsets 의 개념을 사용하는 파일에 대해 alignment 정보가 고려될 필요가 있다.","title":"파일 버퍼링"},{"content":" concurrent 프로그램을 작성할 때 고려해야할 몇가지 사항. 그리고 idiom.\n여러 서적에서 발췌하였으며, 정리 차원에서 작성한 내용이므로 본 글을 처음 접한 사람이 이해하기에 많은 내용을 담지 않을 수 있음.\n어쩌면 작성자의 부사수를 위한 자재가 될지도 모르겠\u0026hellip;(..)\n Concurrent ISSUE - Stack 이번엔 스택.\nif (!s.empty()) {  item = s.top();  s.pop(); } 인터페이스상의 문제이기 때문에 empty 와 top 사이의 safety 를 보장할 수 없다.\ntop() / pop() 도 마찬가지 -\u0026raquo; 조회되지 못하는 아이템이 있을 수 있다. (생각해보자.)\n해결을 위해 ?? -\u0026gt; Returning Pop ? \u0026ndash;\u0026raquo; 역시, 생각해보자. (Hint. Exception)\nOptions Reference 호출전 인스턴스 생성 필요. 생성자의 인자가 항상 제공 가능한 경우가 아닐때도.\n그리고 assign 필요. (Q. 이것이 무엇을 의미하는가? - C++ 개발지식이 있다면 대답할 수 있어야 한다.)\nMove Exception 만이 문제라면 이 선택으로 회피 가능할 수 있지 않은가.\n하지만.. 위와 마찬가지. (Q. 역시, 대답할 수 있어야 한다. )\nPointer 유저에게 메모리 관리 작업을 맡기는 것. (Q. 이게 문제라면, 어떻게 해결할 수 있겠는가?) 간단한 타입에 대해서는 오버헤드.\nCompounded Options 말그대로, 결합.\n끝\n","permalink":"https://nolleh.github.io/concurrency/concurrent-idiom-1-stack/","summary":"concurrent 프로그램을 작성할 때 고려해야할 몇가지 사항. 그리고 idiom.\n여러 서적에서 발췌하였으며, 정리 차원에서 작성한 내용이므로 본 글을 처음 접한 사람이 이해하기에 많은 내용을 담지 않을 수 있음.\n어쩌면 작성자의 부사수를 위한 자재가 될지도 모르겠\u0026hellip;(..)\n Concurrent ISSUE - Stack 이번엔 스택.\nif (!s.empty()) {  item = s.top();  s.pop(); } 인터페이스상의 문제이기 때문에 empty 와 top 사이의 safety 를 보장할 수 없다.\ntop() / pop() 도 마찬가지 -\u0026raquo; 조회되지 못하는 아이템이 있을 수 있다.","title":"Concurrent Idiom 1 - Stack"},{"content":"GitHub-Page 이런게 있다더라 ~ 라고 주변으로부터 처음 들은건 1~2년전이었던것 같은데\n갑자기 꽂혀서 git page 를 만들었다. (!!)\ngithub 에서는 1계정당 1 호스트를 제공하는 것 같고\n\u0026lt;ID\u0026gt;.github.io \n뭐 이런식? github 의 제공 영역은 repo 에 존재하는 index.html 을 repo 에 지정된 1 도메인과\n연결해주는 정도인 것 같다.\nRepository git 을 사용해 본 적이 있다면 간단하다.\n그렇다면 다음 절로 넘어가고, 그렇지 않다면, 다음을 따라하자.\ngithub 가입 이 항목에 있어 더 이상의 자세한 설명은 생략한다.\ngithub\nsshKey 여기를 따라하자.\ngithub-gen-sshkey\ngithub repo 생성  github 본인 메인 페이지에서 Repositories New 버튼 안내에 따라 따라하기  즉, 로컬의 git repo 대상 폴더에서 git init git add -A git commit -m \u0026ldquo;some-message\u0026rdquo; git remote add origin git@github.com:/.git git push -u origin master    이제 github 에 repository 를 올릴수 있게 되었다!\n내 Repo 를 GithubPage 로 지정하기 본 repo 에서 .github.com 의 index.html 을 찾도록 github 에 알려주자.\nMarkDown-To-HTML 잘은 모르겠지만.. github 페이지에서는 유독 MarkDown 을 통해\nhtml 을 작성하는게 잘 권장? 되어있는거 같고,\n 아마도 git page 의 최초 제공 목적 자체가 블로그가 아니라 위키 정리와 같은 마크업 언어로 간단하게 문서를 작성하는 데에 있었기 때문일거다 -  jekyll 이나 hugo 를 통해 MarkDown 으로 작성된 문서를 자동으로 html 로 생성할 수 있다.\nHugo 사실 jekyll 을 많이들 쓰고 있는 것 같고 공식적으로 지원? 하는 것 같은데 내 맥 PC 의 버전으로 ruby 가 잘 설치가 안되서 괴로워하던 중에 지인이 hugo 를 사용하는 것을 보고 그냥 hugo 를 선택했다. 나름 괜찮은 듯.\n공식 가이드는 다음을 살펴보면 되고,\nQuick-Start\n내가 따라가면서 확인한 주요한 내용은 다음과 같다.\nHugo OneStep # 휴고 설치 $ brew install hugo  # 사이트 생성 this/is/my/github/repo$ hugo new site  # 포스트 생성 this/is/my/github/repo$ hugo new post/hello-world.md  # 포스트 수정 this/is/my/github/repo$ vim content/post/hello-world.md  # 로컬에서 확인하기 this/is/my/github/repo$ hugo server ## http://localhost:1313 에서 확인 Hugo - 사이트 꾸미기 hugo 가 올바르게 generate 하기 위한 설정 값 지정 this/is/my/github/repo$ vim config.toml  ### .... config.toml baseurl = \u0026#34;https://nolleh.github.io\u0026#34; languageCode = \u0026#34;ko-KR\u0026#34; title = \u0026#34;The Computer Programmer, Nolleh\u0026#34; theme = \u0026#34;hello-programmer\u0026#34; Paginate = 2 # the number of posts per page disqusShortname = \u0026#34;your-disqus-short-name\u0026#34;  [params]  author = \u0026#34;nolleh\u0026#34;  locale = \u0026#34;ko-KR\u0026#34; hugo 의 테마 페이지를 예쁘게 구성하기 위해, 많은 개발자들이 오픈소스로 공개한 테마를 활용할 수 있다.\n Hugo-Theme-ShowCase All-Themes-Github  1 에서 각 테마의 섬네일을,\n2 에서 각 테마의 repository 를 확인하여 clone 받을 수 있다.\n본인의 gitpage repo root/themes 로 이동하여 2의 repo 를 clone, 위에서 기술한 config.toml 의 theme 항목을 지정하는 것으로 테마를 변경 할 수 있다.\nHugo - Generate 앞서 기술한 hugo - onestep 의 마지막 라인의 hugo server 라인을 통해 html 파일을 생성, http://localhost:1313 에서 확인할 수 있지만 이 html 들을 repo 에 올리면 css 파일을 찾지 못해 원하는 대로 페이지가 렌더링 되지 않는다.\ncss 파일을 서버에서 찾을 수 있도록\nhugo server 실행시 추가 파라메터를 제공, 로컬이 아니라 배포용의 html 을 생성할 수 있도록 하자.\n 이것때문에 얼마나 삽질을 했던지!  $ sudo hugo server --baseUrl=https://nolleh.github.io --destination=public/ --port=80 --appendPort=false Deploy Generate 할때, destination 을 public 으로 지정하였으므로 public 디렉토리에 생성된다. 이 폴더 전체를 다시 github repo 를 생성해서 올려두자.\nthis/is/my/github/repo/public$ git init this/is/my/github/repo/public$ git add -A this/is/my/github/repo/public$ git commit -m \u0026#34;my awesome site\u0026#34; this/is/my/github/repo/public$ git push ... 끝!\n","permalink":"https://nolleh.github.io/env/how-to-make-git-page/","summary":"GitHub-Page 이런게 있다더라 ~ 라고 주변으로부터 처음 들은건 1~2년전이었던것 같은데\n갑자기 꽂혀서 git page 를 만들었다. (!!)\ngithub 에서는 1계정당 1 호스트를 제공하는 것 같고\n\u0026lt;ID\u0026gt;.github.io \n뭐 이런식? github 의 제공 영역은 repo 에 존재하는 index.html 을 repo 에 지정된 1 도메인과\n연결해주는 정도인 것 같다.\nRepository git 을 사용해 본 적이 있다면 간단하다.\n그렇다면 다음 절로 넘어가고, 그렇지 않다면, 다음을 따라하자.\ngithub 가입 이 항목에 있어 더 이상의 자세한 설명은 생략한다.","title":"How To Make Git Page"},{"content":"Let\u0026rsquo;s 사족 처음 회사에 입사 했을 때 자리에는 Mac PC 만이 덩그러니 있었고, Mac 을 사용해본적 없던 꼬꼬마는 자연스럽게 윈도우 CD 를 인사팀에서 받아와서 깔고 있었드랬다.\n \u0026ldquo;기껏 좋은 컴퓨터 줬더니 넌 뭘하고 있는거니?\u0026rdquo;\n 라는 선배의 말을 듣고 그제야 맥에서도 안드로이드 개발이 되는거구나.. (이때는 현업 안드로이드 개발자였다.)\n하곤 윈도우 설치페이지를 취소하고 다시 맥 OS 를 부팅했었지.\n이때가, Mac OS 와의 첫 만남이었드랬다.\nBrew 뭐 전혀 관계 없는 얘기로 포스트를 열었지만.\n어쨌거나 그때부터 Mac 을 수년간 사용하면서 - 그때 쓰던 회사 Mac 은 여전히 내 사무실 책상의 한켠을 차지하고 있다 -\nMac 을 비롯한 Linux 계통에서 Windows 를 압도하는 장점을 들자면,\n 개발자를 위한 환경 설정이 간편하다\n 가 되겠다.\nMac 에서는 그 역할을 충실히 하는 요소 중에 하나가 \u0026ldquo;HomeBrew\u0026rdquo; 라 하겠고.\n[HomeBrew] (http://docs.brew.sh/)\nBrew 설치  다음 라인을 터미널에서 실행하자. brew 설치 자체도 이렇게 간편하다니.. Linux 계통은 보통 이렇게 one line 으로 다 해결이 된다.\n mkdir homebrew \u0026amp;\u0026amp; curl -L https://github.com/Homebrew/brew/tarball/master | tar xz --strip 1 -C homebrew Brew 를 통해 설치하기 Formula 라고 지칭하고 있는게 맞는지는 잘 모르겠지만.\nbrew 를 통해 프로그램/binary 를 설치할 경우 다음과 같이 실행\n최초 설치 $ Brew install ${Formula} 업데이트 $ Brew upgrade ${Formula} Brew Install 이 구 버전만 다운로드 받을 때 이건.. 맥을 사용한 지금까지 잘 모르고 있었던 건데,\nBrew 자체를 업데이트해서 formular 를 갱신할 필요가 있나보다.\n다음을 통한다.\n$ Brew update 업데이트시 다음 에러 노출시 $ Error: /usr/local must be writable! 다음 실행\nsudo chown -R $(whoami) /usr/local ","permalink":"https://nolleh.github.io/env/brew-update/","summary":"Let\u0026rsquo;s 사족 처음 회사에 입사 했을 때 자리에는 Mac PC 만이 덩그러니 있었고, Mac 을 사용해본적 없던 꼬꼬마는 자연스럽게 윈도우 CD 를 인사팀에서 받아와서 깔고 있었드랬다.\n \u0026ldquo;기껏 좋은 컴퓨터 줬더니 넌 뭘하고 있는거니?\u0026rdquo;\n 라는 선배의 말을 듣고 그제야 맥에서도 안드로이드 개발이 되는거구나.. (이때는 현업 안드로이드 개발자였다.)\n하곤 윈도우 설치페이지를 취소하고 다시 맥 OS 를 부팅했었지.\n이때가, Mac OS 와의 첫 만남이었드랬다.\nBrew 뭐 전혀 관계 없는 얘기로 포스트를 열었지만.","title":"Brew Install 이 구버전만 설치할 때"},{"content":"마크다운으로 포스팅하는 Git 페이지를 생성하였으니, 자주 사용되는 대표 문법 정리\n마크다운 문법\nHeading \u0026lsquo;#\u0026rsquo; 으로 처리하며, 단계별로 더 많은 \u0026lsquo;#\u0026rsquo; 을 사용한다.\n# Title ## Heading 1 ### Heading 2 결과\nTitle Heading 1 Heading 2 Listing Asterisk (*) 를 사용하여 순서 없는 목록을, 숫자를 사용하여 순서 있는 목록을 나타낸다.\n순서 없는 경우  이거닷 이거 중요해!  순서가 있는 경우  첫번째 순서 두번째~ 셋!!  Fonts **Bold** _Italic_ ~~CANCEL_LINE~~ Bold Italic CANCEL_LINE\nSRC ![Alt](경로 \u0026#34;Optional Tooltip MSG\u0026#34;) TABLE | Day | Meal | Price | | --------|---------|-------| | Monday | pasta | $6 | | Tuesday | chicken | $8 |    Day Meal Price     Monday pasta $6   Tuesday chicken $8    ","permalink":"https://nolleh.github.io/env/mark-down-syntax/","summary":"마크다운으로 포스팅하는 Git 페이지를 생성하였으니, 자주 사용되는 대표 문법 정리\n마크다운 문법\nHeading \u0026lsquo;#\u0026rsquo; 으로 처리하며, 단계별로 더 많은 \u0026lsquo;#\u0026rsquo; 을 사용한다.\n# Title ## Heading 1 ### Heading 2 결과\nTitle Heading 1 Heading 2 Listing Asterisk (*) 를 사용하여 순서 없는 목록을, 숫자를 사용하여 순서 있는 목록을 나타낸다.\n순서 없는 경우  이거닷 이거 중요해!  순서가 있는 경우  첫번째 순서 두번째~ 셋!!  Fonts **Bold** _Italic_ ~~CANCEL_LINE~~ Bold Italic CANCEL_LINE","title":"markDown 문법"},{"content":"파라미터가 없다면 DelegateToPointer 로 마샬링해서 전달하면되는데,\n이러면 파라미터를 마샬링할 기회가 주어지지 않는다는게 문제다.\n좀 구글링을 해봤는데,\n이런 포스트가 있었다.\n스택오버플로-파라미터와 함께 unmanaged 콜백으로 변환하기\n채택된 답변을 살펴보면 클래스 구조는 대략 다음과 같다.\n클래스 구조   NativeCallbackHandler - msclr::gcroot\u0026lt;OutputManaged^\u0026gt; m_owner (OutputLogManaged) 를 멤버로 보유. OutputLogManaged - native OutputLog* (m_nativeOutputLog) / 1의 Holder 를 보유 (m_nativeHandler)] / 그리고 managed 콜백을 보유 OutputLog - Native Callback 과 void* UserData 를 멤버로 보유.   이해하는데 주요한 클래스는 위 내용 정도인 듯.\n  Main 함수에서는 managed 로거와 native 에 적당한 콜백을 등록해 두고(OnError/GetNative()), Test 함수를 통해 콜백을 호출한다.\n  OutputLogManaged 에는 생성시에 1의 NativeCallbackHandler 가 생성되며 여기에 정의된 native callback 을 OutputLog 의 Callback 멤버변수에 세팅한다. 동시에 NativeCallbackHandler 를 this 로 해서 함께 UserData 라는 객체로 OutputLog 의 멤버로 등록을 한 상태이다.\n(다시 말해 OutputLog 의 UserData 에는 1의 인스턴스가, 같은 객체의 멤버 변수인 NativeCallback 타입에는 그 인스턴스의 함수가 등록이 되어있다.)\n  1의 콜백을 지닌 3 의 객체의 함수를 등록해두었고, 이 함수에서 1의 콜백을 호출하고 있으므로 1의 콜백이 호출이 되는데 (등록해두었던 umanaged 콜백이 호출되는 단순한 전개라 하겠다.)\n이때 OutputLog(3) 의 객체의 멤버함수(최초로 호출되는 콜백)에서 멤버변수로 보유한 NativeCallbackHandler(1) 객체를 1의 콜백의 파라미터로 전달, 콜백 등록 당시의 NativeCallbackHandler(1) 의 인스턴스를 얻어온다 (물론, 콜백을 여러개 등록할 수 있으므로. 각 인스턴스를 별도로 두는 것이 자연스럽다.)\n이 인스턴스의 멤버인 m_owner 를 통해 OutputLogManaged 의 managed 콜백을 호출한다.\n  내용을 말로 설명하려고하니 불필요하게 복잡해진 느낌인데,\n정리하면 다음과 같다.\nSummary unmanged 에서 Managed 의 객체를 들고 있다가 unmanaged 의 콜백이 호출될때 마샬링하여 Managed 의 콜백을 호출한다.\nC++/CLR 을 처음 접하고 필요에 따라 구글링으로 작업을 하다보니 managed 와 unmanged 사이에서 서로 멤버로 두려고 하면 컴파일 에러가 나길래 안되는 거구나..했는데.. 이런 기능이 있었나보다\u0026hellip;\nmsclr::gcroot\u0026lt;...\u0026gt;  gcroot 는 unmanaged 에서 managed 를 참조하는 방법이며, interop 에서는 레퍼런스 카운트를 하나 증가시킨다.\n참고 - gcroot 의 역할\n 약간 허무하군.. (그래 안되면 어떻게 쓰겠냐만서도.. )\n참고 - MSDN / How to: Declare Handles in Native Types\n","permalink":"https://nolleh.github.io/etc/managed_cb_to_unmanaged/","summary":"파라미터가 없다면 DelegateToPointer 로 마샬링해서 전달하면되는데,\n이러면 파라미터를 마샬링할 기회가 주어지지 않는다는게 문제다.\n좀 구글링을 해봤는데,\n이런 포스트가 있었다.\n스택오버플로-파라미터와 함께 unmanaged 콜백으로 변환하기\n채택된 답변을 살펴보면 클래스 구조는 대략 다음과 같다.\n클래스 구조   NativeCallbackHandler - msclr::gcroot\u0026lt;OutputManaged^\u0026gt; m_owner (OutputLogManaged) 를 멤버로 보유. OutputLogManaged - native OutputLog* (m_nativeOutputLog) / 1의 Holder 를 보유 (m_nativeHandler)] / 그리고 managed 콜백을 보유 OutputLog - Native Callback 과 void* UserData 를 멤버로 보유.   이해하는데 주요한 클래스는 위 내용 정도인 듯.","title":"C++ CLI 에서 managed 콜백을 unmanaged 로 전달하기"}]