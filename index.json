[{"content":"Graphical interface Learning Objectives By the end of this chapter, you should be able to:\nManage graphical interface sessions. Perform basic operations using the graphical interface. Change the graphical desktop to suit your needs. ","permalink":"https://nolleh.github.io/linux/4.graphical-interface/1.introduction/","summary":"Graphical interface Learning Objectives By the end of this chapter, you should be able to:\nManage graphical interface sessions. Perform basic operations using the graphical interface. Change the graphical desktop to suit your needs. ","title":"4-1.introduction"},{"content":"Summary Chapter Summary A partition is a logical part of the disk. A filesystem is a method of storing/finding files on a hard disk. By dividing the hard disk into partitions, data can be grouped and separated as needed. When a failure or mistake occurs, only the data in the affected partition will be damaged, while the data on the other partitions will likely survive. The boot process has multiple steps, starting with BIOS, which triggers the boot loader to start up the Linux kernel. From there, the initramfs filesystem is invoked, which triggers the init program to complete the startup process. Determining the appropriate distribution to deploy requires that you match your specific system needs to the capabilities of the different distributions. ","permalink":"https://nolleh.github.io/linux/3.linux-basics-and-system-startup/6.summary/","summary":"Summary Chapter Summary A partition is a logical part of the disk. A filesystem is a method of storing/finding files on a hard disk. By dividing the hard disk into partitions, data can be grouped and separated as needed. When a failure or mistake occurs, only the data in the affected partition will be damaged, while the data on the other partitions will likely survive. The boot process has multiple steps, starting with BIOS, which triggers the boot loader to start up the Linux kernel.","title":"3-6.summary"},{"content":"Linux Distribution Installation Choosing a Linux Distribution Questions to Ask when Choosing a Distribution What is the main function of the system (server or desktop)? What types of packages are important to the organization? For example, web server, word processing, etc. How much hard disk space is required and how much is available? For example, when installing Linux on an embedded device, space is usually constrained. How often are packages updated? How long is the support cycle for each release? For example, LTS releases have long-term support. Do you need kernel customization from the vendor or a third party? What hardware are you running on? For example, it might be X86, ARM, PPC, etc. Do you need long-term stability? Can you accept (or need) a more volatile cutting edge system running the latest software? Linux Installation: Planning the partition layout needs to be decieded at the time of installation. and you can always modify the design later, it is always easier to try and get it right to begin with.\nLinux Installation: Software Choices All installing include the bare minimum software for running a Linux distribution.\nMost installers also provide options for adding categories of software.\nAll installers set up some initial security features on the new system.\nIn some cases (such as Ubuntu), only an initial user is set up; direct root login is not configured and root access requires loggin in first as a normal user and then using sudo.\nLinux Installation: Install Source Many installers can do an installation completely automatically, using a configuration file to specify installation options.\nThis file is called a Kickstart file for Red Hat-based systems, an AutoYAST profile for SUSE-based systems, and Preseed file for Debian-based systems.\n","permalink":"https://nolleh.github.io/linux/3.linux-basics-and-system-startup/5.linux-distribution-installation/","summary":"Linux Distribution Installation Choosing a Linux Distribution Questions to Ask when Choosing a Distribution What is the main function of the system (server or desktop)? What types of packages are important to the organization? For example, web server, word processing, etc. How much hard disk space is required and how much is available? For example, when installing Linux on an embedded device, space is usually constrained. How often are packages updated?","title":"3-5.linux Distribution Installation"},{"content":"3-4. Linux FileSystem Basics Linux FileSystem Conventional disk filesystems: ext3, ext4, XFS, Btrfs, JFS, NTFS, vfat, exfat, etc. Flash storage filesystems: ubifs, jffs2, yaffs, etc. Database filesystems Special purpose filesystems: procfs, sysfs, tmpfs, squashfs, debugfs, fuse, etc. Partitions and Filesystems A partition is physically contiguous section of disk, or what appears to be so in some advanced setups.\nA filesystem is a method of storing/finding files on the hard disk (usually in a partition).\nOne can think of a partition as a container in which a filesystem resides, although in some circumstances,\na filesystem can span more than one partition if one uses symbolic links, which we will discuss much later.\nA comparison between filesystems in Windows and Linux is given in the accompanying table:\nWindows Linux Partition Disk1 /dev/sda1 Filesystem Type NTFS/VFAT EXT3/EXT4/XFS/BTRFS\u0026hellip; Mounting Parmeters DriveLetter MountPoint Base Folder (where OS is stored) C:\\ / The Filesystem Hierarchy Standard Linux system store their important files according to a standard layout called the Filesystem Hierarchy Standard (FHS), Having a starndard is designed to ensure that users, administrators, and developers can move between distributions without having to re-learn how the system is organized.\nMore About the Filesystem Hierarchy Standard All linux filesystem names are case-sensative.\n","permalink":"https://nolleh.github.io/linux/3.linux-basics-and-system-startup/4.linux-filesystem-basics/","summary":"3-4. Linux FileSystem Basics Linux FileSystem Conventional disk filesystems: ext3, ext4, XFS, Btrfs, JFS, NTFS, vfat, exfat, etc. Flash storage filesystems: ubifs, jffs2, yaffs, etc. Database filesystems Special purpose filesystems: procfs, sysfs, tmpfs, squashfs, debugfs, fuse, etc. Partitions and Filesystems A partition is physically contiguous section of disk, or what appears to be so in some advanced setups.\nA filesystem is a method of storing/finding files on the hard disk (usually in a partition).","title":"3-4.linux Filesystem Basics"},{"content":"Kernel, init and Services The Linux Kernel boot loader loads kernel and an initial RAM-based file system (initramfs) into memory, so it can be used directly by the kernel.\nkernel loaded, it immediately initializes and configures the computer\u0026rsquo;s memory and also configures all the hardware attached to the system.\nalso load user space applications.\n/sbin/init and Services Once kernel has set up all its hardware and mounted the root filesystem, the kernel runs sbin/init.\nthis then becomes the initial process, which then starts other processes to get the system running.\nMost other processes on the system trace their origin ultimately to init; exceptions include the so-called kernel processes.\nBesides starting the system, init is responsible for keeping the system running and for shutting it down cleanly.\nthis serial process had the system passing through a sequence of runlevels containing collections of scripts that start and stop services.\nEach runlevel supported a different mode of running the system.\nhowever, all major distributions have moved away from this sequential runlevel method of system initialization,\nalthough they usually emulate many System V utilities for compatibility purposes.\nNext, we discuss the new methods, of witch systemd has become dominant.\nStartup Alternatives SysVinit viewed things as a serial process, devided into a series of sequential stages.\nstartup did not easily take advantage of the parallel processing that could be done on multiple processors or cores. (each stage required completion before the next could proceed)\nfurthermore, shutdown and reboot was seen as a relatively rare event; exactly how long it took was not considered important. (this is no longer true)\nsome modern methods, such as use of containers, can require almost instantaneous startup times. Thus, systems now require methods with faster and enhanced capabilities.\nfinally, the older methods required rather complicated startup scripts, which were difficult to keep universal across distribution versions, kernel versions, architectures, and type of systems.\nThe two main alternatives developed were:\nUpstart\ndeveloped by Ubuntu and first included in 2006 Adopted in Fedora 9 (in 2008) and RHEL 6 and its clones systemd\nAdopted by Fedora first (in 2011) Adopted by RHEL 7 and SUSE Replaced Upstart in Ubuntu 16.04 while the migration to systemd was rather controversial, it has been adopted by all major distributions, and so we will not discuss the older System V method or Upstart.\nsystemd Features systemd replaced serialized set of steps with aggressive parallelization techniques, which make this faster largely.\ncomplicated shell script are replaced with simpler configuration files, which enumerates \u0026hellip;\npreprocess for services how to execute service startup indicate conditions of the service should be accomplished when startup is finished /sbin/init now just points to /lib/systemd/systemd\n","permalink":"https://nolleh.github.io/linux/3.linux-basics-and-system-startup/3.kernel-init-and-services/","summary":"Kernel, init and Services The Linux Kernel boot loader loads kernel and an initial RAM-based file system (initramfs) into memory, so it can be used directly by the kernel.\nkernel loaded, it immediately initializes and configures the computer\u0026rsquo;s memory and also configures all the hardware attached to the system.\nalso load user space applications.\n/sbin/init and Services Once kernel has set up all its hardware and mounted the root filesystem, the kernel runs sbin/init.","title":"3-3.kernel Init and Services"},{"content":"Cheatsheet - Shell 쉘 커맨드들을 자주 까먹곤 해서 자주쓰는것 위주로 생각날때마다 하나씩 등록 예정.\nPrimitives if statement if [ 10 -gt 20 ]; then echo \u0026#39;gt\u0026#39;; else echo \u0026#39;lt\u0026#39;; fi; operator desc ! not true -n 문자열의 길이가 0보다 크다 -z 문자열의 길이가 0이다 = 문자열이 같다 -eq 정수가 같다 -gt 정수가 크다 -lt 정수가 작다 -d dir dir 디렉토리가 있다 -e file file 이 있다 for statement for file in *.sh; do echo $file; done echo 로 출력해보면 마지막 값이 나오는것을 보면, file 이라는 변수에 값을 하나씩 할당하고\nfor 문 바깥에서도 유효함 (스코프바깥) 이 확인된다.\nheredoc cat \u0026gt; file.txt \u0026lt;\u0026lt;EOF hello this is nolleh EOF 표준입력으로부터 파일을 생성하는 구문이다. 이렇게도 사용할 수 있지만, 쉘스크립트를 사용할때 아래와 같은 구문을 작성함으로써 복수의 라인을 변수로 선언하는 형태로도 사용가능하다.\nsql=$(cat \u0026lt;\u0026lt;EOF SELECT foo, bar FROM db WHERE foo=\u0026#39;baz\u0026#39; EOF ) Futher strip string let\u0026rsquo;s say you want to strip \u0026lsquo;sh\u0026rsquo;\necho ${a/.sh} 궁금해서 이렇게도 돌려봄.\ntest=aaabbb echo ${test/a} 결과는 aabbb recursive 하게 제거하지 않고, first occurrence 를 제거\ncurly brace 내부가 평가되어 rvalue 에 evaluation 될 수 있도록 감싸주는것을 잊지 말자.\nlist all files in directories 조금 재미있는건 이 명령어와\nfor file in ./*; do echo $file; done 이 명령어의 결과가 다르다는 점이다.\nfor file in *; do echo $file; done ls ./* 평가 결과와 ls *의 차이로 봐도 무관할듯.\n어떤 폴더의 결과를 출력할때 상대경로의 유무가 그 결과에도 함께 반영이 된다.\n만약 순수하게 파일명만 가져오고 싶다면 후자를 사용해야할 것.\n","permalink":"https://nolleh.github.io/cheatsheet/shell/","summary":"Cheatsheet - Shell 쉘 커맨드들을 자주 까먹곤 해서 자주쓰는것 위주로 생각날때마다 하나씩 등록 예정.\nPrimitives if statement if [ 10 -gt 20 ]; then echo \u0026#39;gt\u0026#39;; else echo \u0026#39;lt\u0026#39;; fi; operator desc ! not true -n 문자열의 길이가 0보다 크다 -z 문자열의 길이가 0이다 = 문자열이 같다 -eq 정수가 같다 -gt 정수가 크다 -lt 정수가 작다 -d dir dir 디렉토리가 있다 -e file file 이 있다 for statement for file in *.","title":"Shell"},{"content":"The Boot Process The Linux boot process is the procedure for initializing the system.\nfrom when the computer power is first swithced on until the user interface is fully operational.\nhaving a good understanding of the steps in the boot process may help you with troubleshooting problems, as well as with tailoring the computer\u0026rsquo;s performance to your needs.\nOn the other hand, the boot process can be rather technical, and you can start using Linux without knowing all the details.\nNOTE: You may want to come back and study this section later, if you want to first get a good feel for how to use a Linux system.\nBIOS - The First Step starting an x86-based Linux system involves a number of stps.\nthe Basic Input/Output System (BIOS) initializes the hardware, including the screen and keyboard, and tests the main memory.\nThis process is also called POST (Power On Self Test).\nThe BIOS software is stored on a ROM chip on the motherboard, After this, the remainder of the boot process is controlled by the operating system (OS).\nMaster Boot Record (MBR) and Boot Loader Once the POST is completed -\u0026gt; pass control to boot loader. boot loader is usually stored on one of the hard disks in the system, either in the boot sector (for traditional BIOS/MBR systems). or EFI partition (for more recent (Unified Extensible Firmware interface or EFI/UEFI systems).\nboot loader stored in \u0026hellip;\nhard disk, boot sector, EFI partition thereafter, date,time and the most important peripherals are loaded from CMOS values.\nA number of bootloaders exist for Linux;\nGRUB, ISOLINUX, DAS U-Boot when booting linux, the bootloader is responsible for loading the kernel image and the initial RAM disk or file system (contains some critical files and device drivers needed to start the system) into memory\nBoot Loader in Action BIOS/MBR system, boot loader resides at the first sector of the hard disk (MBR).\nin this stage, boot loader examines partition table and finds the bootable partition\nOnce it finds bootable partition, it then searches for the second stage boot loader, for example GRUB, and loads it into RAM.\nfind boot loader from first sector\nexamines partition table / find bootable partition\nsearch and loads second stage boot loader (ex. GRUB), and load to RAM EFI/UEFI system, UEFI firmware reads its Boot Manger data to determine which UEFI application is to be launched and from where (disk, EFI partition)\nthen launched the UEFI application, for example GRUB, as defined in he boot entry in the firmware\u0026rsquo;s boot maanger.\nthis procedure is more complicated, but more versatile than the older MBR methods.\nUEFI frimware read boot Manager and find UEFI application\nUEFI application launch (ex. GRUB, defined in boot entry in boot manager)\nmore versatile compaired with MBR\nthe second stage boot loader resides under /boot. after choosing the OS, the boot loader loads the kernel of the selected operating system into RAM\nand passes control to it. Kernels almost always compressed, so its first job is to uncompress it self. after this, check/analyze hardware and initialize drviers.\n/boot\u0026rsquo;s second stage boot loader load kernel and pass control to it.\nuncompress / check hardware / and initializes hard drivers.\nInitial RAM Disk initramfs filesystem image contains programs / and binary files that perform all actions needed to mount the proper root filesystem.\nex.\nproviding kernel functionality for the needed filesystem, device drivers for mass storage controllers with a facility called udev (figuraring out which devices are present, locating the device drivers they need to operate propery) root filesystem has been found, it is checked for errors and mounted. mount program instructs the operating system that a filesystem is ready for use, and associates it with a perticular point in the overall hierachy of the filesystem (the mount point).\nIf this is successful,, the initramfs is cleared from RAM and the init program on the root filesystem (/sbin/init) is executed.\ninit handles the mounting and pivoting over to the final real root filesystem. If special hardware drivers are needed before mass stroage can be accessed, they must be in the initramfs image.\nText-Mode Login init starts a number of text-mode login prompts. and to eventually get a command shell.\ndefault command shell is bash(the GNU Bourne Again Shell)\n","permalink":"https://nolleh.github.io/linux/3.linux-basics-and-system-startup/2.the-boot-process/","summary":"The Boot Process The Linux boot process is the procedure for initializing the system.\nfrom when the computer power is first swithced on until the user interface is fully operational.\nhaving a good understanding of the steps in the boot process may help you with troubleshooting problems, as well as with tailoring the computer\u0026rsquo;s performance to your needs.\nOn the other hand, the boot process can be rather technical, and you can start using Linux without knowing all the details.","title":"3-2.the Boot Process"},{"content":"Learning Objectives Identify Linux filesystems. Identify the differences between partitions and filesystems Describe the boot process. Install Linux on a computer. ","permalink":"https://nolleh.github.io/linux/3.linux-basics-and-system-startup/1.introduction/","summary":"Learning Objectives Identify Linux filesystems. Identify the differences between partitions and filesystems Describe the boot process. Install Linux on a computer. ","title":"3-1.introduction"},{"content":"Chapter Summary Linux boroows heavily from UNIX operating system, with withch its creators were well-versed. LInux accesses many features and services through files and file-like objects. Linux is a fully multi-tasking, multi-user operating system, with built-in networking and service processes known as deamons. Linux is developed by a loose confederation of developers from all over the world, collaborating over the Internet,\nwith Linus Torvalds at th head. Technical sill and a desire to contriubte are the only qualifications for participating. The Linux community is a far reaching ecosystem of developers, vendors , and users and supports and advances the Linux operating system. Some of common terms used in Linux are: kernel, distribution, boot loader, service, filesystem, X Windiow system, desktop environment, and command line, A full Linux distribution consists of the kerenl plus a number of other software tools for file-related operations, user management, and software package management. ","permalink":"https://nolleh.github.io/linux/2.linux-philosophy-and-concepts/6.chapter-summary/","summary":"Chapter Summary Linux boroows heavily from UNIX operating system, with withch its creators were well-versed. LInux accesses many features and services through files and file-like objects. Linux is a fully multi-tasking, multi-user operating system, with built-in networking and service processes known as deamons. Linux is developed by a loose confederation of developers from all over the world, collaborating over the Internet,\nwith Linus Torvalds at th head. Technical sill and a desire to contriubte are the only qualifications for participating.","title":"2-6.chapter summary"},{"content":"Linux Distribution Overview making sure that project works properly on the most widely used Linux distributions. To accomplish this, you need to learn amout the different components, services, and configurations associated with each distribution.\n","permalink":"https://nolleh.github.io/linux/2.linux-philosophy-and-concepts/5.linux-distribution/","summary":"Linux Distribution Overview making sure that project works properly on the most widely used Linux distributions. To accomplish this, you need to learn amout the different components, services, and configurations associated with each distribution.","title":"2-5.linux Distribution"},{"content":"Video: Linux Terminology Kernel: Glue between hardware and applications\nDitribution: Collection of software making up a Linux-based OS\nBootLoader: Program that boots the operating system\nService: Program that runs as a background process\nFilesystem: Method for sotring and organizing files\nX window System: toolkit and protocol to build graphical subsystem\nShell: command line interpreter\n","permalink":"https://nolleh.github.io/linux/2.linux-philosophy-and-concepts/4.linux-terminology-overview/","summary":"Video: Linux Terminology Kernel: Glue between hardware and applications\nDitribution: Collection of software making up a Linux-based OS\nBootLoader: Program that boots the operating system\nService: Program that runs as a background process\nFilesystem: Method for sotring and organizing files\nX window System: toolkit and protocol to build graphical subsystem\nShell: command line interpreter","title":"2-4.linux Terminology Overview"},{"content":"Linux Philosophy Overview Linux is constantly enhanced and maintained by a network of developers from all over the world collaborating over the internet, with Linus Torvalds at the head.\nLinux Philosophy Linux borrows heavily from the well-established UNIX operating system. it was written to be a free and open source system to be used in place of UNIX,\nwhich at the time was designed for computers much more powerful than PCs and was quite expensive.\nLinux is a fully multitasking, multiuser operating system, with built-in networking and service processes known as deamons in the UNIX world.\nNOTE: Linux was inspired by UNIX, but it is not UNIX.\nHow Linux Is Built collaborating is power of Linux!\n2-3 month is period to need to release new version of Linux\nMore About Linux Community users and vendors who use many different forums to connect with one another.\nInternet Relay Chat (IRC) software Online communities and discussion boards including Linux User Gorups Many collaborative projects hosted on services such as GitHub and GitLab Newsgroups and mailing lists, including the Linux Kernel Mailing List Community events, e.g. Hackathons, Install Fests, Open Source Summits and Embedded Linux Conferences. linux.com is hosted by The Linux Foundation and serves over one million unique visitors every month.\n","permalink":"https://nolleh.github.io/linux/2.linux-philosophy-and-concepts/3.linux-philosophy/","summary":"Linux Philosophy Overview Linux is constantly enhanced and maintained by a network of developers from all over the world collaborating over the internet, with Linus Torvalds at the head.\nLinux Philosophy Linux borrows heavily from the well-established UNIX operating system. it was written to be a free and open source system to be used in place of UNIX,\nwhich at the time was designed for computers much more powerful than PCs and was quite expensive.","title":"2-3.linux Philosophy"},{"content":"Linux History Overview initially developed on and for intel x86-based personal computers.\nLinux History Linus Torvalds was a student in Helsinki, Finland, in 1991, when he started a project: writing his own operating system kernal. collected together and/or developed the other essential ingredients required to construct an entire operating system with his kernel at the center.\nIn 1992, Linux was re-licensed using General Public License (GPL) by GNU (a project of the Free Software Foundation or FSF, which promotes freely available software),\nwhich made it possible to build a world wide community of developers.\ncomplete systems called Linux distributions in the mid-90\u0026rsquo;s.\nMore About Linux History In 1998, major companies like IBM and Oracle announced their support for the Linux platform and began major development efforts as well.\ntoday, Linux powers more than half of the servers on the Internet, the majority of smartphones (via the Android system, which is built on top of Linux),\nmore than 90 percent of the public cloud workload, and all of the world\u0026rsquo;s most powerful supercomputeres.\n","permalink":"https://nolleh.github.io/linux/2.linux-philosophy-and-concepts/2.linux-history/","summary":"Linux History Overview initially developed on and for intel x86-based personal computers.\nLinux History Linus Torvalds was a student in Helsinki, Finland, in 1991, when he started a project: writing his own operating system kernal. collected together and/or developed the other essential ingredients required to construct an entire operating system with his kernel at the center.\nIn 1992, Linux was re-licensed using General Public License (GPL) by GNU (a project of the Free Software Foundation or FSF, which promotes freely available software),","title":"2-2.linux History"},{"content":"The Power of Linux Three Important Pieces of Context Things change in Linux\nLinux is contantly evolving. no matter how hard to make up-to-date as possible, Course \u0026lt;-/-\u0026gt; Linux\nWe have repeated some things in the class meterial\nWe have tried to avoid holy wars\nthere are many areas where there are strong preference disagreements in the Linux (and wider open source) community. examples include the best editor: emacs vs. vi; GNOME vs. KDE, etc, we have chosen (when nessary) a paticular alternative to emphasize just to keep thing clean.\nLearning Objectives discuss the history and philosophy of Linux describe the Linux community define the common terms associated with Linux discuss the components of a Linux distribution ","permalink":"https://nolleh.github.io/linux/2.linux-philosophy-and-concepts/1.introduction/","summary":"The Power of Linux Three Important Pieces of Context Things change in Linux\nLinux is contantly evolving. no matter how hard to make up-to-date as possible, Course \u0026lt;-/-\u0026gt; Linux\nWe have repeated some things in the class meterial\nWe have tried to avoid holy wars\nthere are many areas where there are strong preference disagreements in the Linux (and wider open source) community. examples include the best editor: emacs vs. vi; GNOME vs.","title":"2-1.introduction"},{"content":"Course Software Requirements to fully benefit from this course, at least one linux distribution installed.\nyou will learn some more details about many available Linux distributions and the failies thy can be considered to belong to.\nfocus on 3 major distribution families.\nFocus on Three Major Linux Distribution Families The Red Hat Family Red Hat Enterprise Linux (RHEL) heads the family that includes CentOS, CentOS Stream, Fedora and Oracle Linux.\nFedora contains significantly more software than Red Hat\u0026rsquo;s enterprise version.\nCentOS Streams and CentOS are more often for activities, demonstrations, and labs because there is no cost to end user and there is a longer release cylce than Fedora. CentOS 8 has no scheduled updates after 2021. the replacement is CentOS 8 Stream.\nthe difference between the two versions is CentOS Stream gets updates before RHEL, while CentOS gets then after\n3.10 Kernel is used in RHEL/CentOS 7, while version 4.18 is used in RHEL/CentOS 8. it supports hardware platforms such as Intel x86, Arm, Itenium, PowerPC, and IBM System z. it uses yum and dnf RPM-based yum package managers REHL is widely used by enterprises which host their own systems. The SUSE Family We use openSUSE as reference distribution for SUSE family, as it is available to end users at no cost.\nkernel version 4.12 is used in openSUSE Leap 15. RPM-based zypper package manager includes YaST (Yet another Setup Tool) for system administration perposes. SLES is widely used in retail and many other sectors The Debian Family the Debian distribution is upstream for several other distributions, including Ubuntu. Debian is a pure open source community project (not owned by any corporation) and has a strong focus on stability. Ubuntu aims at providing a good compromise between long term stability and ease of use. Since Ubuntu gets most of it packages from Debian\u0026rsquo;s stable branch,\nit also has access to a very large software repository.\nkernel version 5.8 is used in Ubuntu 20.04 LTS it uses the DPKG-based APT package manager (apt, apt-get, apt-cache, etc Ubuntu has been widely used for cloude deployments while Ubuntu is built on top of Debian and is GNOME-based under the hood, it differs visually from the interface on standard Debian, as well as other distributions. ","permalink":"https://nolleh.github.io/linux/1.the-linux-foundation/3.course-linux-requirements/","summary":"Course Software Requirements to fully benefit from this course, at least one linux distribution installed.\nyou will learn some more details about many available Linux distributions and the failies thy can be considered to belong to.\nfocus on 3 major distribution families.\nFocus on Three Major Linux Distribution Families The Red Hat Family Red Hat Enterprise Linux (RHEL) heads the family that includes CentOS, CentOS Stream, Fedora and Oracle Linux.","title":"1-3.course Linux Requirements"},{"content":"founded in 2000, supported by more than 1,000 members and is the world\u0026rsquo;s leading home for collaboration on open source software.\nthe foundation hosts hundreds of world\u0026rsquo;s most important open source projects including linux, kubernetes, Node.js, Hyperledger, ONAP\u0026hellip; and many more.\n","permalink":"https://nolleh.github.io/linux/1.the-linux-foundation/2.the-linux-foundation/","summary":"founded in 2000, supported by more than 1,000 members and is the world\u0026rsquo;s leading home for collaboration on open source software.\nthe foundation hosts hundreds of world\u0026rsquo;s most important open source projects including linux, kubernetes, Node.js, Hyperledger, ONAP\u0026hellip; and many more.","title":"1-2.the Linux Foundation"},{"content":"we will learn\u0026hellip;\nlinux foundation logistics of this online course choosing a linux distribution that\u0026rsquo;s right for you ","permalink":"https://nolleh.github.io/linux/1.the-linux-foundation/1.introduction/","summary":"we will learn\u0026hellip;\nlinux foundation logistics of this online course choosing a linux distribution that\u0026rsquo;s right for you ","title":"1-1.Introduction"},{"content":"","permalink":"https://nolleh.github.io/linux/welcome/","summary":"","title":"Welcome"},{"content":"서론 react, vue, angluar 가 장악하던 FE 진영에서 떠오르고 있는 프레임워크. 주요 철학은 svelte 의 메인 화면에서 보여주고 있는것처럼 \u0026lsquo;보다 짧은 코드\u0026rsquo;, \u0026lsquo;No Virtual DOM\u0026rsquo;, \u0026lsquo;Truely reactive\u0026rsquo; 인 듯하다. 지만 나는 어디까지나 BE 개발자이기 때문에 아직 어떤 의미인지 자세하게는 모르겠고(\u0026hellip;)\n스벨트 컬럼을 새로 생성하며 블로그에 정리를 결심한 것은 어디까지나 호기심이 충만한 나의 심심풀이 변덕이다. (더 정확히는, 팀 내 주니어 개발자와의 원활한 의사 소통을 위해..) 심심할 때 더 자세히 살펴보고 정리할 것. 본문에서는, 단순히 스벨트 프로젝트를 만들고 실행해보는 정도로 정리하겠다.\n시작하기 사용하는 패키지 매니져의 create 명령어(starter kit 을 통해 정의된 프로젝트 생성)\n➜ workspace_github pnpm create vite@latest svelte-test -- -- template svelte Packages: +1 + Packages are hard linked from the content-addressable store to the virtual store. Content-addressable store is at: /Users/nolleh/.pnpm-store/v3 Virtual store is at: node_modules/.pnpm /private/var/folders/97/vks5483s2yn95dxdpdspjsgw0000gq/T/dlx-31846/5: + create-vite 3.1.0 Progress: resolved 1, reused 0, downloaded 1, added 1, done ╭──────────────────────────────────────────────────────────────────╮ │ │ │ Update available! 6.32.3 → 7.13.4. │ │ Changelog: https://github.com/pnpm/pnpm/releases/tag/v7.13.4 │ │ Run pnpm add -g pnpm to update. │ │ │ │ Follow @pnpmjs for updates: https://twitter.com/pnpmjs │ │ │ ╰──────────────────────────────────────────────────────────────────╯ ✔ Select a framework: › Svelte ✔ Select a variant: › TypeScript Scaffolding project in /Users/nolleh/Documents/workspace_github/svelte-test... Done. Now run: cd svelte-test pnpm install pnpm run dev 위 명령은 다음과 같은 폴더들을 생성한다.\n➜ svelte-test l total 128 drwxr-xr-x 15 nolleh staff 480B Oct 11 23:30 . drwxr-xr-x 22 nolleh staff 704B Oct 11 23:29 .. -rw-r--r-- 1 nolleh staff 253B Oct 11 23:29 .gitignore drwxr-xr-x 3 nolleh staff 96B Oct 11 23:29 .vscode -rw-r--r-- 1 nolleh staff 3.1K Oct 11 23:29 README.md -rw-r--r-- 1 nolleh staff 365B Oct 11 23:29 index.html drwxr-xr-x 15 nolleh staff 480B Oct 11 23:30 node_modules -rw-r--r-- 1 nolleh staff 511B Oct 11 23:29 package.json -rw-r--r-- 1 nolleh staff 28K Oct 11 23:29 pnpm-lock.yaml drwxr-xr-x 3 nolleh staff 96B Oct 11 23:29 public drwxr-xr-x 8 nolleh staff 256B Oct 11 23:29 src -rw-r--r-- 1 nolleh staff 207B Oct 11 23:29 svelte.config.js -rw-r--r-- 1 nolleh staff 658B Oct 11 23:29 tsconfig.json -rw-r--r-- 1 nolleh staff 142B Oct 11 23:29 tsconfig.node.json -rw-r--r-- 1 nolleh staff 176B Oct 11 23:29 vite.config.ts ➜ svelte-test 으음 .vscode 폴더도 생성하네, 친절하다. (난 vscode 로 실행할 생각이 없지만) 제일 중요할 package.json 의 내용은 다음과 같음.\n{ \u0026#34;name\u0026#34;: \u0026#34;svelte-test\u0026#34;, \u0026#34;private\u0026#34;: true, \u0026#34;version\u0026#34;: \u0026#34;0.0.0\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;module\u0026#34;, \u0026#34;scripts\u0026#34;: { \u0026#34;dev\u0026#34;: \u0026#34;vite\u0026#34;, \u0026#34;build\u0026#34;: \u0026#34;vite build\u0026#34;, \u0026#34;preview\u0026#34;: \u0026#34;vite preview\u0026#34;, \u0026#34;check\u0026#34;: \u0026#34;svelte-check --tsconfig ./tsconfig.json\u0026#34; }, \u0026#34;devDependencies\u0026#34;: { \u0026#34;@sveltejs/vite-plugin-svelte\u0026#34;: \u0026#34;^1.0.2\u0026#34;, \u0026#34;@tsconfig/svelte\u0026#34;: \u0026#34;^3.0.0\u0026#34;, \u0026#34;svelte\u0026#34;: \u0026#34;^3.49.0\u0026#34;, \u0026#34;svelte-check\u0026#34;: \u0026#34;^2.8.1\u0026#34;, \u0026#34;svelte-preprocess\u0026#34;: \u0026#34;^4.10.7\u0026#34;, \u0026#34;tslib\u0026#34;: \u0026#34;^2.4.0\u0026#34;, \u0026#34;typescript\u0026#34;: \u0026#34;^4.6.4\u0026#34;, \u0026#34;vite\u0026#34;: \u0026#34;^3.1.0\u0026#34; } } vite 라는 패키지를 이용해서 빌드하고 실행하도록 구성되어 있고, check 를 통해 lint 체크등이 일어나는 모양. svelte package 등도 프로젝트 별로 버전을 관리하는 형태로 구성되었다. 모든 dependency 는 devDependency 에 정의되어있으므로, 모든 패키지는 런타임엔 하는 역할이 없다고 봐도 무방.\n생성된 app.svelte 는 대충 이런모양\n\u0026lt;script lang=\u0026#34;ts\u0026#34;\u0026gt; import svelteLogo from \u0026#39;./assets/svelte.svg\u0026#39; import Counter from \u0026#39;./lib/Counter.svelte\u0026#39; \u0026lt;/script\u0026gt; \u0026lt;main\u0026gt; \u0026lt;div\u0026gt; \u0026lt;a href=\u0026#34;https://vitejs.dev\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt; \u0026lt;img src=\u0026#34;/vite.svg\u0026#34; class=\u0026#34;logo\u0026#34; alt=\u0026#34;Vite Logo\u0026#34; /\u0026gt; \u0026lt;/a\u0026gt; \u0026lt;main\u0026gt; \u0026lt;style\u0026gt; .logo { height: 6em; padding: 1.5em; will-change: filter; } .logo:hover { filter: drop-shadow(0 0 2em #646cffaa); } .logo.svelte:hover { filter: drop-shadow(0 0 2em #ff3e00aa); } .read-the-docs { color: #888; } \u0026lt;/style\u0026gt; 즉 다음과 같은 골격을 가지고 있다.\n\u0026lt;script\u0026gt; \u0026lt;main\u0026gt; \u0026lt;style\u0026gt; 이는 vue 에서도 유사한 형태를 가지고 있던것 같다. (@nolleh 의 기억에 의존) 따라서 크게 의아한 점은 없는듯. 해당 app.svelte 를 렌더링하는 부분은 main.ts 인데, 다음과 같이 구성되어 있다.\nimport \u0026#39;./app.css\u0026#39; import App from \u0026#39;./App.svelte\u0026#39; const app = new App({ target: document.getElementById(\u0026#39;app\u0026#39;) }) export default app 역시 vue.js 와 유사한 골격이다. 상대경로에서 필요한 파일들을 가져와서 .svelte 파일에서 생성되는 App 클래스로 인스턴스를 생성하고 export 한다. (이건 좀 신기하다. extends 구문도 없고, 클래스를 정의하는 부분도 없는데 App 이라는 클래스명으로 지정이 된다.\n뭐 어차피 컴파일러도 별도 정의한 것이고, 각 IDE 에서의 에러 여부 판단도 약속만 되어있으면 상관없을 테지만.)\n실행해보면\nVITE v3.1.7 ready in 153 ms ➜ Local: http://127.0.0.1:5173/ ➜ Network: use --host to expose 와 같이 어떤 url 로 접근하면 해당 페이지를 노출할 것인지 보여준다. vite 라는 녀석이 serving 을 해주는 것 같은데, 뭐하는 놈인지 좀 검색해봄.\njavascript 의 태생, 모듈의 니즈 AMD 번들러(webpack)의 등장 esbuild (구현: javascript -\u0026gt; go) 100 배 빠른 빌드 역시 고는 짱짱맨! webpack 이 지원하던 다른 많은 기능들이 4에서는 부재하므로 잘 사용되지 않음 devServer, Loader 를 통한 transfile, HTML, CSS 지원등.. 단순 빌드 도구가 아니라 개발의 통합 툴이었음 snowpack 의 등장 esbuild 를 통한 빌드, 실제 번들은 Webpack vite 의 등장 esbuild 와 브라우저 모듈을 이용한 개발모드,개발서버, 프록시서버, 번들툴, 코드 스프리팅, HMR 등 스노우팩의 컨셉 + 다른 번들도구의 기능을 하나로 모은 도구 Svelte 의 vite 의 차용 \u0026lsquo;2021 년 가장 만족도가 높은 번들툴\u0026rsquo; 로 선정된 vite 의 차용. Dev server + HMR + typescirpt + dev proxy 를 지원하게 되었다. 즉, svelte 에서 사용하는 번들 툴이 되겠다.\n해당 url 로 들어가면 다음과 같은 페이지가 노출 된다.\n","permalink":"https://nolleh.github.io/svelte/overview/","summary":"서론 react, vue, angluar 가 장악하던 FE 진영에서 떠오르고 있는 프레임워크. 주요 철학은 svelte 의 메인 화면에서 보여주고 있는것처럼 \u0026lsquo;보다 짧은 코드\u0026rsquo;, \u0026lsquo;No Virtual DOM\u0026rsquo;, \u0026lsquo;Truely reactive\u0026rsquo; 인 듯하다. 지만 나는 어디까지나 BE 개발자이기 때문에 아직 어떤 의미인지 자세하게는 모르겠고(\u0026hellip;)\n스벨트 컬럼을 새로 생성하며 블로그에 정리를 결심한 것은 어디까지나 호기심이 충만한 나의 심심풀이 변덕이다. (더 정확히는, 팀 내 주니어 개발자와의 원활한 의사 소통을 위해..) 심심할 때 더 자세히 살펴보고 정리할 것.","title":"Overview"},{"content":"서론 예전 회사에서나 현 직장에서나, 면접관으로 들어가다가 C# 이 이력서에 적혀있는 경우 Task 와 async/await 관련하여 동기화 관련한 내용에 대해 물어보곤한다. 그리고 이 질문에서 대부분 깊이가 드러나게 된다. (여담이지만, 대부분의 지원자가 자바스택이라, 이런 재미진? 것들을 물어보기가 어렵다. C# 이랑 C++, 실시간 게임서버는 재미진 질문? 들이 많은데.. ㅎㅎㅎㅎ 면접관으로 들어가기위해서 자바스택의 재미진 토픽들도 좀 찾아봐야겠다\u0026hellip;.\n내 경험에서 질문을 도출하려고 스프링의 라이브러리들을 어떻게 구현할 수 있을지 물어볼수는 없으니\u0026hellip;) 물어보다가 나도 생각도 정리하고, 내가 알고 있는 틀린 부분이 없는지 정리하는겸해서 블로그에 기록해 놓는다.\n내용 출처 - Don\u0026rsquo;t Lock On Async Tasks\n다음과 같이 일반적으로 락을 건다고 하자.\npublic class LockTest{ private readonly object objLock = new object(); public void RecordSuccess(int batchId){ lock(objLock){ // Record a success in database var success = GetCurrentSuccessCountFromDB(); SaveSuccessCountToDB(success+1); } } public void RecordFailure(int batchId){ lock(objLock){ // Record a failure in database var success = GetCurrentFailureCountFromDB(); SaveFailureCountToDB(success+1); } } } 락을 거는 것의 목적은 동시에 해당 영역에 두개이상의 스레드들이 접근 불가하도록 하는것인데, 10 개의 스레드가 락을 얻으려고 한다고 가정할때 순차적으로 락을 얻게 된다.\ntask 와 async/await 으로 위와 같은 코드를 작성하는 경우 async/await 의 이점을 제대로 누리지 못하고 스레드들이 잠기게 될것이다. (it ain\u0026rsquo;t async over here)\n때문에, 컴파일조차 안되게끔 컴파일러에서 막고있다. (이건 nolleh 의 경험상 적은 문구.) 그럼 어떻게 async 하게 wait 할수있을까? 이걸 위해 semapore 와 semaporeslim 이 있음.\n세마포어는 IPC 에서 사용할수 있고 세마포어 슬림은 어플리케이션 레벨에서 사용할 수 있다.\n-\u0026gt; 이제 blocking 에서, suspended 된다. 요렇게 사용하면 됨.\npublic class LockTest{ private readonly SemaphoreSlim _lock= new SemaphoreSlim(1, 1); public async Task RecordSuccess(int batchId){ await _lock.WaitAsync(); try{ // Record a success in database var success = GetCurrentSuccessCountFromDB(); SaveSuccessCountToDB(success+1); } finally{ _lock.Release(); } } public async Task RecordFailure(int batchId){ await _lock.WaitAsync(); try{ // Record a failure in database var success = GetCurrentFailureCountFromDB(); SaveFailureCountToDB(success+1); } finally{ _lock.Release(); } } } nolleh 의 경험상, 여기에서 추가로 더 알아 둬야할 게 있는데, (reentrance 관련) 해당 컬럼은 본 블로그의 같은 카테고리-다음글-에서 찾아볼수 있다. 이어보기 - NeoSmart.AsyncLock 라이브러리에 관하여\n","permalink":"https://nolleh.github.io/csharp/dont-lock-on-async-tasks/","summary":"서론 예전 회사에서나 현 직장에서나, 면접관으로 들어가다가 C# 이 이력서에 적혀있는 경우 Task 와 async/await 관련하여 동기화 관련한 내용에 대해 물어보곤한다. 그리고 이 질문에서 대부분 깊이가 드러나게 된다. (여담이지만, 대부분의 지원자가 자바스택이라, 이런 재미진? 것들을 물어보기가 어렵다. C# 이랑 C++, 실시간 게임서버는 재미진 질문? 들이 많은데.. ㅎㅎㅎㅎ 면접관으로 들어가기위해서 자바스택의 재미진 토픽들도 좀 찾아봐야겠다\u0026hellip;.\n내 경험에서 질문을 도출하려고 스프링의 라이브러리들을 어떻게 구현할 수 있을지 물어볼수는 없으니\u0026hellip;) 물어보다가 나도 생각도 정리하고, 내가 알고 있는 틀린 부분이 없는지 정리하는겸해서 블로그에 기록해 놓는다.","title":"Dont Lock on Async Tasks"},{"content":"복수의 유저 사용하기 맥터미널에서 복수의 유저를 사용하려면 몇가지 신경써야할 부분들이 생긴다.\nhome directory 가 분리 되어 있기 때문에 어떤 유저를 위해 설치한 데이터들은\n다른 유저에서는 사용못할수도 있고 (그러는게 맞고, 그럴려고 격리한거니)\n그러다보니 양쪽에서 같은 데이터를 설치해야하나 ?\n혹은 서로 충돌이 난다거나 하는 불편함들이 생긴다.\n대표적인 예로 brew 에서 이런 문제가 발생하는데,,\n어떤 계정으로 설치한 패키지가 다른 계정에서 권한문제로 접근이 안되게 되면서 엉망이 된다.. (-_\u0026ndash;) dependency 가 있는 다른 패키지 들과도 맞물리게 되면서 내가 설치한 패키지가 아닌 패키지에 대해 데이터를 바꾸려고 하면서 권한 이슈로 연결 되는식.\n트러블 슈팅 진행하면서 겪은 해결책들을 여기에 기록하고자한다.\n1.brew 첫번째(유저그룹변경) / 두번째 (별도 brew 생성) 방법이 있는데 용량 아껴볼려고 첫번째 방법으로 고통받아봤는데,\n잘 해결은 안됐기 때문에 개인적으로 두번째 방법을 추천한다.\nstackoverflow\n1-1. 유저그룹으로 권한 설정 example. brew\necho $(brew --prefix) echo $(groups $(whoami)) sudo dseditgroup -o edit -a $(whoami) -t user admin sudo chgrp -R admin $(brew --prefix) sudo chmod -R g+rwX $(brew --prefix) ls -lah $(brew --prefix) 순서대로,\nbrew install path 확인하고 내 그룹 확인하고. 2에서 어드민 그룹에 없다면 어드민 그룹에 넣고 어드민 그룹으로 폴더 recursive 하게 소유권 변경 어드민 그룹에 있는 유저들에 대해 읽기,쓰기,실행 권한 부여 권한 확인 1-2. 공식 문서 제안법 하나도 사용하지 않거나, 하나의 글로벌 brew 설치를 하고, 모든 다른 유저들에서 지역 버전을 사용하는것이 공식 제안 법.\ncd $HOME git clone https://github.com/Homebrew/brew.git ./brew/bin/brew tap homebrew/core export PATH=$HOME/brew/bin:$PATH \u0026gt;\u0026gt; ~/.zshrc # or ~/.bashrc exec $SHELL which brew ","permalink":"https://nolleh.github.io/env/mac-terminal-multiple-user/","summary":"복수의 유저 사용하기 맥터미널에서 복수의 유저를 사용하려면 몇가지 신경써야할 부분들이 생긴다.\nhome directory 가 분리 되어 있기 때문에 어떤 유저를 위해 설치한 데이터들은\n다른 유저에서는 사용못할수도 있고 (그러는게 맞고, 그럴려고 격리한거니)\n그러다보니 양쪽에서 같은 데이터를 설치해야하나 ?\n혹은 서로 충돌이 난다거나 하는 불편함들이 생긴다.\n대표적인 예로 brew 에서 이런 문제가 발생하는데,,\n어떤 계정으로 설치한 패키지가 다른 계정에서 권한문제로 접근이 안되게 되면서 엉망이 된다.. (-_\u0026ndash;) dependency 가 있는 다른 패키지 들과도 맞물리게 되면서 내가 설치한 패키지가 아닌 패키지에 대해 데이터를 바꾸려고 하면서 권한 이슈로 연결 되는식.","title":"Mac 터미널에서 복수의 유저 사용하기"},{"content":"Overview 개인적으로 업무 진행중 빠르게 DB 데이터를 bulk 로 넣어야할 때에는 function 생성을 선호하는 편이다.\nORM 을 통해 코드로 넣는 방법도 있지만, 코드 수정하고 코드를 다시 실행해서 테스트 코드를 돌리고 데이터 결과를 쿼리로 다시 확인하는것보다. 쿼리를 바로 바로 작성해서 바로 수정하는게 더 생산성이 좋기 때문.\n코드 작성 (IDE) 프로그램 실행 (SVR APP) 테스트 코드 실행 (SWAGGER BROWSER) 데이터 삽입 결과 확인 (DB CLIENT) VS\nfunction 작성 (DB CLIENT) function 실행 (DB CLIENT) 데이터 삽입 결과 확인 (DB CLIENT) 절차는 크게 차이나지 않아보이지만, 화면 이동, 적합한 프로그램 실행등의 과정에서 누적되면 생산성의 차이가 발생한다. (조금이라도 시간을 아끼려는 vimer 들의 습성..이랄까..) 물론, 더미 데이터를 넣는 것 외에도 필요하다고 판단되는 케이스에는 사용하는 편.\n작업시마다 항상 인터넷에서 자료를 찾아서, 비 효율적이므로.. 여기에 정리해둔다.\nCreating Function DROP FUNCTION IF EXISTS database.func DELIMETER $$ CREATE FUNCTION database.func(nums INT) RETURNS INT BEGIN DECLARE i INT DEFAULT 0; DECLARE affected INT DEFAULT 0; DECLARE temp INT DEFAULT 0; WHILE i \u0026lt; nums DO INSERT INTO database.table(name, message) (SELECT name, message FROM database.table_old(name, message)); -- it isn\u0026#39;t good way for in this example, -- but I\u0026#39;ve used this just for showing usage -- for selecting row_count() and set variable in function; SELECT ROW_COUNT() INTO temp; SET affected = affected + temp; SET i = i + 1; END WHILE; RETURN affected; END $$ DELIMETER ; 추후 개인적인 참조를 위해 기본적인 골격만 붙여두어, 이해하는데 어려움은 없을 것.\n","permalink":"https://nolleh.github.io/mysql/functions/","summary":"Overview 개인적으로 업무 진행중 빠르게 DB 데이터를 bulk 로 넣어야할 때에는 function 생성을 선호하는 편이다.\nORM 을 통해 코드로 넣는 방법도 있지만, 코드 수정하고 코드를 다시 실행해서 테스트 코드를 돌리고 데이터 결과를 쿼리로 다시 확인하는것보다. 쿼리를 바로 바로 작성해서 바로 수정하는게 더 생산성이 좋기 때문.\n코드 작성 (IDE) 프로그램 실행 (SVR APP) 테스트 코드 실행 (SWAGGER BROWSER) 데이터 삽입 결과 확인 (DB CLIENT) VS\nfunction 작성 (DB CLIENT) function 실행 (DB CLIENT) 데이터 삽입 결과 확인 (DB CLIENT) 절차는 크게 차이나지 않아보이지만, 화면 이동, 적합한 프로그램 실행등의 과정에서 누적되면 생산성의 차이가 발생한다.","title":"Functions"},{"content":" 다음에서 발췌 http://book.mixu.net/distsys/abstractions.html\n2. Up and down the level of abstraction 이 챕터에서는, 추상화의 레벨을 여행할 것이며, 몇가지 불가능한 결과를 보고, (CAP 와 FLP), 그리고 나서 성능에 대한 항해를 할 것 입니다.\n만약 어떤 프로그래밍을 완료했다면, 추상화. 수준에 대한 개념은 당신에게 익숙할 겁니다. 당신은 이미 추상화와 함께 했고, 어떤 API 를 통해 더 낮은 레이어와 인터페이싱하고 있을 것이며, 더 높은 레이어에 API 나 인터페이스를 제공하고있을 겁니다. OSI 네트워크 7 계층이 좋은 예죠.\n분산 프로그래밍은, 단언하고 싶은데, 분산의 결과를 다루는 것이 많은 부분을 차지합니다. 이것은, 현실과 긴장이 있는데, 많은 도들들과 우리의 욕구, 시스템에 대한것은 \u0026ldquo;하나의 시스템처럼\u0026rdquo; 이기 때문입니다. 이것은 가능한것과 이해 가능한 것과 성능 사이에서 균형을 잡고 좋은 추상화를 하는 것을 찾아 가는것을 의미합니다.\nX 가 Y 보다 더 추상화가 되어있다는 것의 의미는 무엇일까요? 첫째로, X 는 Y 와 근본적인 차이는 없고, 다른 새로운것을 소개 하는 게 아닙니다. 대신, X 는 Y 의 내용을 제거하고 제시하는것, 더 관리하기 쉬운 형태로 제시하는 것을 의미합니다. 둘째로, X 는 Y 로부터 중요하지 않은 문제들을 제거함으로써, 어떤 감각에 대해 Y 보다 더 직관 적일 수 있습니다.\nNietzsche 는 다음과 같이 이야기 했습니다.\n모든 동등에 대한것으로 부터 나온 개념은 동등하지 않다. 어떤 이파리(leaf) 도 다른 것과 완전이 같지 않으며, 이파리(leaf) 의 개념은 각각의 차이들로부터 차이에 대한 것들을 잊음으로써 임의의 추상화를 통해 형성된것이다; 또한, 이것은 어떤 아이디어를 도출하는데, 이파리들의 본성은 이파리와 다른 어떤것을 가지고 있을 수 있다는 것이다 - 어떤 종류 모든 이파리로부터 다른 어떤 자기만의 형태가 있을 수 있으며, 낡고, 마킹되고, 복제되며, 색이 다르며, 구부러지고, 색이 다를 수 있지만, 기술적이지 않은 손길로 인해, 맞는것으로, 믿을 수 있고, 신뢰할 수 있는 본래의 형태의 이미지가 되는 복제가 없다. (TODO refined)\n추상화는, 근본적으로, 진짜가 아닙니다. 모든 상황들은 유일하며, 모든 노드 또한 그렇습니다. 하지만 추상화는 세상을 관리할 수 있게 해줍니다: 문제 상황들에 대해 더 간단하게 하여 - 현실의 자유 - 더 분석적으로 다룰수있고, 어떤 중요한 것들을 무시하지도 않으면서, 해결책을 넓게 적용할 수 있도록 해줍니다.\n실제로, 우리가 다루는 것들은 필수적이면, 우리가 도출할 수 있는 결과도 넓게 적용 가능합니다. 이것은 왜 불가능한 결과가 그렇게 중한지 알려줍니다; 이것들은 문제의 가능한 공식의 가장 단순한 방법을 취하며, 제약과 가정의 집합내에서 해결할 수 없는 문제임을 우리게 설명해 줍니다.\n모든 추상화는 의도적으로 유일한 것들을 무시합니다. 이 트릭은 중요하지 않는 것들을 제거하는 것인데, 어떻게 어떤것이 필수적인지 알 수 있을까요? 글쎄, 당신은 아마도 선험적으로(priori) 알지 못할 것입니다.\n매 시간 우리는 시스템의 측변에서 제외합니다, 시스템의 특정부분들으세ㅓ. 우리는 에러의 source 로부터 소개하는 리스크를 안고 있습니다. 이것은 왜 때때로 우리가 다른 방향으로 접근해야하는지, 선택적으로 실 하드웨어의 어떤 측변을 선택하고, 실제세계의 문제를 다시 선택적해야하는지. 이 것들은 어떤 하드웨어의 특정 부분들을 (e.g. 물리적인 연속성) 나, 다른 물리적인 특징들이 시스템이 충분히 잘 돌아가도록 충분하다 다시 소개하는 것이.\n이것을 머리속에 생각하면서, 분산시스템에서 동작하고 있다는 것을 인지하면서 최소한의 현실은 어떤 것일까? 하나의 시스템 모델은 우리가 중요하다고 고려하는 특징들입니다; 지정한 것들을 갖고 있으면, 불가능한 결과와 도전들을 살펴볼수 있게 됩니다.\nA System model 분산시스템에서 주요한 속성중의 하나는, \u0026lsquo;분산\u0026rsquo;입니다. 더 정확하게는, 분산시스템에서의 프로그램은:\n각각의 독립적인 노드에서 동시에 실행 됩니다. 네트워크를 토앻 연결되어있고, 메시지가 유실되거나 비정의된 동작으로 이어질 수 있습니다. 공유 메모리나, 공유 시간이 없습니다. (shared memory, shared clock) 여기에는 많은 암시사항들이 있는데요:\n각각의 노드 들은 프로그램을 동시에 실행한다. 지식들은 지역적이다: 노드들은 그들의 로컬 상태에는 빠르게 접근 하지만, 글로벌 상태에 대한 정보는 잠재적으로 최신 값이 아닐 수 있다. 노드들은 실패할수 있으며, 실패로 부터 독립적으로 복구 될 수 있습니다. 메시지들은 지연되거나 유실될 수 있습니다. (노드의 실패와는 독립적으로; 네트워크의 실패와 노드 실패 두개를 구분하는 것은 쉬운 일이 아닙니다.) clock 들은 접근하는 노드들 사이에서 동기화 되어있지 않습니다. (한 로컬의 타임스탬프는 실제 글로벌 타임과 다를 수 있고, 쉽게 파악하기 어렵습니다.) 하나의 시스템 모델은 어떤 특정 시스템 디자인과 관계하여 많은 가정들을 내포합니다.\nSystem model 분산시스템이 구현된 환경과 시설에 대한 가정들의 집합\n시스템 모델들은 그들의 가정, 환경과 시설들에 대한 그들의 가정이 다양합니다. 이 가정은 다음을 포함합니다.\n노드가 어떤 수용량(capabilities)을 가지고 있고 어떻게 실패할 수 있는지 어떻게 통신을 연결하여 동작하고, 어떻게 실패 할 수 있는지 전체 시스템의 속성 - 시간과 순서에 대한 가정같은 것들- 건장한 시스템 모델은 가장 작은 가정을 하는 모델입니다; 어떤 알고리즘이 이런 시스템에 쓰여도, 다른 환경에서도 tolerant 하고, 이는 상당히 작은 가정이 있거나, 거의 없기때문입니다.\n한편으로, 우리는 시스템모델에 많은 가정을 함으로써 시스템을 이해하기 쉽게 만들수 있습니다. 예를 들어서, 알고리즘에 대해 노드들은 실패하지 않는다. 라는것은 노드의 실패를 다룰 필요가 없게 되죠. 하지만, 이런 시스템 모델은 현실적이지 않으므로 적용 할 수가 없죠.\n노드의 속성들을 살펴보고, 시간과 순서에 대해 좀 더 살펴봅시다.\nNodes in our System model 노드들은 연산과 저장소의 호스트로서 동작하게 되는데, 이들은 다음을 갖고 있습니다:\n프로그램을 실행할 수 있는 능력 데이터를 휘발성 메보리에 저장할 수 있는 능력과 (실패시에는 소실될 수 있는) 안정적인 상태로 저장 할 수 있는 능력 (실패 이후에도 읽을 수 있는) a clock (정확하다고 믿거나 믿지 않을 수 있는 시계) 노드들은 결정적인(deterministic) 알고리즘들을 실행합니다; 내부 연산, 연산 이후의 내부 상태, 메시지를 수신한 이후 자체적으로(uniquely) 결정한 메시지를 전송한다거나.\n노드가 실패 했을 때의 동작을 기술한 많은 실패 모델들이 있는데, 실제로는 (in practice), 대부분의 시스템들이 크래쉬-복구 실패 모델을 가정합니다; 이것은, 노드들이 크래쉬가 났을 경우에만 실패하며, 일정 시점 이후에는 복구 할 수 있다 라고 가정합니다.\n다른 대안은 노드는 임의의 다른 의도하지 않은 동작을 하여 실패할 수 있다고 가정하는 것인데요, 이것은 비잔틴 실패 tolerance 라고 알려져 있습니다. 비잔틴 실패는 상용 시스템에서는 거의 다뤄지지 않으며, 임의의 실패에 대응 할 수 있는 알고리즘은 구현하기가 훨씬 복잡하고, 비싸기 때문입니다. 이것에 대해 다루지는 않겠습니다.\nCommunication links in our system model 통신 연결들이 각각의 도드들을 연결하며, 메시지들이 어떤 방향으로도 전송 될 수 있도록 해줍니다. 많은 책들에서 분산 알고리즘들은 각각의 노드 쌍에 대해 각각의 연결, 메시지에 대해 FIFO 를 제공하고 그들이 보낸 메시지만 전달하고, 유실될수 있다고 가정합니다.\n어떤 알고리즘들은 이 네트워크가 신뢰할 수 있다고 믿습니다; 메시지들은 절데 유실되지 않으며 절대 무기한 연기되지 않는다. 이런 가정들은 어떤 실세계의 설정에서는 유효한 가정이지만, 일반적인 경우에는 네트워크는 신뢰할 수 없으며 대상들은 메시지를 유실하거나 지연할 수 있다고 고려하는것이 선호 됩니다.\n네트워크 파티션은 네트워크가 실패하여 다른 노드들 자체들은 연산가능한 상태로 남아 있을 때 발 생합니다. 이것이 일어나게 되면, 메시지들은 유실되거나 네트워크 파티션이 복구 될때까지 지연되게 됩니다. 파티션 된 노드들은 어떤 클라이언트에게는 정상적으로 접근가능하므로, 크래쉬 노드와는 다르게 처리되어야 합니다. 아래의 다이어그램은 노느 실패와 네트워크 파티션을 나타냅니다.:\n통신링크에 대해 더 많은 가정을 하는 것은 드뭅니다. 우리는 연결들이 하나의 방향성만 가진다고 가정하거나, 다른 커뮤니케이션 비용을 소개할 수 도 있습니다. (e.g. 물리적 거리로 인한 지연) . 그러나, 이것들은 상업적 환경에서는 큰 걱정사항이 아니며 (WAN 지연과 같은 긴거리의 연결을 제외하고) 그렇기때문에 여기서 논의 하지 않겠습니다; 더 자세한 비용과 topology 에 대한 모델은 복잡성에 대해 더 나은 최적화를 하게 됩니다.\nTiming / ordering assumtions 각각의 노드들이 물리적인 분리가 되어있다는 것은 세상을 유일한 매너로 볼 수 있게 해 줍니다. 이것은 피할 수 없는데, 광속을 뛰어넘는 정보란 있을 수 없기때문입니다. 만약 노드들이 각각 다른 거리에 있고, 어떤 메시지지들도 하나의 노드에서 다른 노드로 전송되면, 노드들 사이에서 각각 다른 순서와 시간으로 도달 할 수 있습니다.\n타이밍에 대한 가정은 현실을 고려할 때 확장하기에 쉽게 해 줍니다. 주요한 두 대안들은:\nSychronous system model 프로세스들은 락 단계 에서 실행됩니다; 메시지 전송 지연에는 알려진 상한이 있으며; 각각의 프로세스들은 정확한 clock 을 가지고 있습니다.\nAsynchronous system model 타이밍에 대한 가정은 없습니다 -e.g. 프로세스들은 독립적인 비율로 실행합니다; 메시지 전송 지연에 대한 범위는 없으며; 유용한 clocks 도 없습니다.\n동기화된 시스템 모델은 시간과 순서에 대한 많은 제약들을 두고 있습니다. 이것은 필수적으로 노드들이 같은 경험을 하도록 가정합니다; 메시지들은 항상 최대 전송 지연 시간 안에 수신되어야하며, 락 단계( lock-step) 에서 실행 되어야 합니다. 이것은 시스템의 디자이너가 시간과 순서에 대한 많은 가정을 할 수 있게 하므로, 편리한 반면에, 비동기화된 시스템모델은 그렇지 않습니다.\n비동시성은 가정이란 없습니다; 그저 타이밍에 대한 가정을 할수 없다 라는 가정 만이 있습니다.\n동기화된 시스템 모델에서 문제를 푸는 것이 더 쉬운데, 실행 스피드, 최대 메시지 전송지연, 시계 정확성에 대한 가정 모두 문제를 푸는데 도움을 주기 때문인데, 이는 가정에 기반하여 추론을 할 수 있게 해주고, 일어나지 않을 것이라고 가정하는 불편한 실패 시나리오들을 생각할 필요가 없기 때문입니다.\n물론, 동기화된 시스템 모델을 고려하는것은 일부는 현실적이지 않스빈다. 실세계의 네트워크는 실패할 수 있으며, 메시지 딜레이에 대한 강력한 범위도 없스빈다. 실세계의 시스템은 최대한 일부적으로 동기화 되어있습니다: 때때로 올바르게 동작하고 최대 지연 범위를 제공하지만, 메시지가 무한하게 딜레이될 수 있고 시계들은 동작에서 벗어 날 수 있습니다. 여기서 동기화된 시스템의 알고리즘에 대해 다루진 않을 것이며, 분석하기 쉽기 때문에 (현실적이지 않지만) 다른 책들에서 많이 다루고 있을 겁니다.\nThe consensus problem 이 문서의 나머지에서, 우리는 시스템모델의 인자들을 다양화 할 것 입니다. 이후에는, 어떻게 두 시스템 송성들을 다양화 할 것인가에 대한 것을 살펴 봅니다.\n네트워크 파티션이 실패 모델에 포함을 할 것인지, 동시성 vs. 비 동시성의 타이밍 가정을 할 것인지. 시스템 디자인 선택의 영향은 두 불가능한 결과(FLP 와 CAP) 를 논의 하는것에 의해 영향을 받습니다.\n물론, 논의를 하기 위해, 풀어야할 문제를 소개할 필요가 있겠네요. 바로 타협 문제입니다.\n몇몇 컴퓨터 (노드) 들은 그들이 어떤 값들에 대해 모두 동의 할 수 있습니다. 더 격의 적으로 이야기하면:\n동의: 모든 올바른 프로세스들은 같은 값들에 동의 해야합니다. 통합: 모든 올바른 프로세스들은 최대 하나의 값을 결정하고, 어떤 값을 정하면, 어떤 프로세스에 의해 제안 되어야 합니다. 종료: 모든 프로세스들은 결과적으로 결정에 다달아야 합니다. 유효성: 만약 모든 올바른 프로세스들이 같은 값 V 를 제안했다면, 모든 올바른 프로세스들이 V 를 결정한 것입니다. 이 타협 문제는 많은 상업용 분산 시스템에서의 주요 문제 입니다. 결과적으로, 우리는 분산에서의 부작용을 다루지 않고 신뢰성과 성능을 얻고 싶으며, aotmic broadcase 와 atomic commit 같은 타협문제와 관련한 더 발전된 문제들을 풀고 싶어하죠.\nTwo impossibility results 첫번째 불가능한 결과 (FLP imossibility result 로 알려진)는 분산시스템을 설계한 사람에 관계한 불가능한 결과 입니다. 두번째는 - The CAP 이론- 실무자에 더 관계한 결과 입니다; 시스템 디자인을 선택 하는 사람들이 알고리즘 디자인에 대한 직접적인 고려가 없는 경우에 해당합니다.\nThe FLP impossibility result 간략하게 FLP 불가능 결과 에 대해 요약해 보면, (교육계에서는 더 중요하게 고려 되지만) FLP 불가능 결과 (Fishcher, Lynch and Patterson 저자에 의해 지어진 이름입니다.) 비동기 시스템 위에서 타협 문제를(기술적으로, 타협문제의 작은 형태인 동의 문제) 검사합니다. 노드들은 크래쉬에 의해 실패할 수 있다고 가정합니다.; 네트워크는 신뢰할 수 있고, 비동기 모델에서의 일반적인 타이밍 문제는 유지 됩니다: e.g. 메시지 지연에 대한 범위는 없습니다.\n이런 가정하에, FLP 결과는 \u0026ldquo;(deterministic)한 알고리즘은 실패할 수 있는 비동기 모델에서 메시지가 절대 유실되지 않더라도, 최대 하나의 프로세스만이 실패할 수 있더라도, 그 이유가 오로지 크래쉬에 의한 것이라도 존재할 수 없다.\u0026rdquo; 라고 이야기 합니다.\n이 결과는 무한하게 지연될 수 없다.라고 가정한 최소한의 시스템 모델에서는 타협문제를 풀 방법이 없다고 이야기 합니다. 이 논쟁은 이런 알고리즘이 존재한다면, 메시지 전송이 임의의 시간동안 지연될 수 있는 결정되지 않은 상태로 남아있는 (2가의 -bivalent) 알고리즘을 고안 할 수 있을 것이다. 그러므로, 이런 알고리즘은 존재하지 않는다. 에 대한 것입니다.\n이 불가능 결과는 비동기 시스템 모델이 tradeoff 를 가짐에 초점을 맞추고 있기 때문에 중요합니다.: 타협문제를 푸는 알고리즘은 메시지 전송에 관한한 지연 범위를 보장할 수 없을때에는 안정성이나 실시간 성을 포기해야함을 시사하고 있습니다.\n이 통찰은 알고리즘을 디자이낳는 사람들에게 더 관계가 있는데, 비동기 시스템 모델에서 풀 수 있다고 알고 있는 문제에 대해 더 강한 제약을 의미하기 때문입니다. CAP 이론은 실무자에게 더 관련되어 있습니다; 이것은 다소 다른 가정(노드 실패가 아닌 네트워크 실패) 만들고, 시스템 디자인 선택을 할때에 실무자가 더 명확한 의미를 갖도록 합니다.\nThe CAP theorem CAP 이론은 처음에는 컴퓨터 과학자 Eric Brewer 에 의해 추측되었습니다. 시스템 디자인을 정할 때 tradeoff 에 대해 생각하는 꽤 유용하고 유명한 방법입니다. Gilbert 와 Lynch 의 공적인 증명 도 있으며, Nathan Marz 는 논의 사이트 가 생각하는 것에도 불구하고 폭로하지 않았습니다. (TODO refined. It even has a formal proof by Gilbert and Lynch and no, Nathan Marz didn\u0026rsquo;t debunk it, in spite of what a particular discussion site thinks.)\n이 이론은 다음과 같은 세가지 속성을 가집니다.:\n일관성: 모든 노드들은 같은 때에 같은 값을 가진다. 가용성: 노드 실패가 다른 생존자들이 동작하는 것을 막지 않는다. 일부 tolerance: 시스템은 네트워크나 노드 실패로 인한 메시지 유실에도 계속해서 동작한다. 동시에 두개 만이 만족될 수 있습니다. 보기좋게 다이어그램으로 만들어보면, 셋 중에 두 속성을 선택하는 것은 세가지의 시스템 타입을 나타내는데, 각각의 교집합으로 표현 되어 있습니다.\n이 이론은 (모든 세개의 속성에서) 중앙의 조각은 얻어질 수 없음을 이야기 합니다. 세개의 시스템 타입은 다음과 같습니다.\nCA (consistency + availability). 정족수(quorum) 규약을 엄격히 따르는 예제로서, 2 phase commit 과 같은 예를 생각해볼 수 있습니다. CP (consistency + partition tolerance). 다수 정족수를 따르는 경우로, 소수의 파티션은 (Paxos 같은) 사용할 수 없게 됩니다. AP (consistency + partition tolerance). 다이나모 같은 충돌 해결을 사용하는 프로토콜입니다. CA 와 CP 시스템 디자인은 모두 같은 일관성 모델을 제안합니다: 강력한 일관성. 둘의 유일한 차이는 CA 는 노드 실패에 대해 tolerate 하지 않다는 접입니다; CP 시스템은 비잔틴 실패가 없는 2f + 1 노드에서 f 실패까지 tolerant 합니다. (다시 말해서, 다수인 f + 1 이 살아 있는 동안 소수인 f 의 실패까지는 버틸 수 있습니다.) 그 이유는 간단합니다:\nCA 시스템은 도드의 실패와 네트워크 실패를 구분하지 않으며, 따라서 분리(복수의 복제)를 피하기 위해 쓰기를 중지해야합니다. 이것은 원격의 노드가 내려간 것인지, 네트워크 연결이 중지된 것인지 말할 수 없습니다: 따라서 유일한 안전한 방법은 쓰기를 중지하는 것 뿐입니다. CP 시스템은 두 파티션의 비대칭 동작을 강제로 막음으로써 분리(divergence - 한개의 복제 일관성 만을 유지합니다)를 막습니다. 만약 다수의 파티션을 유지하기만 한다면, 소수의 파티션만이 비가용 적이도록 유지한다면, (e.g. 쓰기를 막는다), 가용정도는 유지하면서 여전히 하나의 복제 일관성만을 유지할 수 있습니다. 이 것들에 대해서는 Paxos 에 대에 논의 할때 복제에 대해 더 자세히 다루겠습니다. CP 모델에서 중요한것은 협조적이지 않은 네트워크 파티션은 다수의 파티션과 구분한다는 것입니다. (Paxos, Raft, viewstamped 복제와 같은 알고리즘을 사용하여) CA 시스템은 파티션에 자각적이지 않고, 역사적으로 더 흔한 시스템 입니다; 보통 2-phase 커밋 알고리즘 같은 것들이 전통적인 분산 관계형 데이터 베이스에서 흔히 사용됩니다.\n파티션이 일어 났다고 가정했을때, 이 이론은 가용성과 일관성, 어떤 것을 선택할 것인지로 문제를 줄입니다.\nCAP 이론으로부터 4개의 결론을 낼 수 있을 것 같네요.\n첫째, 전통적인 관계형 데이터베이스와 같은 분산시스템 디자인들은 파티션 tolerance 에 대해 다루지 않았다. (e.g. CA 디자인이었다). 파티션 tolerance 는 현대의 시스템에서는 중요한 속성이며, 네트워크 파티션이 물리적으로 분산되어 더 잘발생할 수 있어졌기 때문입니다.\n둘째, 네트워크 파티션이 발생하였을때 강력한 일관성 모델과 높은 가용 성을 유지하는것 사이에서 긴장이 있다. CAP 이론은 분산 연산에서 강력한 보장을 위해서는 tradeoff 가 있음을 설명하고 있습니다.\n어떤 경우에는, 예측할 수 없는 네트워크로 연결되어있는 독립적인 노드들로 이루어진 분산 시스템에서 \u0026ldquo;비분산 시스템과 구분할수 없는 방식으로 동작하게 할거야\u0026rdquo; 라는 것을 약속하는 것은 꽤 미친 짓이죠!\u0026quot;\n강력한 일관성은 파티션이 발생한 동안은 가용성을 포기합니다. 이것은 두 복제가 서로 통신할 수 없는 상황에서 양쪽 파티션에서 쓰기를 허용하면 분리(divergence)를 막을 수 없기 때문입니다.\n어떻게 이것들 사이에서 일할 수 있을까요? 가정을 더 강화(파티션은 없어!) 하거나, 보장을 약화할 수 밖에 없습니다. 일관성은 가용성과 tradeoff 관계에 있습니다.(또, 오프라인 접근성의 용량과 낮은 지연과 관련해 있습니다). 만약 \u0026ldquo;일관성\u0026rdquo; 이 \u0026ldquo;모든 노드들은 동시에 같은 데이터를 보고 있다\u0026rdquo; 라는 것보다 작은 것이라면, 가용성과 더 (약한) 일관성을 보장 받을 수 있습니다.\n셋째, 일반적인 동작에서, 강력한 일관성과 성능 사이에는 긴장이 있다\n강력한 일관성 / 하나의 복사 일관성은 노드 통신이 되면서 모든 연산에 대해 동의 해야함을 의미합니다. 이것은 일반적인 연산에 있어서 높은 지연으로 이어집니다.\n만약 고전적이지 않은 일관성 모델에서 살고 있다면, 복제의 지연이나 분리를 허용하고 있을것이며, 이후에 일반적인 연산을 하면서 지연을 줄이고 파티션의 존재에 대해 가용성을 유지하고 있을 것입니다.\n더 적은 메시지와 더 적은 노드가 관계할수록 어떤 연산들은 더 빠르게 완료될 수 있습니다. 하지만 이것을 이루기 위해서는 보장을 완화하는 방법밖에 없습니다: 어떤 노드들이 더 적게 접촉할수록 할수 밖에 없는데, 이는 이전 데이터를 갖고 있다는 의미죠.\n이 것은 이상(anomalies) 가 이뤄지게 합니다. 더이상 최신의 값을 보장 받을 수 없습니다. 어떤 보장을 받을지에 의존 함에 따라서, 당신은 기대보다 이전의 데이터를 읽을 수 있으며, 심지어 수차례의 업데이트를 놓칠 수도 있습니다.\n넷째 - 좀 간접적이지만 - 네트워크 파티션으로 인한 가용성을 포기하고 싶지 않다면, 우리의 목적을 위해 강력한 일관성과는 다른 일관성 모델을 찾을 필요가 있다\n예를 들어서, 유저 데이터가 물리적으로 여러 데이터 센터에 있더라도, 두 데이터 센터의 연결이 일시적으로 고장나더라도, 대부분의 경우에 유저가 우리의 웹사이트/서비스를 이용하게 허용하고 싶습니다. 이것은 나중에 두 데이터를 다시 화해( reconciling -비지니스 적으로도 리스키하고 기술적으로도 도전적인 작업인 -) 시켜야함을 의미합니다. 그러나, 이 기술적으로 도전적이고 비즈니스적으로도 리스키한 작업이 종종 관리 될 수 있으며, 고 가용성을 위해 선호 되는 편입니다.\n일관성과 가용성은 강력한 일관성으로 제약하지 않는다면, 사실 완전히 이지선다는 아닙니다. 강력한 일관성은 그저 하나의 일관성 모델일 뿐입니다: 활성화 되어있는 하나만의 데이터를 유지하기 위해서만 가용성을 포기해야할 필요가 있죠. Bewer 자신이 지적한 것처럼, \u0026ldquo;셋 중의 둘\u0026rdquo; 이라는 해석은 잘못된 것이라고 할 수 있습니다.\n만약 이 토론에 대해 하나의 아이디어만 뽑아낸다면, 이것일 것입니다. \u0026ldquo;일관성\u0026rdquo; 은 단수형이나, 모호하지 않은 속성이 아닙니다. 기억하세요.\nACID 일관성 !=\nCAP 일관성 !=\nOatmeal 일관성\n대신에, 일관성은 그걸 사용하는 프로그램에 데이터 저장소가 제공하는 보증입니다.\nConsistency model 시스템은 프로그래머가 어떤 특정한 규칙에 따른다면 시스템이 데이터가 저장되는 결과가 예측가능하도록 보장하는 프로그래머와 시스템 사이의 계약서\nCAP 의 \u0026ldquo;C\u0026rdquo; 는 강력한 일관성이 지만, \u0026ldquo;일관성\u0026quot;은 \u0026ldquo;강력한 일관성\u0026quot;과 같은 말이 아닙니다.\n이제 다른 일관성 모델을 살펴 보죠.\nStrong consistency vs. other consistency models 일관성 모델은 두가지 타입으로 분류 될 수 있습니다: 강력하거나, 약하거나:\n강력한 일관성 모델 (하나의 복사만을 유지함) 선형 적인 일관성 순차적인 일관성 약화된 일관성 모델 (강력하지 않음) 클라이언트 사이드의 일관성 모델 캐주얼한 일관성: 강력한 모델이 가능할 때 결과적으로 일관적인 모델 강력한 일관성 모델은 명확한 순서나, 갱신에 대한 가시성을 보장하여 복제 되지 않은 시스템과 동등한 시스템을 유지합니다. 약화된 일관성 모델은, 반면에, 이런 보장들을 하지 않습니다.\n이것이. 철저한 리스트는 아님을 주지해주세요. 다시 말해서, 일관성 모델은 임의의 계약 (시스템과 프로그래머 사이의) 이어서, 어떤 것이든 될 수 있습니다.\nStrong consistency models 강력한 일관성 모델은 두 비슷한 모델로 나뉘어 질 수 있습니다. (일부가 다릅니다.)\n선형적인 일관성: 이 일관성 모델에서는, 모든 연산들이 아토믹하게 순서대로 이뤄지며 글로벌 실세계의 연산 순서를 따릅니다. (Herilhy \u0026amp; Wing, 1991) 순차적인 일관성: 이 일관성 모델에서는, 모든 연산들은 모든 노드와 동등한 각각의 노드들에 의해 일관적인 순서로 아토믹하게 연산이 이뤄집니다. (Lamport, 1979) 두 일관성 모델의 차이가 되는 열쇠는, 선형적인 일관성에서는 실시간의 연산 순서와 동등하게 연산이 수행 되어야 한다는 점입니다. 순차적인 일관성은 각각의 노드에서 확인 할 수 있는 일관성이 유지 되는한, 연산이 재배치 되는 것을 허용합니다. 이 둘을 구분할수 있는 유일한 방법은 입력이 시스템에 반영되는 타이밍을 관찰하는 것 밖에 없습니다; 노드들과 교류하는 클라이언트의 관점에서는, 둘은 동등합니다.\n두 차이는 중요하지 않은 것 같아 보이지만, 순차적인 일관성이 결합하지 않는 다는 점은 주목할 필요가 있습니다.\n강력한 일관성 모델은 프로그래머가 하나의 서버를 분산된 도드들의 클러스터로 대체하여도 어떤 문제도 없게 해 줍니다.\n모든 다른 일관성 모델은 anomailies (강력한 일관성 모델과 비교해서)가 있으며, 복제되지 않은 시스템과 구별되는 동작을 하기 때문입니다. 하지만, 이런 이상 증상들은 보통 수용가능하며, 일시적인 이슈는 괜찮거나, 비 일관적인 상태를 다루도록 코드를 작성했기 때문입니다.\n약화된 일관성 모델에서 범우주적인 토폴로지는 없다는 것을 명심해주세요. 왜냐하면, \u0026ldquo;강력한 일관성모델이 아닌 모델\u0026rdquo; (e.g. 어떤 방식으로든 복제되지 않는 시스템과 구분가능한것\u0026rdquo;) 은 어떤 모양이든 가질 수 있으니까요.\nclient-centric consistency models client-centric consistency models는 클라이언트나 세션의 개념을 포함한 일관성 모델입니다. 예를 들면, 클라이언트 중심 일관성 모델은 클라이언트는 절대 예전버전을 보지 않음을 보장하는 것이죠. 이것은 종종 클라이언트 라이브러리에서의 추가적인 캐싱을 구현하여 클라이언트가 예전 버전의 복제 노드로 이동하면, 예전 데이터를 보유한 복제본의 데이터를 반환하는 것 대신 캐쉬의 데이터를 반환 하는 형태로 구현됩니다.\n클라이언트는 예전 버전의 데이터를 볼수 있지만, 복제본의 노드가 최신의 데이터를 갖고 잇지않다면, 그렇지만 이전 버전의 재 표면화로 인한 (e.g. 다른 복제본으로 연결 됨으로 인해) 이상현상은 보지 않게 됩니다. 이런 일관 성 모델에는 많은 종류가 있다는 것을 기억해 주세요.\neventual consistency 결과적 일관성 모델은 값을 변경하는 것을 멈춘다면, 정의되지 않은 얼마간의 시간뒤에 모든 복제들은 같은 값을 갖게 됩니다. 이것은 그 시간 전까지는 복제본들 사이에서 정의되지 않은 형태로 일관적이지 않은 데이터를 가질 수 있음을 내포하고 있습니다. 사소하게 만족적 이기 때문에, 보충 정보가 없이는 유효하지 않습니다.\n어떤것을 단순하게 결과적으로 일관적이다. 라고 이야기 할때, \u0026ldquo;사람들은 결과적으로 죽는다\u0026rdquo; 라고 이야기하는 것과 비슷합니다. 이것은 상당히 약한 제약조건이며, 최소한 다음과 같은 두 특징을 얻기를 원할 것입니다.:\n첫째, \u0026ldquo;결과적으로\u0026rdquo; 라는 것은 얼마나 긴 것인지? 이것은 하한선을 정해 두는 것이 유용할 수 있으며, 아니면, 같은 값에 대한 시스템의 커버리지를 일반적으로 얼마나 길것인지 에 대한 최소한의 아이디어를 가져가는 형태입니다.\n둘째로, 어떻게 값에 대한 동의를 할 것 인가? 인데, \u0026ldquo;42\u0026rdquo; 라고 항상 이야기하는 시스템은 결과적으로 일관적 입니다: 모든 복제본들은 같은 값을 통의합니다. 이것은 단지 유용한 값에 대해 커버리지가 없을 뿐입니다. 대신에, 우리는 방법에 대한 더 좋은 아이디어가 있습니다. 예를 들면, 가장 큰 타임스탬프를 가진 값이 항상 이기는 것입니다.\n따라서, 제공자가 \u0026ldquo;결과적으로 일관적이다\u0026rdquo; 라고 이야기하면, 더 정확한 용어를 의미하는 것일 수있습니다. \u0026ldquo;결과적으로 최근값이 이기고, 그동안 가장 최근값으로 관측 되는 값이 일겅진다\u0026rdquo; 일관성과 같이 요. 이 \u0026ldquo;어떻게?\u0026rdquo; 가 관건이며, 좋지 않은 메소드는 쓰기 작업을 잃어버릴 수도 있기 때문입니다. 예를 들어서, 만약 어떤 노드의 시계가. 잘못 설정되어 있었고, 그 타임스탬픅가 사용될 수 도 있죠\u0026hellip;\n이 두가지 질문에 대해 약화된 일관성 보델에 대한 복제 방식 챕터에서 더 자세히 다루겠습니다.\n","permalink":"https://nolleh.github.io/distributed-systems/2.level-of-abstraction/","summary":"다음에서 발췌 http://book.mixu.net/distsys/abstractions.html\n2. Up and down the level of abstraction 이 챕터에서는, 추상화의 레벨을 여행할 것이며, 몇가지 불가능한 결과를 보고, (CAP 와 FLP), 그리고 나서 성능에 대한 항해를 할 것 입니다.\n만약 어떤 프로그래밍을 완료했다면, 추상화. 수준에 대한 개념은 당신에게 익숙할 겁니다. 당신은 이미 추상화와 함께 했고, 어떤 API 를 통해 더 낮은 레이어와 인터페이싱하고 있을 것이며, 더 높은 레이어에 API 나 인터페이스를 제공하고있을 겁니다. OSI 네트워크 7 계층이 좋은 예죠.","title":"2.level of Abstraction"},{"content":"자주 사용하는 서브 모듈 명령어.\nadd submodule git submodule add {remote-repo} update git submodule init\ngit 에서 서브모듈을 관리하기위한 설정파일, gitmodules 를 설정한다. git submodule update remote 저장소로부터 업데이트 내용을 가져와서 적용한다. git submodule update --init remove submodule git submodule deinit -f {path} rm -rf .git/modules/{path} git rm -f {path} ","permalink":"https://nolleh.github.io/git/sub-module/","summary":"자주 사용하는 서브 모듈 명령어.\nadd submodule git submodule add {remote-repo} update git submodule init\ngit 에서 서브모듈을 관리하기위한 설정파일, gitmodules 를 설정한다. git submodule update remote 저장소로부터 업데이트 내용을 가져와서 적용한다. git submodule update --init remove submodule git submodule deinit -f {path} rm -rf .git/modules/{path} git rm -f {path} ","title":"서브 모듈 추가하기"},{"content":"1.12. Active-Passive Messaging Clusters 1.12.1 Overview HA 모듈은 active-passive, hot-standby 메시징 클러스터들을 장애에 tolerent 하도록 제공한다.\nactive-passive 클러스터는 하나의 브로커만 존재하며, 이를 프라이머리라고 부르며, 액티브 하고 클라이언트를 serving 한다. 다른 브로커들은 백업을 위해 존재한다. 프라이머리의 변경은 모든 백업들에 반영되므로, 백업들은 최신상태이거나 \u0026lsquo;hot\u0026rsquo; 상태이다. 백업 브로커들은 클라이언트의 연결을 거부하며, 클라이언트들은 프라이머리에 연결해야한다.\n만약 프라이머리가 실패하는 경우, 백업중의 하나가 새로운 프라이머리가 되기위해 자리를 차지한다. 클라이언트는 새로운 프라이머리에 자동으로 연결한다.\n만약 복수개의 백업이 있다면, 다른 백업들은 새로운 프라이머리의 백업이 되도록 장애처리를 진행한다.\n이 접근은 외부의 클러스터 리소스 매니저가 장애를 탐지하고, 새로운 프라이머리를 선택하며, 네트워크 파티션을 핸들링하는 것을 믿는것이다. rgmanager 는 이를 기본적으로 지원하며, 다른 것들은 미래에 제공될 것이다.\n1.12.1.1. Avoiding message loss 메시지가 모든 백업 브로커들에 대해 복제되는 것을 대기하거나 프라이머리 큐에서 consumed 되고 클라이언트로 응답(acknowledgement) 을 줌으로써 메시지의 유실을 회피한다.\n이것은 응답이 돌아온 모든 메시지들은 \u0026lsquo;safe\u0026rsquo; 하다는 것을 보장한다. : consumed 되거나, 다른 모든 브로커로 복제 되었음을. 복제 되기전에 consumed 된 메시지들은 복제가 될 필요가 없다. 액티브한 컨슈머가 있는 큐에 복제하는 부담을 줄여준다.\nprimary 에 의해 응답을 받기 전까지 버퍼에 미응답상태의 메시지를 보관해야한다. 만약 프라이머리가 실패하면, 클라이언트는 새로운 프라이머리에 연결하고 다시 메시지를 전송하는 장애처리를 수행해야한다.\n만약 프라이머리에 크래쉬가 발생하는 경우, 모든 응답을 받은 메시지들은 백업에 의해 가용하고, 이중에 새로운 프라이머리가 있을 것이다. 그래서 유실은 발생하지 않는다.\n하나 알아두어야 할것은, 메시지가 중복되서 전송될 수 있다는 것이다. 장애 발생시에 새로운 프라이머리에 의해 클라이언트로 다시 메시지를 전송하는 것이 가능하다. 이를 감지하고 중복을 제거하는 것은 어플리케이션의 몫이다.\n프라이머리가 새로 승격하는경우, 처음에 \u0026ldquo;recovering\u0026rdquo; 모드에 진입한다. 이 모드에서는, 모든 백업들이 프라이머리에 성공적으로 연결할때까지 메시지들에 대한 응답들을 지연한다.\n백업브로커에 모든 메시지가 복제될 필요는 없다. 만약 메시지가 consumed 되고 응답을 받은경우 복제될 필요는 없다.\nHA Broker State\nStand-alone cluster 의 일부가 아니다 Joining 새로 시작된 브로커이고, 어떤 프라이머리에도 아직 연결되지 않았다. Catch-up 프라이머리에 연결되었고, 상태를 다운로드 받는 중이다 (queues, messages.. ) Ready catch-up 을 완료했고 프라이머리가 될 준비가 되었다. Recovering 새로 승격한 프라이머리이며, 백업들이 연결하여 catchup 하도록 기다리고 있다. 클라이언트들은 연결할 수 있지만 프라이머리가 액티브 상태가 될때까지 엔진을 멈춘다. Active 모든 백업들이 연결되고 캐치업된 프라이머리 브로커 1.12.1.2. Limitations 현재 구현상 알려진 제한이 있다. 새 버전에서는 수정될 것.\n","permalink":"https://nolleh.github.io/qpid/1.12.active-passive-messaging-clusters/","summary":"1.12. Active-Passive Messaging Clusters 1.12.1 Overview HA 모듈은 active-passive, hot-standby 메시징 클러스터들을 장애에 tolerent 하도록 제공한다.\nactive-passive 클러스터는 하나의 브로커만 존재하며, 이를 프라이머리라고 부르며, 액티브 하고 클라이언트를 serving 한다. 다른 브로커들은 백업을 위해 존재한다. 프라이머리의 변경은 모든 백업들에 반영되므로, 백업들은 최신상태이거나 \u0026lsquo;hot\u0026rsquo; 상태이다. 백업 브로커들은 클라이언트의 연결을 거부하며, 클라이언트들은 프라이머리에 연결해야한다.\n만약 프라이머리가 실패하는 경우, 백업중의 하나가 새로운 프라이머리가 되기위해 자리를 차지한다. 클라이언트는 새로운 프라이머리에 자동으로 연결한다.\n만약 복수개의 백업이 있다면, 다른 백업들은 새로운 프라이머리의 백업이 되도록 장애처리를 진행한다.","title":"Active Passive Messaging Clusters"},{"content":"1.4 Broker Federation 메시지 라우트를 정의하여 하나의 브로커에서 다른 브로커로 자동으로 전달하게 한다.\n일반적으로 일방향이며, 라우트는 durable 하고 tansient 한다.\n연결이 소실되면 메시지는 누적되다가 재연결이 되면 다시 전송한다.\n라우팅에 사용되는 룰은 서버가 변경됨에 따라 동적으로 변경할 수 있으며, 변경의 책임은 다른 변경조건에 맞게 반영된다,.\n1.4.1 Message Routes pull / push 방식이 있음.\npull 은 dest 에서.\npush 는 src 에서 설정함\nqueue \u0026lt;-\u0026gt; exchage exchange \u0026lt;-\u0026gt; exchange excg \u0026lt;-\u0026gt; excg 는 다음과 같은 라우트를 가질 수 있다.\n1.4.1.1 Queue Routes 모든 메시지를 src 에서 dest 로.\n1.4.1.2 Exchange Routes 바인딩키에 따라 라우트함\n실제로는 내부적으로 큐가 (auto-delete, exclusive) 만들어지고, 이를 통해 연결하는 것.\n1.4.1.3 Dynamic Exchange Routes 클라이언트가 바인딩을 맺고, 이 exchange 만이 아니라 dynamic exchange route 를 통해 생성된 다른 exchange 도 수신한다. 바인딩 변경시, 이 exhcange 와 관련한 다른 exchange routes 또한 변경한다.\nsource 에 연결 된 모든 dest exchange 에 대해 적용되는데, 하나의 메시지라도 매치가 되면 dest 에 라우트되도록한다. dest 에서 바인딩들이 추가되거나 삭제되는경우, 이 변화는 DER 에 적용이 된다. dest 브로커가 바인딩을 주어진 바인딩키를 만들경우 라우트에 반영이되고 바인딩키를 제거할 경우 라우트는 더이상 메시지를 브로커들에게 전달하는 오버헤드를 갖지 않는다. 만약 두 excg 가 der 을 서로에 대해 갖는경우, 각각의 excg 에 대한 모든 바인딩은 der 에 반영된다. DER 에서, source 와 destination exchages 들은 같은 excage 타입을 가지고 있어야하고, 같은 이름을 가져야 한다. 내부적으로 dynamic exchage routes 는 exchage 라우트와 동일하게 구현되어 있는데, 다른점은 DEST Excg 에 바인딩이 있는 경우 DER 을 구현하는데 사용한 바인딩들이 수정됐다는것. (? except that the bindings used to implement dynamic exchange routes are modified if the bindings in the destination exchange change.)\nDER 은 항상 pull route 형식이다.\n1.4.2 Federation Topolpogies 보통 이 네트워크는 트리구조, 스타구조, 선형, 양방향 링크, 로 구성된다. 링 형태도 가능하지만, 이때는 단방향링크들만 사용하여야 한다.\n메시지를 빨리 전달 받기 위해서는 브로커 사이 홉을 줄이는 것이 중요. 그래서 대부분의 경우 트리나 스타 토폴로지가 최고다.\nA, B 가 있다고 할 때 서로를 연결하는 경로는 하나만이 있어야 할 것.\n만약 하나 이상의 경로가 있으면 중복된 메시지 전송을 야기하고 네트워크의 홍수를 일으킬 것.\n1.4.3 Federation among High Availablity Message Clusters fedration 은 일반적으로 High Availability Message Clusters 와 사용이 되는데, 클러스터들이 각각의 LAN 에 대해 고 안정성을 얻게끔한다.\n메시지 상태가 클러스터에서 복제 되기 때문에,\n같은 클러스터의 다른 브로커 사이에서 메시지 라우트를 정의하는 작은 개념을 만들어 준다.\n두 클러스터 사이에서 메시지를 생성하기 위해, 첫번째 클러스터에서 다른 클러스터의 브로커로 라우터를 만들어주면된다.\n1.4.4 The qpid-route Utility $ qpid-route [OPTIONS] dynamic add \u0026lt;dest-broker\u0026gt; \u0026lt;src-broker\u0026gt; \u0026lt;exchange\u0026gt; $ qpid-route [OPTIONS] dynamic del \u0026lt;dest-broker\u0026gt; \u0026lt;src-broker\u0026gt; \u0026lt;exchange\u0026gt; $ qpid-route [OPTIONS] route add \u0026lt;dest-broker\u0026gt; \u0026lt;src-broker\u0026gt; \u0026lt;exchange\u0026gt; \u0026lt;routing-key\u0026gt; $ qpid-route [OPTIONS] route del \u0026lt;dest-broker\u0026gt; \u0026lt;src-broker\u0026gt; \u0026lt;exchange\u0026gt; \u0026lt;routing-key\u0026gt; $ qpid-route [OPTIONS] queue add \u0026lt;dest-broker\u0026gt; \u0026lt;src-broker\u0026gt; \u0026lt;dest-exchange\u0026gt; \u0026lt;src-queue\u0026gt; $ qpid-route [OPTIONS] queue del \u0026lt;dest-broker\u0026gt; \u0026lt;src-broker\u0026gt; \u0026lt;dest-exchange\u0026gt; \u0026lt;src-queue\u0026gt; $ qpid-route [OPTIONS] list [\u0026lt;broker\u0026gt;] $ qpid-route [OPTIONS] flush [\u0026lt;broker\u0026gt;] $ qpid-route [OPTIONS] map [\u0026lt;broker\u0026gt;] $ qpid-route [OPTIONS] list connections [\u0026lt;broker\u0026gt;] The syntax for broker, dest-broker, and src-broker is as follows:\n[username/password@] hostname | ip-address [:\u0026lt;port\u0026gt;] The following are all valid examples of the above syntax: localhost, 10.1.1.7:10000, broker-host:10000, guest/guest@localhost.\nTable 1.9. qpid-route options\n-v Verbose output. -q Quiet output, will not print duplicate warnings. -d Make the route durable. \u0026ndash;timeout N Maximum time to wait when qpid-route connects to a broker, in seconds. Default is 10 seconds. \u0026ndash;ack N Acknowledge transfers of routed messages in batches of N. Default is 0 (no acknowledgements). Setting to 1 or greater enables acknowledgements; when using acknowledgements, values of N greater than 1 can significnantly improve performance, especially if there is significant network latency between the two brokers. -s [ \u0026ndash;src-local ] Configure the route in the source broker (create a push route). -t \u0026lt;transport\u0026gt; [ --transport \u0026lt;transport\u0026gt;] Transport protocol to be used for the route. _ tcp (default) _ ssl * rdma 1.4.4.1. Creating and Deleting Queue Routes $ qpid-route [OPTIONS] queue add \u0026lt;dest-broker\u0026gt; \u0026lt;src-broker\u0026gt; \u0026lt;dest-exchange\u0026gt; \u0026lt;src-queue\u0026gt; $ qpid-route [OPTIONS] queue del \u0026lt;dest-broker\u0026gt; \u0026lt;src-broker\u0026gt; \u0026lt;dest-exchange\u0026gt; \u0026lt;src-queue\u0026gt; 1.4.4.2. Exchange Routes ","permalink":"https://nolleh.github.io/qpid/1.4.broker-federation/","summary":"1.4 Broker Federation 메시지 라우트를 정의하여 하나의 브로커에서 다른 브로커로 자동으로 전달하게 한다.\n일반적으로 일방향이며, 라우트는 durable 하고 tansient 한다.\n연결이 소실되면 메시지는 누적되다가 재연결이 되면 다시 전송한다.\n라우팅에 사용되는 룰은 서버가 변경됨에 따라 동적으로 변경할 수 있으며, 변경의 책임은 다른 변경조건에 맞게 반영된다,.\n1.4.1 Message Routes pull / push 방식이 있음.\npull 은 dest 에서.\npush 는 src 에서 설정함\nqueue \u0026lt;-\u0026gt; exchage exchange \u0026lt;-\u0026gt; exchange excg \u0026lt;-\u0026gt; excg 는 다음과 같은 라우트를 가질 수 있다.","title":"Broker Federation"},{"content":" time_wait 종료 시간 확인 : ndd -get /dev/tcp tcp_time_wait_interval time_wait 종료 시간 30초로 설정 : ndd -set /dev/tcp tcp_time_wait_interval 30000 fin_wait_2 타임 아웃 시간 확인 : ndd -get /dev/tcp tcp_fin_wait_2_timeout fin_wait_2 타임 아웃 시간 5분으로 설정 : ndd -set /dev/tcp tcp_fin_wait_2_timeout 300000 출처: https://hyeonstorage.tistory.com/287 [개발이 하고 싶어요]\n","permalink":"https://nolleh.github.io/cheatsheet/network/","summary":"time_wait 종료 시간 확인 : ndd -get /dev/tcp tcp_time_wait_interval time_wait 종료 시간 30초로 설정 : ndd -set /dev/tcp tcp_time_wait_interval 30000 fin_wait_2 타임 아웃 시간 확인 : ndd -get /dev/tcp tcp_fin_wait_2_timeout fin_wait_2 타임 아웃 시간 5분으로 설정 : ndd -set /dev/tcp tcp_fin_wait_2_timeout 300000 출처: https://hyeonstorage.tistory.com/287 [개발이 하고 싶어요]","title":"Network"},{"content":"Docker Cheat Sheet 1. docker conntainer 내부 소켓 상태 확인 $ docker inspect -f \u0026#39;{{.State.Pid}}\u0026#39; cb2939r52s22 5645 [ec2-user@ip-10-100-77-76 ~]$ sudo nsenter -t 5645 -n netstat Active Internet connections (w/o servers) Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 0 ip-172-17-0-2.ec2.:webcache ip-10-100-77-225.ec2.:45104 ESTABLISHED tcp 0 0 ip-172-17-0-2.ec2.:webcache ip-10-100-77-225.ec2.:14804 TIME_WAIT tcp 0 0 ip-172-17-0-2.ec2.:webcache ip-10-100-76-6:seclayer-tls TIME_WAIT tcp 0 0 ip-172-17-0-2.ec2.:webcache ip-10-100-76-65.ec:plethora TIME_WAIT tcp 0 0 ip-172-17-0-2.ec2.:webcache ip-10-100-77-225.ec2.:14830 TIME_WAIT tcp 0 0 ip-172-17-0-2.ec2.:webcache ip-10-100-76-65.ec2.i:23284 ESTABLISHED tcp 0 0 ip-172-17-0-2.ec2.:webcache ip-10-100-76-65.ec2.i:27948 ESTABLISHED tcp 0 0 ip-172-17-0-2.ec2.:webcache ip-10-100-77-225.ec2.:14848 TIME_WAIT tcp 0 0 ip-172-17-0-2.ec2.:webcache ip-10-100-77-225.ec2.:45544 ESTABLISHED Active UNIX domain sockets (w/o servers) Proto RefCnt Flags Type State I-Node Path docker container 의 ulimit 가 호스트를 따라가지 않을 수 있음.\n빠르게 open 하고 close 시, 사용하는 ORM 솔루션에 따라 기대하는 동작과 다를 수 있음.\nsmall idle connection.. -\u0026gt; cause high reconnect rate.\n","permalink":"https://nolleh.github.io/cheatsheet/docker/","summary":"Docker Cheat Sheet 1. docker conntainer 내부 소켓 상태 확인 $ docker inspect -f \u0026#39;{{.State.Pid}}\u0026#39; cb2939r52s22 5645 [ec2-user@ip-10-100-77-76 ~]$ sudo nsenter -t 5645 -n netstat Active Internet connections (w/o servers) Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 0 ip-172-17-0-2.ec2.:webcache ip-10-100-77-225.ec2.:45104 ESTABLISHED tcp 0 0 ip-172-17-0-2.ec2.:webcache ip-10-100-77-225.ec2.:14804 TIME_WAIT tcp 0 0 ip-172-17-0-2.ec2.:webcache ip-10-100-76-6:seclayer-tls TIME_WAIT tcp 0 0 ip-172-17-0-2.ec2.:webcache ip-10-100-76-65.ec:plethora TIME_WAIT tcp 0 0 ip-172-17-0-2.ec2.:webcache ip-10-100-77-225.ec2.:14830 TIME_WAIT tcp 0 0 ip-172-17-0-2.","title":"Docker"},{"content":"한개 이상의 노드들의 논리적인 그룹을 의미하며, 각각은 유저와, 가상 호스트, 큐, exchanges, bindings 을 공유한다.\nCluster Formation 다음 방법들로 구성 가능\nDeclaratively by listing cluster nodes in config file Declaratively using DNS-based discovery Declaratively using AWS (EC2) instance discovery (via a plugin) Declaratively using Kubernetes discovery (via a plugin) Declaratively using Consul-based discovery (via a plugin) Declaratively using etcd-based discovery (via a plugin) Manually with rabbitmqctl 구성은 동적으로 변경 될수 있고, 모든 RabbitMQ 브로커는 하나의 노드로부터 시작해서 클러스터에 참여시키거나, 다시 개별의 브로커로 돌아갈 수 있다.\nNode Names (Identifiers) 클러스터 내에서 서로 구분할 수 있는 고유 값이어야함.\n환경 변수로 지정. RABBITMQ_NODENAME\nfully qulified domain names (FQDNs)를 사용하는 경우 RABBITMQ_USE_LONGNAME true 로 지정\nNodes in a Cluster 정상적으로 동작하기위해 모든 노드에 걸쳐 데이터와 상태가 복제 되어야 한다. 하나의 예외는 메시지 큐인데, 기본적으로 하나의 노드에서만 존재하지만 다른 노드들 사이에서 visible 하고 reachable 하다. 이마저도 복제하고 싶다면 HA 를 참고하라.\nNodes are Equal Peers 어떤 분산시스템들은 leader 와 follower 가 있지만 rabbitMQ 에서는 일반적으로 그렇지 않다. 모든 노드는 동등하다. 다만, 이주제는 queue mirroring 과 연관이 되면 미묘해진다.\nHOW CLI Tools Authenticate to Nodes (And Nodes to Each Other): the Erlang Cookie erlang cookie 라고 부르는 대칭키를 함께 보유하고 있어야한다.\n로컬키에 저장해둠.\n소유자에게 접근권한이 있어야함. (600 이나 유사 권한)\n파일이 없으면 생성하나, 이 방식은 모든 노드가 각자의 데이터를 생성하니, 개발단계에서 사용할 것.\n쿠키 생성은 클러스터 배포단계에서 완료되어야하며, 자동화와 오케스트레이션 툴을 이용하는 것을 추천한다.\nNode Counts and Quorum consensus 를 요구하는 플러그인들이 있으므로, 홀수개의 노드 추천.\nClustrering and Clients 모든 멤버가 정상적으로 동작할때 클라이언트는 어느노드나 붙어서 작업을 수행할 수 있다. 노드들은 연산을 큐 마스터 노드 (HA) 로 투명히 전달, 클라이언트로 돌려준다.\n실패한 경우 클라이언트는 다른 노드에 재연결하여 토폴로지를 복구하고, 다시 연산을 재개해야 한다. 이가 여의치 않은 경우 \u0026lsquo;미러링 되지 않은 큐가 실패한 노드에 있을 경우\u0026rsquo; 참고.\nClustering and Observability 클라이언트 연결과 채널, 큐들은 클러스터 노드들에 나뉘어져 있다.\n운영자들은 모든 클러스터 노드에 걸쳐 이를 관찰하고 모니터 할 필요가 있다.\nrabbitmq-diagnostics 와 rabbitmqctl 과 같은 CLI 툴의 경우 클러스터 단위의 리소스를 관찰하는 명령어들을 제공한다.\n어떤 커맨드들은 하나의 노드에 집중하기도 한다.0\n(e.g. rabbitmq-diagnostics environment and rabbitmq-diagnostics status)\nNode Failure Handling 각 개별의 노드의 장애에 대해서는 tolerate 하다.\n노드는 다른 클러스터 멤버 노드에 연결을 할 수 있는한, 원하면 실행되거나 중지될 수 있다.\n큐 미러링은 큐의 데이터가 복수의 클러스터 노드에 복제 될 수 있도록 한다.\n미러링 되지 않은 큐들도 클러스터에 사용될 수 있는데, 이런 큐들의 경우 노드 장애시 큐 durability 속성에 의해 동작이 정해진다.\nrabbitmq 클러스터링은 네트워크 파티션을 다루기 위한 (주로 일관성을 중시하는) 몇가지 모드가 있다.\nDisk and RAM Nodes 노드는 디스크 노드이거나 램 노드 일 수 있다. 램 노드들은 램에만 데이터베이스 테이블을 저장한다.\n여기에 메시지들은 포함하지 않는다.\n메시지는 색인, 큐 색인과 다른 노드 상태를 저장한다.\n대부분 디스크 노드를 사용하는 것을 원할 것이다. 램 노드는 큐, exchange, bind 가 많을때 성능 개선을 원하는 경우에 사용할 것이다. 램노드를 사용한다고 해서 메시지 비율이 개선 되진 않는다.\n램노드는 내부 데이터베이스테이블을 사용하기 때문에 peer 노드가 구동되는 경우 sync 해 줘야한다. 이는 하나의 디스크 노드는 필요하다는 것.\n","permalink":"https://nolleh.github.io/rabbitmq/clustering-guide/","summary":"한개 이상의 노드들의 논리적인 그룹을 의미하며, 각각은 유저와, 가상 호스트, 큐, exchanges, bindings 을 공유한다.\nCluster Formation 다음 방법들로 구성 가능\nDeclaratively by listing cluster nodes in config file Declaratively using DNS-based discovery Declaratively using AWS (EC2) instance discovery (via a plugin) Declaratively using Kubernetes discovery (via a plugin) Declaratively using Consul-based discovery (via a plugin) Declaratively using etcd-based discovery (via a plugin) Manually with rabbitmqctl 구성은 동적으로 변경 될수 있고, 모든 RabbitMQ 브로커는 하나의 노드로부터 시작해서 클러스터에 참여시키거나, 다시 개별의 브로커로 돌아갈 수 있다.","title":"Clustering Guide"},{"content":"","permalink":"https://nolleh.github.io/crypto/ssl/","summary":"","title":"SSL"},{"content":"ECDSA ref. https://m.blog.naver.com/aepkoreanet/221178375642\nec (타원곡선) 을 이용한 기술들의 집합 - ECC,\n이중에 디지털서명 관련 기술이 ECDSA\nTerms 유한체\n집합에 속해있는 원소의 수가 한정되어 있고 덧셈, 곱셈에 대해 닫혀있는 집합 유한체 F 표기법\n원소의 개수가 p 인 유한체 F 는 Fp 혹은 GF(p) 로 표기 유한체 상에 정의된 타원 곡선\nE(Fp) 암호학에서 사용되는 유한체 - Prime Field 원소의 개수가 소수 ECC 사용시 타원 곡선을 정의하는 domain parameter 를 정의해야함. (p, a, b, G, n, h) 를 정의해야하는건데, 여러 표준단체에서 Field Size 에 맞는 타원곡선에 대한 파라미터 발표.\np : Modulo Prime Number a : 타원곡선 방정식에서 사용되는 계수 b : 타원곡선 방정식에서 사용되는 계수 Base point 또는 Generator Point, G 는 E(Fp) 에 속해있는 point n : the order of point G (G 를 n번 더하면 무한원점이 되는값 : nG = ∞) H : cofactor 타원 곡선이란, 타원 곡선 방정식을 만족하는 집합을 곡선 그래프로 표시한 것\ny^2 = x^3 + ax + b\nsecp256k1 곡선의 경우 a = 0, b = 7 을 사용\nECC 의 privateKey 와 publicKey Private Key d : P 보다 적은 소수 (Prime) 로, 난수 생성기로 생성 Public Key Q : Q(x, y) = d x G(x0, y0) ECDSA 와 secp256k1 ECDSA 의 파라메터로 secp256k1 curve 를 사용 secp256k1\nsec - standard for Efficient Cryptography\np - parameter p over Fp\n256 - field size p 의 bit 수\nk - koblitz curve 변형\n1 - sequence number\nDomain Parameter T = (p,a,b,G,n,h) p : FFFFFFFF FFFFFFFF FFFFFFFF FFFFFFFF FFFFFFFF FFFFFFFF FFFFFFFF FFFFFC2F a : 00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000 b : 00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000007 G : 02 79BE667E F9DCBBAC 55A06295 CE870B07 029BFCDB 2DCE28D9 59F2815B 16F81798 또는 G : 04 79BE667E F9DCBBAC 55A06295 CE870B07 029BFCDB 2DCE28D9 59F2815B 16F81798 483ADA77 26A3C465 5DA4FBFC 0E1108A8 FD17B448 A6855419 9C47D08F FB10D4B8 N : FFFFFFFF FFFFFFFF FFFFFFFF FFFFFFFE BAAEDCE6 AF48A03B BFD25E8C D0364141 h : 01 서명은 어떻게 이루어지는가 ? https://ko.wikipedia.org/wiki/%ED%83%80%EC%9B%90%EA%B3%A1%EC%84%A0_DSA\ndomain parameter 로 (CURVE, g, n) 을 사용한다.\nCurve : 타원곡선의 체 (field) 와 여기 사용된 수식. g : 타원 곡선의 기준점 (base point). 해당 타원곡선의 생성원(generator) 이다. n : g 의 차수이다. n X g = 0 이며, 반드시 소수여야한다. 보통 충분히 큰 소수를 사용한다. privateKey, d 생성. - RNG 로 생성된 무작위로 선택된 1~ n-1 사이의 정수\npublicKey, Q 생성 - Q = dg 를 만족하는 정수. (g 를 d 번 더한 값)\n서명 프로세스\n필요한 것: E(Fp), d, Q, m\n1. e = H(m). 메시지를 해쉬하고 이를 e 라고 한다. 2. z = Ln(e) e 의 binary 값에서 왼쪽으로부터 n 번째 까지 잘라낸 값을 z 라고 한다. (left most n\u0026#39;th bit) 3. 암호학적으로 안전한 난수 k 를 [1, n-1] 사이에서 무작위로 선택한다. 4. 곡선 위의 점 (x1, y1) = k * g 를 계산한다. - 타원곡선에서의 덧셈은, 결국 다시 점이 된다. - 위 k * g 는 g 를 k 번 더하는 것을 의미하고, 결국 점이 된다. 5. r = x1 (mod n) 을 계산 한다. r 이 0 인 경우, k 를 다시 선택한다. 6. s = k^(-1)(z + rd) (mod n) 을 계산. s = 0 이면 3 으로 되돌아가 다른 k 를 선택, 순서대로 진행한다. 완성된 서명은 (r, s) 이다. 검증 프로세스\n필요한 것: E(Fp), (r,s), m\n- 곡선위의 점 인증 1. Q =/= O (identity element) 2. Q 가 곡선 위의 점인지 3. n x Q = O 인지 확인 - 서명 유효성 인증 1. r,s 가 1부터 n-1 사이의 정수인지 확인. 2. e = H(m) 을 계산. 3. z 계산 4. w = s^(-1)(mod n) 계산, u1 = zw, u2 = rw (mod n) 계산 5. shamir\u0026#39;s trick 을 사용해서 (x1, y1) = u1 x g + u2 x Q 를 계산. (x1, y1) = O 이면 무효 6. r = x1 (mod n) 일때만 유효. 즉, 서명 프로세스는 타원 곡선에서 새로운 k 와 (x1, y1) 을 구한 후\nECDSA 시그니쳐에서 어떻게 public key 를 복원할 수 있는가 ? stack exchange link\nECDSA signature (r,s)\n사실 곡선과 사용된 해쉬 함수, 서명된 메시지 원본을 알고 있더라도 signature 로부터 public key 를 recover 하는 것은 불가능하다.\n그러나, signature 와 원본 메시지, 곡선에 대한 정보로 두개의 public key 를 생성하는게 가능하다. (이 중에 private key 가 사용된 public key 가 있을 것)\n동작 원리는 다음과 같다.\nR 과 R\u0026rsquo; x 좌표로 r 값을 갖는 좌표를 찾는다. r^-1 을 연산하는데, 이는 시그니쳐의 r 의 곱셈 역원이다. (mod n) z 메시지 해쉬의 하위 n bit 인 z 를 연산한다. public key 는 r^(−1)(sR−zG) and r^(−1)(sR′−zG) 가 된다.\n","permalink":"https://nolleh.github.io/crypto/ecdsa/","summary":"ECDSA ref. https://m.blog.naver.com/aepkoreanet/221178375642\nec (타원곡선) 을 이용한 기술들의 집합 - ECC,\n이중에 디지털서명 관련 기술이 ECDSA\nTerms 유한체\n집합에 속해있는 원소의 수가 한정되어 있고 덧셈, 곱셈에 대해 닫혀있는 집합 유한체 F 표기법\n원소의 개수가 p 인 유한체 F 는 Fp 혹은 GF(p) 로 표기 유한체 상에 정의된 타원 곡선\nE(Fp) 암호학에서 사용되는 유한체 - Prime Field 원소의 개수가 소수 ECC 사용시 타원 곡선을 정의하는 domain parameter 를 정의해야함. (p, a, b, G, n, h) 를 정의해야하는건데, 여러 표준단체에서 Field Size 에 맞는 타원곡선에 대한 파라미터 발표.","title":"ECDSA"},{"content":"Best Practices for Using Cloud Storage 버킷에 변화가 있을때 반응하게 할 수 있다. https://cloud.google.com/storage/docs/pubsub-notifications\nDemo coldline 은 일년에 한번 접근하는것과 같은 문제발생시 복구하는 용도로 사용하면 좋다..\nhttps://cloud.google.com/storage/docs/managing-lifecycles\nDemo2 - Cors cors - https://developer.mozilla.org/en-US/docs/Web/HTTP/CORS cross-origin-resource sharing\ninstance 만들고 / apache 깔고 / cors 설정 여는 데모..\nBest Practices for cloud Storage request rate 가 초당 1000 쓰기 요청 이나 5000 읽기 요청을 넘어가면 ..\n이 기준 요청량내에서 요청을 시작해서 20 분마다 요청을 두배로 해라. ","permalink":"https://nolleh.github.io/coursera/gcp/6.datastorage/","summary":"Best Practices for Using Cloud Storage 버킷에 변화가 있을때 반응하게 할 수 있다. https://cloud.google.com/storage/docs/pubsub-notifications\nDemo coldline 은 일년에 한번 접근하는것과 같은 문제발생시 복구하는 용도로 사용하면 좋다..\nhttps://cloud.google.com/storage/docs/managing-lifecycles\nDemo2 - Cors cors - https://developer.mozilla.org/en-US/docs/Web/HTTP/CORS cross-origin-resource sharing\ninstance 만들고 / apache 깔고 / cors 설정 여는 데모..\nBest Practices for cloud Storage request rate 가 초당 1000 쓰기 요청 이나 5000 읽기 요청을 넘어가면 ..\n이 기준 요청량내에서 요청을 시작해서 20 분마다 요청을 두배로 해라.","title":"6. DataStorage"},{"content":"Cloud Datastore Concepts and Indexes Cloud Data Store concepts 데이터 오브젝트는 엔터티라고 불림 엔터티들은 하나이상의 프로퍼티로 구성됨 프로퍼티들은 하나이상의 값(values) 를 가질수 있음 각각의 엔터티는 구분되는 하나의 키를 가지고 있는데, 다음으로 구성 된다. 네임스페이스 엔터티 Kind 식별자 (스트링 or 숫자) 부모 ID 하나 이상의 엔터티에 대한 동작은 트랜잭션으로 불린다. Datastore has two types of indexes Built-in indexes Composite indexes 각각의 엔터티 Kind의 각각의 프로퍼티에 대해 자동으로 정의 인덱싱된 엔터티에 대해 다중의 프로퍼티 값을 인덱스함 간단한 쿼리에 적합 컴플렉스 쿼리에 적합 인덱스 설정파일에 정의 concept cloud datastore relational database 오브젝트 카테고리 Kind Table 한개 오브젝트 entity row 하나의 오브젝트를 위한 개별 데이터 프로퍼티 field 유니크 ID Key PrimaryKey Design Considerations \u0026amp; Sharding Design Your application for scale 엔터티 그룹에 대한 최대 쓰기율은 1/초 사전적으로 가까운 키에 대한 읽기와 쓰기를 너무 자주하지 말것. 구글의 noSQL 데이터베이스 Bigtable 을 이용해서 구현되어있는데 확장할때 로우들을 별도 테이블로 샤딩하는데 이 로우들이 키에 대해 사전적으로 정렬되어있기 때문. 점진적으로 ramp up traffic 을 새로운 클라우드 데이터 스토어에.. 빅테이블이 테이블을 분리하기에 충분할 시간을 주도록.. 클라우드 데이터스토어의 엔터티를 적은 범위의 키로 삭제하는 동작을 피해라 컴팩션(삭제된 엔트리를 제거하고 데이터를 재구성하여 읽기와 쓰기가 더 효율적으로 동작하도록 주기적으로 테이블을 다시쓰는 작업) 타임스탬프가 비슷해서 함께 있을 엔터티들을 많이 삭제하면, 이에 대한 쿼리가 컴팩션이 완료되기 전까지 늦을 수 있다. 핫 클라우드 데이터 스토어 키들에 대해 : use sharding, 쓰기가 빈번한 키 range 에. use replication, 읽기가 빈번한 키 range. When sharding, remember: 트랜잭션 스루풋은 1 write/sec per entity group 복수의 kinds 에 걸쳐 자주 업데이트 되는 엔터티는 분리하라. Shared counters to avoid contention with high writes contention 을 줄이기 위해:\nsharded counter 를 구축하라 (카운터를 N 개의 다른 카운터로 쪼개라) - 카운터를 올리기 위해 임의의 샤드를 선택하여 올린다 - 전체 카운트를 알기위해, 모든 샤드카운터를 읽어서 더해라. 샤드의 넘버를 올리는 것은 스루풋을 올리는 것.. increasing the number of shards will increase the throughput you will have for increments on you counter. Replicaion, Query Types, Transactions, and Handling Errors Use replication to read a portion of the key range 읽기 비율이 높은데에 사용. 엔터티에 대한 사본을 N 개에 대해 두면, 읽기 연산에 대해 N 배 빠르다.\nDevices -\u0026gt; Cloud Load Balance -\u0026gt; Front end App (AppEngine - auto scailiing)\nUse qurey types based on your needs Keys-only Projection (엔터티에서 프로퍼티를 얻어옴.) Ancester - 쿼리의 강한 일관성을 요할때. select * from task where __key__ has ancestor key(TaskList, \u0026lsquo;default\u0026rsquo;) Entity select * from task where done = FALSE Improve Your query latency by using cursors instead of offsets Demo: Use Cloud Dataflow to bulk-load data into Cloud data store pip install apache-beam\nlab git clone https://github.com/GoogleCloudPlatform/training-data-analyst\nSummary 조상을 지정하는 것으로 엔터티 그룹을 설정할수 있다.\n이렇게 해서 모든 관계된 엔터티들이 하나의 트랜잭션으로 업데이트 될 수 있다. 트래픽 램프업을 위해 555 룰을 따라라. 처음엔 초당 500 정도를 쓰다가 5분마다 50퍼센트씩 증가 시키는 것.\n","permalink":"https://nolleh.github.io/coursera/gcp/5.datastore/","summary":"Cloud Datastore Concepts and Indexes Cloud Data Store concepts 데이터 오브젝트는 엔터티라고 불림 엔터티들은 하나이상의 프로퍼티로 구성됨 프로퍼티들은 하나이상의 값(values) 를 가질수 있음 각각의 엔터티는 구분되는 하나의 키를 가지고 있는데, 다음으로 구성 된다. 네임스페이스 엔터티 Kind 식별자 (스트링 or 숫자) 부모 ID 하나 이상의 엔터티에 대한 동작은 트랜잭션으로 불린다. Datastore has two types of indexes Built-in indexes Composite indexes 각각의 엔터티 Kind의 각각의 프로퍼티에 대해 자동으로 정의 인덱싱된 엔터티에 대해 다중의 프로퍼티 값을 인덱스함 간단한 쿼리에 적합 컴플렉스 쿼리에 적합 인덱스 설정파일에 정의 concept cloud datastore relational database 오브젝트 카테고리 Kind Table 한개 오브젝트 entity row 하나의 오브젝트를 위한 개별 데이터 프로퍼티 field 유니크 ID Key PrimaryKey Design Considerations \u0026amp; Sharding Design Your application for scale 엔터티 그룹에 대한 최대 쓰기율은 1/초 사전적으로 가까운 키에 대한 읽기와 쓰기를 너무 자주하지 말것.","title":"5. Cloud DataStore Concepts and Indexes"},{"content":"Cloud Storage 크고 자주 사용되지 않은 비구조화된 데이터\nOverview ideal for 완전히 관리되고 고 신뢰가능 이미지와 비디오 비용절감. 확장가능한 오브젝트/블롭 저장 오브젝트와 블롭 http 로 접근 구조화되어있지 않은 데이터 오브젝트 이름이 키 정적 웹사이트 호스팅 Ideal for Cloud Datastore 관계형이나 데이터 분석에는 적합하지 않고 GAE 앱이나 구조화된 순수 제공 사용례에 적합한 구조화된 제공을 위한 스케일러블 저장소.\nOverView ideal for NoSQL 도큐먼트 데이터베이스 세미구조의 어플리케이션 데이터 확장가능 내구성이 필요한 키 밸류 데이터 계층구조 데이터 복수 인덱스 매니징 트랜잭션 Cloud Bigtable 고구조화 / 트랜잭셔널 데이터에는 적합하지 않고, flat 하고 많은 read/write 연산이나 분석을 위한 데이터에 적합한 큰 용량의 저지연 데이터베이스.\nOverview ideal for 고성능의 wide 컬럼의 NoSQL 동작가능한 어플리케이션 성긴 테이블 분석적 어플리케이션 백억의 로우, 수천컬럼으로 확장가능 단일키의 데이터가 크다 TB 나 PB 데이터 저장가능 맵리듀스 동작 Cloud SQL 확장성/분석/큰 쓰기 연산에는 적합하지 않은, 웹 프레임워크의 기존에 존재하는 어플리케이션에 적용 가능한 잘알려진 VM 용 RDBMS\nOverview idealfor 관리되는 서비스 (복제/페일오버/백업) 웹프레임워크 MySQL 과 PostgreSQL 구조화된 데이터 RDBMS OLTP 워크로드 프록시가 안전한 second 생성 인스턴스에 접근하도록 해줌(화이트리스팅없이.) MySQL/PGS 를 사용하는 어플리케이션 Cloud Spanner 분석적인 데이터에는 적합하지 않고, 저 지연의 트랜잭션적 시스템의 관계형 DB service\nOverview ideal for 미션 크리티컬 DB 미션크리티컬 어플리케이션 트랜잭션 일관성 높은 트랜잭션 글로벌 확장 확장과 일관성있는 요구사항들 고 사용성 멀티리젼 복제 99.999% SLA BigQuery 빠른 앱 빌딩에는 적합하지 않고, 정적 데이터 집합과의 분석을 위한 데에 사용되는 오토스케일링 분석 데이터 저장소\nOverview ideal for 저 비용의 엔터프라이즈 데이터 창고 온라인 분석 처리 (OLAP) 워크로드 완전히 관리됨 빅 데이터 탐색과 처리 페타바이트 스케일 비지니스 지능 툴을 통한 리포팅 빠른 응답성 서버리스 Run Microsoft SQL Server on GCP 구글 컴퓨트 엔진에서 SQL 서버 이미지 선택가능. 컴퓨트 엔진 VM 에 SQL Server 를 프리로드 할수있음 라이센싱은 자동으로 포함됨 지원 버전은 SQL Server Standard SQL Server Web SQL Server Enterprise ","permalink":"https://nolleh.github.io/coursera/gcp/4.db-overview/","summary":"Cloud Storage 크고 자주 사용되지 않은 비구조화된 데이터\nOverview ideal for 완전히 관리되고 고 신뢰가능 이미지와 비디오 비용절감. 확장가능한 오브젝트/블롭 저장 오브젝트와 블롭 http 로 접근 구조화되어있지 않은 데이터 오브젝트 이름이 키 정적 웹사이트 호스팅 Ideal for Cloud Datastore 관계형이나 데이터 분석에는 적합하지 않고 GAE 앱이나 구조화된 순수 제공 사용례에 적합한 구조화된 제공을 위한 스케일러블 저장소.\nOverView ideal for NoSQL 도큐먼트 데이터베이스 세미구조의 어플리케이션 데이터 확장가능 내구성이 필요한 키 밸류 데이터 계층구조 데이터 복수 인덱스 매니징 트랜잭션 Cloud Bigtable 고구조화 / 트랜잭셔널 데이터에는 적합하지 않고, flat 하고 많은 read/write 연산이나 분석을 위한 데이터에 적합한 큰 용량의 저지연 데이터베이스.","title":"4.Cloud Storage, Cloud Datastore, Cloud Bigtable, Cloud SQL, and Cloud Spanner"},{"content":"What are the Google Cloud Client Libraries? 관용적인 코드를 각각의 랭귀지에 대해 제공 gRPC 에서 성능 효과를 보는 라이브러리도 있다.\ngithub repo\ngcloud - 커맨드 라인툴, gcp를 위한.\nGC cloud 빅쿼리를 위한 커맨드라인 툴\ngsuitl 버킷이랑 통신하기 위한 커맨드라인 툴\ngcloud init (initialize )\nCloud Shell 브라우저 베이스 커맨드라인툴. 일시적인 vm에 대한 접근을 제공. 5GB 디스크 SDK 에 이미 설치되어있음\n구글클라우드 콘솔프로젝트에대한 authorization /리소스 제공\n코드 에디터가 포함 (beta)\nModule Review Api Explore: google cloud api 를 테스트하기위한 샌드박스로 사용 Google Cloud Client Library : GCP 서비스와 커뮤니케이션 GCP Service 의 스크립트 작성 : Google Cloud SDK\n","permalink":"https://nolleh.github.io/coursera/gcp/3.sdk/","summary":"What are the Google Cloud Client Libraries? 관용적인 코드를 각각의 랭귀지에 대해 제공 gRPC 에서 성능 효과를 보는 라이브러리도 있다.\ngithub repo\ngcloud - 커맨드 라인툴, gcp를 위한.\nGC cloud 빅쿼리를 위한 커맨드라인 툴\ngsuitl 버킷이랑 통신하기 위한 커맨드라인 툴\ngcloud init (initialize )\nCloud Shell 브라우저 베이스 커맨드라인툴. 일시적인 vm에 대한 접근을 제공. 5GB 디스크 SDK 에 이미 설치되어있음\n구글클라우드 콘솔프로젝트에대한 authorization /리소스 제공\n코드 에디터가 포함 (beta)\nModule Review Api Explore: google cloud api 를 테스트하기위한 샌드박스로 사용 Google Cloud Client Library : GCP 서비스와 커뮤니케이션 GCP Service 의 스크립트 작성 : Google Cloud SDK","title":"3.SDK"},{"content":"12 Best Practices for user saccount https://cloud.google.com/blog/products/gcp/12-best-practices-for-user-account GCP 에서는 유저 계정에 대한 안전한 핸들링과 인증을 위한 툴을 게공한다. 웹사이트가 구글 쿠버네티스엔진에 호스트 되는 웹사이트를 담당하든, apigee 의 api 를 담당하든, firebase 를 사용하든, 어떤 다른 서비스를 통해 유저를 인증하든, 이 포스트는 좋은 연습을 제공해서, 안전하고 확장가능하고 쓸만한 계정 인증 시스템을 사용할 수 있게 도와줄 것이다.\n1. 패스워드를 해시하라. 패스워드를 포함해서, 예민한 개인정보를 어떻게 저장할 것인가가 계정관리의 가장 중요한 규칙이다. 이 데이터를 신성하게 다뤄야한다. 다시 reverse 될 수 없는 강력한 해쉬로되어야한다. 예를들면, PBKDF2, Argon2, Scripy, Bcrypt .. 또한, 이 해쉬는 salted 되어야 한다. MD5 나 SHA1 같은 deprecate 된 해쉬기술은 사용하면 안되며, revirsiable 될 수 있는 인크립션을 사용해야하는 상황은 어디에도 없으며, 직접 해쉬 알고리즘을 개발할 필요도 없다. 라고 생각하자.\n2. 서드파티 식별 제공자를 허락하자. 믿을수 있게한다. 구글, 페이스북, 트위터등이 흔히 사용된다. firebase Auth 시스템을 통해 인증처리를 할 수도 있다. -다른 사례들을 보면, 반나절만에 적용하고 그렇다. fabulas?\n3. 유저 식별의 개념을 유저 계정의 개념과 분리하라. 유저는 이메일 어드레스도, 핸드폰 번호도, OAUTH 응답의 unique ID 도 아니다. 유저 유저는 유일성의 최고점에 있으며, 당신 서비스의 개인화된 데이터와 경험이다. 잘 디자인된 유저관리 체계는 low 커플링 되어있으며, 고수준으로 응집되어있다.\n유저 계정과 보안을 분리하는 개념을 고수하는 것은 서드파티의 식별제공자를 구현하는 과정을 크게 단순화 할 수 있다. 유저는 유저 이름이나 다중의 정체성을 하나의 유저 계정에 연결 할 수도 있게 된다. 실제 용어로 옮기면, 내부의 전역 식별자를 모든 유저와 그들의 프로필과, 인증에 연결할 수도 있다.\n4. 하나의 계정에 복수의 정체성을 허용할 수 있도록 제공하라. 한 유저는 유저명과 패스워드를 사용하여 인증한후에, 이 과정이 계정을 생성할 수 있는지 모르고 구글 사이닝을 선택할 수있다. 유사하게, 어떤 유저는 복수의 이메일 주서를 당신의 서비스에 연결할 이유가 있었을 수도 있습니다. 만약 유저 식별과 인증을 분리해 두었다면, 하나의 유저에 대해 다양한 식별 정보를 연결하는게 간단하다.\n사용자가 기존 계정에 연결되지 않은 서드파티 아이디를 사용하고 있다는 것을 깨닫기전에 새로 가입하는 프로세스를 수행할 수 있는 가능성을 고려해야 한다. 흔한 식별 정보를 제공하도록 묻는것 만으로도 해결될 수 있다. 이메일어드레스, 폰이나 유저명 등.. 시스템에 존재한다면, 인증 후 새로운 아이디를 존재하는 계정에 연결하자.\n5. 길거나 복잡한 패스워드를 막지 말자. NIST 는 최근에 패스워드 복잡도와 강인함에 대해 가이드라인을 제공했다. 패스워드 길이를 막아서 얻을 수 있는건 POST 사이즈 뿐.. (끽해봐야 1MB?)\n해쉬된 패스워드는 알려진 적은 ASCII문자의 선택으로 압축될 수 있고, 그렇지 않으면 그냥 바이너리 해쉬를 Base64 로 변경해도 된다.\n6. user name 에 타당치 않은 규칙을 강요하지 마라 ","permalink":"https://nolleh.github.io/coursera/gcp/1-1.12-tips/","summary":"12 Best Practices for user saccount https://cloud.google.com/blog/products/gcp/12-best-practices-for-user-account GCP 에서는 유저 계정에 대한 안전한 핸들링과 인증을 위한 툴을 게공한다. 웹사이트가 구글 쿠버네티스엔진에 호스트 되는 웹사이트를 담당하든, apigee 의 api 를 담당하든, firebase 를 사용하든, 어떤 다른 서비스를 통해 유저를 인증하든, 이 포스트는 좋은 연습을 제공해서, 안전하고 확장가능하고 쓸만한 계정 인증 시스템을 사용할 수 있게 도와줄 것이다.\n1. 패스워드를 해시하라. 패스워드를 포함해서, 예민한 개인정보를 어떻게 저장할 것인가가 계정관리의 가장 중요한 규칙이다. 이 데이터를 신성하게 다뤄야한다.","title":"1-1. 계정관리를 위한 12 tips"},{"content":"3. Security, Reliablitiy, and Migration Use federated identity management firebase authentication~ 외부의 identity provider 를 통해 ..\nImplement health-check endpoint Stackdriver monitoring (helth monitoring agent) -\u0026gt; /health upcheck. 어디에 ? storage / database, network connection, 다른 의존들 .. 실패하면 자동으로 알림을 준다.\n로깅과 모니터를 어플리케이션의 성능에 대해 두라. 로그를 이벤트 스트림으로 취급하라. 어플리케이션에서는 건들지 말고 stdout 등으로 노출되는 데이터를 다른애가 후처리 해라 . 구글의 스택드라이버를 통해 어플리케이션을 디버그할 수 있고, 에러 모니터링을 설정할 수 있다.\n사소한 에러와 오래 지속되는 에러를 우아하게 다뤄라. trasient erros: 지수적으로 backoff 하여 재시도 해라. 구글클라이언트 클라이언트라이브러리는 재시도에 대해 자동적으로 수행한다.\n서비스 가용성 에러: 서킷브레이커를 구현해라. 유저에게 에러를 매번 노출하는 것은 피하는 것노출하는 것도 고려. .\n데이터 sovereignnty 와 compliance 요구사항을 고려하라. 어떤 나라에서 데이터보관에 대해 어떻게 규정하고 있는지\u0026hellip;\n가능한 테스팅과 재앙으로부터 복구계획을 구상하고 어플을 테스트하라. 실패시나리오의 예: 연결 실패 데이터 센터나 클라우드 제공자의 실패 GCP 존이나 리전 실패 배포 롤백 네트워크나 어플리케이션 이슈의 데이터 파괴\n계속되는 통합모델 (CI) 을 구현하고 파이프라인으로 배송하라. (CD) 강력한 devops 모델을 구현하라.\n코드 저장소 -\u0026gt; 빌드시스템 (배포아티팩트빌드/유닛테스트 실행) -\u0026gt; 배포시스템 (실환경과 테스트환경에 아티팩트를 배포) -\u0026gt; 1. 테스트환경 (통합테스트, 보안, 퍼포먼스 테스트.) / 2. 실환경 (성능 관찰)\n큰 수정이 있을때 배포하는 것이 아니라 작은 수정이 이씅ㄹ때마다 배포가 자동화되어 regression 의 리스크를 줄이며 디버그를 재빨리 하며, 이전 테이블의 빌드로 쉽게 롤백할 수 있게한다.\nStrangler 패턴을 새로 어플리케이션을 구조화하는데 사용하라. 이패턴: 구버전의 어플리케이션을 조금씩 새로운 서비스의 컴포넌트로 교체해 나가는것.\n","permalink":"https://nolleh.github.io/coursera/gcp/2.security-reliability-migration/","summary":"3. Security, Reliablitiy, and Migration Use federated identity management firebase authentication~ 외부의 identity provider 를 통해 ..\nImplement health-check endpoint Stackdriver monitoring (helth monitoring agent) -\u0026gt; /health upcheck. 어디에 ? storage / database, network connection, 다른 의존들 .. 실패하면 자동으로 알림을 준다.\n로깅과 모니터를 어플리케이션의 성능에 대해 두라. 로그를 이벤트 스트림으로 취급하라. 어플리케이션에서는 건들지 말고 stdout 등으로 노출되는 데이터를 다른애가 후처리 해라 . 구글의 스택드라이버를 통해 어플리케이션을 디버그할 수 있고, 에러 모니터링을 설정할 수 있다.","title":"2.Security-Reliability-Migration"},{"content":"Loosely Coupled Microservices and API gateway 모놀리틱에서는 기본 코드가 부풀게 되서, 어디를 고쳐야하는지 알기가 어렵다. 패키지들의 의존성들이 얼키고 설킨다.\n작은 기본 코드를 고쳐도 전체 프로그램이 배포되어 테스트될 필요가 있다.\n원격지에 의한 제어는 비동기 처리를 하자.\n가능한한 이벤트 드리븐 처리를 하자. -\u0026gt; 예를들어 구글 클라우드서비스에 이미지를 업데이트하고~ 이 이벤트에 반응하여 동작하는 어플리케이션을 만들 수 있다.\n커플링을 줄이기 위해 메시지 큐 등을 사용할 수 있다. 토픽에 대해 발송, 받아 처리.\nCache content 반응성을 위해 컨텐츠를 캐싱해서, TTL 이 지나기전의 캐쉬 데이터를 준다. 없거나 만료됐으면 새로 계산(이후 캐시에 저장) 멤캐시나 레디스에 저장한다.\nImplement API gateway, 컨슈머 어플리케이션에 백엔드 기능이 동작할 수 있도록..\n","permalink":"https://nolleh.github.io/coursera/gcp/1.msaandapigateway/","summary":"Loosely Coupled Microservices and API gateway 모놀리틱에서는 기본 코드가 부풀게 되서, 어디를 고쳐야하는지 알기가 어렵다. 패키지들의 의존성들이 얼키고 설킨다.\n작은 기본 코드를 고쳐도 전체 프로그램이 배포되어 테스트될 필요가 있다.\n원격지에 의한 제어는 비동기 처리를 하자.\n가능한한 이벤트 드리븐 처리를 하자. -\u0026gt; 예를들어 구글 클라우드서비스에 이미지를 업데이트하고~ 이 이벤트에 반응하여 동작하는 어플리케이션을 만들 수 있다.\n커플링을 줄이기 위해 메시지 큐 등을 사용할 수 있다. 토픽에 대해 발송, 받아 처리.\nCache content 반응성을 위해 컨텐츠를 캐싱해서, TTL 이 지나기전의 캐쉬 데이터를 준다.","title":"1.MSA and ApiGateway"},{"content":" 다음에서 발췌 ()[]\nSmart Contract 블록은 트랜잭션을 포함한다. 트랜잭션은 액션의 기록이다. 액션은 컨트랙트의 동작이다. 스마트컨트랙트의 사용\neos.io 의 컨트랙트는 abi 로 표현된다. 어플리케이션 코드는 json data 를 이용한 http 를 통해 contract 를 트리거 한다. EOS.IO 는 컨트랙트를 간단히 스크립팅하거나 테스팅하기위한 커맨드라인 인터페이스를 제공한다. Intro Smart Contracts EOS.IO 스마트 컨트랙트는 WebAssembly 로 구동된다. (WASM)\nweb 표준으로 떠오르는중 c/c++ 로부터 clang/llvm 을 통해 생성된다. 다른 언어들도 언젠가 지원될 것 Transaction - 실행되는 하나이상의 액션의 집합.\n하나의 액션이라도 실패하면 모든 트랜잭션이 실패한다 Action - 스마트컨트랙트를 실행하는 고수준의 함수\n데이터를 컨트랙트에 전송하기 위해서는 payload 를 포함해야한다. cloes 는 http 를 호출하는 syntatic sugar~\ntransaction json 을 살펴보면. signature 가 있고, 이 특정한 트랜잭션의 시그니쳐를 표현한다.\naction json 은 이런 형태\nactions : [{ \u0026quot;account\u0026quot;: \u0026quot;eosio\u0026quot;, \u0026quot;name\u0026quot;: \u0026quot;newaccount\u0026quot;,\u0026quot;actor\u0026quot;: \u0026quot;eosio\u0026quot;, \u0026quot;permission\u0026quot;: \u0026quot;acitve\u0026quot; }], \u0026quot;Data\u0026quot;: \u0026quot;000000000ea30550 .. 000a8ed32320100\u0026quot; }]\naccount : 액션을 실행하는 계정의 이름 (스마트 컨트랙트가 올라가있는 계정. 어떻게 action 을 실행할지에 대해 알고있다.) name : \u0026ldquo;authroization\u0026rdquo;: [{ // 어떤 시그니쳐가 필요한지 나타낸다. data : hex 로 표현된 값 table 을 업데이트할때, payer 에 대해 0 를 전달하면 이전 payer 를 그대로 사용한다.\nunittest - test_api -\u0026gt; tests directories . - api_tests.cpp\n#include \u0026lt;boost/test/unit_test.hpp\u0026gt; #inclue \u0026lt;eosio.token/eosio.token.wast.hpp\u0026gt; abi.hpp\u0026gt; BOOST_AUTO_TEST_SUITE(dice_tests) BOOST_FIXTURE_TEST_CASE(dice_test, dice_tester) try { create_accounts( {N(eosio.token), N(dice), N(alice), N(bob), false}); set_code(N(eosio.token), eosio_token_wast); set_abi(N(eosio.token), eosio_token_abi); push_action(N(eosio.token), N(create), N(eosio.toekn), mvo() (\u0026#34;issuer\u0026#34;, \u0026#34;eosio.token\u0026#34;)) } load balcancing 을 담당하는 릴레이노드 / producer node 가 별개로 있다\n특정노드에 컨트랙트를 전송 ? host 지정 하면 된다.\ncontext free action 를 어디서배우면 되나~ //\ntransaction 을 트랙킹하기위해 플러그인을 사용해도 된다. mongodb plugin 등.\n","permalink":"https://nolleh.github.io/block-chain-youtube/building-distributed-app/","summary":"다음에서 발췌 ()[]\nSmart Contract 블록은 트랜잭션을 포함한다. 트랜잭션은 액션의 기록이다. 액션은 컨트랙트의 동작이다. 스마트컨트랙트의 사용\neos.io 의 컨트랙트는 abi 로 표현된다. 어플리케이션 코드는 json data 를 이용한 http 를 통해 contract 를 트리거 한다. EOS.IO 는 컨트랙트를 간단히 스크립팅하거나 테스팅하기위한 커맨드라인 인터페이스를 제공한다. Intro Smart Contracts EOS.IO 스마트 컨트랙트는 WebAssembly 로 구동된다. (WASM)\nweb 표준으로 떠오르는중 c/c++ 로부터 clang/llvm 을 통해 생성된다. 다른 언어들도 언젠가 지원될 것 Transaction - 실행되는 하나이상의 액션의 집합.","title":"Building Distributed App"},{"content":" 다음에서 발췌 http://book.mixu.net/distsys/intro.html\n1. Distributed systems at a highlevel 분산 프로그래밍은 같은 문제를 하나의 컴퓨터에서 해결할 수 있는 문제를 여러 컴퓨터에서 해결하는 예술이다. 컴퓨터 시스템이라면 해결해야 하는 두개의 문제가 있습니다.\n저장소 연산 분산 프로그래밍은 하나의 컴퓨터에서 해결할 수 있는 문제를 여러 컴퓨터를 통해 해결하는 예술입니다. 보통 하나의 컴퓨터에서 해결하기에는 적합하지 않은 문제를 위해서입니다.\n실세계에서의 어떤것도 분산시스템을 요구하지는 않습니다. 무한한 돈과 무한한 실시간 연구 시간이 있다면, 분산시스템은 필요없습니다. 모든 연산과 모든 저장소는 매직박스 안에서 실행 될 수 있습니다 - 하나의, 믿을 수 없을정도로 빠르고, 믿을 수 없을정도로 신뢰할 수 있는 시스템은 누군가에게 돈을 지불하거나 당신이 직접 디자인할 필요가 있겟죠.\n하지만, 그렇게 무한한 자원을 가지고 있는 사람은 별로 없습니다. 때문에, 그들은 좋은 장소와실제 세계에서, 비용적인 측면에서 고려할 수 있는 적합한 실세계의 장소를 찾아야 합니다. 작은 사이즈 에서는 하드웨어를 업그레이드 하는 것은 필수적인 전략입니다. 하지만, 문제의 사이즈가 커짐에 따라 싱글 노드의 하드웨어 업그레이드 만으로는 문제를 해결할수 없거나, 비용적으로 막히는 지점이 오게 됩니다. 이 포인트에서, 분산 시스템으로 오신것을 환영할 때가 된것 같네요!\n이것은 현재의 현실이고 어떤 현실이냐면 가장 가치있는 중앙 범위, 상업적인 소프트웨어 - 유지보수 비용이 문제가 발생했을때도 괜찮은 소프트웨어로 유지될 수 있도록 해줍니다.\n연산(computations)은 대부분 고수준의 하드웨어가 네트워크 접근을 내부 메모리 접근으로 변경했을때 혜택을 본다고 할 수 있습니다. 노드들 사이에서의 방대한 커뮤니케이션을 요구하는 작업들로 인해 제한 되던 하드웨어들에서 효과를 볼 수 있겠죠.\n위의 Barroso, Cildaras \u0026amp; Holzle 피규어에서 보여주듯, 고수준과 상품(commodity) 하드웨어의 성능 차이가\n모든 노드에 걸쳐 하나의 메모리 접근으로 가게 됨에 따라 줄어듦을 살펴 볼수 있습니다.\n이상적으로, 하나의 머신을 추가하는 것은 시스템의 생산력과(capacity) 성능을 선형적으로 올려줄겁니다. 그러나 물론 이것은 불가능하며, 분리된 컴퓨터들 사이에 오버헤드가 추가 됨으로써 야기 됩니다. 데이터들은 복사될 필요가 있고, 연산 작업들은 조정되어야 하는 등의 작업들이 그렇습니다. 이 때문에 분산 알고리즘을 공부하는 것에 가치가 생기게 됩니다. - 어떤 문제들에 있어서 효율적인 솔루션을 제공하고, 가능하다면 올바르게 구현함을 통해 최소한의 비용만 사용할 수 있도록 가이드 해주거나, 불가능함을 알 수 있게 됩니다.\n이 문서의 목적은 일반적인 경우의 분산 프로그래밍에 대해 초점을 둘 것 이지만, 상업적에 관련한 설정에 대해서도 관심을 둘겁니다: 데이터 센터. 예를 들어서, 괴짜적인 네트워크 설정에 대해서는 논의 하지 않을것이며, 공유 메모리를 위한 설정에 대해서도 이야기 하지 않을 겁니다. 또한, 이 문서에서는 어떤 특정 디자인에 대해 최적화를 하기보다, 시스템 디자인 공간을 탐험하는데 시간을 할애할 겁니다. - 특정 디자인에 대한 최적화는 보다 특화된 주제 입니다.\nWhat we want to achieve: Scalability and other good things 모든 것은 결국 사이즈를 다루는 데서 시작합니다.\n대부분의 것들은 사소하고, 작은 스케일에서 시작되도 됩니다. - 그리고 같은 문제들은 어떤 특정사이즈, 볼륨, 물리적인 제약을 초과하게 되면서 점점 어려워지게 됩니다. 초콜릿을 들어올리는 것은 쉽지만, 산을 들어올리는 것은 어려워 집니다. 한 방에 몇명이 있는지 세는 것은 쉽지만, 한 나라에 얼마나 많은 사람들이 있는지 세는것은 어려워 지듯이요.\n그래서, 모든것은 사이즈에서 시작합니다 - 확장성. 공식적으로 말해서, 문제들이 크게 나빠지지 않도록 작은 시스템에서 큰 시스템으로 확장될 수 있는 시스템. 여기 다른 정의가 있습니다.\nScalability: 어떤 시스템, 네트워크, 프로세스의 늘어나는 작업을 핸들링 하거나, 수용력을 확장할 수 있도록 하는 능력.\n\u0026lsquo;늘어난다\u0026rsquo;는 것은 무엇인가? \u0026lsquo;성장\u0026rsquo;을 어떤 용어로는 측정할 수 있습니다. (사람이 늘어난다, 전력량이 늘어난다 등등). 하지만, 다음과 같이 특히 관심게 봐두면 좋을 것들이 있습니다.\n사이즈의 확장성: 노드를 추가하면, 시스템을 선형적으로 빠르게 만들어야 한다; 데이터집합의 증가가 지연을 만들지 않아야 한다. 지역적인 확장성: 복수의 데이터 센터를 사용하여 유저의 쿼리에 대한 응답성을 유지해야하며, 데이터 센터의 교점에 있어서는 감각적인 방법으로 잘 처리해야할 것. 운영적인 확장성: 노드를 추가하는것 운영 코스트를 증대 시키지 않아야한다. (운영자-장비 비율) 물론, 실제 시스템의 증대는 다른 차원의(여러 축의) 문제이긴 합니다.; 각각의 메트릭(요소)들이 성장의 한 측면을 캡쳐하고 있습니다.\n확장 가능한 시스템은 유저가 증대됨에도 지속적으로 요구를 충족시킴을 의미합니다. 이것에 관련한 두개의 관점이 있습니다. - 성능과 가용성 - 이것들은 다양한 방법으로 측정될 수 있습니다.\nPerformance (and latency) Performance 는 시간과 리소스 측면에서 유용한 작업의 양으로 특징할 수 있다.\n문맥에 따라, 아래의 내용과 한 개 이상 관여할 수 있습니다.\n주어진 작업 수행을 위한 응답성/적은 지연 높은 처리량 (처리량의 비율) 낮은 리소스 사용률 이런 결과를 얻기 위해 포기해야할 비용들이 있기 마련입니다. 연산 오버헤드를 줄이고 높은 처리량을 위해 더 큰 배치를 처리하는경우, 개별의 작업에 대한 응답은 더 늦어지는 결과로 이어지게 되는것처럼요.\n낮은 지연 - 빠른 응답성 - 은 성능에 있어서, 물리적(비용적인 측면보다는)인 제약에 크게 영향받기 때문에 가장 관심있는 요소가 됩니다. 성능의 다른 요소들에 비해 비용을 투자해서 \u0026lsquo;지연\u0026rsquo;을 다루기엔 어렵죠.\n지연에 대한 많은 정의가 있지만, 다음과 같이 연상되는 아이디어를 좋아합니다.\nLatency 지연된다; 지연, 어떤 것이 개시된 시점으로부터 일어나기까지의 시간\n그럼 \u0026rsquo;latent\u0026rsquo; 란?\nLatent 라틴어 lateo (숨겨져 있는) 의 현재 분사형인 latens, latentis 로부터 유래. 비활성화 되어있거나, 숨겨져 있음을 나타내는데 사용된다.\n이 정의는 꽤 멋진데, 왜냐하면 지연이라는 것이 어떻게 시작되고 영향을 주고 볼수있게 되는지 에 대한 시간간격을 나타내는데 초점을 두고 있기 때문입니다.\n예를들어서, 당신이 에어본 바이러스에 감염되어 사람들을 좀비로 만들고 있다고 해봅시다. 이 지연 시간은 당신이 감염되었을때 시작되어 당신이 좀비로 변하는 시간이 됩니다. 이것이 지연입니다: 이미 일어난 어떤것이 숨겨져서 보이지 않는것.\n우리 분산시스템이 하나의 큰 작업을 필요로 한다고 생각해봅시다: 시스템의 모든 데이터를 읽어 하나의 결과를 연산해야합니다. 다른 말로 하면, 하나의 분산 시스템을 데이터 저장소로 생각하고 하나의 연산을 해야하는데, 현재 저장된 데이터들에 대해 수행해야 합니다. :\nresult = query(all data in the system)\n어떤일이 일어날까요? 과거데이터가 아니라 현재의 새로운 데이터에 처리되어야한다면요. 사용자에게 보여지기 까지의 시간으로 지연을 측정할 수 있겠습니다.\n또 다른 키포인트는, 아무일도 일어나지 않은것에 대한 정의에 기반할 수 있는데, 여기엔 \u0026lsquo;지연시간\u0026rsquo;이 없습니다.\n분산시스템에서, 최소한의 지연은 극복될 수 없습니다: 광속의 한계, 하드웨어 컴포넌트들이 최소한의 지연 비용이 연산마다 있기 때문입니다. (램과 하드드라이브, CPU 도 생각해보세요.)\n최소한의 지연시간이 어느 정도냐가 전송되어야하는 물리적거리, 쿼리의 본질에 영향을 받아 당신의 쿼리의 지연시간에 영향을 줄겁니다.\nAvailability (and fault tolerance) 확장 가능한 시스템에 두번째로 고려해 볼 것은 가용성입니다.\nAvailablility 기능적인 측면(상태, condition) 에서의 시스템의 시간 비율. 만약 유저가 시스템에 접근할 수 없다면, 가용적이지 않다. 라고 이야기 할 수 있다.\n분산 시스템은 하나의 시스템에서 이루기 어려운일을 이룰수 있게 해줍니다. 예를 들면, 하나의 머신으로 구성된 시스템은 실패하거나, 동작하지 않기때문에 (or doesn\u0026rsquo;t) 어떤 오류에도 tolerant 하지 않습니다.\n분산 시스템은 \u0026lsquo;신뢰성 없는 묶음\u0026rsquo; 으로 신뢰성 있는 시스템을 만들어냅니다.\n불필요하게 장황하지 않은 시스템은 아래 구성되어있는 요소들만큼 가용성이 있습니다. 불필요하게 장황하게 구성된 시스템은 일부의 실패에 대해서도 tolerant 하고, 따라서 더 가용성이 있습니다. \u0026lsquo;불필요하게 장황하다\u0026rsquo;라는 말이 어떤 시각으로 보느냐에 따라 다른 의미를 가질 수 있겠네요 - 컴포넌트, 서버, 데이터센터, 등등..\n공식화해보자면, 가용성이란: Availability = uptime / (uptime + downtime)\n기술적인 측면에서 가용성이란, fault tolerant 를 의미합니다. 컴포넌트의 구성 요소들이 늘어남에 따라 실패의 확률이 늘어나기 때문에, 시스템은 컴포넌트의 숫자와 신뢰성이 반비례 하지 않도록 구성되어야합니다.\n예를 들어서:\nAvailability % 일년에 downtime 이 얼마나 허용될 수 있을까 ? 90% (one nine) More Than a month 99% (two nines) Less than 4 days 99.9 % (three nines) Less than 9 hours 99.99% (four nines) Less than an hour 99.999% (five nines) ~ 5 minues 99.99999% (six nines) ~ 31 seconds 가용성은 uptime 이라는 개념보다 더 넓은 개념으로 널리 사용되기도 하는데, 이는 서비스의 가용성은 네트워크의 outage 나 서비스를 책임지는 회사의 영향을 받기 때문입니다. (fault tolerance 와 실질적으로 연관되어있지는 않지만 시스템의 가용성에 영향을 줄 수 있음). 그러나 시스템의 면면을 알고 있지 않으면, 우리가 할 수 있는 건 fault tolerance 겠네요.\nfault tolerant 하다는건 어떤 말일까요.\nFault tolerance 시스템에 fault 가 발생했을때 잘정의된 방식으로 동작하는 것\nfault tolerance 는 이렇게 정리할 수 있습니다: 어떤 실패가 있을것이라 예상하고 시스템이나 알고리즘을 디자인하는가. 실패를 예상하지 못하면, 고려될 수도 없다.\nWhat prevent us from acheving good things? 분산 시스템은 두 물리적 요소로 인해 제약됩니다.\n노드의 개수 (요구되는 저장소와 연산 용량에 영향) 노드간의 거리 (정보가 전달되기 위함. 최대속도는 광속) 이 제약들 위에서 작업하기 위해:\n독립된 노드의 수들의 증가는 시스템의 실패율을 올린다. (가용성을 줄이고 운영 비용을 높임) 독립된 노드의 수의 증가는 노드들간의 통신 필요성을 높일수 있다. (스케일이 커짐에 따라 성능이 줄어든다.) 서로 떨어진 노드들 끼리의 물리적인 거리의 증가는 최소한의 통신지연을 높인다. (어떤 동작들의 퍼포먼스를 저해한다.) 이런 경향들을 넘어서 - 물리적인 제약의 결과 - 는 것이 시스템 디자인의 세계입니다.\n퍼포먼스와 가용성 시스템이 구성하는 외부적인 보증에 의해 정의됩니다. 고수준의 시스템에서, SLA (서비스 레벨 동의?) 를 통해 보장되고 있습니다; 데이터를 쓰면, 얼마나 빨리 다른 곳에서 접근할 수 있을까? 데이터가 쓰여지고 나면, 내구성이 있음은 어떻게보 장받을수 있을까 ? 시스템이 연산을 하도록 요청하면, 얼마나 빨리 결과를 돌려줄까 ? 구성 요소가 실패하면, 혹은, 동작에서 제외 되면, 시스템에 어떤 영향을 줄까?\n다른 기준이 있는데, 명시적으로 언급되진 않았지만, 내포되어있습니다; 이해성인데, 보장하는 내용이 얼마나 수용가능한가? 물론, 무엇이 수용가능한지 쉽게 정의할 수 있는 단순한 메트릭은 없습니다.\n저는 \u0026lsquo;이해성\u0026rsquo;을 물리적인 제한으로 분류하는 경향이 있습니다. 결국에는, 하드웨어의 제한이 우리가 우리 손가락 이상으로 움직이는 것들을 (외국 속담인듯. 예상이상의 일들을 일컫는것으로 추측된다) 이해하는걸 어렵게 하고 있죠. 에러와 변칙의 차이가 될겁니다 - 에러는 정상적이지 않은 동작, 변칙적인것은 예상치 못한 동작. 만약 당신이 똑똑하다면, 변칙적인 동작도 예상할 수 있을 겁니다.\nAbstractions and models 추상화와 모델이 역할을 할 때가 됐군요. 추상화는 문제를 해결하는 데 필요없는 문제들을 제거함으로써 문제를 더 통제할 수 있도록 만들어 줍니다. 모델들은 분산시스템의 속성들의 주요 속성들을 꽤 적합한 매너로 묘사합니다. 다음 챕터에서 더 많은 모델에 대해 다룰 건데, 이런겁니다.\n시스템 모델 (비동기/동기) 실패 모델 (크래쉬-실패, 파티셔닝, 비잔틴) 지속성 모델 (강하거나, 이벤트 기반이거나) 좋은 추상화는 시스템을 이해하기 쉽게 만들고, 특정 목적에 관련한 요소들을 제한(capture) 하는데 도움을 줍니다.\n많은 노드들과 다른 우리의 욕구.. \u0026lsquo;하나의 시스템처럼 동작\u0026rsquo;을 유지하는 데에는 긴장이 있습니다. 종종, 우리가 익숙한 대부분은(예를들어 분산시스템에서 추상화된 공유 메모리를 구현하는것) 너무 비용이 많이 듭니다.\n더 작은 보장을 할수록, 동작에 대 많은 자유를 보장하고, 잠재적으로 더 높은 퍼포 먼스를 제공하게 됩니다 - 그러나 이것 역시 잠재적으로 이유를 알아내기가 어렵습니다. 사람들은 단일 시스템에 대해 추리(리즈닝)하는 데 더 낫고, 노드들의 집합에는 상대적으로 약하죠.\n보통 시스템의 내부에 대해 디테일을 노출하는 것으로 성능을 얻기도 합니다. 예를 들면, columnar storage 에서, 유저는 추측할수 있다. 키밸류 페어의 지역성에 대하여, 그리고 결정할 수 있다.일반적인 쿼리의 성능의 영향성을. 시스템은 이런 디테일을 숨기는 시스템은 더 쉽다 이해하기가. (왜냐하면, 그들은 하나의 단위로 동작하는 것과 같고, 디테일에 대해 생각할 게 더 적다). 반면에 더 실세계의 디테일을 노출하는 것은 더 좋은 수행자다.(실세계에 더 가까우니까)\n몇몇의 실패의 유형에서, 단일 시스템으로 구성된것처럼 분산시스템에서 동작하도록 하는 것은 어렵습니다. 네트워크 지연과 네트워크 파티션 (노드들 사이의 모든 네트워크 실패) 은 시스템이 가용하게 유지하지만 어떤 중대한 보장을 강제하지 못하는 것을 감수 할지, 혹은 안전하게, 요청을 거절할지 선택해야할 수 있습니다.\nCAP 이론 - 다음 챕터에서 다룰 - 은 이런 긴장을 다룹니다(captures). 마지막에는, 이상적인 시스템은 프로그래머의 필요(클린한 의도)와 비즈니스 요구 (가용성/지속성/지연성). 을 만족시킵니다.\nDesign techniques: partition and replicate 어떤 데이터 집합이 복수의 노드에 분산되도록 하는 매너는 상당히 어려운 주제 입니다. 어떤 연산이 수행되도록 하기 위해서는, 우리는 데이터를 위치시키고, 여기에 동작할 필요가 있습니다.\n데이터 집합에 적용될 수 있는 두가지 기본 테크닉이있는데, 다양한 노드들에 분할 하여, (partitioning) 동시에 실행 될 수 있는 양을 늘리는 겁니다. 이것은 또한 다른 노드에 복사되거나 캐쉬 되어 클라이언트와 서버 사이의 거리를 줄여, 더 큰 fault tolerance 를 얻는 방법이 있습니다. (replication).\nDivide and conquer - I mean, partition and replicate. 아래의 그림은 이 두개의 차이점을 보여줍니다.: 파티션데이터 (A 와 B). 독립된 두개집합으로 나뉘었으며, 복제 데이터는 두 위치에 복사되어 위치되어 있습니다.\n이 것은 분산시스템에서 어떤 문제든 해결하는 원-투 펀치 입니다. 물론, 트릭은 구체적인 구현에 따라 올바른 테크닉을 선택하는 겁니다; 복제와 파티셔닝을 구현하는 많은 알고리즘들이 있고, 각각은 다른 제한과 이점이있어 원하는 디자인 목표를 이루기 위해 적절한 평가가 이뤄져야 합니다.\nPartitioning 파티셔닝은 데이터셋을 작은 구분된 집합으로 나눕닙니다; 이것은 데이터 집합의 성장을 줄이는데, 각각의 파티션이 데이터의 서브셋이기 때문입니다.\n파티셔닝은 측정되어야하는 데이터의 양을 제한하고, 관련한 데이터들을 함께 위치시켜 성능을 증대시킵니다. 파티셔닝은 파티션들은 독립적으로 실패하도록 허용함으로써, 가용성을 증대시키고, 가용성이 희생되기 전에 실패해야하는 노드 수를 증가 시킵니다. 파티셔닝은 또한 상당히 어플리케이션 특화되어 있어서, 세부 내용을 알지 못하면 자세히 이야기 할 수 없습니다. 그렇기때문에 복제가 대부분의 문서에서 다뤄지게 됩니다. (이 문서를 포함해서)\n파티셔닝은 대부분 당신이 주로 접근하는 패턴이라 생각하는 것에 기반해서 파티션을 정의하게 되며, 독립적인 파티션을 갖게 됨에 따라 오게 되는 제한들을 다루게 되게 됩니다. (e.g. 효율적이지 않은 파티션의 접근, 성장 비율과 다른 비율, 등등 )\nReplication 복제는 같은 데이터를 복수의 장비에 위치시킵니다; 이것은 연산에 더 많은 장비가 참여할 수 있도록 합니다.\n호머 제이 심슨을 인용해 보겠습니다.\n복제를 하기 위해! 모든 인생의 문제의 원인, 해결책이다.\n복제 - 복사나 어떤것의 재현 - 은 우리가 지연과 함께 싸울 수 있는 주요한 방법 입니다.\n복제는 새 데이터의 복사본에 적용가능한 추가적인 컴퓨팅 파워와 대역폭을 통해 추가적인 성능을 얻습니다.\n복제는 데이터의 복사를 생성함으로써 가용성을 향상시키고, 가용성이 희생 되기 전에 노드의 수를 증가 시킵니다.\n복제는 추가적인 대역폭을 제공하는 것이며, 캐싱이 의존하는 형태가 됩니다 이것은 또한 일관성을 유지하며 지속성모델에 따라 유지 합니다.\n복제는 확장을, 퍼포먼스를, fault tolerance 를 가능하게 합니다. 가용성의 손실이나 저해된 성능이 걱정되시나요? 데이터를 복제하는것이 한 지점에서의 실패나 병목 현상을 회피 할 수 있게 해줍니다. 낮은 연산? 복수의 시스템에서 연산하도록 복제하세요. 낮은 I/O? 로컬캐쉬를 데이터에 적용하여 지연을 줄이거나 복수의 장비에 적용하여 대역폭을 증대시킬 수 있도록 복제하세요.\n복제는 또한 많은 문제들의 원인이기도 한데, 복사된 데이터들은 이제 독립적이기때문에, 동기화가 이뤄져야하기 때문입니다 - 이것은 복제가 일관성 모델을 따라야함을 의미합니다.\n일관성 모델을 선택하는 것은 중대합니다: 좋은 일관성 모델은 프로그래머에게 간결한 의미를 제공합니다. (다른 말로하면, 이해하기 쉬운 형태로 유지가 된다는 이야기힙니다.) 또한 고가용성/강력한 일관성에 대한 비지니스/디자인 목표를 충족합니다.\n복제에 대한 하나의 일관성 모델 - 강력한 일관성 - 은 프로그램이 복제되지 않은 것 처럼 동작하게 합니다. 다른 일관성 모델은 내부적인 처리를 프로그래머가 감안하도록 합니다. 그러나, 더 약한 일관성 모델룰 수록 낮은 지연과 높은 가용성을 제공합니다 - 그리고 이해하기 어려운것이 아니라, 다를 뿐입니다.\n","permalink":"https://nolleh.github.io/distributed-systems/1.highlevel/","summary":"다음에서 발췌 http://book.mixu.net/distsys/intro.html\n1. Distributed systems at a highlevel 분산 프로그래밍은 같은 문제를 하나의 컴퓨터에서 해결할 수 있는 문제를 여러 컴퓨터에서 해결하는 예술이다. 컴퓨터 시스템이라면 해결해야 하는 두개의 문제가 있습니다.\n저장소 연산 분산 프로그래밍은 하나의 컴퓨터에서 해결할 수 있는 문제를 여러 컴퓨터를 통해 해결하는 예술입니다. 보통 하나의 컴퓨터에서 해결하기에는 적합하지 않은 문제를 위해서입니다.\n실세계에서의 어떤것도 분산시스템을 요구하지는 않습니다. 무한한 돈과 무한한 실시간 연구 시간이 있다면, 분산시스템은 필요없습니다. 모든 연산과 모든 저장소는 매직박스 안에서 실행 될 수 있습니다 - 하나의, 믿을 수 없을정도로 빠르고, 믿을 수 없을정도로 신뢰할 수 있는 시스템은 누군가에게 돈을 지불하거나 당신이 직접 디자인할 필요가 있겟죠.","title":"1. Distributed systems at a highlevel"},{"content":"hello 라는 이름의 디렉토리를 contracts directory 에 생성하자.\ncd CONTRACTS_DIR mkdir hello cd hello hello.cpp 를 생성하고 에디터로 열자.\ntouch hello.cpp 필요한 라이브러리를 이 파일에 include 한다.\n#include \u0026lt;eosiolib/eosio.hpp\u0026gt; #include \u0026lt;eosiolib/print.hpp\u0026gt; 코드를 간결하게 해줄 eosio 네임스페이스를 contract 에 추가한다.\nusing namespace eosio; eosiolib/eosio.hpp 가 EOSIO C 와 C++ API 를 당신의 contract 스코프에 로드한다. 표준 C++11 클래스를 생성한다. 이 contract class 는 eosio::contract 를 확장해야한다.\n#include \u0026lt;eosiolib/eosio.hpp\u0026gt; #include \u0026lt;eosiolib/print.hpp\u0026gt; using namespace eosio; class hello : public contract {}; 비어있는 contract 는 좋지 않으니, public 접근 지정자와 using 선언을 추가하자. 이 using 선언은 좀 더 간결한 코드를 쓸 수 있도록 도움을 줄것이다.\n이제 contract 는 어떤 작업을 하도록 구성한다. hello world 의 정신을 받아 \u0026ldquo;name\u0026rdquo; 파라메터를 수신하고, 파라메터를 출력하는 작업을 해보자.\n#include \u0026lt;eosiolib/eosio.hpp\u0026gt; #include \u0026lt;eosiolib/print.hpp\u0026gt; using namespace eosio; class hello : public contract { public: using contract::contract; [[eosio::action]] void hi( name user ) { print( \u0026#34;Hello, \u0026#34;, name{user}); } }; 위의 동작은 user 라는 이름의 파라메터를 name type 으로 전달 받는다.\nEOSIO 는 몇개의 typedef 를 선언하고 있는데, 이 중에 흔한 하나가 바로 이 name 이다.\neosio::print를 사용함으로써, 문자열을 user 파라미터와 붙여 출력한다.\n괄호를 이용한 초기화 name{user} 는 user 파라메터가 출력될 수 있도록 해준다.\neosio.cdt 의 abi 생성자는 atttrubite 없이는 hi() 의 동작을 알 수 없다. c++11 스타일의 attribute 를 action 의 상위에 추가하여 abi generator 가 신뢰 할 수 있는 출력을 할 수 있도록 한다.\n#include \u0026lt;eosiolib/eosio.hpp\u0026gt; #include \u0026lt;eosiolib/print.hpp\u0026gt; using namespace eosio; class hello : public contract { public: using contract::contract; [[eosio::action]] void hi( name user ) { print( \u0026#34;Hello, \u0026#34;, user); } }; EOSIO_DISPATCH( hello, (hi)) 마지막으로, EOSIO_DISPATCH 매크로를 추가하여 hello contract 의 dispatch 액션을 처리하도록 한다.\n이제 web assembly 를 통해 컴파일해보자.\neosio-cpp -o hello.wasm hello.cpp --abigen contract 가 배포되면, 계정으로 배포되어 이 계정이 contract 의 인터페이스가 된다.\n이 튜토리얼의 이전에 언급하였듯, 같은 public key 를 모든계정에서 사용하여 간단히 할 수 있다.\ncleos wallet keys 이 contract 를 위한 계정을 생성하기 위해 cleos create account 를 사용한다.\ncleos create account eosio hello YOUR_PUBLIC_KEY -p eosio@active 컴파일된 wasm 을 cleos set contract 를 통해 블록체인으로 broadcast 한다.\ncleos set contract hello CONTRACTS_DIR/hello -p hello@active 훌륭하다! 이제 contract 가 설정 되었고, action 을 push 해보자.\ncleos push action hello hi \u0026#39;[\u0026#34;bob\u0026#34;]\u0026#39; -p bob@active executed transaction: 28d92256c8ffd8b0255be324e4596b7c745f50f85722d0c4400471bc184b9a16 244 bytes 1000 cycles # hello.code \u0026lt;= hello.code::hi {\u0026#34;user\u0026#34;:\u0026#34;bob\u0026#34;} \u0026gt;\u0026gt; Hello, bob 예상했던대로 hello, bob 이 출력된다.\n이번 경우, \u0026ldquo;alice\u0026rdquo; 가 권한이 있고 user 는 단순한 argument 이다. contract 를 수정하여 권한이 있는 유저가 \u0026ldquo;hi\u0026rdquo; 를 받을 유저와 동일한 경우에만 동작하도록 해보자.\nrequire_auth 메소드를 사용한다.\n이 메소드는 name 을 파라메터로 받아서 action 을 수행하는 사용자가 제공된 파라메터와 일치하는지 확인한다.\nvoid hi( name user ) { require_auth( user ); print( \u0026#34;Hello, \u0026#34;, name{user} ); } 다시 컴파일 한다.\neosio-cpp -o hello.wasm hello.cpp --abigen 그리고 update 한다.\ncleos set contract hello CONTRACTS_DIR/hello -p hello@active 실행하되, 이번에는 권한이 일치 않도록 한다.\ncleos push action hello hi \u0026#39;[\u0026#34;bob\u0026#34;]\u0026#39; -p alice@active Error 3090004: Missing required authority Ensure that you have the related authority inside your transaction!; If you are currently using \u0026#39;cleos push action\u0026#39; command, try to add the [relevant](**http://google.com**) authority using -p option. 우리의 contract 수정으로, 제공된 name user 가 승인 유저와 동일한지 확인한다.\n다시 실행하되, 이번엔 alice account 의 권한으로 실행해보자.\ncleos push action hello hi \u0026#39;[\u0026#34;alice\u0026#34;]\u0026#39; -p alice@active executed transaction: 235bd766c2097f4a698cfb948eb2e709532df8d18458b92c9c6aae74ed8e4518 244 bytes 1000 cycles # hello \u0026lt;= hello::hi {\u0026#34;user\u0026#34;:\u0026#34;alice\u0026#34;} \u0026gt;\u0026gt; Hello, alice ","permalink":"https://nolleh.github.io/block-chain/2.1-helloworld/","summary":"hello 라는 이름의 디렉토리를 contracts directory 에 생성하자.\ncd CONTRACTS_DIR mkdir hello cd hello hello.cpp 를 생성하고 에디터로 열자.\ntouch hello.cpp 필요한 라이브러리를 이 파일에 include 한다.\n#include \u0026lt;eosiolib/eosio.hpp\u0026gt; #include \u0026lt;eosiolib/print.hpp\u0026gt; 코드를 간결하게 해줄 eosio 네임스페이스를 contract 에 추가한다.\nusing namespace eosio; eosiolib/eosio.hpp 가 EOSIO C 와 C++ API 를 당신의 contract 스코프에 로드한다. 표준 C++11 클래스를 생성한다. 이 contract class 는 eosio::contract 를 확장해야한다.\n#include \u0026lt;eosiolib/eosio.hpp\u0026gt; #include \u0026lt;eosiolib/print.hpp\u0026gt; using namespace eosio; class hello : public contract {}; 비어있는 contract 는 좋지 않으니, public 접근 지정자와 using 선언을 추가하자.","title":"EOSIO - 2.1/Hello World!"},{"content":" 다음에서 발췌 EOSIO - 1.7 Create Test Accounts\nWhat is an account? 블록체인에 저장되어 송신자와 수신자를 구분하는데 사용되는 승인의 집합체라 할 수 있다. 유연한 권한 승인 구조를 가질 수 있는데, 권한이 어떻게 설정되느냐에 따른 개인이나 그룹에 의해 소유될 수 있다.\n하나의 계정은 블록체인의 트랜잭션을 보내거나 받기 위해 요구된다.\n이 튜토리얼에서는 두개의 user 계정, bob 과 alice, 그리고 설정을 위한 기본 eosio 계정을 사용한다. 추가로 계정들은 다양한 contracts 를 위해 이 튜토리얼 시리즈에서 만들어 질 수 있다.\nStep 1: Create Test Accounts 이전 단계에서, wallet 과 개발키 쌍을 생성하였다. form 에 public key 를 지정하도록 요청받았지만, 이 단계를 넘기거나 쿠키를 사용하지 않도록 설정하였을 수있다. 생성된 publickey 를 YOUR_PUBLIC_KEY 에 기입하여 진행하자.\n이 튜토리얼동안 유저 bob 가 alice 가 사용된다. 두 계정은 cleos create accounts 를 통해 생성된다.\ncleos create account eosio bob YOUR_PUBLIC_KEY cleos create account eosio alice YOUR_PUBLIC_KEY 트랜잭션이 발송 되었음을 나타내는 다음과 같은 메시지가 노출된다.\nexecuted transaction: 40c605006de... 200 bytes 153 us # eosio \u0026lt;= eosio::newaccount {\u0026#34;creator\u0026#34;:\u0026#34;eosio\u0026#34;,\u0026#34;name\u0026#34;:\u0026#34;alice\u0026#34;,\u0026#34;owner\u0026#34;:{\u0026#34;threshold\u0026#34;:1,\u0026#34;keys\u0026#34;:[{\u0026#34;key\u0026#34;:\u0026#34;EOS5rti4LTL53xptjgQBXv9HxyU... warning: transaction executed locally, but may not be confirmed by the network yet ] Using Different Keys for Active/Owner on a PRODUCTION Network EOSIO has a unique authorization structure that has added security for you account. You can minimize the exposure of your account by keeping the owner key cold, while using the key associated with your active permission. This way, if your active key were every compromised, you could regain control over your account with your owner key.\n","permalink":"https://nolleh.github.io/block-chain/1.7-createtestaccount/","summary":"다음에서 발췌 EOSIO - 1.7 Create Test Accounts\nWhat is an account? 블록체인에 저장되어 송신자와 수신자를 구분하는데 사용되는 승인의 집합체라 할 수 있다. 유연한 권한 승인 구조를 가질 수 있는데, 권한이 어떻게 설정되느냐에 따른 개인이나 그룹에 의해 소유될 수 있다.\n하나의 계정은 블록체인의 트랜잭션을 보내거나 받기 위해 요구된다.\n이 튜토리얼에서는 두개의 user 계정, bob 과 alice, 그리고 설정을 위한 기본 eosio 계정을 사용한다. 추가로 계정들은 다양한 contracts 를 위해 이 튜토리얼 시리즈에서 만들어 질 수 있다.","title":"EOSIO - 1.7/Test 계정 생성하기"},{"content":"Step 1: Wallet 생성하기 먼저 wallet 을 생성한다. cleos wallet create 를 통해 기본 wallet 을 --to-console 옵션을 사용하여 간단하게 생성한다.\ncleos 를 production 환경에서 사용한다면, 대신 --to-file 옵션을 사용하여 wallet 의 패스워드를 배쉬 기록에 남지않도록 한다.\n개발 목적으로 사용하는 production 환경의 키가 아니기때문에 \u0026ndash;to-console 으로 보안 위협없이 사용할 수 있다.\ncleos wallet create --to-console cleos 는 패스워드를 반환하며, 이 패스워드를 다음 튜토리얼에서 이용할 수 있도록 저장하자.\nCreating wallet: default Save password to use in the future to unlock this wallet. Without password imported keys will not be retrievable. \u0026#34;PW5Kewn9L76X8Fpd....................t42S9XCw2\u0026#34; wallet 에 대해 wallet 의 암호 해독성에 대한 흔한 오해중의 하나는 토큰을 저장할 것이라는 것이다. wallet 은 토큰을 저장하지 않는다. wallet 은 private key 를 암호화된 파일에 저장하고 사이닝 트랜젝션에 활용한다.\n유저는 주로 인터페이스를 통해 트랜잭션 오브젝트를 빌드하고, 그 오브젝트를 서명될 수 있도록 wallet 에 전송하여, wallet 이 이후 시그니쳐와 함께 오브젝트를 네트워크를 통해 반환한다. 네트워크가 트랜잭션을 유효하다고 판단하면, 이를 블록체인의 블록에 포함시킨다.\nStep2: Open the wallet keosd 인스턴스를 시작하고 다면 wallet은 닫히게 된다. 실행시키고 싶다면 다음 명령어를 활용한다.\ncleos wallet open 다시 리스트를 조회해보면\ncleos wallet list 다음과 같이 반환된다.\nWallets: [ \u0026#34;default\u0026#34; ] Step 3: Unlock it keosd wallet 은 열려있지만 여전히 잠겨있다. 좀전에 비밀번호를 제공받았으므로, 이를 이제 사용한다.\ncleos wallet unlock 비밀번호를 입력하고 다시 리스트를 조회해보면\nWallets: [ \u0026#34;default *\u0026#34; ] 열렸음을 의미하는 * 가 붙어있다.\nStep 4: Import keys into your wallet private key 를 생성하기 위한 cleos 명령어가 있다.\ncleos wallet create_key Step 5: Follow this tutorial series more easily 얻은 public key 를 입력하자.\nStep 6:Import the Development Key 새로운 EOSIO 체인마다 \u0026ldquo;eosio\u0026rdquo; 라 불리는 기본적인 \u0026ldquo;system\u0026rdquo; 유저를 보유한다.\n이 계정은 시스템 contracts 들을 로딩함으로써 governance 와 EOSIO 체인의 컨센서스를 지휘하는 체인을 설정하는데 사용된다.\n모든 EOSIO 체인은 development key 와 함께 제공되는데, 모두 동일하다. 이 키를 로드하여 시스템유저(eosio) 대신 트랜잭션을 서명해보자.\ncleos wallet import private key 를 질의 할텐데, 다음을 입력한다.\n5KQwrPbwdL6PhXujxW37FSSQZ1JiwsST4cqQzDeyXtP79zkvFD3 이제 default wallet 이 해금되고 key 로 load 되었으니, 다음을 진행 할 수 있게 되었다.\n","permalink":"https://nolleh.github.io/block-chain/1.6-createdevelopmentwallet/","summary":"Step 1: Wallet 생성하기 먼저 wallet 을 생성한다. cleos wallet create 를 통해 기본 wallet 을 --to-console 옵션을 사용하여 간단하게 생성한다.\ncleos 를 production 환경에서 사용한다면, 대신 --to-file 옵션을 사용하여 wallet 의 패스워드를 배쉬 기록에 남지않도록 한다.\n개발 목적으로 사용하는 production 환경의 키가 아니기때문에 \u0026ndash;to-console 으로 보안 위협없이 사용할 수 있다.\ncleos wallet create --to-console cleos 는 패스워드를 반환하며, 이 패스워드를 다음 튜토리얼에서 이용할 수 있도록 저장하자.\nCreating wallet: default Save password to use in the future to unlock this wallet.","title":"EOSIO - 1.6/개발 Wallet 생성하기"},{"content":" 다음에서 발췌 - EOSIO - 1.5 Install The CDT\nEOSIO Contract Development Toolkit, CDT 는 contract 컴파일을 위한 툴의 집합이다. 뒤따를 튜토리얼들은 contract 들을 컴파일하고 ABI 를 생성하는 주요 CDT 를 사용한다.\n1.3.x 버전부터, CDT 는 Mac OS X brew, linux debian 과 RPM 패키지들을 지원한다. 설치하기 위한 가장쉬운 선택지는 이 패키지 시스템들을 이용하는 것이다. 하나의 방법을 선택하자.\nHomeBrew (Mac OS X) Install brew tap eosio/eosio.cdt brew install eosio.cdt Uninstall brew remove eosio.cdt ","permalink":"https://nolleh.github.io/block-chain/1.5-installthecdt/","summary":"다음에서 발췌 - EOSIO - 1.5 Install The CDT\nEOSIO Contract Development Toolkit, CDT 는 contract 컴파일을 위한 툴의 집합이다. 뒤따를 튜토리얼들은 contract 들을 컴파일하고 ABI 를 생성하는 주요 CDT 를 사용한다.\n1.3.x 버전부터, CDT 는 Mac OS X brew, linux debian 과 RPM 패키지들을 지원한다. 설치하기 위한 가장쉬운 선택지는 이 패키지 시스템들을 이용하는 것이다. 하나의 방법을 선택하자.\nHomeBrew (Mac OS X) Install brew tap eosio/eosio.cdt brew install eosio.cdt Uninstall brew remove eosio.","title":"EOSIO - 1.5/CDT 설치하기"},{"content":" 다음에서 발췌 - Step 1: Boot Node And Wallet Step 1.1: Start keosd 먼저 keosd 를 시작한다.\nkeosd \u0026amp; 다음과 유사한 결과를 얻게 된다.\ninfo 2018-11-26T06:54:24.789 thread-0 wallet_plugin.cpp:42 plugin_initialize ] initializing wallet plugin info 2018-11-26T06:54:24.795 thread-0 http_plugin.cpp:554 add_handler ] add api url: /v1/keosd/stop info 2018-11-26T06:54:24.796 thread-0 wallet_api_plugin.cpp:73 plugin_startup ] starting wallet_api_plugin info 2018-11-26T06:54:24.796 thread-0 http_plugin.cpp:554 add_handler ] add api url: /v1/wallet/create info 2018-11-26T06:54:24.796 thread-0 http_plugin.cpp:554 add_handler ] add api url: /v1/wallet/create_key info 2018-11-26T06:54:24.796 thread-0 http_plugin.cpp:554 add_handler ] add api url: /v1/wallet/get_public_keys enter 를 치면 종료 된다.\nStep 1.2: Start nodeos nodeos -e -p eosio \\ --plugin eosio::producer_plugin \\ --plugin eosio::chain_api_plugin \\ --plugin eosio::http_plugin \\ --plugin eosio::history_plugin \\ --plugin eosio::history_api_plugin \\ --data-dir CONTRACTS_DIR/eosio/data \\ --config-dir CONTRACTS_DIR/eosio/config \\ --access-control-allow-origin=\u0026#39;*\u0026#39; \\ --contracts-console \\ --http-validate-host=false \\ --verbose-http-errors \\ --filter-on=\u0026#39;*\u0026#39; \u0026gt;\u0026gt; nodeos.log 2\u0026gt;\u0026amp;1 \u0026amp; 이 설정은 다음과 같은 작업을 진행한다.\n개발 디렉토리 하위의 eosio 디렉토리안에서 블록체인 데이터와 설정 데이터를 사용 할수 있도록 지정. eosio/data 와 eosio/config 을 각각 사용하게 된다. nodeos 를 실행한다. 이 커맨드는 기본적인 플러그인을 로드하고, 서버 주소를 설정하며, CORS 를 사용가능하게 하며 일부 contract 디버깅과 로깅을 가능케한다. CORS 가 (*) 에 대한 제약이 없도록 한다. CORS 의 * 에 대한 제약제거는 개발 과정에서만 사용하도록 한다. 어떤 노드에 대해 public 하게 * 에 접근하도록 하는 것은 지양해야한다!\nStep 2: Check the installation Step 2.1: Check That Nodeos is Producing Blocks 아래의 명령어를 실행한다.\ntail -f nodeos.log 아래와 유사한 출력 결과를 볼 수 있다.\n1929001ms thread-0 producer_plugin.cpp:585 block_production_loo ] Produced block 0000366974ce4e2a... #13929 @ 2018-05-23T16:32:09.000 signed by eosio [trxs: 0, lib: 13928, confirmed: 0] 1929502ms thread-0 producer_plugin.cpp:585 block_production_loo ] Produced block 0000366aea085023... #13930 @ 2018-05-23T16:32:09.500 signed by eosio [trxs: 0, lib: 13929, confirmed: 0] 1930002ms thread-0 producer_plugin.cpp:585 block_production_loo ] Produced block 0000366b7f074fdd... #13931 @ 2018-05-23T16:32:10.000 signed by eosio [trxs: 0, lib: 13930, confirmed: 0] 1930501ms thread-0 producer_plugin.cpp:585 block_production_loo ] Produced block 0000366cd8222adb... #13932 @ 2018-05-23T16:32:10.500 signed by eosio [trxs: 0, lib: 13931, confirmed: 0] 1931002ms thread-0 producer_plugin.cpp:585 block_production_loo ] Produced block 0000366d5c1ec38d... #13933 @ 2018-05-23T16:32:11.000 signed by eosio [trxs: 0, lib: 13932, confirmed: 0] 1931501ms thread-0 producer_plugin.cpp:585 block_production_loo ] Produced block 0000366e45c1f235... #13934 @ 2018-05-23T16:32:11.500 signed by eosio [trxs: 0, lib: 13933, confirmed: 0] 1932001ms thread-0 producer_plugin.cpp:585 block_production_loo ] Produced block 0000366f98adb324... #13935 @ 2018-05-23T16:32:12.000 signed by eosio [trxs: 0, lib: 13934, confirmed: 0] 1932501ms thread-0 producer_plugin.cpp:585 block_production_loo ] Produced block 00003670a0f01daa... #13936 @ 2018-05-23T16:32:12.500 signed by eosio [trxs: 0, lib: 13935, confirmed: 0] 1933001ms thread-0 producer_plugin.cpp:585 block_production_loo ] Produced block 00003671e8b36e1e... #13937 @ 2018-05-23T16:32:13.000 signed by eosio [trxs: 0, lib: 13936, confirmed: 0] 1933501ms thread-0 producer_plugin.cpp:585 block_production_loo ] Produced block 0000367257fe1623... #13938 @ 2018-05-23T16:32:13.500 signed by eosio [trxs: 0, lib: 13937, confirmed: 0] 로그를 닫기 위해 Ctrl + c 를 누르자.\nStep 2.2: Check the wallet 쉘을 열고 아래 명령어를 기입한다.\ncleos wallet list 다음과 같은 결과가 노출된다.\nWallets: [] 이 시점에서 앞으로, 당신의 로컬시스템에서 이 명령어들을 칠 것이라 기대한다.\nStep 2.3: Check Nodeos endpoints 다음은 RPC API 가 정상적으로 동작하는지 확인할 것이다. 하나를 선택하자.\n다음 브라우저에서 chain_api_plugin 을 통해 제공되는 get_info 를 확인해본다. : http://localhost:8888/v1/chain/get_info 같은 것을 확인하지만, 호스트머신의 콘솔에서 확인한다. curl http://localhost:8888/v1/chain/get_info ","permalink":"https://nolleh.github.io/block-chain/1.4-startyournodeandsetup/","summary":"다음에서 발췌 - Step 1: Boot Node And Wallet Step 1.1: Start keosd 먼저 keosd 를 시작한다.\nkeosd \u0026amp; 다음과 유사한 결과를 얻게 된다.\ninfo 2018-11-26T06:54:24.789 thread-0 wallet_plugin.cpp:42 plugin_initialize ] initializing wallet plugin info 2018-11-26T06:54:24.795 thread-0 http_plugin.cpp:554 add_handler ] add api url: /v1/keosd/stop info 2018-11-26T06:54:24.796 thread-0 wallet_api_plugin.cpp:73 plugin_startup ] starting wallet_api_plugin info 2018-11-26T06:54:24.796 thread-0 http_plugin.cpp:554 add_handler ] add api url: /v1/wallet/create info 2018-11-26T06:54:24.796 thread-0 http_plugin.cpp:554 add_handler ] add api url: /v1/wallet/create_key info 2018-11-26T06:54:24.","title":"EOSIO - 1.4/노드 시작하고 설정하기"},{"content":" 발췌 - EOSIO - 1.3 About The Stack\n방금 설치한 툴들을 시작하기 전에, 각각의 컴포넌트들이 어떻게 상호작용하는지 이해하는게 좋다.\nnodeos (node + eos = nodeos) - 노드를 실행하기 위한 플러그인들로 설정될 수 있는 Core EOSIO 데몬. 예제는 로컬개발과 API 종단점을 위해 블록제품을 사용한다.\ncleos (cli + eos = cleos) - 블록 체인과 상호작용하고 wallet 을 관리하기위한 커맨드 라인 인터페이스.\nkeosd (key + eos = keosd) - wallet 안의 EOSIO key 를 안전하게 저장 하기 위한 컴포넌트\neosio-cpp - eosio.cdt 의 일부로, C++ 코드를 WASM 로 컴파일하고 ABI 들을 생성한다.\n","permalink":"https://nolleh.github.io/block-chain/1.3-aboutthestack/","summary":"발췌 - EOSIO - 1.3 About The Stack\n방금 설치한 툴들을 시작하기 전에, 각각의 컴포넌트들이 어떻게 상호작용하는지 이해하는게 좋다.\nnodeos (node + eos = nodeos) - 노드를 실행하기 위한 플러그인들로 설정될 수 있는 Core EOSIO 데몬. 예제는 로컬개발과 API 종단점을 위해 블록제품을 사용한다.\ncleos (cli + eos = cleos) - 블록 체인과 상호작용하고 wallet 을 관리하기위한 커맨드 라인 인터페이스.\nkeosd (key + eos = keosd) - wallet 안의 EOSIO key 를 안전하게 저장 하기 위한 컴포넌트","title":"EOSIO - 1.3/스택에 대해"},{"content":" 발췌 - (EOSIO - 1.2 Before You Begin)[https://developers.eos.io/eosio-home/docs/setting-up-your-environment]\nStep 1: Install Binaries 이 튜토리얼은 선빌드된 바이너리를 사용한다.\n가장 빨리 시작하는 방법은 이게 가장 좋은 선택지 일것이다. 소스로부터 빌드하는 것도 하나의 선택지이지만, 한시간 이상 걸릴 수 도 있으며 빌드 에러가 발생 할 수도 있다.\n아래의 명령어들이 각각의 OS 에서 바이너리를 다운로드 할 것이다.\nbrew tap eosio/eosio brew install eosio Step 2: Setup a development directory, stick to it 작업을 진행할 디렉토리를 선택할 필요가 있다.\ncontracts 폴더를 로컬드라이브 어딘가에 생성하는 것을 추천한다.\nmkdir contracts cd contracts Step 3: Enter your local directory below. 그 폴더의 경로를 얻어 저장해둬서 필요할 때 사용 할 수 있도록 다음 명령어를 통하면 된다.\npwd 절대 경로를 아래에 기입하면 문서의 내용에 반영, 더 읽기 편하게 만들어 줄 것이다. 이 기능은 쿠키를 사용한다.\n","permalink":"https://nolleh.github.io/block-chain/1.2-beforeyoubegin/","summary":"발췌 - (EOSIO - 1.2 Before You Begin)[https://developers.eos.io/eosio-home/docs/setting-up-your-environment]\nStep 1: Install Binaries 이 튜토리얼은 선빌드된 바이너리를 사용한다.\n가장 빨리 시작하는 방법은 이게 가장 좋은 선택지 일것이다. 소스로부터 빌드하는 것도 하나의 선택지이지만, 한시간 이상 걸릴 수 도 있으며 빌드 에러가 발생 할 수도 있다.\n아래의 명령어들이 각각의 OS 에서 바이너리를 다운로드 할 것이다.\nbrew tap eosio/eosio brew install eosio Step 2: Setup a development directory, stick to it 작업을 진행할 디렉토리를 선택할 필요가 있다.","title":"EOSIO - 1.2/시작하기 전에"},{"content":" 발췌 EOSIO - 1.1 Introduction\n배울 수 있는 것 노드로 얼마나 빨리 갖고 놀 수 있는가 Wallet 과 Key 를 어떻게 관리할 수 있는가 계정을 만드는 법 contract 작성법 컴파일과 ABI contract 배포 C / C++ 경험 EOSIO 기반 블록체인은 WebAssembly 를 이용하여 유저가 생성한 어플리케이션과 코드를 실행한다.\nWASM 은 구글, 마이크로소프트, 애플, 그리고 다른 주요 업체의 지원을 받는 떠오르는 웹 표준이다.\n오늘날 WASM 을 빌드하기위해 사용되는 성숙된 도구는 C/C++ 컴파일러를 통한 clang/llvm 이다.\n최고의 호환성을 위해, EOSIO C++ 툴체인을 사용하도록 권장한다.\n서드파티에 의해 개발중인 다른 툴체인들은 다음과 같다: Rust, Python, Solidity. 이들의 언어는 단순해 보이지만, 성능은 당신이 빌드하는 어플리케이션의 규모에 따라 다르다. C++ 가 가장 안전하고 고성능일 것이라고 기대한다.\nLinux / Mac OS Experience Amazon 2017.09 CentOS 7 Fedora 25 Mint 18 Ubuntu 16.04 (16.10 추천) Ubuntu 18.04 MacOS Darwin 10.12+ (10.13 추천) Command Line Knowlege EOSIO 의 다양한 툴을 이용하기 위해서는 기본적인 커맨드라인 지식이 필요하다.\nC++ Environment Setup C++ 문법 하이라이팅을 지원하는 어떤 텍스트 에디터를 사용해도 되지만 주요한 에디터는 Sublime Text, Atom 이 있다. 다른 선택지는 철학적인 코드 완성과 개발 경험이 더 많은 철학적인 IDE 를 선택해서 사용하면된다. 개인 선호에 따라 작업하면 되지만, 확신이 없다면 다음 선택지 중에서 살펴보면 된다.\nPotential Editors and IDEs Sublime Text Atom Editor CLion Eclips Visual Studio Code Operating System of Development Enviornment linux 향의 OS 를 사용한다면 튜토리얼을 따를 수 있다. 다음을 포함하지만, 여기에 제한된건 아니다.\nMac OS Ubuntu Debian Fedora Windows 현재는 powershell 포트등에 대해 지원하지 않는다. 미래에는 powershell 명령어를 지원할 계획이지만, 그전까지는 Ubuntu VM 을 활용하여 개발환경을 구성하는 편이 최선이다. Linux 명령에 익숙한 개발자라면 적은 어려움 만이 있을 것이다.\n","permalink":"https://nolleh.github.io/block-chain/1.1-introduction/","summary":"발췌 EOSIO - 1.1 Introduction\n배울 수 있는 것 노드로 얼마나 빨리 갖고 놀 수 있는가 Wallet 과 Key 를 어떻게 관리할 수 있는가 계정을 만드는 법 contract 작성법 컴파일과 ABI contract 배포 C / C++ 경험 EOSIO 기반 블록체인은 WebAssembly 를 이용하여 유저가 생성한 어플리케이션과 코드를 실행한다.\nWASM 은 구글, 마이크로소프트, 애플, 그리고 다른 주요 업체의 지원을 받는 떠오르는 웹 표준이다.\n오늘날 WASM 을 빌드하기위해 사용되는 성숙된 도구는 C/C++ 컴파일러를 통한 clang/llvm 이다.","title":"EOSIO - 1.1/소개"},{"content":"개요 다음에서 발췌\n비동기 프로그램의 제어 흐름\n코드 public partial class MainWindow : Window { // . . . private async void startButton_Click(object sender, RoutedEventArgs e) { // ONE Task\u0026lt;int\u0026gt; getLengthTask = AccessTheWebAsync(); // FOUR int contentLength = await getLengthTask; // SIX resultsTextBox.Text += $\u0026#34;\\r\\nLength of the downloaded string: {contentLength}.\\r\\n\u0026#34;; } async Task\u0026lt;int\u0026gt; AccessTheWebAsync() { // TWO HttpClient client = new HttpClient(); Task\u0026lt;string\u0026gt; getStringTask = client.GetStringAsync(\u0026#34;https://msdn.microsoft.com\u0026#34;); // THREE string urlContents = await getStringTask; // FIVE return urlContents.Length; } } Three 에서 yield 되어 Four.\n","permalink":"https://nolleh.github.io/csharp/async-control-flow-msdn/","summary":"개요 다음에서 발췌\n비동기 프로그램의 제어 흐름\n코드 public partial class MainWindow : Window { // . . . private async void startButton_Click(object sender, RoutedEventArgs e) { // ONE Task\u0026lt;int\u0026gt; getLengthTask = AccessTheWebAsync(); // FOUR int contentLength = await getLengthTask; // SIX resultsTextBox.Text += $\u0026#34;\\r\\nLength of the downloaded string: {contentLength}.\\r\\n\u0026#34;; } async Task\u0026lt;int\u0026gt; AccessTheWebAsync() { // TWO HttpClient client = new HttpClient(); Task\u0026lt;string\u0026gt; getStringTask = client.GetStringAsync(\u0026#34;https://msdn.microsoft.com\u0026#34;); // THREE string urlContents = await getStringTask; // FIVE return urlContents.","title":"비동기 프로그램의 제어 흐름"},{"content":"개요 다음에서 발췌 MSDN\n반응성을 향상시키는 비동기 잠재적인 차단 작업 완료 될때까지 다른 작업을 게속 수행\n작성이 간편한 비동기 메서드 반환 형식은 다음 중 하나\nTask Task void - 비동기 이벤트 처리기 작성 GetAwaiter 포함 모든 기타 형식 await 을 만나면 yield 함 (호출자로 제어가 돌아감) 이때, Task 가 호출자에게 반환되고 이는 언젠가 다운로드된 문자열의 길이가 반환된다는 약속 (future) 을 의미한다. await 전에 작업이 완료된다면 제어가 돌아가지 않는다. 스레드 비동기 메서드의 await 식은 대기한 작업이 실행되는 동안 현재 스레드를 차단하지 않는다. 대신, 메서드의 나머지를 연속으로 등록하고 비동기 메서드 호출자에 반환.\nasync / await 으로 인해 스레드가 추가로 생성되지 않는다.\n비동기 메서드는 자체 스레드에서 실행되지 않고 현재 동기화 컨텍스트에서 실행되며,\n활성화된 경우에만 스레드에서 시간을 사용.\n","permalink":"https://nolleh.github.io/csharp/async-await-msdn/","summary":"개요 다음에서 발췌 MSDN\n반응성을 향상시키는 비동기 잠재적인 차단 작업 완료 될때까지 다른 작업을 게속 수행\n작성이 간편한 비동기 메서드 반환 형식은 다음 중 하나\nTask Task void - 비동기 이벤트 처리기 작성 GetAwaiter 포함 모든 기타 형식 await 을 만나면 yield 함 (호출자로 제어가 돌아감) 이때, Task 가 호출자에게 반환되고 이는 언젠가 다운로드된 문자열의 길이가 반환된다는 약속 (future) 을 의미한다. await 전에 작업이 완료된다면 제어가 돌아가지 않는다. 스레드 비동기 메서드의 await 식은 대기한 작업이 실행되는 동안 현재 스레드를 차단하지 않는다.","title":"Async Await 을 사용한 비동기 프로그래밍"},{"content":"Dispose 에 대한 여러가지 MSDN Implementing a Dispose method\nthreadSafety stackoverflow dispose 의 threadsafety\n많은 경우 어떤 스레드든지 다른 스레드가 dispose 를 시작했을때 오브젝트에 대해 작업을 하고 있을 수 있기 때문에, interlocked.Exchange 를 통해 배제하는게 옳아 보인다.\n물론, 좋은 생각이고 표준 dispose 패턴의 일부가 되어야 한다고 생각한다.\n(champareExchange가 base class 에 봉인됨으로써 derived class 에서 private 한 disposed flag 를 사용하는 것을 피해야한다.)\n하지만 불행히도, dispose 가 정확히 어떤것을 하는지 생각해보면 문제는 좀 더 복잡해진다.\nDispose 의 진짜 목적은 그 오브젝트가 버려지게 하는 목적이라기보다, 그 오브젝트가 들고 있는 레퍼런스를 비우는데 목적이 있다.\n이 엔터티 들은 managed objects 일 수도 있고, system object 일수도 있고, 다른 어떤 것일 수도 있다; 심지어 같은 컴퓨터에 존재하지 않을 수도 있다.\nthread-safe 하려면, 이 Dispose 가 정리하는 동시에 다른 스레드가 이를 가지고 다른 일을 할 수 있도록 다른 엔티티들이 허용해야한다.\n어떤 객체들은 이렇게 할 수 있지만, 그렇지 않은 객체들도 있다.\n짜증나는 예를 들어보자: 객체들은 thread-safe 하지 않은 RemoveHandler 이벤트를 갖도록 허용되어있다. 결과적으로, 구독이 이루어졌던 그 스레드에서만 Dispose 를 호출하도록 해야한다.\n","permalink":"https://nolleh.github.io/csharp/dispose/","summary":"Dispose 에 대한 여러가지 MSDN Implementing a Dispose method\nthreadSafety stackoverflow dispose 의 threadsafety\n많은 경우 어떤 스레드든지 다른 스레드가 dispose 를 시작했을때 오브젝트에 대해 작업을 하고 있을 수 있기 때문에, interlocked.Exchange 를 통해 배제하는게 옳아 보인다.\n물론, 좋은 생각이고 표준 dispose 패턴의 일부가 되어야 한다고 생각한다.\n(champareExchange가 base class 에 봉인됨으로써 derived class 에서 private 한 disposed flag 를 사용하는 것을 피해야한다.)\n하지만 불행히도, dispose 가 정확히 어떤것을 하는지 생각해보면 문제는 좀 더 복잡해진다.","title":"Dispose"},{"content":"NeoSmart.AsyncLock 라이브러리에 관하여 다음에서 발췌, 번역 - Neosmart Docs.\n개요 semaporeslim 은 reentrance 를 지원하지 않는다. 따라서, recursion 에서 적절히 사용되지 않으면 데드락이 발생한다.\nasynclock 은 reentrance 기능을 semaphoreslim 에 추가한거.\n대안 간단한 방법은 semaphoreslim 으로 교체하고, recursion 인 경우를 스레드 아이디로 확인 하는 것.\n이 경우의 문제는\nasync / await 의 가장 기본적인 목적인 ui 의 불필요한 블럭킹 없이 작업의 완료를 기다린다는 문제를 그대로 안고 있다.\nawait 코드를 넣어도 다른 코드가 실행 될 수 없다.\nclass ThreadIdConflict { BadAsyncLock _lock = new BadAsyncLock(); async void Button1_Click() { using (_lock.Lock()) { await Task.Delay(-1); //at this point, control goes back to the UI thread } } async void Button2_Click() { using (_lock.Lock()) { await Task.Delay(-1); //at this point, control goes back to the UI thread } } } 원래 메인스레드는 메시지 펌핑을 하면서 콜백을 호출해주는 구조로 되어 있고,\n\u0026ldquo;hard\u0026rdquo; await 을 마주쳐서 메인 ui 로 돌아갈때도\n이벤트 핸들러의 실행을 일시 정지하지만 실제 스레드가 동작을 멈추지는 않는다.\nawait 이 완료 되고 나면, continuation 이 다시 main 스레드에서 실행된다.\n여기에서 중요한 것은, 항상 같은 스레드가 실행된다는 것이다. (non- awaited async 함수 호출을 제외하고.) Button1_Click() 을 실행한 스레드가 await 을 만나 동작을 정지하고, 이후 Button2_cllick 을 호출한다. Button1_click() 의 남은 코드는 옆에 놓여지는거지, 실제로 정지 되는것이 아니다. 이 의미는, Button2_click 이 실행되어야할 때 Button1_click() 은 세마포어를 통해 상호 배제적인 접근을 하고 있으므로 접근 불가해야하나, owningthreadId 가 같으므로 두 메소드가 동시에 실행된다.\nAsyncLock 그럼 어떻게 해야하는가? recursion 을 체크하기위해 뭔가 다른 방법을 찾아야한다. Envrionment 클래스를 통해 스택 트레이스에 접근 할 수 있다. 이를 락을 얻기 위한 요건으로 사용할 수 있지 않을까 ?\nUpdate 5/25/2017 (AsyncLock 은 이제는 taskid 를 통해 확인하고 있다. )\nList _stackTraces = new List(); async Task Lock() { if (!lock.locked) { _stackTraces.Add(Environment.StackTrace); lock.Wait(); return true; } else if (_stackTraces.Peek().IsParentOf(Environment.StackTrace)) { _stackTraces.Add(Environment.StackTrace); return true; } else { //wait for the lock to become available somehow return true; } } Lock() 의 호출이 스택추적을 낭비하지 않는다고 가정하면,(?) isParentOf 메소드가 현재 호출이 저장된 스택트레이스의 자식인지 확인한다.\n하지만 이런 접근은 첫번째 솔루션으로는 쉽게 해결 됐을 다음 코드를 처리하지 못한다.\nclass StackTraceConflict { BadAsyncLock _lock = new BadAsyncLock(); async void DoSomething() { using (_lock.Lock()) { await Task.Delay(-1); } } void DoManySomethings() { while(true) { DoSomething(); //no wait here! } } } 모두 같은 지점에서 실행되기 때문에 다른 스레드에서 같은 스택트레이스를 갖게 되고 완벽하게 실패하게 된다!\n따라서 적절한 솔루션은, 두 솔루션을 결합하는 것이다.\nclass AsyncLockTest { AsyncLock _lock = new AsyncLock(); void Test() { //the code below will be run immediately (and asynchronously, in a new thread) Task.Run(async () =\u0026gt; { //this first call to LockAsync() will obtain the lock without blocking using (await _lock.LockAsync()) { //this second call to LockAsync() will be recognized as being a reëntrant call and go through using (await _lock.LockAsync()) { //we now hold the lock exclusively and no one else can use it for 1 minute await Task.Delay(TimeSpan.FromMinutes(1)); } } }).Wait(TimeSpan.FromSeconds(30)); //this call to obtain the lock is synchronously made from the main thread //It will, however, block until the asynchronous code which obtained the lock above finishes using (_lock.Lock()) { //now we have obtained exclusive access } } } task 가 먼저 실행되도록 하기위해 30 초를 대기했다가 평범하게 락을 건다.\n첫번째 락은 평범하게 얻어진 뒤에, 다시 reentrant call 이 발생하고, 이것 또한 넘어가게 된다. (# await 실행된 스레드아이디 + 실행된 콜스택의 부모)\nTask.Delay 를 마주쳐서 스레드는 pause 상태로 전환되고, 이 시간동안 공유되는 리소스에 대해 배제적 접근을 하게 된다.\n30 초 뒤에 lock 을 얻으려고 시도할때, 이 시도는 실패하게 되고\n다시 30초 뒤에 task 가 완료되어 lock 을 release 하게 되면 메인스레드가 락을 얻어 동작이 재개 된다.\n이 코드 조각은 두개의 락 옵션을 사용하고 있다. Lock() 과 LockAsync() 인데, 이들은 둘다 기본 개념은 같고, async 메소드는 async/ await 패러다임을 품어 이 실행이 lock 이 사용 가능할때에 새로 얻을 수 있도록 한 개념이다. 이렇게 해서 await lock.LockAsync() 가 블러킹 되지 않도록 한 것이다.\n","permalink":"https://nolleh.github.io/csharp/async-await/","summary":"NeoSmart.AsyncLock 라이브러리에 관하여 다음에서 발췌, 번역 - Neosmart Docs.\n개요 semaporeslim 은 reentrance 를 지원하지 않는다. 따라서, recursion 에서 적절히 사용되지 않으면 데드락이 발생한다.\nasynclock 은 reentrance 기능을 semaphoreslim 에 추가한거.\n대안 간단한 방법은 semaphoreslim 으로 교체하고, recursion 인 경우를 스레드 아이디로 확인 하는 것.\n이 경우의 문제는\nasync / await 의 가장 기본적인 목적인 ui 의 불필요한 블럭킹 없이 작업의 완료를 기다린다는 문제를 그대로 안고 있다.\nawait 코드를 넣어도 다른 코드가 실행 될 수 없다.","title":"Async Await"},{"content":" Nancy 에 대한 문서 번역 #1. By Nolleh\nIntroduction 가장 먼저, Nancy 의 세계에 온것을 환영합니다!\n루비의 sinatra 프레임워크에 영감을 받아 Nancy 라는 이름을 붙이게 되었습니다. (Frank Sinatra 의 딸이름이 Nancy 니까요!)\nNancyFx 의 Fx 에 대해 많은 사람들이 궁금해하여 여기에 붙입니다만, framework 라는 뜻입니다 :)\nNancyFx 는 모든 컴포넌트들을 포함하는 umbrella project 입니다. (#역자주: 우산효과의 우산처럼, 포괄적인 프로젝트라는 의미로 쓴게 아닐까? )\n이 가이드는 앞으로 개괄적이고 빠르게 Nancy 의 특징들을 살펴 독자 스스로 Nancy 의 세계를 탐험해 볼 수 있는 시야를 제공할겁니다.\nNancy 는 가볍고, 적은 준비의식(#역자주: 라이브러리를 쓰기 위한 선제 작업)의 HTTP 기반의 서비스를 개발할 수 있는 .Net 과 Mono 기반 프레임 워크입니다.\n이 프레임워크의 목적은 모든 상호 통신(ineractions)을 신경쓰지 않으면서도 동시에 슈퍼-엄청-행복한 방법으로-(super-duper-happy-path) 제공하는 것입니다.\n이 말은 Nancy 를 통한 모든 것들이 당신을 개고생하게 만드는 설정 지옥에서 벗어날 수 있도록 관습적이고/기본적인 설정 값을 적극 활용하는 것을 의미합니다.\nNancy 와 함께라면 아무것도 없는 상태에서 수 분안에 웹사이트를 만들 수 있습니다. 문자 그대로요!!\nNancy 는 DELETE, GET, HEAD, OPTIONS, POST, PUT, PATH 요청을 단순하고 우아한 Domain Specific Language (DSL) 을 몇번의 타이핑만으로 응답으로 전달하도록 디자인 되어 있어 당신은 다른 좀 더 중요한 당신의 코드, 당신의 어플리케이션에 집중 할 수 있도록 하였습니다.\n이 모든 것들은 MIT License 의 오픈 소스 입니다.\nNuget, our TeamCity Server 와 github repository 로부터 살펴 보실 수 있습니다.\nBuilt to run anywhere 원하는 곳 어디에서든 빌드되고 실행될 수 있습니다.\nNancy 는 어떤 존재하는 프레임워크에도 의존성이 없도록 디자인 되었습니다.\nrequest / response 객체 전부 자체에 포함되어 있으므로, .NET framework client profile 을 통해 빌드하여 Nancy 는 당신이 원하는 곳 어디에서든 사용될 수 있습니다.\nNancy 의 핵심 개념중의 하나로 hosts 가 있습니다. 하나의 호스트는 nancy 와 호스팅 환경의 어댑터로서 동작하게 되므로 Nancy 를 기존의 존재하는 - ASP.Net, WCF, OWIN, 다른 통합 응용프로그램 - 기술에서 활용해보십시오.\n특정 호스트 구현은 Nancy 프레임워크의 핵심 기능을 제공하지 않을 수 있습니다. 이런 추가기능들 - 인증과 같은- 은 개별로 제공됩니다.\nNancy 응용 프로그램을 빌드하는 것은 웹프레임워크의 buffet 으로부터 가장 좋아하는 부분을 뽑아내는 것과 같습니다! Nancy 서비스를 빌드하는데 사용할 최소한의 부분은 핵심 프레임워크와 host 가 될 것입니다.\nThe super-duper-happy-path 그 \u0026ldquo;super-duper-happy-path\u0026rdquo; (말을 줄이길 좋아하는 요새 사람들을 따르자면 SDHP 랄까요?) 란, Nancy 의 정신을 바로 짚는 용어라 하겠습니다;동시에 Nancy 의 API 를 이용하는 동안 \u0026ldquo;슈퍼-엄청-행복한-길\u0026rdquo; 에 대한 경험을 당신에게 제공하는 것이라 할 수도 있겠네요.\n결국에는 대단히 감정적 용어이기때문에 정확히 어떤 것인지 짚어보기 전에 이 배후의 아이디어를 살펴보도록합시다.\n\u0026ldquo;그냥 동작해\u0026rdquo; - 이것 저것 할것 없이 하나 집어서 사용하면 됩니다. 새로운 모듈을 추가한다? 이것들은 다 당신을 위해 자동으로 이뤄집니다. 새로운 뷰 엔진을 쓴다? 당신은 아무것도 할 것 없이, 미리 준비되어 있습니다. 당신 모듈에 새로운 의존성을 추가하는 것마저 자동으로 injection 해줄겁니다! - 설정노노해!-\n\u0026ldquo;쉬운 커스터 마이즈\u0026rdquo; - \u0026ldquo;그냥 동작해\u0026rdquo; 와 같은 기능이 커스터마이즈를 어렵게 할 것 같지만 그렇지 않습니다. 다른 컨테이너를 원하세요? 문제 없어요! 라우딩 되는 다른 경로를 원하세요 ? 하세요! 우리의 bootstrapper 가 이 모든 것들을 누워서 떡먹게 해줍니다.\n\u0026ldquo;적은 준비 의식\u0026rdquo; - 당신의 응용 프로그램을 위한 Nancy code 의 양은 아주 적습니다. Nancy 응용프로그램의 중요한 부분은 당신의 코드입니다. 실제 동작하는 Nancy 어플리케이션이 다음의 한 개의 트위터 글로 작성될 수 있다는 게 바로 그 증거죠.\n\u0026ldquo;적은 마찰\u0026rdquo; - Nancy 로 소프트웨어를 빌드할때 API 들이 도와줄 것입니다. 이름은 명확하고 요구되는 설정은 최소한이지만 강력한 성능과 확장성은 당신이 필요로 할 때 여전히 그 자리에 있어 줄 겁니다 :)\n위 내용들을 종합해 볼때, Nancy 로 응용프로그램을 작성하는 것은 즐겁고 재밌을거예요! 하지만 응용프로그램이 성장할 수록 성능이나 확장성을 포기해야할 때가 올 수도 있죠..\nCreating your first Nancy application 이야기는 이제 충분합니다. 이제 코드를 봅시다! Nuget (혹은 Mono) 은 설치되어 있을 것이라 가정하겠습니다.\n(우리곁의 어디에나 있는) 유비쿼터스 \u0026ldquo;Hello World\u0026rdquo; 응용프로그램을 Nancy 와 Nancy 의 ASP.NET 호스팅으로 빌드해보겠습니다.\nvisual studio 2012 이상이라면 SideWaffle Template Pack for Visual Studio 을, 2010 사용자라면 Nancy project templates 을 설치합시다.\nNancy empty project with ASP.NET host 메뉴 (sidewaffle) / Nancy Empty Web Application with ASP.NET Hosting 메뉴 (Nancy project template) 를 선택합니다.\nNancy Module 을 C# 클래스로 추가하고 root url 에 라우트 핸들러를 생성자에 작은 코드를 넣어 정의합니다:\nCompile and run to see result !\n강제하진 않지만 권장하는 내용으로, 새로운 업데이트를 체크하기 위해 Nuget Package Manager 를 사용해보세요.\nThe HelloModule.cs code\npublic class HelloModule : NancyModule { public HelloModule() { Get[\u0026#34;/\u0026#34;] = parameters =\u0026gt; \u0026#34;Hello World\u0026#34;; } } 모듈을 public 으로 선언하지 않으면 NancyFx 가 찾을 수 없으므로, 잊지마세요!\nMore Info - Why use NancyFX?\n","permalink":"https://nolleh.github.io/nancy/introduction/","summary":"Nancy 에 대한 문서 번역 #1. By Nolleh\nIntroduction 가장 먼저, Nancy 의 세계에 온것을 환영합니다!\n루비의 sinatra 프레임워크에 영감을 받아 Nancy 라는 이름을 붙이게 되었습니다. (Frank Sinatra 의 딸이름이 Nancy 니까요!)\nNancyFx 의 Fx 에 대해 많은 사람들이 궁금해하여 여기에 붙입니다만, framework 라는 뜻입니다 :)\nNancyFx 는 모든 컴포넌트들을 포함하는 umbrella project 입니다. (#역자주: 우산효과의 우산처럼, 포괄적인 프로젝트라는 의미로 쓴게 아닐까? )\n이 가이드는 앞으로 개괄적이고 빠르게 Nancy 의 특징들을 살펴 독자 스스로 Nancy 의 세계를 탐험해 볼 수 있는 시야를 제공할겁니다.","title":"Nancy Introduction"},{"content":" 네트워킹의 바이블이라 할 수 있는 Unix Network Programming 의 내용 정리\nBooks Introduction Socket 을 통해 통신하는 프로그램을 작성하는 개발자를 위해 쓰여진 책.\n시작하는 사람에게나, 프로페셔널에게나 유용한 책.\n물론 유지보수를 하거나, 새로 작성하는 사람, 네트워크 시스템 함수를 이해하는 모두에게 유용하다.\n실제 텍스트들은 유닉스 시스템에서 구동가능하나, OS 에 독립적인 socket api 를 지원하는 다른 OS 에서도, 본문에서 제안하는 일반적인 개념을 활용가능하다.\n많은 OS 는 셀수 없이 많은 네트워크 응용프로그램을 제공하고 있으며 - 예컨데 웹브라우저, email.. 이 프로그램들을 클라이언트와 / 서버로 분류하여 언급할 것이다.\nUsing This Book 초심자와 전문 프로그래머 모두 활용가능하다. 튜토리얼이 목적이라면 Part2 에 포커스를 맞추면 좋으며, 여기서 TCP 와 UDP, SCTP 모두에 대한 소켓 함수를 다루고 I/O multiplexing, socket options, basic name, address conversion 등을 다룬다.\nSection 1.4 에서는 본문 전체에서 다루는 래퍼펑션들이 소개된다.\nPart 3 에서는 \u0026ldquo;진화된 소켓\u0026rdquo; 에 대해 다루므로 아무나 읽어도 된다.\n소스코드는, 여기\nunpbook\n","permalink":"https://nolleh.github.io/network/unix-01-intro/","summary":"네트워킹의 바이블이라 할 수 있는 Unix Network Programming 의 내용 정리\nBooks Introduction Socket 을 통해 통신하는 프로그램을 작성하는 개발자를 위해 쓰여진 책.\n시작하는 사람에게나, 프로페셔널에게나 유용한 책.\n물론 유지보수를 하거나, 새로 작성하는 사람, 네트워크 시스템 함수를 이해하는 모두에게 유용하다.\n실제 텍스트들은 유닉스 시스템에서 구동가능하나, OS 에 독립적인 socket api 를 지원하는 다른 OS 에서도, 본문에서 제안하는 일반적인 개념을 활용가능하다.\n많은 OS 는 셀수 없이 많은 네트워크 응용프로그램을 제공하고 있으며 - 예컨데 웹브라우저, email.","title":"Unix 01 Intro"},{"content":" 어쩌다보니 그동안 손댈 일이 없던 웹서버에 좀 손을 대게 되서 (게임서버, 클라이언트, 그리고 웹서버..정녕 풀스택 개발자가 되는것인가..ㅋ), 예전 선배님이 버리고 간(?) 스프링 책을 꺼내서 읽어 보며 정리한 내용이므로 본 글을 처음 접한 사람이 이해하기에 많은 내용을 담지 않을 수 있음.\nSpring Bean 객체 스프링에서 생성하여 관리하여 주는 스프링 빈 객체 혹은 빈 객체라고 부른다. res/applicationContext.xml 에 태그로 선언할 수도 있다. 이렇게 선언한경우, 리플렉션을 활용하여 bean id 클래스의 인스턴스를 지정한 세부 태그의 속성으로 메서드를 호출하여 객체를 초기화한다.\nApplicationContext 스프링에서 제공하는 인터페이스. 컨테이너가 제공해야할 기본 기능 정의. BeanFactory 인터페이스를 상위에 두고 있다.\nApplicationContext::getBean 인자는 이름/타입. 이를 통해 빈객체를 얻어올 수 있다.\nSpring DI 설명이 장황한데, 여기서의 의존은 (composite 패턴으로) 다른 객체를 요할때를 의미한다.\n생성자를 통해 객체를 받거나 다른 멤버메서드를 통해 객체를 받거나 DI 의존성을 주입하는 방식으로, 외부로부터 의존객체를 전달 받는 구현 방식을 의미한다.\n스프링은, 결국 DI 컨테이너다.\nXML 을 통한 DI 설정 \u0026lt;beans xmlns=\u0026#34;http://www.springframework.org/scheme/beans\u0026#34;...\u0026gt; \u0026lt;bean id=\u0026#34;식별자\u0026#34; class=\u0026#34;클래스명\u0026#34;\u0026gt; \u0026lt;constructor-arg value=\u0026#34;test\u0026#34;/\u0026gt; \u0026lt;constructor-arg ref=\u0026#34;Other Bean\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;프로퍼티명\u0026#34;\u0026gt; \u0026lt;value\u0026gt;프로퍼티값\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;/beans\u0026gt; 프로퍼티 지정시, 역시 리플렉션을 활용, set{PropertyName}() 을 이용하여 값을 설정한다.\n스프링의 property 태그는 자바빈 규약에 따른다. 자바코드를 이용한 DI 설정 org.stringframework.annotation.AnnotationConfigApplicationContext 빈컨테이너 사용\n@Configuration 클래스를 스프링 설정으로 사용함을 의미\n@Bean 메서드의 리턴값을 빈 객체로 사용함을 의미\nexample @configuration public class Config { @Bean public User user1() { return new User(\u0026#34;nolleh\u0026#34;); } } 요렇게 선언하고\nAnnotationConfigApplicationContext ctx = new AnnotationConfigApplicationContext(Config.class); User user1 = ctx.getBean(\u0026#34;user1\u0026#34;, User.class); 요렇게 쓴다.\n생성자나 프로퍼티 값 설정시 직접 호출하면 된다.\nset{프로퍼티}(..);\n끝\n","permalink":"https://nolleh.github.io/web/fund-spring/","summary":"어쩌다보니 그동안 손댈 일이 없던 웹서버에 좀 손을 대게 되서 (게임서버, 클라이언트, 그리고 웹서버..정녕 풀스택 개발자가 되는것인가..ㅋ), 예전 선배님이 버리고 간(?) 스프링 책을 꺼내서 읽어 보며 정리한 내용이므로 본 글을 처음 접한 사람이 이해하기에 많은 내용을 담지 않을 수 있음.\nSpring Bean 객체 스프링에서 생성하여 관리하여 주는 스프링 빈 객체 혹은 빈 객체라고 부른다. res/applicationContext.xml 에 태그로 선언할 수도 있다. 이렇게 선언한경우, 리플렉션을 활용하여 bean id 클래스의 인스턴스를 지정한 세부 태그의 속성으로 메서드를 호출하여 객체를 초기화한다.","title":"스프링 기본 용어/정리"},{"content":" 다음에서 발췌, 번역\nhttps://msdn.microsoft.com/en-gb/library/windows/desktop/cc644950(v=vs.85).aspx File Buffering 파일버퍼링 - unbuffered file I/O.\n본문에선 시스템에 의해 캐싱되지 않는 (buffered) 데이터를\n어떻게 유저 모드의 응용프로그램에서 데이터를 활용할 수 (interact) 있을지에 대해 다룬다.\nFILE_FLAG_NO_BUFFERING 플래그를 통해 CreateFile 을 Open 하면,\n파일을 읽거나 쓸때 시스템의 캐싱을 비활성화 하도록 제어할 수 있다.\nI/O 버퍼링을 사용한것과 같은 효과를 내려면, 데이터 alignment 가 반드시 고려되어야 한다.\nNote 파일에 대해 Seeking 과 위치포인터, offsets 의 개념을 사용하는 파일에 대해 alignment 정보가 고려될 필요가 있다. 물리 디스크와 파일 시스템 저장소의 계층에서 write 연산은 alignment 기준을 맞추지 못한다면 실패 할 것이다.\nAlignment and File Access Requirement 다음을 만족시켜야한다.\n파일 접근 사이즈. OVERLAPPED 구조체의 offset 을 포함해서,\n지정된다면 volume 의 섹터사이즈의 정수배로 지정되어야한다. 읽기/쓰기 연산의 버퍼주소는 물리적 섹터에 aligned 되어있어야 한다.\n즉, 물리 섹터 사이즈의 정수배로 메모리가 주소에 정렬되어 있어야함을 의미한다.\n디스크에 따라 강제사항이 아닐 수도 있다. 4096 byte 의 미디어 섹터사이즈가 시장에 나온 것을 고려해야하는데,\n일시적인 방안으로, ATA / SCSI 명령어를 통해 일반적인 512 바이트의 섹터 저장소가\n에뮬레이트 되도록 할 수 있다.\n이 에뮬레이트를 사용할때, 다음 두 가지를 알아야한다.\n논리섹터: 미디어에 접근할때 사용되는 논리 블럭의 단위. 이 부분이 바로 \u0026ldquo;emulation\u0026rdquo; 물리섹터: 읽기/쓰기가 하나의 연산으로 이뤄지는 단위. 최적의 성능과 신뢰성을 위해 unbuffered I/O 가 aligned 되어야하는 단위이기도 하다. IOCTL_DISK_GET_DRIVE_GEOMETRY 와 GetDiskFreeSpace 를 통해 논리 섹터사이즈를 알 수 있으며,\nIOCTL_STORAGE_QUERY_PROPERTY 제어코드와\nSTORAGE_ACCESS_ALIGNMENT_DESCRIPTOR 구조체의\nBytesPerPhysicalSector 멤버의 사용을 통해 물리 섹터 사이즈를 구할 수 있다.\nWindows Server 2003 과 XP 에서는 STORAGE_ACCESS_ALIGNMENT_DESCRIPTOR 가 지원되지 않는다. 섹터 align 버퍼를 얻기 위해 VirtualAlloc 함수를 사용할 수 있다.\nVertualAlloc 은 메모리를 시스템페이지의 정수배의 사이즈로 align 되도록 메모리를 할당한다.\nx64 나 x86 에서는 4,096 바이트이며, Itanium-기반 시스템에서는 8,192 이다.\n더 자세한 정보는 GetSystemInfo 함수를 통해 얻을 수 있다. 직접 접근하는 저장소의 일반적인 섹터사이즈는 512 ~ 4,096 byte 이며, CD-ROM 에서는 2,048 바이트. 페이지/섹터사이즈 모두 2의 거듭제곱. 섹터사이즈가 페이지사이즈보다 큰 경우는 적기 때문에,\n대부분의 경우 page 에 align 된 메모리는 sector 에 대해서도 align 되어있다.\n수동으로 align 된 메모리버퍼를 얻는 또하나의 방법은 _aligned_malloc 함수를 사용하는 것이다.\n수동으로 align 된 버퍼를 사용하는 방법은 WriteFile 절의 예제코드를 살펴보라.\n","permalink":"https://nolleh.github.io/operating-system/file-buffering/","summary":"다음에서 발췌, 번역\nhttps://msdn.microsoft.com/en-gb/library/windows/desktop/cc644950(v=vs.85).aspx File Buffering 파일버퍼링 - unbuffered file I/O.\n본문에선 시스템에 의해 캐싱되지 않는 (buffered) 데이터를\n어떻게 유저 모드의 응용프로그램에서 데이터를 활용할 수 (interact) 있을지에 대해 다룬다.\nFILE_FLAG_NO_BUFFERING 플래그를 통해 CreateFile 을 Open 하면,\n파일을 읽거나 쓸때 시스템의 캐싱을 비활성화 하도록 제어할 수 있다.\nI/O 버퍼링을 사용한것과 같은 효과를 내려면, 데이터 alignment 가 반드시 고려되어야 한다.\nNote 파일에 대해 Seeking 과 위치포인터, offsets 의 개념을 사용하는 파일에 대해 alignment 정보가 고려될 필요가 있다.","title":"파일 버퍼링"},{"content":" concurrent 프로그램을 작성할 때 고려해야할 몇가지 사항. 그리고 idiom.\n여러 서적에서 발췌하였으며, 정리 차원에서 작성한 내용이므로 본 글을 처음 접한 사람이 이해하기에 많은 내용을 담지 않을 수 있음.\n어쩌면 작성자의 부사수를 위한 자재가 될지도 모르겠\u0026hellip;(..)\nConcurrent ISSUE - Stack 이번엔 스택.\nif (!s.empty()) { item = s.top(); s.pop(); } 인터페이스상의 문제이기 때문에 empty 와 top 사이의 safety 를 보장할 수 없다.\ntop() / pop() 도 마찬가지 -\u0026raquo; 조회되지 못하는 아이템이 있을 수 있다. (생각해보자.)\n해결을 위해 ?? -\u0026gt; Returning Pop ? \u0026ndash;\u0026raquo; 역시, 생각해보자. (Hint. Exception)\nOptions Reference 호출전 인스턴스 생성 필요. 생성자의 인자가 항상 제공 가능한 경우가 아닐때도.\n그리고 assign 필요. (Q. 이것이 무엇을 의미하는가? - C++ 개발지식이 있다면 대답할 수 있어야 한다.)\nMove Exception 만이 문제라면 이 선택으로 회피 가능할 수 있지 않은가.\n하지만.. 위와 마찬가지. (Q. 역시, 대답할 수 있어야 한다. )\nPointer 유저에게 메모리 관리 작업을 맡기는 것. (Q. 이게 문제라면, 어떻게 해결할 수 있겠는가?) 간단한 타입에 대해서는 오버헤드.\nCompounded Options 말그대로, 결합.\n끝\n","permalink":"https://nolleh.github.io/concurrency/concurrent-idiom-1-stack/","summary":"concurrent 프로그램을 작성할 때 고려해야할 몇가지 사항. 그리고 idiom.\n여러 서적에서 발췌하였으며, 정리 차원에서 작성한 내용이므로 본 글을 처음 접한 사람이 이해하기에 많은 내용을 담지 않을 수 있음.\n어쩌면 작성자의 부사수를 위한 자재가 될지도 모르겠\u0026hellip;(..)\nConcurrent ISSUE - Stack 이번엔 스택.\nif (!s.empty()) { item = s.top(); s.pop(); } 인터페이스상의 문제이기 때문에 empty 와 top 사이의 safety 를 보장할 수 없다.\ntop() / pop() 도 마찬가지 -\u0026raquo; 조회되지 못하는 아이템이 있을 수 있다.","title":"Concurrent Idiom 1 - Stack"},{"content":"GitHub-Page 이런게 있다더라 ~ 라고 주변으로부터 처음 들은건 1~2년전이었던것 같은데\n갑자기 꽂혀서 git page 를 만들었다. (!!)\ngithub 에서는 1계정당 1 호스트를 제공하는 것 같고\n\u0026lt;ID\u0026gt;.github.io 뭐 이런식? github 의 제공 영역은 repo 에 존재하는 index.html 을 repo 에 지정된 1 도메인과\n연결해주는 정도인 것 같다.\nRepository git 을 사용해 본 적이 있다면 간단하다.\n그렇다면 다음 절로 넘어가고, 그렇지 않다면, 다음을 따라하자.\ngithub 가입 이 항목에 있어 더 이상의 자세한 설명은 생략한다.\ngithub\nsshKey 여기를 따라하자.\ngithub-gen-sshkey\ngithub repo 생성 github 본인 메인 페이지에서 Repositories New 버튼 안내에 따라 따라하기 즉, 로컬의 git repo 대상 폴더에서 git init git add -A git commit -m \u0026ldquo;some-message\u0026rdquo; git remote add origin git@github.com:/.git git push -u origin master 이제 github 에 repository 를 올릴수 있게 되었다!\n내 Repo 를 GithubPage 로 지정하기 본 repo 에서 .github.com 의 index.html 을 찾도록 github 에 알려주자.\nMarkDown-To-HTML 잘은 모르겠지만.. github 페이지에서는 유독 MarkDown 을 통해\nhtml 을 작성하는게 잘 권장? 되어있는거 같고,\n아마도 git page 의 최초 제공 목적 자체가 블로그가 아니라 위키 정리와 같은 마크업 언어로 간단하게 문서를 작성하는 데에 있었기 때문일거다 - jekyll 이나 hugo 를 통해 MarkDown 으로 작성된 문서를 자동으로 html 로 생성할 수 있다.\nHugo 사실 jekyll 을 많이들 쓰고 있는 것 같고 공식적으로 지원? 하는 것 같은데 내 맥 PC 의 버전으로 ruby 가 잘 설치가 안되서 괴로워하던 중에 지인이 hugo 를 사용하는 것을 보고 그냥 hugo 를 선택했다. 나름 괜찮은 듯.\n공식 가이드는 다음을 살펴보면 되고,\nQuick-Start\n내가 따라가면서 확인한 주요한 내용은 다음과 같다.\nHugo OneStep # 휴고 설치 $ brew install hugo # 사이트 생성 this/is/my/github/repo$ hugo new site # 포스트 생성 this/is/my/github/repo$ hugo new post/hello-world.md # 포스트 수정 this/is/my/github/repo$ vim content/post/hello-world.md # 로컬에서 확인하기 this/is/my/github/repo$ hugo server ## http://localhost:1313 에서 확인 Hugo - 사이트 꾸미기 hugo 가 올바르게 generate 하기 위한 설정 값 지정 this/is/my/github/repo$ vim config.toml ### .... config.toml baseurl = \u0026#34;https://nolleh.github.io\u0026#34; languageCode = \u0026#34;ko-KR\u0026#34; title = \u0026#34;The Computer Programmer, Nolleh\u0026#34; theme = \u0026#34;hello-programmer\u0026#34; Paginate = 2 # the number of posts per page disqusShortname = \u0026#34;your-disqus-short-name\u0026#34; [params] author = \u0026#34;nolleh\u0026#34; locale = \u0026#34;ko-KR\u0026#34; hugo 의 테마 페이지를 예쁘게 구성하기 위해, 많은 개발자들이 오픈소스로 공개한 테마를 활용할 수 있다.\nHugo-Theme-ShowCase All-Themes-Github 1 에서 각 테마의 섬네일을,\n2 에서 각 테마의 repository 를 확인하여 clone 받을 수 있다.\n본인의 gitpage repo root/themes 로 이동하여 2의 repo 를 clone, 위에서 기술한 config.toml 의 theme 항목을 지정하는 것으로 테마를 변경 할 수 있다.\nHugo - Generate 휴고 명령어를 통해 html 파일을 generate 한다. 기본적으로 public 폴더에 데이터가 생성되므로, 해당 repo 를 submodule 로 github page 에 연결해두어도 괜찮다. 즉, 이런 느낌\n---- hugo contents repo (git@github.com:nolleh/nolleh.github.io-hugo) | |----- content | |---- my-posts... | |----- @public (git@github.com:nolleh/nolleh.github.io) 실행은 다음과 같은 휴고 명령어를 사용한다.\n@DEPRECATED\n$ sudo hugo server --baseUrl=https://nolleh.github.io --destination=public/ --port=80 --appendPort=false edited. 휴고 특정버전(?)부터, 다음과 같이 generate 하도록 변경되었다.\n-D 옵션은 draft (작성중) 파일의 포함 여부.\n$ hugo -D Deploy Generate 할때, destination 을 public 으로 지정하였으므로 public 디렉토리에 생성된다. 이 폴더 전체를 다시 github repo 를 생성해서 올려두자.\nthis/is/my/github/repo/public$ git init this/is/my/github/repo/public$ git add -A this/is/my/github/repo/public$ git commit -m \u0026#34;my awesome site\u0026#34; this/is/my/github/repo/public$ git push ... 끝!\n","permalink":"https://nolleh.github.io/env/how-to-make-git-page/","summary":"GitHub-Page 이런게 있다더라 ~ 라고 주변으로부터 처음 들은건 1~2년전이었던것 같은데\n갑자기 꽂혀서 git page 를 만들었다. (!!)\ngithub 에서는 1계정당 1 호스트를 제공하는 것 같고\n\u0026lt;ID\u0026gt;.github.io 뭐 이런식? github 의 제공 영역은 repo 에 존재하는 index.html 을 repo 에 지정된 1 도메인과\n연결해주는 정도인 것 같다.\nRepository git 을 사용해 본 적이 있다면 간단하다.\n그렇다면 다음 절로 넘어가고, 그렇지 않다면, 다음을 따라하자.\ngithub 가입 이 항목에 있어 더 이상의 자세한 설명은 생략한다.","title":"How To Make Git Page"},{"content":"Let\u0026rsquo;s 사족 처음 회사에 입사 했을 때 자리에는 Mac PC 만이 덩그러니 있었고, Mac 을 사용해본적 없던 꼬꼬마는 자연스럽게 윈도우 CD 를 인사팀에서 받아와서 깔고 있었드랬다.\n\u0026ldquo;기껏 좋은 컴퓨터 줬더니 넌 뭘하고 있는거니?\u0026rdquo;\n라는 선배의 말을 듣고 그제야 맥에서도 안드로이드 개발이 되는거구나.. (이때는 현업 안드로이드 개발자였다.)\n하곤 윈도우 설치페이지를 취소하고 다시 맥 OS 를 부팅했었지.\n이때가, Mac OS 와의 첫 만남이었드랬다.\nBrew 뭐 전혀 관계 없는 얘기로 포스트를 열었지만.\n어쨌거나 그때부터 Mac 을 수년간 사용하면서 - 그때 쓰던 회사 Mac 은 여전히 내 사무실 책상의 한켠을 차지하고 있다 -\nMac 을 비롯한 Linux 계통에서 Windows 를 압도하는 장점을 들자면,\n개발자를 위한 환경 설정이 간편하다\n가 되겠다.\nMac 에서는 그 역할을 충실히 하는 요소 중에 하나가 \u0026ldquo;HomeBrew\u0026rdquo; 라 하겠고.\n[HomeBrew] (http://docs.brew.sh/)\nBrew 설치 다음 라인을 터미널에서 실행하자. brew 설치 자체도 이렇게 간편하다니.. Linux 계통은 보통 이렇게 one line 으로 다 해결이 된다.\nmkdir homebrew \u0026amp;\u0026amp; curl -L https://github.com/Homebrew/brew/tarball/master | tar xz --strip 1 -C homebrew Brew 를 통해 설치하기 Formula 라고 지칭하고 있는게 맞는지는 잘 모르겠지만.\nbrew 를 통해 프로그램/binary 를 설치할 경우 다음과 같이 실행\n최초 설치 $ Brew install ${Formula} 업데이트 $ Brew upgrade ${Formula} Brew Install 이 구 버전만 다운로드 받을 때 이건.. 맥을 사용한 지금까지 잘 모르고 있었던 건데,\nBrew 자체를 업데이트해서 formular 를 갱신할 필요가 있나보다.\n다음을 통한다.\n$ Brew update 업데이트시 다음 에러 노출시 $ Error: /usr/local must be writable! 다음 실행\nsudo chown -R $(whoami) /usr/local ","permalink":"https://nolleh.github.io/env/brew-update/","summary":"Let\u0026rsquo;s 사족 처음 회사에 입사 했을 때 자리에는 Mac PC 만이 덩그러니 있었고, Mac 을 사용해본적 없던 꼬꼬마는 자연스럽게 윈도우 CD 를 인사팀에서 받아와서 깔고 있었드랬다.\n\u0026ldquo;기껏 좋은 컴퓨터 줬더니 넌 뭘하고 있는거니?\u0026rdquo;\n라는 선배의 말을 듣고 그제야 맥에서도 안드로이드 개발이 되는거구나.. (이때는 현업 안드로이드 개발자였다.)\n하곤 윈도우 설치페이지를 취소하고 다시 맥 OS 를 부팅했었지.\n이때가, Mac OS 와의 첫 만남이었드랬다.\nBrew 뭐 전혀 관계 없는 얘기로 포스트를 열었지만.\n어쨌거나 그때부터 Mac 을 수년간 사용하면서 - 그때 쓰던 회사 Mac 은 여전히 내 사무실 책상의 한켠을 차지하고 있다 -","title":"Brew Install 이 구버전만 설치할 때"},{"content":"마크다운으로 포스팅하는 Git 페이지를 생성하였으니, 자주 사용되는 대표 문법 정리\n마크다운 문법\nHeading \u0026lsquo;#\u0026rsquo; 으로 처리하며, 단계별로 더 많은 \u0026lsquo;#\u0026rsquo; 을 사용한다.\n# Title ## Heading 1 ### Heading 2 결과\nTitle Heading 1 Heading 2 Listing Asterisk (*) 를 사용하여 순서 없는 목록을, 숫자를 사용하여 순서 있는 목록을 나타낸다.\n순서 없는 경우 이거닷 이거 중요해! 순서가 있는 경우 첫번째 순서 두번째~ 셋!! Fonts **Bold** _Italic_ ~~CANCEL_LINE~~ Bold Italic CANCEL_LINE\nSRC ![Alt](경로 \u0026#34;Optional Tooltip MSG\u0026#34;) TABLE | Day | Meal | Price | | --------|---------|-------| | Monday | pasta | $6 | | Tuesday | chicken | $8 | Day Meal Price Monday pasta $6 Tuesday chicken $8 ","permalink":"https://nolleh.github.io/env/mark-down-syntax/","summary":"마크다운으로 포스팅하는 Git 페이지를 생성하였으니, 자주 사용되는 대표 문법 정리\n마크다운 문법\nHeading \u0026lsquo;#\u0026rsquo; 으로 처리하며, 단계별로 더 많은 \u0026lsquo;#\u0026rsquo; 을 사용한다.\n# Title ## Heading 1 ### Heading 2 결과\nTitle Heading 1 Heading 2 Listing Asterisk (*) 를 사용하여 순서 없는 목록을, 숫자를 사용하여 순서 있는 목록을 나타낸다.\n순서 없는 경우 이거닷 이거 중요해! 순서가 있는 경우 첫번째 순서 두번째~ 셋!! Fonts **Bold** _Italic_ ~~CANCEL_LINE~~ Bold Italic CANCEL_LINE","title":"markDown 문법"},{"content":"파라미터가 없다면 DelegateToPointer 로 마샬링해서 전달하면되는데,\n이러면 파라미터를 마샬링할 기회가 주어지지 않는다는게 문제다.\n좀 구글링을 해봤는데,\n이런 포스트가 있었다.\n스택오버플로-파라미터와 함께 unmanaged 콜백으로 변환하기\n채택된 답변을 살펴보면 클래스 구조는 대략 다음과 같다.\n클래스 구조 NativeCallbackHandler - msclr::gcroot\u0026lt;OutputManaged^\u0026gt; m_owner (OutputLogManaged) 를 멤버로 보유. OutputLogManaged - native OutputLog* (m_nativeOutputLog) / 1의 Holder 를 보유 (m_nativeHandler)] / 그리고 managed 콜백을 보유 OutputLog - Native Callback 과 void* UserData 를 멤버로 보유. 이해하는데 주요한 클래스는 위 내용 정도인 듯.\nMain 함수에서는 managed 로거와 native 에 적당한 콜백을 등록해 두고(OnError/GetNative()), Test 함수를 통해 콜백을 호출한다.\nOutputLogManaged 에는 생성시에 1의 NativeCallbackHandler 가 생성되며 여기에 정의된 native callback 을 OutputLog 의 Callback 멤버변수에 세팅한다. 동시에 NativeCallbackHandler 를 this 로 해서 함께 UserData 라는 객체로 OutputLog 의 멤버로 등록을 한 상태이다.\n(다시 말해 OutputLog 의 UserData 에는 1의 인스턴스가, 같은 객체의 멤버 변수인 NativeCallback 타입에는 그 인스턴스의 함수가 등록이 되어있다.)\n1의 콜백을 지닌 3 의 객체의 함수를 등록해두었고, 이 함수에서 1의 콜백을 호출하고 있으므로 1의 콜백이 호출이 되는데 (등록해두었던 umanaged 콜백이 호출되는 단순한 전개라 하겠다.)\n이때 OutputLog(3) 의 객체의 멤버함수(최초로 호출되는 콜백)에서 멤버변수로 보유한 NativeCallbackHandler(1) 객체를 1의 콜백의 파라미터로 전달, 콜백 등록 당시의 NativeCallbackHandler(1) 의 인스턴스를 얻어온다 (물론, 콜백을 여러개 등록할 수 있으므로. 각 인스턴스를 별도로 두는 것이 자연스럽다.)\n이 인스턴스의 멤버인 m_owner 를 통해 OutputLogManaged 의 managed 콜백을 호출한다.\n내용을 말로 설명하려고하니 불필요하게 복잡해진 느낌인데,\n정리하면 다음과 같다.\nSummary unmanged 에서 Managed 의 객체를 들고 있다가 unmanaged 의 콜백이 호출될때 마샬링하여 Managed 의 콜백을 호출한다.\nC++/CLR 을 처음 접하고 필요에 따라 구글링으로 작업을 하다보니 managed 와 unmanged 사이에서 서로 멤버로 두려고 하면 컴파일 에러가 나길래 안되는 거구나..했는데.. 이런 기능이 있었나보다\u0026hellip;\nmsclr::gcroot\u0026lt;...\u0026gt; gcroot 는 unmanaged 에서 managed 를 참조하는 방법이며, interop 에서는 레퍼런스 카운트를 하나 증가시킨다.\n참고 - gcroot 의 역할\n약간 허무하군.. (그래 안되면 어떻게 쓰겠냐만서도.. )\n참고 - MSDN / How to: Declare Handles in Native Types\n","permalink":"https://nolleh.github.io/etc/managed_cb_to_unmanaged/","summary":"파라미터가 없다면 DelegateToPointer 로 마샬링해서 전달하면되는데,\n이러면 파라미터를 마샬링할 기회가 주어지지 않는다는게 문제다.\n좀 구글링을 해봤는데,\n이런 포스트가 있었다.\n스택오버플로-파라미터와 함께 unmanaged 콜백으로 변환하기\n채택된 답변을 살펴보면 클래스 구조는 대략 다음과 같다.\n클래스 구조 NativeCallbackHandler - msclr::gcroot\u0026lt;OutputManaged^\u0026gt; m_owner (OutputLogManaged) 를 멤버로 보유. OutputLogManaged - native OutputLog* (m_nativeOutputLog) / 1의 Holder 를 보유 (m_nativeHandler)] / 그리고 managed 콜백을 보유 OutputLog - Native Callback 과 void* UserData 를 멤버로 보유. 이해하는데 주요한 클래스는 위 내용 정도인 듯.","title":"C++ CLI 에서 managed 콜백을 unmanaged 로 전달하기"}]